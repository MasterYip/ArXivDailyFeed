<!DOCTYPE html>
<html lang="en">

<head>
    <title>ArXivDailyFeed</title>
    <meta charset="utf-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="robots" content="noindex, nofollow"/>
    <meta name="viewport" content="width=device-width, initial-scale=1"/>
    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
    <link href="index.css" rel="stylesheet"/>
    <link href="https://cdn.jsdelivr.net/npm/remixicon@2.5.0/fonts/remixicon.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"
          integrity="sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"
          integrity="sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs" crossorigin="anonymous">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"
            integrity="sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx"
            crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js"
            integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR"
            crossorigin="anonymous"></script>
    <script>
        document.addEventListener("DOMContentLoaded", function () {
            renderMathInElement(document.body, {
                // customised options
                // • auto-render specific keys, e.g.:
                delimiters: [
                    {left: '$$', right: '$$', display: true},
                    {left: '$', right: '$', display: false},
                    {left: '\\(', right: '\\)', display: false},
                    {left: '\\[', right: '\\]', display: true},
                    {left: "\\begin{equation}", right: "\\end{equation}", display: true},
                    {left: "\\begin{align}", right: "\\end{align}", display: true},
                    {left: "\\begin{alignat}", right: "\\end{alignat}", display: true},
                    {left: "\\begin{gather}", right: "\\end{gather}", display: true},
                    {left: "\\begin{CD}", right: "\\end{CD}", display: true},
                ],
                // • rendering keys, e.g.:
                throwOnError: false
            });
        });
    </script>
</head>

<body>
<section class="header-container">
    <div style="display:flex; justify-content:space-between; align-items:flex-end;">
        <div>
            <div class="header-title">
                MyArxiv
            </div>
        </div>

        <div class=icons>
            <label class="theme-switch" for="checkbox">
                <input type="checkbox" id="checkbox"/>
                <i id="theme-icon" class="ri-moon-line" style="font-size: 32px" rel="noopener noreferrer"></i>
            </label>
        </div>
    </div>
</section>

    <section class="day-container">
        <div class="date">
            <time datetime="2025-03-13T00:00:00Z">2025-03-13</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Robotics <span class="chip" style="font-size: 60%">56</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         <span class="highlight-title">★</span> HybridVLA: Collaborative Diffusion and Autoregression in a Unified
  Vision-Language-Action Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10631v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10631v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jia<span class="highlight-author">ming Liu</span>, Hao Chen, Pengju An, Zhuoyang Liu, Renrui Zhang, Chenyang Gu, Xiaoqi Li, Ziyu Guo, Sixiang Chen, Mengzhen Liu, Chengkai Hou, Mengdi Zhao, KC alex Zhou, Pheng-Ann Heng, Shanghang Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in vision-language models (VLMs) for common-sense
reasoning have led to the development of vision-language-action (VLA) models,
enabling robots to perform generalized manipulation. Although existing
autoregressive VLA methods leverage large-scale pretrained knowledge, they
disrupt the continuity of actions. Meanwhile, some VLA methods incorporate an
additional diffusion head to predict continuous actions, relying solely on
VLM-extracted features, which limits their reasoning capabilities. In this
paper, we introduce HybridVLA, a unified framework that seamlessly integrates
the strengths of both autoregressive and diffusion policies within a single
large language model, rather than simply connecting them. To bridge the
generation gap, a collaborative training recipe is proposed that injects the
diffusion modeling directly into the next-token prediction. With this recipe,
we find that these two forms of action prediction not only reinforce each other
but also exhibit varying performance across different tasks. Therefore, we
design a collaborative action ensemble mechanism that adaptively fuses these
two predictions, leading to more robust control. In experiments, HybridVLA
outperforms previous state-of-the-art VLA methods across various simulation and
real-world tasks, including both single-arm and dual-arm robots, while
demonstrating stable manipulation in previously unseen configurations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ UniGoal: Towards Universal Zero-shot Goal-oriented <span class="highlight-title">Navigation</span> <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10630v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10630v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hang Yin, Xiuwei Xu, Lingqing Zhao, Ziwei Wang, Jie Zhou, Jiwen Lu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we propose a general framework for universal zero-shot
goal-oriented navigation. Existing zero-shot methods build inference framework
upon large language models (LLM) for specific tasks, which differs a lot in
overall pipeline and fails to generalize across different types of goal.
Towards the aim of universal zero-shot navigation, we propose a uniform graph
representation to unify different goals, including object category, instance
image and text description. We also convert the observation of agent into an
online maintained scene graph. With this consistent scene and goal
representation, we preserve most structural information compared with pure text
and are able to leverage LLM for explicit graph-based reasoning. Specifically,
we conduct graph matching between the scene graph and goal graph at each time
instant and propose different strategies to generate long-term goal of
exploration according to different matching states. The agent first iteratively
searches subgraph of goal when zero-matched. With partial matching, the agent
then utilizes coordinate projection and anchor pair alignment to infer the goal
location. Finally scene graph correction and goal verification are applied for
perfect matching. We also present a blacklist mechanism to enable robust switch
between stages. Extensive experiments on several benchmarks show that our
UniGoal achieves state-of-the-art zero-shot performance on three studied
navigation tasks with a single model, even outperforming task-specific
zero-shot methods and supervised universal methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to CVPR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ NIL: No-data Imitation Learning by Leveraging Pre-trained Video
  Diffusion Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10626v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10626v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mert Albaba, Chenhao Li, Markos Diomataris, Omid Taheri, Andreas Krause, Michael Black
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Acquiring physically plausible motor skills across diverse and unconventional
morphologies-including humanoid robots, quadrupeds, and animals-is essential
for advancing character simulation and robotics. Traditional methods, such as
reinforcement learning (RL) are task- and body-specific, require extensive
reward function engineering, and do not generalize well. Imitation learning
offers an alternative but relies heavily on high-quality expert demonstrations,
which are difficult to obtain for non-human morphologies. Video diffusion
models, on the other hand, are capable of generating realistic videos of
various morphologies, from humans to ants. Leveraging this capability, we
propose a data-independent approach for skill acquisition that learns 3D motor
skills from 2D-generated videos, with generalization capability to
unconventional and non-human forms. Specifically, we guide the imitation
learning process by leveraging vision transformers for video-based comparisons
by calculating pair-wise distance between video embeddings. Along with
video-encoding distance, we also use a computed similarity between segmented
video frames as a guidance reward. We validate our method on locomotion tasks
involving unique body configurations. In humanoid robot locomotion tasks, we
demonstrate that 'No-data Imitation Learning' (NIL) outperforms baselines
trained on 3D motion-capture data. Our results highlight the potential of
leveraging generative video models for physically plausible skill learning with
diverse morphologies, effectively replacing data collection with data
generation for imitation learning.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DriveLMM-o1: A Step-by-Step Reasoning Dataset and Large Multimodal Model
  for Driving Scenario Understanding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10621v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10621v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ayesha Ishaq, Jean Lahoud, Ketan More, Omkar Thawakar, Ritesh Thawkar, Dinura Dissanayake, Noor Ahsan, Yuhao Li, Fahad Shahbaz Khan, Hisham Cholakkal, Ivan Laptev, Rao Muhammad Anwer, Salman Khan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While large multimodal models (LMMs) have demonstrated strong performance
across various Visual Question Answering (VQA) tasks, certain challenges
require complex multi-step reasoning to reach accurate answers. One
particularly challenging task is autonomous driving, which demands thorough
cognitive processing before decisions can be made. In this domain, a sequential
and interpretive understanding of visual cues is essential for effective
perception, prediction, and planning. Nevertheless, common VQA benchmarks often
focus on the accuracy of the final answer while overlooking the reasoning
process that enables the generation of accurate responses. Moreover, existing
methods lack a comprehensive framework for evaluating step-by-step reasoning in
realistic driving scenarios. To address this gap, we propose DriveLMM-o1, a new
dataset and benchmark specifically designed to advance step-wise visual
reasoning for autonomous driving. Our benchmark features over 18k VQA examples
in the training set and more than 4k in the test set, covering diverse
questions on perception, prediction, and planning, each enriched with
step-by-step reasoning to ensure logical inference in autonomous driving
scenarios. We further introduce a large multimodal model that is fine-tuned on
our reasoning dataset, demonstrating robust performance in complex driving
scenarios. In addition, we benchmark various open-source and closed-source
methods on our proposed dataset, systematically comparing their reasoning
capabilities for autonomous driving tasks. Our model achieves a +7.49% gain in
final answer accuracy, along with a 3.62% improvement in reasoning score over
the previous best open-source model. Our framework, dataset, and model are
available at https://github.com/ayesha-ishaq/DriveLMM-o1.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 4 figures, 3 tables, github:
  https://github.com/ayesha-ishaq/DriveLMM-o1</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Safe Path Tracking Using the Simplex Architecture 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10559v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10559v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Georg Jäger, Nils-Jonathan Friedrich, Hauke Petersen, Benjamin Noack
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Robot navigation in complex environments necessitates controllers that are
adaptive and safe. Traditional controllers like Regulated Pure Pursuit, Dynamic
Window Approach, and Model-Predictive Path Integral, while reliable, struggle
to adapt to dynamic conditions. Reinforcement Learning offers adaptability but
lacks formal safety guarantees. To address this, we propose a path tracking
controller leveraging the Simplex architecture. It combines a Reinforcement
Learning controller for adaptiveness and performance with a high-assurance
controller providing safety and stability. Our contribution is twofold. We
firstly discuss general stability and safety considerations for designing
controllers using the Simplex architecture. Secondly, we present a
Simplex-based path tracking controller. Our simulation results, supported by
preliminary in-field tests, demonstrate the controller's effectiveness in
maintaining safety while achieving comparable performance to state-of-the-art
methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ NuExo: A Wearable Exoskeleton Covering all Upper Limb ROM for Outdoor
  Data Collection and Teleoperation of Humanoid Robots 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10554v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10554v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rui Zhong, Chuang Cheng, Junpeng Xu, Yantong Wei, Ce Guo, Daoxun Zhang, Wei Dai, Huimin Lu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The evolution from motion capture and teleoperation to robot skill learning
has emerged as a hotspot and critical pathway for advancing embodied
intelligence. However, existing systems still face a persistent gap in
simultaneously achieving four objectives: accurate tracking of full upper limb
movements over extended durations (Accuracy), ergonomic adaptation to human
biomechanics (Comfort), versatile data collection (e.g., force data) and
compatibility with humanoid robots (Versatility), and lightweight design for
outdoor daily use (Convenience). We present a wearable exoskeleton system,
incorporating user-friendly immersive teleoperation and multi-modal sensing
collection to bridge this gap. Due to the features of a novel shoulder
mechanism with synchronized linkage and timing belt transmission, this system
can adapt well to compound shoulder movements and replicate 100% coverage of
natural upper limb motion ranges. Weighing 5.2 kg, NuExo supports backpack-type
use and can be conveniently applied in daily outdoor scenarios. Furthermore, we
develop a unified intuitive teleoperation framework and a comprehensive data
collection system integrating multi-modal sensing for various humanoid robots.
Experiments across distinct humanoid platforms and different users validate our
exoskeleton's superiority in motion range and flexibility, while confirming its
stability in data collection and teleoperation accuracy in dynamic scenarios.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ KUDA: Keypoints to Unify Dynamics Learning and Visual Prompting for
  Open-Vocabulary Robotic <span class="highlight-title">Manipulation</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10546v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10546v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zixian Liu, Mingtong Zhang, Yunzhu Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the rapid advancement of large language models (LLMs) and
vision-language models (VLMs), significant progress has been made in developing
open-vocabulary robotic manipulation systems. However, many existing approaches
overlook the importance of object dynamics, limiting their applicability to
more complex, dynamic tasks. In this work, we introduce KUDA, an
open-vocabulary manipulation system that integrates dynamics learning and
visual prompting through keypoints, leveraging both VLMs and learning-based
neural dynamics models. Our key insight is that a keypoint-based target
specification is simultaneously interpretable by VLMs and can be efficiently
translated into cost functions for model-based planning. Given language
instructions and visual observations, KUDA first assigns keypoints to the RGB
image and queries the VLM to generate target specifications. These abstract
keypoint-based representations are then converted into cost functions, which
are optimized using a learned dynamics model to produce robotic trajectories.
We evaluate KUDA on a range of manipulation tasks, including free-form language
instructions across diverse object categories, multi-object interactions, and
deformable or granular objects, demonstrating the effectiveness of our
framework. The project page is available at http://kuda-dynamics.github.io.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project website: http://kuda-dynamics.github.io</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Learning Robotic Policy with Imagined Transition: Mitigating the
  Trade-off between Robustness and Optimality 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10484v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10484v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wei Xiao, Shangke Lyu, Zhefei Gong, Renjie Wang, Donglin Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing quadrupedal locomotion learning paradigms usually rely on extensive
domain randomization to alleviate the sim2real gap and enhance robustness. It
trains policies with a wide range of environment parameters and sensor noises
to perform reliably under uncertainty. However, since optimal performance under
ideal conditions often conflicts with the need to handle worst-case scenarios,
there is a trade-off between optimality and robustness. This trade-off forces
the learned policy to prioritize stability in diverse and challenging
conditions over efficiency and accuracy in ideal ones, leading to overly
conservative behaviors that sacrifice peak performance. In this paper, we
propose a two-stage framework that mitigates this trade-off by integrating
policy learning with imagined transitions. This framework enhances the
conventional reinforcement learning (RL) approach by incorporating imagined
transitions as demonstrative inputs. These imagined transitions are derived
from an optimal policy and a dynamics model operating within an idealized
setting. Our findings indicate that this approach significantly mitigates the
domain randomization-induced negative impact of existing RL algorithms. It
leads to accelerated training, reduced tracking errors within the distribution,
and enhanced robustness outside the distribution.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ World Modeling Makes a Better <span class="highlight-title">Plan</span>ner: Dual Preference <span class="highlight-title">Optimization</span> for
  Embodied Task <span class="highlight-title">Plan</span>ning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10480v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10480v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Siyin Wang, Zhaoye Fei, Qinyuan Cheng, Shiduo Zhang, Panpan Cai, Jinlan Fu, Xipeng Qiu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in large vision-language models (LVLMs) have shown promise
for embodied task planning, yet they struggle with fundamental challenges like
dependency constraints and efficiency. Existing approaches either solely
optimize action selection or leverage world models during inference,
overlooking the benefits of learning to model the world as a way to enhance
planning capabilities. We propose Dual Preference Optimization (D$^2$PO), a new
learning framework that jointly optimizes state prediction and action selection
through preference learning, enabling LVLMs to understand environment dynamics
for better planning. To automatically collect trajectories and stepwise
preference data without human annotation, we introduce a tree search mechanism
for extensive exploration via trial-and-error. Extensive experiments on
VoTa-Bench demonstrate that our D$^2$PO-based method significantly outperforms
existing methods and GPT-4o when applied to Qwen2-VL (7B), LLaVA-1.6 (7B), and
LLaMA-3.2 (11B), achieving superior task success rates with more efficient
execution paths.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Stratified Topological Autonomy for Long-Range Coordination (STALC) 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10475v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10475v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Cora A. Dimmig, Adam Goertz, Adam Polevoy, Mark Gonzales, Kevin C. Wolfe, Bradley Woosley, John Rogers, Joseph Moore
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Achieving unified multi-robot coordination and motion planning in complex
environments is a challenging problem. In this paper, we present a hierarchical
approach to long-range coordination, which we call Stratified Topological
Autonomy for Long-Range Coordination (STALC). In particular, we look at the
problem of minimizing visibility to observers and maximizing safety with a
multi-robot team navigating through a hazardous environment. At its core, our
approach relies on the notion of a dynamic topological graph, where the edge
weights vary dynamically based on the locations of the robots in the graph. To
create this dynamic topological graph, we evaluate the visibility of the robot
team from a discrete set of observer locations (both adversarial and friendly),
and construct a topological graph whose edge weights depend on both adversary
position and robot team configuration. We then impose temporal constraints on
the evolution of those edge weights based on robot team state and use
Mixed-Integer Programming (MIP) to generate optimal multirobot plans through
the graph. The visibility information also informs the lower layers of the
autonomy stack to plan minimal visibility paths through the environment for the
team of robots. Our approach presents methods to reduce the computational
complexity for a team of robots that interact and coordinate across the team to
accomplish a common goal. We demonstrate our approach in simulated and hardware
experiments in forested and urban environments.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This work has been submitted to the IEEE for possible publication.
  arXiv admin note: text overlap with arXiv:2303.11966</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Finetuning Generative Trajectory Model with Reinforcement Learning from
  Human Feedback 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10434v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10434v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Derun Li, Jianwei Ren, Yue Wang, Xin Wen, Pengxiang Li, Leimeng Xu, Kun Zhan, Zhongpu Xia, Peng Jia, Xianpeng Lang, Ningyi Xu, Hang Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generating human-like and adaptive trajectories is essential for autonomous
driving in dynamic environments. While generative models have shown promise in
synthesizing feasible trajectories, they often fail to capture the nuanced
variability of human driving styles due to dataset biases and distributional
shifts. To address this, we introduce TrajHF, a human feedback-driven
finetuning framework for generative trajectory models, designed to align motion
planning with diverse driving preferences. TrajHF incorporates
multi-conditional denoiser and reinforcement learning with human feedback to
refine multi-modal trajectory generation beyond conventional imitation
learning. This enables better alignment with human driving preferences while
maintaining safety and feasibility constraints. TrajHF achieves PDMS of 93.95
on NavSim benchmark, significantly exceeding other methods. TrajHF sets a new
paradigm for personalized and adaptable trajectory generation in autonomous
driving.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A nonlinear real time capable motion cueing algorithm based on deep
  reinforcement learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10419v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10419v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hendrik Scheidel, Camilo Gonzalez, Houshyar Asadi, Tobias Bellmann, Andreas Seefried, Shady Mohamed, Saeid Nahavandi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In motion simulation, motion cueing algorithms are used for the trajectory
planning of the motion simulator platform, where workspace limitations prevent
direct reproduction of reference trajectories. Strategies such as motion
washout, which return the platform to its center, are crucial in these
settings. For serial robotic MSPs with highly nonlinear workspaces, it is
essential to maximize the efficient utilization of the MSPs kinematic and
dynamic capabilities. Traditional approaches, including classical washout
filtering and linear model predictive control, fail to consider
platform-specific, nonlinear properties, while nonlinear model predictive
control, though comprehensive, imposes high computational demands that hinder
real-time, pilot-in-the-loop application without further simplification. To
overcome these limitations, we introduce a novel approach using deep
reinforcement learning for motion cueing, demonstrated here for the first time
in a 6-degree-of-freedom setting with full consideration of the MSPs kinematic
nonlinearities. Previous work by the authors successfully demonstrated the
application of DRL to a simplified 2-DOF setup, which did not consider
kinematic or dynamic constraints. This approach has been extended to all 6 DOF
by incorporating a complete kinematic model of the MSP into the algorithm, a
crucial step for enabling its application on a real motion simulator. The
training of the DRL-MCA is based on Proximal Policy Optimization in an
actor-critic implementation combined with an automated hyperparameter
optimization. After detailing the necessary training framework and the
algorithm itself, we provide a comprehensive validation, demonstrating that the
DRL MCA achieves competitive performance against established algorithms.
Moreover, it generates feasible trajectories by respecting all system
constraints and meets all real-time requirements with low...
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Compliant Control of Quadruped Robots for Assistive Load Carrying 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10401v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10401v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nimesh Khandelwal, Amritanshu Manu, Shakti S. Gupta, Mangal Kothari, Prashanth Krishnamurthy, Farshad Khorrami
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents a novel method for assistive load carrying using
quadruped robots. The controller uses proprioceptive sensor data to estimate
external base wrench, that is used for precise control of the robot's
acceleration during payload transport. The acceleration is controlled using a
combination of admittance control and Control Barrier Function (CBF) based
quadratic program (QP). The proposed controller rejects disturbances and
maintains consistent performance under varying load conditions. Additionally,
the built-in CBF guarantees collision avoidance with the collaborative agent in
front of the robot. The efficacy of the overall controller is shown by its
implementation on the physical hardware as well as numerical simulations. The
proposed control framework aims to enhance the quadruped robot's ability to
perform assistive tasks in various scenarios, from industrial applications to
search and rescue operations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 20 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LUMOS: Language-Conditioned Imitation Learning with World Models <span class="chip">ICRA</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10370v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10370v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Iman Nematollahi, Branton DeMoss, Akshay L Chandra, Nick Hawes, Wolfram Burgard, Ingmar Posner
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce LUMOS, a language-conditioned multi-task imitation learning
framework for robotics. LUMOS learns skills by practicing them over many
long-horizon rollouts in the latent space of a learned world model and
transfers these skills zero-shot to a real robot. By learning on-policy in the
latent space of the learned world model, our algorithm mitigates policy-induced
distribution shift which most offline imitation learning methods suffer from.
LUMOS learns from unstructured play data with fewer than 1% hindsight language
annotations but is steerable with language commands at test time. We achieve
this coherent long-horizon performance by combining latent planning with both
image- and language-based hindsight goal relabeling during training, and by
optimizing an intrinsic reward defined in the latent space of the world model
over multiple time steps, effectively reducing covariate shift. In experiments
on the difficult long-horizon CALVIN benchmark, LUMOS outperforms prior
learning-based methods with comparable approaches on chained multi-task
evaluations. To the best of our knowledge, we are the first to learn a
language-conditioned continuous visuomotor control for a real-world robot
within an offline world model. Videos, dataset and code are available at
http://lumos.cs.uni-freiburg.de.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at the 2025 IEEE International Conference on Robotics and
  Automation (ICRA)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Autonomous Robotic Radio Source Localization via a Novel Gaussian
  Mixture Filtering Approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10349v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10349v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sukkeun Kim, Sangwoo Moon, Ivan Petrunin, Hyo-Sang Shin, Shehryar Khattak
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study proposes a new Gaussian Mixture Filter (GMF) to improve the
estimation performance for the autonomous robotic radio signal source search
and localization problem in unknown environments. The proposed filter is first
tested with a benchmark numerical problem to validate the performance with
other state-of-practice approaches such as Particle Gaussian Mixture (PGM)
filters and Particle Filter (PF). Then the proposed approach is tested and
compared against PF and PGM filters in real-world robotic field experiments to
validate its impact for real-world robotic applications. The considered
real-world scenarios have partial observability with the range-only measurement
and uncertainty with the measurement model. The results show that the proposed
filter can handle this partial observability effectively whilst showing
improved performance compared to PF, reducing the computation requirements
while demonstrating improved robustness over compared techniques.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HALO: Fault-Tolerant Safety Architecture For High-Speed Autonomous
  Racing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10341v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10341v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aron Harder, Amar Kulkarni, Madhur Behl
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The field of high-speed autonomous racing has seen significant advances in
recent years, with the rise of competitions such as RoboRace and the Indy
Autonomous Challenge providing a platform for researchers to develop software
stacks for autonomous race vehicles capable of reaching speeds in excess of 170
mph. Ensuring the safety of these vehicles requires the software to
continuously monitor for different faults and erroneous operating conditions
during high-speed operation, with the goal of mitigating any unreasonable risks
posed by malfunctions in sub-systems and components. This paper presents a
comprehensive overview of the HALO safety architecture, which has been
implemented on a full-scale autonomous racing vehicle as part of the Indy
Autonomous Challenge. The paper begins with a failure mode and criticality
analysis of the perception, planning, control, and communication modules of the
software stack. Specifically, we examine three different types of faults - node
health, data health, and behavioral-safety faults. To mitigate these faults,
the paper then outlines HALO safety archetypes and runtime monitoring methods.
Finally, the paper demonstrates the effectiveness of the HALO safety
architecture for each of the faults, through real-world data gathered from
autonomous racing vehicle trials during multi-agent scenarios.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>27 pages, 7 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhanced View <span class="highlight-title">Plan</span>ning for Robotic Harvesting: Tackling Occlusions with
  Imitation Learning <span class="chip">ICRA 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10334v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10334v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lun Li, Hamidreza Kasaei
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In agricultural automation, inherent occlusion presents a major challenge for
robotic harvesting. We propose a novel imitation learning-based viewpoint
planning approach to actively adjust camera viewpoint and capture unobstructed
images of the target crop. Traditional viewpoint planners and existing
learning-based methods, depend on manually designed evaluation metrics or
reward functions, often struggle to generalize to complex, unseen scenarios.
Our method employs the Action Chunking with Transformer (ACT) algorithm to
learn effective camera motion policies from expert demonstrations. This enables
continuous six-degree-of-freedom (6-DoF) viewpoint adjustments that are
smoother, more precise and reveal occluded targets. Extensive experiments in
both simulated and real-world environments, featuring agricultural scenarios
and a 6-DoF robot arm equipped with an RGB-D camera, demonstrate our method's
superior success rate and efficiency, especially in complex occlusion
conditions, as well as its ability to generalize across different crops without
reprogramming. This study advances robotic harvesting by providing a practical
"learn from demonstration" (LfD) solution to occlusion challenges, ultimately
enhancing autonomous harvesting performance and productivity.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at ICRA 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ OSMa-Bench: Evaluating Open Semantic Mapping Under Varying Lighting
  Conditions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10331v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10331v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Maxim Popov, Regina Kurkova, Mikhail Iumanov, Jaafar Mahmoud, Sergey Kolyubin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Open Semantic Mapping (OSM) is a key technology in robotic perception,
combining semantic segmentation and SLAM techniques. This paper introduces a
dynamically configurable and highly automated LLM/LVLM-powered pipeline for
evaluating OSM solutions called OSMa-Bench (Open Semantic Mapping Benchmark).
The study focuses on evaluating state-of-the-art semantic mapping algorithms
under varying indoor lighting conditions, a critical challenge in indoor
environments. We introduce a novel dataset with simulated RGB-D sequences and
ground truth 3D reconstructions, facilitating the rigorous analysis of mapping
performance across different lighting conditions. Through experiments on
leading models such as ConceptGraphs, BBQ and OpenScene, we evaluate the
semantic fidelity of object recognition and segmentation. Additionally, we
introduce a Scene Graph evaluation method to analyze the ability of models to
interpret semantic structure. The results provide insights into the robustness
of these models, forming future research directions for developing resilient
and adaptable robotic systems. Our code is available at
https://be2rlab.github.io/OSMa-Bench/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project page: https://be2rlab.github.io/OSMa-Bench/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ 6D Object Pose Tracking in Internet Videos for Robotic <span class="highlight-title">Manipulation</span> <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10307v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10307v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Georgy Ponimatkin, Martin Cífka, Tomáš Souček, Médéric Fourmy, Yann Labbé, Vladimir Petrik, Josef Sivic
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We seek to extract a temporally consistent 6D pose trajectory of a
manipulated object from an Internet instructional video. This is a challenging
set-up for current 6D pose estimation methods due to uncontrolled capturing
conditions, subtle but dynamic object motions, and the fact that the exact mesh
of the manipulated object is not known. To address these challenges, we present
the following contributions. First, we develop a new method that estimates the
6D pose of any object in the input image without prior knowledge of the object
itself. The method proceeds by (i) retrieving a CAD model similar to the
depicted object from a large-scale model database, (ii) 6D aligning the
retrieved CAD model with the input image, and (iii) grounding the absolute
scale of the object with respect to the scene. Second, we extract smooth 6D
object trajectories from Internet videos by carefully tracking the detected
objects across video frames. The extracted object trajectories are then
retargeted via trajectory optimization into the configuration space of a
robotic manipulator. Third, we thoroughly evaluate and ablate our 6D pose
estimation method on YCB-V and HOPE-Video datasets as well as a new dataset of
instructional videos manually annotated with approximate 6D object
trajectories. We demonstrate significant improvements over existing
state-of-the-art RGB 6D pose estimation methods. Finally, we show that the 6D
object motion estimated from Internet videos can be transferred to a 7-axis
robotic manipulator both in a virtual simulator as well as in a real world
set-up. We also successfully apply our method to egocentric videos taken from
the EPIC-KITCHENS dataset, demonstrating potential for Embodied AI
applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ICLR 2025. Project page available at
  https://ponimatkin.github.io/wildpose/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CODEI: Resource-Efficient Task-Driven Co-Design of Perception and
  Decision Making for Mobile Robots Applied to Autonomous Vehicles 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10296v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10296v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dejan Milojevic, Gioele Zardini, Miriam Elser, Andrea Censi, Emilio Frazzoli
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper discusses the integration challenges and strategies for designing
mobile robots, by focusing on the task-driven, optimal selection of hardware
and software to balance safety, efficiency, and minimal usage of resources such
as costs, energy, computational requirements, and weight. We emphasize the
interplay between perception and motion planning in decision-making by
introducing the concept of occupancy queries to quantify the perception
requirements for sampling-based motion planners. Sensor and algorithm
performance are evaluated using False Negative Rates (FPR) and False Positive
Rates (FPR) across various factors such as geometric relationships, object
properties, sensor resolution, and environmental conditions. By integrating
perception requirements with perception performance, an Integer Linear
Programming (ILP) approach is proposed for efficient sensor and algorithm
selection and placement. This forms the basis for a co-design optimization that
includes the robot body, motion planner, perception pipeline, and computing
unit. We refer to this framework for solving the co-design problem of mobile
robots as CODEI, short for Co-design of Embodied Intelligence. A case study on
developing an Autonomous Vehicle (AV) for urban scenarios provides actionable
information for designers, and shows that complex tasks escalate resource
demands, with task performance affecting choices of the autonomy stack. The
study demonstrates that resource prioritization influences sensor choice:
cameras are preferred for cost-effective and lightweight designs, while lidar
sensors are chosen for better energy and computational efficiency.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages, 33 images, IEEE Transactions on Robotics</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SurgRAW: Multi-Agent Workflow with Chain-of-Thought Reasoning for
  Surgical Intelligence 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10265v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10265v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chang Han Low, Ziyue Wang, Tianyi Zhang, Zhitao Zeng, Zhu Zhuo, Evangelos B. Mazomenos, Yueming Jin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Integration of Vision-Language Models (VLMs) in surgical intelligence is
hindered by hallucinations, domain knowledge gaps, and limited understanding of
task interdependencies within surgical scenes, undermining clinical
reliability. While recent VLMs demonstrate strong general reasoning and
thinking capabilities, they still lack the domain expertise and task-awareness
required for precise surgical scene interpretation. Although Chain-of-Thought
(CoT) can structure reasoning more effectively, current approaches rely on
self-generated CoT steps, which often exacerbate inherent domain gaps and
hallucinations. To overcome this, we present SurgRAW, a CoT-driven multi-agent
framework that delivers transparent, interpretable insights for most tasks in
robotic-assisted surgery. By employing specialized CoT prompts across five
tasks: instrument recognition, action recognition, action prediction, patient
data extraction, and outcome assessment, SurgRAW mitigates hallucinations
through structured, domain-aware reasoning. Retrieval-Augmented Generation
(RAG) is also integrated to external medical knowledge to bridge domain gaps
and improve response reliability. Most importantly, a hierarchical agentic
system ensures that CoT-embedded VLM agents collaborate effectively while
understanding task interdependencies, with a panel discussion mechanism
promotes logical consistency. To evaluate our method, we introduce
SurgCoTBench, the first reasoning-based dataset with structured frame-level
annotations. With comprehensive experiments, we demonstrate the effectiveness
of proposed SurgRAW with 29.32% accuracy improvement over baseline VLMs on 12
robotic procedures, achieving the state-of-the-art performance and advancing
explainable, trustworthy, and autonomous surgical assistance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SCOOP: A Framework for Proactive Collaboration and Social Continual
  Learning through Natural Language Interaction andCausal Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10241v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10241v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dimitri Ognibene, Sabrina Patania, Luca Annese, Cansu Koyuturk, Franca Garzotto, Giuseppe Vizzari, Azzurra Ruggeri, Simone Colombani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal information-gathering settings, where users collaborate with AI in
dynamic environments, are increasingly common. These involve complex processes
with textual and multimodal interactions, often requiring additional structural
information via cost-incurring requests. AI helpers lack access to users' true
goals, beliefs, and preferences and struggle to integrate diverse information
effectively.
  We propose a social continual learning framework for causal knowledge
acquisition and collaborative decision-making. It focuses on autonomous agents
learning through dialogues, question-asking, and interaction in open, partially
observable environments. A key component is a natural language oracle that
answers the agent's queries about environmental mechanisms and states, refining
causal understanding while balancing exploration or learning, and exploitation
or knowledge use.
  Evaluation tasks inspired by developmental psychology emphasize causal
reasoning and question-asking skills. They complement benchmarks by assessing
the agent's ability to identify knowledge gaps, generate meaningful queries,
and incrementally update reasoning. The framework also evaluates how knowledge
acquisition costs are amortized across tasks within the same environment.
  We propose two architectures: 1) a system combining Large Language Models
(LLMs) with the ReAct framework and question-generation, and 2) an advanced
system with a causal world model, symbolic, graph-based, or subsymbolic, for
reasoning and decision-making. The latter builds a causal knowledge graph for
efficient inference and adaptability under constraints. Challenges include
integrating causal reasoning into ReAct and optimizing exploration and
question-asking in error-prone scenarios. Beyond applications, this framework
models developmental processes combining causal reasoning, question generation,
and social learning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PRISM: Preference Refinement via Implicit Scene Modeling for 3D
  Vision-Language Preference-Based Reinforcement Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10177v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10177v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yirong Sun, Yanjun Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose PRISM, a novel framework designed to overcome the limitations of
2D-based Preference-Based Reinforcement Learning (PBRL) by unifying 3D point
cloud modeling and future-aware preference refinement. At its core, PRISM
adopts a 3D Point Cloud-Language Model (3D-PC-LLM) to mitigate occlusion and
viewpoint biases, ensuring more stable and spatially consistent preference
signals. Additionally, PRISM leverages Chain-of-Thought (CoT) reasoning to
incorporate long-horizon considerations, thereby preventing the short-sighted
feedback often seen in static preference comparisons. In contrast to
conventional PBRL techniques, this integration of 3D perception and
future-oriented reasoning leads to significant gains in preference agreement
rates, faster policy convergence, and robust generalization across unseen
robotic environments. Our empirical results, spanning tasks such as robotic
manipulation and autonomous navigation, highlight PRISM's potential for
real-world applications where precise spatial understanding and reliable
long-term decision-making are critical. By bridging 3D geometric awareness with
CoT-driven preference modeling, PRISM establishes a comprehensive foundation
for scalable, human-aligned reinforcement learning.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         <span class="highlight-title">★</span> GS-SDF: LiDAR-Augmented Gaussian Splatting and Neural SDF for
  Geometrically Consistent Rendering and Reconstruction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10170v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10170v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jianheng Liu, Yunfei Wan, Bowen Wang, Chunran Zheng, Jiarong Lin, <span class="highlight-author">Fu Zhang</span>
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Digital twins are fundamental to the development of autonomous driving and
embodied artificial intelligence. However, achieving high-granularity surface
reconstruction and high-fidelity rendering remains a challenge. Gaussian
splatting offers efficient photorealistic rendering but struggles with
geometric inconsistencies due to fragmented primitives and sparse observational
data in robotics applications. Existing regularization methods, which rely on
render-derived constraints, often fail in complex environments. Moreover,
effectively integrating sparse LiDAR data with Gaussian splatting remains
challenging. We propose a unified LiDAR-visual system that synergizes Gaussian
splatting with a neural signed distance field. The accurate LiDAR point clouds
enable a trained neural signed distance field to offer a manifold geometry
field, This motivates us to offer an SDF-based Gaussian initialization for
physically grounded primitive placement and a comprehensive geometric
regularization for geometrically consistent rendering and reconstruction.
Experiments demonstrate superior reconstruction accuracy and rendering quality
across diverse trajectories. To benefit the community, the codes will be
released at https://github.com/hku-mars/GS-SDF.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Mapless <span class="highlight-title">Collision</span>-Free Flight via MPC using Dual KD-Trees in Cluttered
  Environments 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10141v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10141v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Linzuo Zhang, Yu Hu, Yang Deng, Feng Yu, Danping Zou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Collision-free flight in cluttered environments is a critical capability for
autonomous quadrotors. Traditional methods often rely on detailed 3D map
construction, trajectory generation, and tracking. However, this cascade
pipeline can introduce accumulated errors and computational delays, limiting
flight agility and safety. In this paper, we propose a novel method for
enabling collision-free flight in cluttered environments without explicitly
constructing 3D maps or generating and tracking collision-free trajectories.
Instead, we leverage Model Predictive Control (MPC) to directly produce safe
actions from sparse waypoints and point clouds from a depth camera. These
sparse waypoints are dynamically adjusted online based on nearby obstacles
detected from point clouds. To achieve this, we introduce a dual KD-Tree
mechanism: the Obstacle KD-Tree quickly identifies the nearest obstacle for
avoidance, while the Edge KD-Tree provides a robust initial guess for the MPC
solver, preventing it from getting stuck in local minima during obstacle
avoidance. We validate our approach through extensive simulations and
real-world experiments. The results show that our approach significantly
outperforms the mapping-based methods and is also superior to imitation
learning-based methods, demonstrating reliable obstacle avoidance at up to 12
m/s in simulations and 6 m/s in real-world tests. Our method provides a simple
and robust alternative to existing methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ An Real-Sim-Real (RSR) Loop Framework for Generalizable Robotic Policy
  Transfer with Differentiable Simulation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10118v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10118v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lu Shi, Yuxuan Xu, Shiyu Wang, Jinhao Huang, Wenhao Zhao, Yufei Jia, Zike Yan, Weibin Gu, Guyue Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The sim-to-real gap remains a critical challenge in robotics, hindering the
deployment of algorithms trained in simulation to real-world systems. This
paper introduces a novel Real-Sim-Real (RSR) loop framework leveraging
differentiable simulation to address this gap by iteratively refining
simulation parameters, aligning them with real-world conditions, and enabling
robust and efficient policy transfer. A key contribution of our work is the
design of an informative cost function that encourages the collection of
diverse and representative real-world data, minimizing bias and maximizing the
utility of each data point for simulation refinement. This cost function
integrates seamlessly into existing reinforcement learning algorithms (e.g.,
PPO, SAC) and ensures a balanced exploration of critical regions in the real
domain. Furthermore, our approach is implemented on the versatile Mujoco MJX
platform, and our framework is compatible with a wide range of robotic systems.
Experimental results on several robotic manipulation tasks demonstrate that our
method significantly reduces the sim-to-real gap, achieving high task
performance and generalizability across diverse scenarios of both explicit and
implicit environmental uncertainties.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ IMPACT: Intelligent Motion <span class="highlight-title">Plan</span>ning with Acceptable Contact Trajectories
  via Vision-Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10110v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10110v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yiyang Ling, Karan Owalekar, Oluwatobiloba Adesanya, Erdem Bıyık, Daniel Seita
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Motion planning involves determining a sequence of robot configurations to
reach a desired pose, subject to movement and safety constraints. Traditional
motion planning finds collision-free paths, but this is overly restrictive in
clutter, where it may not be possible for a robot to accomplish a task without
contact. In addition, contacts range from relatively benign (e.g., brushing a
soft pillow) to more dangerous (e.g., toppling a glass vase). Due to this
diversity, it is difficult to characterize which contacts may be acceptable or
unacceptable. In this paper, we propose IMPACT, a novel motion planning
framework that uses Vision-Language Models (VLMs) to infer environment
semantics, identifying which parts of the environment can best tolerate contact
based on object properties and locations. Our approach uses the VLM's outputs
to produce a dense 3D "cost map" that encodes contact tolerances and seamlessly
integrates with standard motion planners. We perform experiments using 20
simulation and 10 real-world scenes and assess using task success rate, object
displacements, and feedback from human evaluators. Our results over 3620
simulation and 200 real-world trials suggest that IMPACT enables efficient
contact-rich motion planning in cluttered settings while outperforming
alternative methods and ablations. Supplementary material is available at
https://impact-planning.github.io/.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ AhaRobot: A Low-Cost Open-Source Bimanual Mobile <span class="highlight-title">Manipulator</span> for
  Embodied AI 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10070v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10070v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haiqin Cui, Yifu Yuan, Yan Zheng, Jianye Hao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Navigation and manipulation in open-world environments remain unsolved
challenges in the Embodied AI. The high cost of commercial mobile manipulation
robots significantly limits research in real-world scenes. To address this
issue, we propose AhaRobot, a low-cost and fully open-source dual-arm mobile
manipulation robot system with a hardware cost of only $1,000 (excluding
optional computational resources), which is less than 1/15 of the cost of
popular mobile robots. The AhaRobot system consists of three components: (1) a
novel low-cost hardware architecture primarily composed of off-the-shelf
components, (2) an optimized control solution to enhance operational precision
integrating dual-motor backlash control and static friction compensation, and
(3) a simple remote teleoperation method RoboPilot. We use handles to control
the dual arms and pedals for whole-body movement. The teleoperation process is
low-burden and easy to operate, much like piloting. RoboPilot is designed for
remote data collection in embodied scenarios. Experimental results demonstrate
that RoboPilot significantly enhances data collection efficiency in complex
manipulation tasks, achieving a 30% increase compared to methods using 3D mouse
and leader-follower systems. It also excels at completing extremely
long-horizon tasks in one go. Furthermore, AhaRobot can be used to learn
end-to-end policies and autonomously perform complex manipulation tasks, such
as pen insertion and cleaning up the floor. We aim to build an affordable yet
powerful platform to promote the development of embodied tasks on real devices,
advancing more robust and reliable embodied AI. All hardware and software
systems are available at https://aha-robot.github.io.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The first two authors contributed equally. Website:
  https://aha-robot.github.io</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SmartWay: Enhanced Waypoint Prediction and Backtracking for Zero-Shot
  Vision-and-Language <span class="highlight-title">Navigation</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10069v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10069v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiangyu Shi, Zerui Li, Wenqi Lyu, Jiatong Xia, Feras Dayoub, Yanyuan Qiao, Qi Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision-and-Language Navigation (VLN) in continuous environments requires
agents to interpret natural language instructions while navigating
unconstrained 3D spaces. Existing VLN-CE frameworks rely on a two-stage
approach: a waypoint predictor to generate waypoints and a navigator to execute
movements. However, current waypoint predictors struggle with spatial
awareness, while navigators lack historical reasoning and backtracking
capabilities, limiting adaptability. We propose a zero-shot VLN-CE framework
integrating an enhanced waypoint predictor with a Multi-modal Large Language
Model (MLLM)-based navigator. Our predictor employs a stronger vision encoder,
masked cross-attention fusion, and an occupancy-aware loss for better waypoint
quality. The navigator incorporates history-aware reasoning and adaptive path
planning with backtracking, improving robustness. Experiments on R2R-CE and
MP3D benchmarks show our method achieves state-of-the-art (SOTA) performance in
zero-shot settings, demonstrating competitive results compared to fully
supervised methods. Real-world validation on Turtlebot 4 further highlights its
adaptability.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ V2X-ReaLO: An Open Online Framework and Dataset for Cooperative
  Perception in Reality 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10034v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10034v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hao Xiang, Zhaoliang Zheng, Xin Xia, Seth Z. Zhao, Letian Gao, Zewei Zhou, Tianhui Cai, Yun Zhang, Jiaqi Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Cooperative perception enabled by Vehicle-to-Everything (V2X) communication
holds significant promise for enhancing the perception capabilities of
autonomous vehicles, allowing them to overcome occlusions and extend their
field of view. However, existing research predominantly relies on simulated
environments or static datasets, leaving the feasibility and effectiveness of
V2X cooperative perception especially for intermediate fusion in real-world
scenarios largely unexplored. In this work, we introduce V2X-ReaLO, an open
online cooperative perception framework deployed on real vehicles and smart
infrastructure that integrates early, late, and intermediate fusion methods
within a unified pipeline and provides the first practical demonstration of
online intermediate fusion's feasibility and performance under genuine
real-world conditions. Additionally, we present an open benchmark dataset
specifically designed to assess the performance of online cooperative
perception systems. This new dataset extends V2X-Real dataset to dynamic,
synchronized ROS bags and provides 25,028 test frames with 6,850 annotated key
frames in challenging urban scenarios. By enabling real-time assessments of
perception accuracy and communication lantency under dynamic conditions,
V2X-ReaLO sets a new benchmark for advancing and optimizing cooperative
perception systems in real-world applications. The codes and datasets will be
released to further advance the field.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         <span class="highlight-title">★</span> LEVA: A high-mobility logistic vehicle with legged suspension <span class="chip">ICRA</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10028v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10028v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Marco Arnold, Lukas Hildebrandt, Kaspar Janssen, Efe Ongan, Pascal Bürge, Ádám Gyula Gábriel, James Kennedy, Rishi Lolla, Quanisha Oppliger, Micha Schaaf, Joseph Church, Michael Fritsche, Victor Klemm, Turcan Tuna, Giorgio Valsecchi, Cedric Weibel, <span class="highlight-author">Marco Hutter</span>
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The autonomous transportation of materials over challenging terrain is a
challenge with major economic implications and remains unsolved. This paper
introduces LEVA, a high-payload, high-mobility robot designed for autonomous
logistics across varied terrains, including those typical in agriculture,
construction, and search and rescue operations. LEVA uniquely integrates an
advanced legged suspension system using parallel kinematics. It is capable of
traversing stairs using a rl controller, has steerable wheels, and includes a
specialized box pickup mechanism that enables autonomous payload loading as
well as precise and reliable cargo transportation of up to 85 kg across uneven
surfaces, steps and inclines while maintaining a cot of as low as 0.15. Through
extensive experimental validation, LEVA demonstrates its off-road capabilities
and reliability regarding payload loading and transport.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for publication at the 2025 IEEE International Conference on
  Robotics and Automation (ICRA). This is the author's preprint version. 6
  pages, 8 figures, 2 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Post-disaster building indoor damage and survivor detection using
  autonomous path <span class="highlight-title">plan</span>ning and deep learning with unmanned aerial vehicles 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10027v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10027v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiao Pan, Sina Tavasoli, T. Y. Yang, Sina Poorghasem
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Rapid response to natural disasters such as earthquakes is a crucial element
in ensuring the safety of civil infrastructures and minimizing casualties.
Traditional manual inspection is labour-intensive, time-consuming, and can be
dangerous for inspectors and rescue workers. This paper proposed an autonomous
inspection approach for structural damage inspection and survivor detection in
the post-disaster building indoor scenario, which incorporates an autonomous
navigation method, deep learning-based damage and survivor detection method,
and a customized low-cost micro aerial vehicle (MAV) with onboard sensors.
Experimental studies in a pseudo-post-disaster office building have shown the
proposed methodology can achieve high accuracy in structural damage inspection
and survivor detection. Overall, the proposed inspection approach shows great
potential to improve the efficiency of existing manual post-disaster building
inspection.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 9 figures, accepted in the International Association for
  Bridge and Structural Engineering (IABSE) Symposium 2025, Tokyo, Japan</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ES-Parkour: Advanced Robot Parkour with Bio-inspired Event Camera and
  Spiking Neural Network 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09985v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09985v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qiang Zhang, Jiahang Cao, Jingkai Sun, Gang Han, Wen Zhao, Yijie Guo, Renjing Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, quadruped robotics has advanced significantly, particularly
in perception and motion control via reinforcement learning, enabling complex
motions in challenging environments. Visual sensors like depth cameras enhance
stability and robustness but face limitations, such as low operating
frequencies relative to joint control and sensitivity to lighting, which hinder
outdoor deployment. Additionally, deep neural networks in sensor and control
systems increase computational demands. To address these issues, we introduce
spiking neural networks (SNNs) and event cameras to perform a challenging
quadruped parkour task. Event cameras capture dynamic visual data, while SNNs
efficiently process spike sequences, mimicking biological perception.
Experimental results demonstrate that this approach significantly outperforms
traditional models, achieving excellent parkour performance with just 11.7% of
the energy consumption of an artificial neural network (ANN)-based model,
yielding an 88.3% energy reduction. By integrating event cameras with SNNs, our
work advances robotic reinforcement learning and opens new possibilities for
applications in demanding environments.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ RMG: Real-Time Expressive Motion Generation with Self-<span class="highlight-title">collision</span>
  Avoidance for 6-DOF Companion Robotic Arms 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09959v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09959v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiansheng Li, Haotian Song, Jinni Zhou, Qiang Nie, Yi Cai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The six-degree-of-freedom (6-DOF) robotic arm has gained widespread
application in human-coexisting environments. While previous research has
predominantly focused on functional motion generation, the critical aspect of
expressive motion in human-robot interaction remains largely unexplored. This
paper presents a novel real-time motion generation planner that enhances
interactivity by creating expressive robotic motions between arbitrary start
and end states within predefined time constraints. Our approach involves three
key contributions: first, we develop a mapping algorithm to construct an
expressive motion dataset derived from human dance movements; second, we train
motion generation models in both Cartesian and joint spaces using this dataset;
third, we introduce an optimization algorithm that guarantees smooth,
collision-free motion while maintaining the intended expressive style.
Experimental results demonstrate the effectiveness of our method, which can
generate expressive and generalized motions in under 0.5 seconds while
satisfying all specified constraints.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         <span class="highlight-title">★</span> PanoGen++: Domain-Adapted Text-Guided Panoramic Environment Generation
  for Vision-and-Language <span class="highlight-title">Navigation</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09938v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09938v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sen Wang, Dongliang Zhou, Liang Xie, <span class="highlight-author">Chao Xu</span>, Ye Yan, Erwei Yin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision-and-language navigation (VLN) tasks require agents to navigate
three-dimensional environments guided by natural language instructions,
offering substantial potential for diverse applications. However, the scarcity
of training data impedes progress in this field. This paper introduces
PanoGen++, a novel framework that addresses this limitation by generating
varied and pertinent panoramic environments for VLN tasks. PanoGen++
incorporates pre-trained diffusion models with domain-specific fine-tuning,
employing parameter-efficient techniques such as low-rank adaptation to
minimize computational costs. We investigate two settings for environment
generation: masked image inpainting and recursive image outpainting. The former
maximizes novel environment creation by inpainting masked regions based on
textual descriptions, while the latter facilitates agents' learning of spatial
relationships within panoramas. Empirical evaluations on room-to-room (R2R),
room-for-room (R4R), and cooperative vision-and-dialog navigation (CVDN)
datasets reveal significant performance enhancements: a 2.44% increase in
success rate on the R2R test leaderboard, a 0.63% improvement on the R4R
validation unseen set, and a 0.75-meter enhancement in goal progress on the
CVDN validation unseen set. PanoGen++ augments the diversity and relevance of
training environments, resulting in improved generalization and efficacy in VLN
tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This paper was accepted by Neural Networks</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Confidence-Controlled Exploration: Efficient Sparse-Reward Policy
  Learning for Robot <span class="highlight-title">Navigation</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2306.06192v9">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2306.06192v9.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bhrij Patel, Kasun Weerakoon, Wesley A. Suttle, Alec Koppel, Brian M. Sadler, Tianyi Zhou, Amrit Singh Bedi, Dinesh Manocha
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reinforcement learning (RL) is a promising approach for robotic navigation,
allowing robots to learn through trial and error. However, real-world robotic
tasks often suffer from sparse rewards, leading to inefficient exploration and
suboptimal policies due to sample inefficiency of RL. In this work, we
introduce Confidence-Controlled Exploration (CCE), a novel method that improves
sample efficiency in RL-based robotic navigation without modifying the reward
function. Unlike existing approaches, such as entropy regularization and reward
shaping, which can introduce instability by altering rewards, CCE dynamically
adjusts trajectory length based on policy entropy. Specifically, it shortens
trajectories when uncertainty is high to enhance exploration and extends them
when confidence is high to prioritize exploitation. CCE is a principled and
practical solution inspired by a theoretical connection between policy entropy
and gradient estimation. It integrates seamlessly with on-policy and off-policy
RL methods and requires minimal modifications. We validate CCE across
REINFORCE, PPO, and SAC in both simulated and real-world navigation tasks. CCE
outperforms fixed-trajectory and entropy-regularized baselines, achieving an
18\% higher success rate, 20-38\% shorter paths, and 9.32\% lower elevation
costs under a fixed training sample budget. Finally, we deploy CCE on a
Clearpath Husky robot, demonstrating its effectiveness in complex outdoor
environments.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 6 figures, 2 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ <span class="highlight-title">★</span> Versatile Demonstration Interface: Toward More Flexible Robot
  Demonstration Collection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.19141v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.19141v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Michael Hagenow, Dimosthenis Kontogiorgos, Yanwei Wang, <span class="highlight-author">Julie Shah</span>
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Previous methods for Learning from Demonstration leverage several approaches
for a human to teach motions to a robot, including teleoperation, kinesthetic
teaching, and natural demonstrations. However, little previous work has
explored more general interfaces that allow for multiple demonstration types.
Given the varied preferences of human demonstrators and task characteristics, a
flexible tool that enables multiple demonstration types could be crucial for
broader robot skill training. In this work, we propose Versatile Demonstration
Interface (VDI), an attachment for collaborative robots that simplifies the
collection of three common types of demonstrations. Designed for flexible
deployment in industrial settings, our tool requires no additional
instrumentation of the environment. Our prototype interface captures human
demonstrations through a combination of vision, force sensing, and state
tracking (e.g., through the robot proprioception or AprilTag tracking). Through
a user study where we deployed our prototype VDI at a local manufacturing
innovation center with manufacturing experts, we demonstrated VDI in
representative industrial tasks. Interactions from our study highlight the
practical value of VDI's varied demonstration types, expose a range of
industrial use cases for VDI, and provide insights for future tool design.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Maintaining Strong $r$-Robustness in Reconfigurable Multi-Robot Networks
  using Control Barrier Functions <span class="chip">ICRA</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.14675v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.14675v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haejoon Lee, Dimitra Panagou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In leader-follower consensus, strong $r$-robustness of the communication
graph provides a sufficient condition for followers to achieve consensus in the
presence of misbehaving agents. Previous studies have assumed that robots can
form and/or switch between predetermined network topologies with known
robustness properties. However, robots with distance-based communication models
may not be able to achieve these topologies while moving through spatially
constrained environments, such as narrow corridors, to complete their
objectives. This paper introduces a Control Barrier Function (CBF) that ensures
robots maintain strong $r$-robustness of their communication graph above a
certain threshold without maintaining any fixed topologies. Our CBF directly
addresses robustness, allowing robots to have flexible reconfigurable network
structure while navigating to achieve their objectives. The efficacy of our
method is tested through various simulation and hardware experiments.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted and will appear at IEEE International Conference on Robotics
  and Automation (ICRA) 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Knowledge-data fusion dominated vehicle platoon dynamics modeling and
  analysis: A physics-encoded deep learning approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08658v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08658v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hao Lyu, Yanyong Guo, Pan Liu, Shuo Feng, Weilin Ren, Quansheng Yue
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, artificial intelligence (AI)-enabled nonlinear vehicle platoon
dynamics modeling plays a crucial role in predicting and optimizing the
interactions between vehicles. Existing efforts lack the extraction and capture
of vehicle behavior interaction features at the platoon scale. More
importantly, maintaining high modeling accuracy without losing physical
analyzability remains to be solved. To this end, this paper proposes a novel
physics-encoded deep learning network, named PeMTFLN, to model the nonlinear
vehicle platoon dynamics. Specifically, an analyzable parameters encoded
computational graph (APeCG) is designed to guide the platoon to respond to the
driving behavior of the lead vehicle while ensuring local stability. Besides, a
multi-scale trajectory feature learning network (MTFLN) is constructed to
capture platoon following patterns and infer the physical parameters required
for APeCG from trajectory data. The human-driven vehicle trajectory datasets
(HIGHSIM) were used to train the proposed PeMTFLN. The trajectories prediction
experiments show that PeMTFLN exhibits superior compared to the baseline models
in terms of predictive accuracy in speed and gap. The stability analysis result
shows that the physical parameters in APeCG is able to reproduce the platoon
stability in real-world condition. In simulation experiments, PeMTFLN performs
low inference error in platoon trajectories generation. Moreover, PeMTFLN also
accurately reproduces ground-truth safety statistics. The code of proposed
PeMTFLN is open source.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Generalized Adaptive Jacobian Controller for Soft Robots 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.04094v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.04094v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zixi Chen, Xuyang Ren, Yuya Hamamatsu, Gastone Ciuti, Cesare Stefanini
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The nonlinearity and hysteresis of soft robot motions have posed challenges
in control. The Jacobian controller is transferred from rigid robot controllers
and exhibits conciseness, but the improper assumption of soft robots induces
the feasibility only in a small local area. Accurate controllers like neural
networks can deal with delayed and nonlinear motion, achieving high accuracy,
but they suffer from the high data amount requirement and black-box property.
Inspired by these approaches, we propose an adaptive generalized Jacobian
controller for soft robots. This controller is constructed by the concise
format of the Jacobian controller but includes more states and independent
matrices, which is suitable for soft robotics. In addition, the initialization
leverages the motor babbling strategy and batch optimization from neural
network controllers. In experiments, we first analyze the online controllers,
including the Jacobian controller, the Gaussian process regression, and our
controller. Real experiments have validated that our controller outperforms the
RNN controller even with fewer data samples, and it is adaptive to various
situations without fine-tuning, like different control frequencies, softness,
and even manufacturing errors. Future work may include online adjustment of the
controller format and adaptability validation in more scenarios.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 8 figures, 4 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A new metaheuristic approach for the art gallery problem 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2107.05540v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2107.05540v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bahram Sadeghi Bigham, Sahar Badri, Nazanin Padkan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the problem "Localization and trilateration with the minimum number of
landmarks", we faced the 3-Guard and classic Art Gallery Problems. The goal of
the art gallery problem is to find the minimum number of guards within a simple
polygon to observe and protect its entirety. It has many applications in
robotics, telecommunications, etc. There are some approaches to handle the art
gallery problem that is theoretically NP-hard. This paper offers an efficient
method based on the Particle Filter algorithm which solves the most fundamental
state of the problem in a nearly optimal manner. The experimental results on
the random polygons generated by Bottino et al. \cite{bottino2011nearly} show
that the new method is more accurate with fewer or equal guards. Furthermore,
we discuss resampling and particle numbers to minimize the run time.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This article has undergone many changes and should be reviewed and
  rewritten in a different format</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Unified Feedback Linearization for Nonlinear Systems with Dexterous and
  Energy-Saving Modes 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.20524v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.20524v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mirko Mizzoni, Pieter van Goor, Antonio Franchi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Systems with a high number of inputs compared to the degrees of freedom (e.g.
a mobile robot with Mecanum wheels) often have a minimal set of
energy-efficient inputs needed to achieve a main task (e.g. position tracking)
and a set of energy-intense inputs needed to achieve an additional auxiliary
task (e.g. orientation tracking). This letter presents a unified control
scheme, derived through feedback linearization, that can switch between two
modes: an energy-saving mode, which tracks the main task using only the
energy-efficient inputs while forcing the energy-intense inputs to zero, and a
dexterous mode, which also uses the energy-intense inputs to track the
auxiliary task as needed. The proposed control guarantees the exponential
tracking of the main task and that the dynamics associated with the main task
evolve independently of the a priori unknown switching signal. When the control
is operating in dexterous mode, the exponential tracking of the auxiliary task
is also guaranteed. Numerical simulations on an omnidirectional Mecanum wheel
robot validate the effectiveness of the proposed approach and demonstrate the
effect of the switching signal on the exponential tracking behavior of the main
and auxiliary tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ReVLA: Reverting Visual Domain Limitation of Robotic Foundation Models <span class="chip">ICRA-2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.15250v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.15250v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sombit Dey, Jan-Nico Zaech, Nikolay Nikolov, Luc Van Gool, Danda Pani Paudel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent progress in large language models and access to large-scale robotic
datasets has sparked a paradigm shift in robotics models transforming them into
generalists able to adapt to various tasks, scenes, and robot modalities. A
large step for the community are open Vision Language Action models which
showcase strong performance in a wide variety of tasks. In this work, we study
the visual generalization capabilities of three existing robotic foundation
models, and propose a corresponding evaluation framework.
  Our study shows that the existing models do not exhibit robustness to visual
out-of-domain scenarios. This is potentially caused by limited variations in
the training data and/or catastrophic forgetting, leading to domain limitations
in the vision foundation models. We further explore OpenVLA, which uses two
pre-trained vision foundation models and is, therefore, expected to generalize
to out-of-domain experiments. However, we showcase catastrophic forgetting by
DINO-v2 in OpenVLA through its failure to fulfill the task of depth regression.
  To overcome the aforementioned issue of visual catastrophic forgetting, we
propose a gradual backbone reversal approach founded on model merging. This
enables OpenVLA which requires the adaptation of the visual backbones during
initial training -- to regain its visual generalization ability. Regaining this
capability enables our ReVLA model to improve over OpenVLA by a factor of 77%
and 66% for grasping and lifting in visual OOD tasks .
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at ICRA-2025, Atlanta</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ PhysVLM: Enabling Visual Language Models to Understand Robotic Physical
  Reachability 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08481v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08481v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Weijie Zhou, Manli Tao, Chaoyang Zhao, Haiyun Guo, Honghui Dong, Ming Tang, Jinqiao Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Understanding the environment and a robot's physical reachability is crucial
for task execution. While state-of-the-art vision-language models (VLMs) excel
in environmental perception, they often generate inaccurate or impractical
responses in embodied visual reasoning tasks due to a lack of understanding of
robotic physical reachability. To address this issue, we propose a unified
representation of physical reachability across diverse robots, i.e.,
Space-Physical Reachability Map (S-P Map), and PhysVLM, a vision-language model
that integrates this reachability information into visual reasoning.
Specifically, the S-P Map abstracts a robot's physical reachability into a
generalized spatial representation, independent of specific robot
configurations, allowing the model to focus on reachability features rather
than robot-specific parameters. Subsequently, PhysVLM extends traditional VLM
architectures by incorporating an additional feature encoder to process the S-P
Map, enabling the model to reason about physical reachability without
compromising its general vision-language capabilities. To train and evaluate
PhysVLM, we constructed a large-scale multi-robot dataset, Phys100K, and a
challenging benchmark, EQA-phys, which includes tasks for six different robots
in both simulated and real-world environments. Experimental results demonstrate
that PhysVLM outperforms existing models, achieving a 14\% improvement over
GPT-4o on EQA-phys and surpassing advanced embodied VLMs such as RoboMamba and
SpatialVLM on the RoboVQA-val and OpenEQA benchmarks. Additionally, the S-P Map
shows strong compatibility with various VLMs, and its integration into
GPT-4o-mini yields a 7.1\% performance improvement.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Efficient End-to-End 6-Dof <span class="highlight-title">Grasp</span> Detection Framework for Edge Devices
  with Hierarchical Heatmaps and Feature Propagation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.22980v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.22980v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kaiqin Yang, Yixiang Dai, Guijin Wang, Siang Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  6-DoF grasp detection is critically important for the advancement of
intelligent embodied systems, as it provides feasible robot poses for object
grasping. Various methods have been proposed to detect 6-DoF grasps through the
extraction of 3D geometric features from RGBD or point cloud data. However,
most of these approaches encounter challenges during real robot deployment due
to their significant computational demands, which can be particularly
problematic for mobile robot platforms, especially those reliant on edge
computing devices. This paper presents an Efficient End-to-End Grasp Detection
Network (E3GNet) for 6-DoF grasp detection utilizing hierarchical heatmap
representations. E3GNet effectively identifies high-quality and diverse grasps
in cluttered real-world environments.Benefiting from our end-to-end methodology
and efficient network design, our approach surpasses previous methods in model
inference efficiency and achieves real-time 6-Dof grasp detection on edge
devices. Furthermore, real-world experiments validate the effectiveness of our
method, achieving a satisfactory 94% object grasping success rate.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by 2025 IEEE International Symposium on Circuits and Systems</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Long-horizon Embodied <span class="highlight-title">Plan</span>ning with Implicit Logical Inference and
  Hallucination Mitigation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.15658v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.15658v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Siyuan Liu, Jiawei Du, Sicheng Xiang, Zibo Wang, Dingsheng Luo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Long-horizon embodied planning underpins embodied AI. To accomplish
long-horizon tasks, one of the most feasible ways is to decompose abstract
instructions into a sequence of actionable steps. Foundation models still face
logical errors and hallucinations in long-horizon planning, unless provided
with highly relevant examples to the tasks. However, providing highly relevant
examples for any random task is unpractical. Therefore, we present ReLEP, a
novel framework for Real-time Long-horizon Embodied Planning. ReLEP can
complete a wide range of long-horizon tasks without in-context examples by
learning implicit logical inference through fine-tuning. The fine-tuned large
vision-language model formulates plans as sequences of skill functions. These
functions are selected from a carefully designed skill library. ReLEP is also
equipped with a Memory module for plan and status recall, and a Robot
Configuration module for versatility across robot types. In addition, we
propose a data generation pipeline to tackle dataset scarcity. When
constructing the dataset, we considered the implicit logical relationships,
enabling the model to learn implicit logical relationships and dispel
hallucinations. Through comprehensive evaluations across various long-horizon
tasks, ReLEP demonstrates high success rates and compliance to execution even
on unseen tasks and outperforms state-of-the-art baseline methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ PCLA: A Framework for Testing Autonomous Agents in the CARLA Simulator 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09385v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09385v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Masoud Jamshidiyan Tehrani, Jinhan Kim, Paolo Tonella
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent research on testing autonomous driving agents has grown significantly,
especially in simulation environments. The CARLA simulator is often the
preferred choice, and the autonomous agents from the CARLA Leaderboard
challenge are regarded as the best-performing agents within this environment.
However, researchers who test these agents, rather than training their own ones
from scratch, often face challenges in utilizing them within customized test
environments and scenarios. To address these challenges, we introduce PCLA
(Pretrained CARLA Leaderboard Agents), an open-source Python testing framework
that includes nine high-performing pre-trained autonomous agents from the
Leaderboard challenges. PCLA is the first infrastructure specifically designed
for testing various autonomous agents in arbitrary CARLA
environments/scenarios. PCLA provides a simple way to deploy Leaderboard agents
onto a vehicle without relying on the Leaderboard codebase, it allows
researchers to easily switch between agents without requiring modifications to
CARLA versions or programming environments, and it is fully compatible with the
latest version of CARLA while remaining independent of the Leaderboard's
specific CARLA version. PCLA is publicly accessible at
https://github.com/MasoudJTehrani/PCLA.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This work will be published at the FSE 2025 demonstration track</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ECBench: Can Multi-modal Foundation Models Understand the Egocentric
  World? A Holistic Embodied Cognition <span class="highlight-title">Benchmark</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.05031v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.05031v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ronghao Dang, Yuqian Yuan, Wenqi Zhang, Yifei Xin, Boqiang Zhang, Long Li, Liuyi Wang, Qinyang Zeng, Xin Li, Lidong Bing
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The enhancement of generalization in robots by large vision-language models
(LVLMs) is increasingly evident. Therefore, the embodied cognitive abilities of
LVLMs based on egocentric videos are of great interest. However, current
datasets for embodied video question answering lack comprehensive and
systematic evaluation frameworks. Critical embodied cognitive issues, such as
robotic self-cognition, dynamic scene perception, and hallucination, are rarely
addressed. To tackle these challenges, we propose ECBench, a high-quality
benchmark designed to systematically evaluate the embodied cognitive abilities
of LVLMs. ECBench features a diverse range of scene video sources, open and
varied question formats, and 30 dimensions of embodied cognition. To ensure
quality, balance, and high visual dependence, ECBench uses class-independent
meticulous human annotation and multi-round question screening strategies.
Additionally, we introduce ECEval, a comprehensive evaluation system that
ensures the fairness and rationality of the indicators. Utilizing ECBench, we
conduct extensive evaluations of proprietary, open-source, and task-specific
LVLMs. ECBench is pivotal in advancing the embodied cognitive capabilities of
LVLMs, laying a solid foundation for developing reliable core models for
embodied agents. All data and code are available at
https://github.com/Rh-Dang/ECBench.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ <span class="highlight-title">★</span> AgiBot World Colosseo: A Large-scale <span class="highlight-title">Manipulation</span> Platform for Scalable
  and Intelligent Embodied Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06669v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06669v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                         AgiBot-World-Contributors, Qingwen Bu, Jisong Cai, Li Chen, Xiuqi Cui, Yan Ding, Siyuan Feng, Shenyuan Gao, Xindong He, Xu Huang, Shu Jiang, Yuxin Jiang, Cheng Jing, Hongyang Li, Jialu Li, Chi<span class="highlight-author">ming Liu</span>, Yi Liu, Yuxiang Lu, Jianlan Luo, Ping Luo, Yao Mu, Yuehan Niu, Yixuan Pan, Jiangmiao Pang, Yu Qiao, Guanghui Ren, Cheng Ruan, Jiaqi Shan, Yongjian Shen, Chengshi Shi, Mingkang Shi, Modi Shi, Chonghao Sima, Jianheng Song, Huijie Wang, Wenhao Wang, Dafeng Wei, Chengen Xie, Guo Xu, Junchi Yan, Cunbiao Yang, Lei Yang, Shukai Yang, Maoqing Yao, Jia Zeng, Chi Zhang, Qinglin Zhang, Bin Zhao, Chengyue Zhao, Jiaqi Zhao, Jianchao Zhu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We explore how scalable robot data can address real-world challenges for
generalized robotic manipulation. Introducing AgiBot World, a large-scale
platform comprising over 1 million trajectories across 217 tasks in five
deployment scenarios, we achieve an order-of-magnitude increase in data scale
compared to existing datasets. Accelerated by a standardized collection
pipeline with human-in-the-loop verification, AgiBot World guarantees
high-quality and diverse data distribution. It is extensible from grippers to
dexterous hands and visuo-tactile sensors for fine-grained skill acquisition.
Building on top of data, we introduce Genie Operator-1 (GO-1), a novel
generalist policy that leverages latent action representations to maximize data
utilization, demonstrating predictable performance scaling with increased data
volume. Policies pre-trained on our dataset achieve an average performance
improvement of 30% over those trained on Open X-Embodiment, both in in-domain
and out-of-distribution scenarios. GO-1 exhibits exceptional capability in
real-world dexterous and long-horizon tasks, achieving over 60% success rate on
complex tasks and outperforming prior RDT approach by 32%. By open-sourcing the
dataset, tools, and models, we aim to democratize access to large-scale,
high-quality robot data, advancing the pursuit of scalable and general-purpose
intelligence.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project website: https://agibot-world.com/. Github repo:
  https://github.com/OpenDriveLab/AgiBot-World. The author list is ordered
  alphabetically by surname, with detailed contributions provided in the
  appendix</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ 2HandedAfforder: Learning Precise Actionable Bimanual Affordances from
  Human Videos 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09320v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09320v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Marvin Heidinger, Snehal Jauhri, Vignesh Prasad, Georgia Chalvatzaki
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  When interacting with objects, humans effectively reason about which regions
of objects are viable for an intended action, i.e., the affordance regions of
the object. They can also account for subtle differences in object regions
based on the task to be performed and whether one or two hands need to be used.
However, current vision-based affordance prediction methods often reduce the
problem to naive object part segmentation. In this work, we propose a framework
for extracting affordance data from human activity video datasets. Our
extracted 2HANDS dataset contains precise object affordance region
segmentations and affordance class-labels as narrations of the activity
performed. The data also accounts for bimanual actions, i.e., two hands
co-ordinating and interacting with one or more objects. We present a VLM-based
affordance prediction model, 2HandedAfforder, trained on the dataset and
demonstrate superior performance over baselines in affordance region
segmentation for various activities. Finally, we show that our predicted
affordance regions are actionable, i.e., can be used by an agent performing a
task, through demonstration in robotic manipulation scenarios.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project site: https://sites.google.com/view/2handedafforder</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ForceGrip: Data-Free Curriculum Learning for Realistic Grip Force
  Control in VR Hand <span class="highlight-title">Manipulation</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08061v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08061v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        DongHeun Han, Byungmin Kim, RoUn Lee, KyeongMin Kim, Hyoseok Hwang, HyeongYeop Kang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Realistic hand manipulation is a key component of immersive virtual reality
(VR), yet existing methods often rely on a kinematic approach or motion-capture
datasets that omit crucial physical attributes such as contact forces and
finger torques. Consequently, these approaches prioritize tight,
one-size-fits-all grips rather than reflecting users' intended force levels. We
present ForceGrip, a deep learning agent that synthesizes realistic hand
manipulation motions, faithfully reflecting the user's grip force intention.
Instead of mimicking predefined motion datasets, ForceGrip uses generated
training scenarios-randomizing object shapes, wrist movements, and trigger
input flows-to challenge the agent with a broad spectrum of physical
interactions. To effectively learn from these complex tasks, we employ a
three-phase curriculum learning framework comprising Finger Positioning,
Intention Adaptation, and Dynamic Stabilization. This progressive strategy
ensures stable hand-object contact, adaptive force control based on user
inputs, and robust handling under dynamic conditions. Additionally, a proximity
reward function enhances natural finger motions and accelerates training
convergence. Quantitative and qualitative evaluations reveal ForceGrip's
superior force controllability and plausibility compared to state-of-the-art
methods. The video presentation of our paper is accessible at
https://youtu.be/lR-YAfninJw.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages, 10 figs (with appendix). Demo Video:
  https://youtu.be/lR-YAfninJw</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LaMMA-P: Generalizable Multi-Agent Long-Horizon Task Allocation and
  <span class="highlight-title">Plan</span>ning with LM-Driven PDDL <span class="highlight-title">Plan</span>ner <span class="chip">ICRA 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.20560v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.20560v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaopan Zhang, Hao Qin, Fuquan Wang, Yue Dong, Jiachen Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Language models (LMs) possess a strong capability to comprehend natural
language, making them effective in translating human instructions into detailed
plans for simple robot tasks. Nevertheless, it remains a significant challenge
to handle long-horizon tasks, especially in subtask identification and
allocation for cooperative heterogeneous robot teams. To address this issue, we
propose a Language Model-Driven Multi-Agent PDDL Planner (LaMMA-P), a novel
multi-agent task planning framework that achieves state-of-the-art performance
on long-horizon tasks. LaMMA-P integrates the strengths of the LMs' reasoning
capability and the traditional heuristic search planner to achieve a high
success rate and efficiency while demonstrating strong generalization across
tasks. Additionally, we create MAT-THOR, a comprehensive benchmark that
features household tasks with two different levels of complexity based on the
AI2-THOR environment. The experimental results demonstrate that LaMMA-P
achieves a 105% higher success rate and 36% higher efficiency than existing
LM-based multiagent planners. The experimental videos, code, datasets, and
detailed prompts used in each module can be found on the project website:
https://lamma-p.github.io.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>IEEE Conference on Robotics and Automation (ICRA 2025); Project
  website: https://lamma-p.github.io/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ HumanoidPano: Hybrid Spherical Panoramic-LiDAR Cross-Modal Perception
  for Humanoid Robots 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09010v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09010v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qiang Zhang, Zhang Zhang, Wei Cui, Jingkai Sun, Jiahang Cao, Yijie Guo, Gang Han, Wen Zhao, Jiaxu Wang, Chenghao Sun, Lingfeng Zhang, Hao Cheng, Yujie Chen, Lin Wang, Jian Tang, Renjing Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The perceptual system design for humanoid robots poses unique challenges due
to inherent structural constraints that cause severe self-occlusion and limited
field-of-view (FOV). We present HumanoidPano, a novel hybrid cross-modal
perception framework that synergistically integrates panoramic vision and LiDAR
sensing to overcome these limitations. Unlike conventional robot perception
systems that rely on monocular cameras or standard multi-sensor configurations,
our method establishes geometrically-aware modality alignment through a
spherical vision transformer, enabling seamless fusion of 360 visual context
with LiDAR's precise depth measurements. First, Spherical Geometry-aware
Constraints (SGC) leverage panoramic camera ray properties to guide
distortion-regularized sampling offsets for geometric alignment. Second,
Spatial Deformable Attention (SDA) aggregates hierarchical 3D features via
spherical offsets, enabling efficient 360{\deg}-to-BEV fusion with
geometrically complete object representations. Third, Panoramic Augmentation
(AUG) combines cross-view transformations and semantic alignment to enhance
BEV-panoramic feature consistency during data augmentation. Extensive
evaluations demonstrate state-of-the-art performance on the 360BEV-Matterport
benchmark. Real-world deployment on humanoid platforms validates the system's
capability to generate accurate BEV segmentation maps through panoramic-LiDAR
co-perception, directly enabling downstream navigation tasks in complex
environments. Our work establishes a new paradigm for embodied perception in
humanoid robotics.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Technical Report</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Diver Attention Estimation Framework for Effective Underwater
  Human-Robot Interaction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2209.14447v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2209.14447v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sadman Sakib Enan, Junaed Sattar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Many underwater tasks, such as cable-and-wreckage inspection and
search-and-rescue, can benefit from robust Human-Robot Interaction (HRI)
capabilities. With the recent advancements in vision-based underwater HRI
methods, Autonomous Underwater Vehicles (AUVs) have the capability to interact
with their human partners without requiring assistance from a topside operator.
However, in these methods, the AUV assumes that the diver is ready for
interaction, while in reality, the diver may be distracted. In this paper, we
attempt to address this problem by presenting a diver attention estimation
framework for AUVs to autonomously determine the attentiveness of a diver, and
developing a robot controller to allow the AUV to navigate and reorient itself
with respect to the diver before initiating interaction. The core element of
the framework is a deep convolutional neural network called DATT-Net. It is
based on a pyramid structure that can exploit the geometric relations among 10
facial keypoints of a diver to estimate their head orientation, which we use as
an indicator of attentiveness. Our on-the-bench experimental evaluations and
real-world experiments during both closed- and open-water robot trials confirm
the efficacy of the proposed framework.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, 6 figures, 2 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Sensor-Invariant Tactile Representation <span class="chip">ICLR'25</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.19638v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.19638v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Harsh Gupta, Yuchen Mo, Shengmiao Jin, Wenzhen Yuan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  High-resolution tactile sensors have become critical for embodied perception
and robotic manipulation. However, a key challenge in the field is the lack of
transferability between sensors due to design and manufacturing variations,
which result in significant differences in tactile signals. This limitation
hinders the ability to transfer models or knowledge learned from one sensor to
another. To address this, we introduce a novel method for extracting
Sensor-Invariant Tactile Representations (SITR), enabling zero-shot transfer
across optical tactile sensors. Our approach utilizes a transformer-based
architecture trained on a diverse dataset of simulated sensor designs, allowing
it to generalize to new sensors in the real world with minimal calibration.
Experimental results demonstrate the method's effectiveness across various
tactile sensing applications, facilitating data and model transferability for
future advancements in the field.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ICLR'25. Project webpage: https://hgupt3.github.io/sitr/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Low Fidelity Visuo-Tactile Pretraining Improves Vision-Only <span class="highlight-title">Manipulation</span>
  Performance 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.15639v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.15639v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Selam Gano, Abraham George, Amir Barati Farimani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Tactile perception is essential for real-world manipulation tasks, yet the
high cost and fragility of tactile sensors can limit their practicality. In
this work, we explore BeadSight (a low-cost, open-source tactile sensor)
alongside a tactile pre-training approach, an alternative method to precise,
pre-calibrated sensors. By pre-training with the tactile sensor and then
disabling it during downstream tasks, we aim to enhance robustness and reduce
costs in manipulation systems. We investigate whether tactile pre-training,
even with a low-fidelity sensor like BeadSight, can improve the performance of
an imitation learning agent on complex manipulation tasks. Through
visuo-tactile pre-training on both similar and dissimilar tasks, we analyze its
impact on a longer-horizon downstream task. Our experiments show that
visuo-tactile pre-training improved performance on a USB cable plugging task by
up to 65% with vision-only inference. Additionally, on a longer-horizon drawer
pick-and-place task, pre-training--whether on a similar, dissimilar, or
identical task--consistently improved performance, highlighting the potential
for a large-scale visuo-tactile pre-trained encoder.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Computer Vision and Pattern Recognition <span class="chip" style="font-size: 60%">150</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Studying Classifier(-Free) Guidance From a Classifier-Centric
  Perspective 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10638v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10638v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaoming Zhao, Alexander G. Schwing
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Classifier-free guidance has become a staple for conditional generation with
denoising diffusion models. However, a comprehensive understanding of
classifier-free guidance is still missing. In this work, we carry out an
empirical study to provide a fresh perspective on classifier-free guidance.
Concretely, instead of solely focusing on classifier-free guidance, we trace
back to the root, i.e., classifier guidance, pinpoint the key assumption for
the derivation, and conduct a systematic study to understand the role of the
classifier. We find that both classifier guidance and classifier-free guidance
achieve conditional generation by pushing the denoising diffusion trajectories
away from decision boundaries, i.e., areas where conditional information is
usually entangled and is hard to learn. Based on this classifier-centric
understanding, we propose a generic postprocessing step built upon
flow-matching to shrink the gap between the learned distribution for a
pre-trained denoising diffusion model and the real data distribution, majorly
around the decision boundaries. Experiments on various datasets verify the
effectiveness of the proposed approach.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ GoT: Unleashing Reasoning Capability of Multimodal Large Language Model
  for Visual Generation and Editing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10639v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10639v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rongyao Fang, Chengqi Duan, Kun Wang, Linjiang Huang, Hao Li, Shilin Yan, Hao Tian, Xingyu Zeng, Rui Zhao, Jifeng Dai, Xihui Liu, Hongsheng Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Current image generation and editing methods primarily process textual
prompts as direct inputs without reasoning about visual composition and
explicit operations. We present Generation Chain-of-Thought (GoT), a novel
paradigm that enables generation and editing through an explicit language
reasoning process before outputting images. This approach transforms
conventional text-to-image generation and editing into a reasoning-guided
framework that analyzes semantic relationships and spatial arrangements. We
define the formulation of GoT and construct large-scale GoT datasets containing
over 9M samples with detailed reasoning chains capturing semantic-spatial
relationships. To leverage the advantages of GoT, we implement a unified
framework that integrates Qwen2.5-VL for reasoning chain generation with an
end-to-end diffusion model enhanced by our novel Semantic-Spatial Guidance
Module. Experiments show our GoT framework achieves excellent performance on
both generation and editing tasks, with significant improvements over
baselines. Additionally, our approach enables interactive visual generation,
allowing users to explicitly modify reasoning steps for precise image
adjustments. GoT pioneers a new direction for reasoning-driven visual
generation and editing, producing images that better align with human intent.
To facilitate future research, we make our datasets, code, and pretrained
models publicly available at https://github.com/rongyaofang/GoT.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Dataset and models are released in https://github.com/rongyaofang/GoT</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The Curse of Conditions: Analyzing and Improving Optimal Transport for
  Conditional Flow-Based Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10636v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10636v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ho Kei Cheng, Alexander Schwing
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Minibatch optimal transport coupling straightens paths in unconditional flow
matching. This leads to computationally less demanding inference as fewer
integration steps and less complex numerical solvers can be employed when
numerically solving an ordinary differential equation at test time. However, in
the conditional setting, minibatch optimal transport falls short. This is
because the default optimal transport mapping disregards conditions, resulting
in a conditionally skewed prior distribution during training. In contrast, at
test time, we have no access to the skewed prior, and instead sample from the
full, unbiased prior distribution. This gap between training and testing leads
to a subpar performance. To bridge this gap, we propose conditional optimal
transport C^2OT that adds a conditional weighting term in the cost matrix when
computing the optimal transport assignment. Experiments demonstrate that this
simple fix works with both discrete and continuous conditions in
8gaussians-to-moons, CIFAR-10, ImageNet-32x32, and ImageNet-256x256. Our method
performs better overall compared to the existing baselines across different
function evaluation budgets. Code is available at
https://hkchengrex.github.io/C2OT
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project page: https://hkchengrex.github.io/C2OT</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Distilling Diversity and Control in Diffusion Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10637v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10637v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rohit Gandikota, David Bau
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Distilled diffusion models suffer from a critical limitation: reduced sample
diversity compared to their base counterparts. In this work, we uncover that
despite this diversity loss, distilled models retain the fundamental concept
representations of base models. We demonstrate control distillation - where
control mechanisms like Concept Sliders and LoRAs trained on base models can be
seamlessly transferred to distilled models and vice-versa, effectively
distilling control without any retraining. This preservation of
representational structure prompted our investigation into the mechanisms of
diversity collapse during distillation. To understand how distillation affects
diversity, we introduce Diffusion Target (DT) Visualization, an analysis and
debugging tool that reveals how models predict final outputs at intermediate
steps. Through DT-Visualization, we identify generation artifacts,
inconsistencies, and demonstrate that initial diffusion timesteps
disproportionately determine output diversity, while later steps primarily
refine details. Based on these insights, we introduce diversity distillation -
a hybrid inference approach that strategically employs the base model for only
the first critical timestep before transitioning to the efficient distilled
model. Our experiments demonstrate that this simple modification not only
restores the diversity capabilities from base to distilled models but
surprisingly exceeds it, while maintaining nearly the computational efficiency
of distilled inference, all without requiring additional training or model
modifications. Our code and data are available at
https://distillation.baulab.info
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project Page: https://distillation.baulab.info</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ V2Edit: Versatile Video Diffusion Editor for Videos and 3D Scenes 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10634v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10634v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yanming Zhang, Jun-Kun Chen, Jipeng Lyu, Yu-Xiong Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces V$^2$Edit, a novel training-free framework for
instruction-guided video and 3D scene editing. Addressing the critical
challenge of balancing original content preservation with editing task
fulfillment, our approach employs a progressive strategy that decomposes
complex editing tasks into a sequence of simpler subtasks. Each subtask is
controlled through three key synergistic mechanisms: the initial noise, noise
added at each denoising step, and cross-attention maps between text prompts and
video content. This ensures robust preservation of original video elements
while effectively applying the desired edits. Beyond its native video editing
capability, we extend V$^2$Edit to 3D scene editing via a
"render-edit-reconstruct" process, enabling high-quality, 3D-consistent edits
even for tasks involving substantial geometric changes such as object
insertion. Extensive experiments demonstrate that our V$^2$Edit achieves
high-quality and successful edits across various challenging video editing
tasks and complex 3D scene editing tasks, thereby establishing state-of-the-art
performance in both domains.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project Website: https://immortalco.github.io/V2Edit/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Frustratingly Simple Yet Highly Effective Attack Baseline: Over 90%
  Success Rate Against the Strong Black-box Models of GPT-4.5/4o/o1 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10635v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10635v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhaoyi Li, Xiaohan Zhao, Dong-Dong Wu, Jiacheng Cui, Zhiqiang Shen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite promising performance on open-source large vision-language models
(LVLMs), transfer-based targeted attacks often fail against black-box
commercial LVLMs. Analyzing failed adversarial perturbations reveals that the
learned perturbations typically originate from a uniform distribution and lack
clear semantic details, resulting in unintended responses. This critical
absence of semantic information leads commercial LVLMs to either ignore the
perturbation entirely or misinterpret its embedded semantics, thereby causing
the attack to fail. To overcome these issues, we notice that identifying core
semantic objects is a key objective for models trained with various datasets
and methodologies. This insight motivates our approach that refines semantic
clarity by encoding explicit semantic details within local regions, thus
ensuring interoperability and capturing finer-grained features, and by
concentrating modifications on semantically rich areas rather than applying
them uniformly. To achieve this, we propose a simple yet highly effective
solution: at each optimization step, the adversarial image is cropped randomly
by a controlled aspect ratio and scale, resized, and then aligned with the
target image in the embedding space. Experimental results confirm our
hypothesis. Our adversarial examples crafted with local-aggregated
perturbations focused on crucial regions exhibit surprisingly good
transferability to commercial LVLMs, including GPT-4.5, GPT-4o,
Gemini-2.0-flash, Claude-3.5-sonnet, Claude-3.7-sonnet, and even reasoning
models like o1, Claude-3.7-thinking and Gemini-2.0-flash-thinking. Our approach
achieves success rates exceeding 90% on GPT-4.5, 4o, and o1, significantly
outperforming all prior state-of-the-art attack methods. Our optimized
adversarial examples under different configurations and training code are
available at https://github.com/VILA-Lab/M-Attack.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Code at: https://github.com/VILA-Lab/M-Attack</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Charting and Navigating Hugging Face's Model Atlas 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10633v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10633v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Eliahu Horwitz, Nitzan Kurer, Jonathan Kahana, Liel Amar, Yedid Hoshen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As there are now millions of publicly available neural networks, searching
and analyzing large model repositories becomes increasingly important.
Navigating so many models requires an atlas, but as most models are poorly
documented charting such an atlas is challenging. To explore the hidden
potential of model repositories, we chart a preliminary atlas representing the
documented fraction of Hugging Face. It provides stunning visualizations of the
model landscape and evolution. We demonstrate several applications of this
atlas including predicting model attributes (e.g., accuracy), and analyzing
trends in computer vision models. However, as the current atlas remains
incomplete, we propose a method for charting undocumented regions.
Specifically, we identify high-confidence structural priors based on dominant
real-world model training practices. Leveraging these priors, our approach
enables accurate mapping of previously undocumented areas of the atlas. We
publicly release our datasets, code, and interactive atlas.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         <span class="highlight-title">★</span> HybridVLA: Collaborative Diffusion and Autoregression in a Unified
  Vision-Language-Action Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10631v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10631v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jia<span class="highlight-author">ming Liu</span>, Hao Chen, Pengju An, Zhuoyang Liu, Renrui Zhang, Chenyang Gu, Xiaoqi Li, Ziyu Guo, Sixiang Chen, Mengzhen Liu, Chengkai Hou, Mengdi Zhao, KC alex Zhou, Pheng-Ann Heng, Shanghang Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in vision-language models (VLMs) for common-sense
reasoning have led to the development of vision-language-action (VLA) models,
enabling robots to perform generalized manipulation. Although existing
autoregressive VLA methods leverage large-scale pretrained knowledge, they
disrupt the continuity of actions. Meanwhile, some VLA methods incorporate an
additional diffusion head to predict continuous actions, relying solely on
VLM-extracted features, which limits their reasoning capabilities. In this
paper, we introduce HybridVLA, a unified framework that seamlessly integrates
the strengths of both autoregressive and diffusion policies within a single
large language model, rather than simply connecting them. To bridge the
generation gap, a collaborative training recipe is proposed that injects the
diffusion modeling directly into the next-token prediction. With this recipe,
we find that these two forms of action prediction not only reinforce each other
but also exhibit varying performance across different tasks. Therefore, we
design a collaborative action ensemble mechanism that adaptively fuses these
two predictions, leading to more robust control. In experiments, HybridVLA
outperforms previous state-of-the-art VLA methods across various simulation and
real-world tasks, including both single-arm and dual-arm robots, while
demonstrating stable manipulation in previously unseen configurations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Kolmogorov-Arnold Attention: Is Learnable Attention Better For Vision
  Transformers? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10632v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10632v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Subhajit Maity, Killian Hitsman, Xin Li, Aritra Dutta
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Kolmogorov-Arnold networks (KANs) are a remarkable innovation consisting of
learnable activation functions with the potential to capture more complex
relationships from data. Although KANs are useful in finding symbolic
representations and continual learning of one-dimensional functions, their
effectiveness in diverse machine learning (ML) tasks, such as vision, remains
questionable. Presently, KANs are deployed by replacing multilayer perceptrons
(MLPs) in deep network architectures, including advanced architectures such as
vision Transformers (ViTs). In this paper, we are the first to design a general
learnable Kolmogorov-Arnold Attention (KArAt) for vanilla ViTs that can operate
on any choice of basis. However, the computing and memory costs of training
them motivated us to propose a more modular version, and we designed particular
learnable attention, called Fourier-KArAt. Fourier-KArAt and its variants
either outperform their ViT counterparts or show comparable performance on
CIFAR-10, CIFAR-100, and ImageNet-1K datasets. We dissect these architectures'
performance and generalization capacity by analyzing their loss landscapes,
weight distributions, optimizer path, attention visualization, and spectral
behavior, and contrast them with vanilla ViTs. The goal of this paper is not to
produce parameter- and compute-efficient attention, but to encourage the
community to explore KANs in conjunction with more advanced architectures that
require a careful understanding of learnable activations. Our open-source code
and implementation details are available on: https://subhajitmaity.me/KArAt
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint, Appendix included</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ UniGoal: Towards Universal Zero-shot Goal-oriented <span class="highlight-title">Navigation</span> <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10630v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10630v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hang Yin, Xiuwei Xu, Lingqing Zhao, Ziwei Wang, Jie Zhou, Jiwen Lu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we propose a general framework for universal zero-shot
goal-oriented navigation. Existing zero-shot methods build inference framework
upon large language models (LLM) for specific tasks, which differs a lot in
overall pipeline and fails to generalize across different types of goal.
Towards the aim of universal zero-shot navigation, we propose a uniform graph
representation to unify different goals, including object category, instance
image and text description. We also convert the observation of agent into an
online maintained scene graph. With this consistent scene and goal
representation, we preserve most structural information compared with pure text
and are able to leverage LLM for explicit graph-based reasoning. Specifically,
we conduct graph matching between the scene graph and goal graph at each time
instant and propose different strategies to generate long-term goal of
exploration according to different matching states. The agent first iteratively
searches subgraph of goal when zero-matched. With partial matching, the agent
then utilizes coordinate projection and anchor pair alignment to infer the goal
location. Finally scene graph correction and goal verification are applied for
perfect matching. We also present a blacklist mechanism to enable robust switch
between stages. Extensive experiments on several benchmarks show that our
UniGoal achieves state-of-the-art zero-shot performance on three studied
navigation tasks with a single model, even outperforming task-specific
zero-shot methods and supervised universal methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to CVPR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Hierarchical Self-Supervised Adversarial Training for Robust Vision
  Models in Histopathology 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10629v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10629v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hashmat Shadab Malik, Shahina Kunhimon, Muzammal Naseer, Fahad Shahbaz Khan, Salman Khan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Adversarial attacks pose significant challenges for vision models in critical
fields like healthcare, where reliability is essential. Although adversarial
training has been well studied in natural images, its application to biomedical
and microscopy data remains limited. Existing self-supervised adversarial
training methods overlook the hierarchical structure of histopathology images,
where patient-slide-patch relationships provide valuable discriminative
signals. To address this, we propose Hierarchical Self-Supervised Adversarial
Training (HSAT), which exploits these properties to craft adversarial examples
using multi-level contrastive learning and integrate it into adversarial
training for enhanced robustness. We evaluate HSAT on multiclass histopathology
dataset OpenSRH and the results show that HSAT outperforms existing methods
from both biomedical and natural image domains. HSAT enhances robustness,
achieving an average gain of 54.31% in the white-box setting and reducing
performance drops to 3-4% in the black-box setting, compared to 25-30% for the
baseline. These results set a new benchmark for adversarial training in this
domain, paving the way for more robust models. Our Code for training and
evaluation is available at https://github.com/HashmatShadab/HSAT.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SciVerse: Unveiling the Knowledge Comprehension and Visual Reasoning of
  LMMs on Multi-modal Scientific Problems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10627v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10627v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ziyu Guo, Ray Zhang, Hao Chen, Jialin Gao, Dongzhi Jiang, Jiaze Wang, Pheng-Ann Heng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid advancement of Large Multi-modal Models (LMMs) has enabled their
application in scientific problem-solving, yet their fine-grained capabilities
remain under-explored. In this paper, we introduce SciVerse, a multi-modal
scientific evaluation benchmark to thoroughly assess LMMs across 5,735 test
instances in five distinct versions. We aim to investigate three key dimensions
of LMMs: scientific knowledge comprehension, multi-modal content
interpretation, and Chain-of-Thought (CoT) reasoning. To unveil whether LMMs
possess sufficient scientific expertise, we first transform each problem into
three versions containing different levels of knowledge required for solving,
i.e., Knowledge-free, -lite, and -rich. Then, to explore how LMMs interpret
multi-modal scientific content, we annotate another two versions, i.e.,
Vision-rich and -only, marking more question information from texts to
diagrams. Comparing the results of different versions, SciVerse systematically
examines the professional knowledge stock and visual perception skills of LMMs
in scientific domains. In addition, to rigorously assess CoT reasoning, we
propose a new scientific CoT evaluation strategy, conducting a step-wise
assessment on knowledge and logical errors in model outputs. Our extensive
evaluation of different LMMs on SciVerse reveals critical limitations in their
scientific proficiency and provides new insights into future developments.
Project page: https://sciverse-cuhk.github.io
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Initially released in September 2024. Project page:
  https://sciverse-cuhk.github.io</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ NIL: No-data Imitation Learning by Leveraging Pre-trained Video
  Diffusion Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10626v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10626v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mert Albaba, Chenhao Li, Markos Diomataris, Omid Taheri, Andreas Krause, Michael Black
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Acquiring physically plausible motor skills across diverse and unconventional
morphologies-including humanoid robots, quadrupeds, and animals-is essential
for advancing character simulation and robotics. Traditional methods, such as
reinforcement learning (RL) are task- and body-specific, require extensive
reward function engineering, and do not generalize well. Imitation learning
offers an alternative but relies heavily on high-quality expert demonstrations,
which are difficult to obtain for non-human morphologies. Video diffusion
models, on the other hand, are capable of generating realistic videos of
various morphologies, from humans to ants. Leveraging this capability, we
propose a data-independent approach for skill acquisition that learns 3D motor
skills from 2D-generated videos, with generalization capability to
unconventional and non-human forms. Specifically, we guide the imitation
learning process by leveraging vision transformers for video-based comparisons
by calculating pair-wise distance between video embeddings. Along with
video-encoding distance, we also use a computed similarity between segmented
video frames as a guidance reward. We validate our method on locomotion tasks
involving unique body configurations. In humanoid robot locomotion tasks, we
demonstrate that 'No-data Imitation Learning' (NIL) outperforms baselines
trained on 3D motion-capture data. Our results highlight the potential of
leveraging generative video models for physically plausible skill learning with
diverse morphologies, effectively replacing data collection with data
generation for imitation learning.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LHM: Large Animatable Human Reconstruction Model from a Single Image in
  Seconds 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10625v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10625v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lingteng Qiu, Xiaodong Gu, Peihao Li, Qi Zuo, Weichao Shen, Junfei Zhang, Kejie Qiu, Weihao Yuan, Guanying Chen, Zilong Dong, Liefeng Bo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Animatable 3D human reconstruction from a single image is a challenging
problem due to the ambiguity in decoupling geometry, appearance, and
deformation. Recent advances in 3D human reconstruction mainly focus on static
human modeling, and the reliance of using synthetic 3D scans for training
limits their generalization ability. Conversely, optimization-based video
methods achieve higher fidelity but demand controlled capture conditions and
computationally intensive refinement processes. Motivated by the emergence of
large reconstruction models for efficient static reconstruction, we propose LHM
(Large Animatable Human Reconstruction Model) to infer high-fidelity avatars
represented as 3D Gaussian splatting in a feed-forward pass. Our model
leverages a multimodal transformer architecture to effectively encode the human
body positional features and image features with attention mechanism, enabling
detailed preservation of clothing geometry and texture. To further boost the
face identity preservation and fine detail recovery, we propose a head feature
pyramid encoding scheme to aggregate multi-scale features of the head regions.
Extensive experiments demonstrate that our LHM generates plausible animatable
human in seconds without post-processing for face and hands, outperforming
existing methods in both reconstruction accuracy and generalization ability.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project Page: https://lingtengqiu.github.io/LHM/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ETCH: Generalizing Body Fitting to Clothed Humans via Equivariant
  Tightness 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10624v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10624v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Boqian Li, Haiwen Feng, Zeyu Cai, Michael J. Black, Yuliang Xiu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Fitting a body to a 3D clothed human point cloud is a common yet challenging
task. Traditional optimization-based approaches use multi-stage pipelines that
are sensitive to pose initialization, while recent learning-based methods often
struggle with generalization across diverse poses and garment types. We propose
Equivariant Tightness Fitting for Clothed Humans, or ETCH, a novel pipeline
that estimates cloth-to-body surface mapping through locally approximate SE(3)
equivariance, encoding tightness as displacement vectors from the cloth surface
to the underlying body. Following this mapping, pose-invariant body features
regress sparse body markers, simplifying clothed human fitting into an
inner-body marker fitting task. Extensive experiments on CAPE and 4D-Dress show
that ETCH significantly outperforms state-of-the-art methods -- both
tightness-agnostic and tightness-aware -- in body fitting accuracy on loose
clothing (16.7% ~ 69.5%) and shape accuracy (average 49.9%). Our equivariant
tightness design can even reduce directional errors by (67.2% ~ 89.8%) in
one-shot (or out-of-distribution) settings. Qualitative results demonstrate
strong generalization of ETCH, regardless of challenging poses, unseen shapes,
loose clothing, and non-rigid dynamics. We will release the code and models
soon for research purposes at https://boqian-li.github.io/ETCH/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Page: https://boqian-li.github.io/ETCH/, Code:
  https://github.com/boqian-li/ETCH</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         <span class="highlight-title">★</span> Transformers without Normalization <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10622v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10622v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiachen Zhu, Xinlei Chen, <span class="highlight-author">Kaiming He</span>, Yann LeCun, Zhuang Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Normalization layers are ubiquitous in modern neural networks and have long
been considered essential. This work demonstrates that Transformers without
normalization can achieve the same or better performance using a remarkably
simple technique. We introduce Dynamic Tanh (DyT), an element-wise operation
$DyT($x$) = \tanh(\alpha $x$)$, as a drop-in replacement for normalization
layers in Transformers. DyT is inspired by the observation that layer
normalization in Transformers often produces tanh-like, $S$-shaped input-output
mappings. By incorporating DyT, Transformers without normalization can match or
exceed the performance of their normalized counterparts, mostly without
hyperparameter tuning. We validate the effectiveness of Transformers with DyT
across diverse settings, ranging from recognition to generation, supervised to
self-supervised learning, and computer vision to language models. These
findings challenge the conventional understanding that normalization layers are
indispensable in modern neural networks, and offer new insights into their role
in deep networks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>CVPR 2025; Project page: https://jiachenzhu.github.io/DyT/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DriveLMM-o1: A Step-by-Step Reasoning Dataset and Large Multimodal Model
  for Driving Scenario Understanding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10621v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10621v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ayesha Ishaq, Jean Lahoud, Ketan More, Omkar Thawakar, Ritesh Thawkar, Dinura Dissanayake, Noor Ahsan, Yuhao Li, Fahad Shahbaz Khan, Hisham Cholakkal, Ivan Laptev, Rao Muhammad Anwer, Salman Khan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While large multimodal models (LMMs) have demonstrated strong performance
across various Visual Question Answering (VQA) tasks, certain challenges
require complex multi-step reasoning to reach accurate answers. One
particularly challenging task is autonomous driving, which demands thorough
cognitive processing before decisions can be made. In this domain, a sequential
and interpretive understanding of visual cues is essential for effective
perception, prediction, and planning. Nevertheless, common VQA benchmarks often
focus on the accuracy of the final answer while overlooking the reasoning
process that enables the generation of accurate responses. Moreover, existing
methods lack a comprehensive framework for evaluating step-by-step reasoning in
realistic driving scenarios. To address this gap, we propose DriveLMM-o1, a new
dataset and benchmark specifically designed to advance step-wise visual
reasoning for autonomous driving. Our benchmark features over 18k VQA examples
in the training set and more than 4k in the test set, covering diverse
questions on perception, prediction, and planning, each enriched with
step-by-step reasoning to ensure logical inference in autonomous driving
scenarios. We further introduce a large multimodal model that is fine-tuned on
our reasoning dataset, demonstrating robust performance in complex driving
scenarios. In addition, we benchmark various open-source and closed-source
methods on our proposed dataset, systematically comparing their reasoning
capabilities for autonomous driving tasks. Our model achieves a +7.49% gain in
final answer accuracy, along with a 3.62% improvement in reasoning score over
the previous best open-source model. Our framework, dataset, and model are
available at https://github.com/ayesha-ishaq/DriveLMM-o1.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 4 figures, 3 tables, github:
  https://github.com/ayesha-ishaq/DriveLMM-o1</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DiT-Air: Revisiting the Efficiency of Diffusion Model Architecture
  Design in Text to Image Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10618v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10618v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chen Chen, Rui Qian, Wenze Hu, Tsu-Jui Fu, Lezhi Li, Bowen Zhang, Alex Schwing, Wei Liu, Yinfei Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work, we empirically study Diffusion Transformers (DiTs) for
text-to-image generation, focusing on architectural choices, text-conditioning
strategies, and training protocols. We evaluate a range of DiT-based
architectures--including PixArt-style and MMDiT variants--and compare them with
a standard DiT variant which directly processes concatenated text and noise
inputs. Surprisingly, our findings reveal that the performance of standard DiT
is comparable with those specialized models, while demonstrating superior
parameter-efficiency, especially when scaled up. Leveraging the layer-wise
parameter sharing strategy, we achieve a further reduction of 66% in model size
compared to an MMDiT architecture, with minimal performance impact. Building on
an in-depth analysis of critical components such as text encoders and
Variational Auto-Encoders (VAEs), we introduce DiT-Air and DiT-Air-Lite. With
supervised and reward fine-tuning, DiT-Air achieves state-of-the-art
performance on GenEval and T2I CompBench, while DiT-Air-Lite remains highly
competitive, surpassing most existing models despite its compact size.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ OVTR: End-to-End Open-Vocabulary Multiple Object Tracking with
  Transformer <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10616v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10616v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jinyang Li, En Yu, Sijia Chen, Wenbing Tao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Open-vocabulary multiple object tracking aims to generalize trackers to
unseen categories during training, enabling their application across a variety
of real-world scenarios. However, the existing open-vocabulary tracker is
constrained by its framework structure, isolated frame-level perception, and
insufficient modal interactions, which hinder its performance in
open-vocabulary classification and tracking. In this paper, we propose OVTR
(End-to-End Open-Vocabulary Multiple Object Tracking with TRansformer), the
first end-to-end open-vocabulary tracker that models motion, appearance, and
category simultaneously. To achieve stable classification and continuous
tracking, we design the CIP (Category Information Propagation) strategy, which
establishes multiple high-level category information priors for subsequent
frames. Additionally, we introduce a dual-branch structure for generalization
capability and deep multimodal interaction, and incorporate protective
strategies in the decoder to enhance performance. Experimental results show
that our method surpasses previous trackers on the open-vocabulary MOT
benchmark while also achieving faster inference speeds and significantly
reducing preprocessing requirements. Moreover, the experiment transferring the
model to another dataset demonstrates its strong adaptability. Models and code
are released at https://github.com/jinyanglii/OVTR.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ R1-Onevision: Advancing Generalized Multimodal Reasoning through
  Cross-Modal Formalization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10615v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10615v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yi Yang, Xiaoxuan He, Hongkun Pan, Xiyan Jiang, Yan Deng, Xingtao Yang, Haoyu Lu, Dacheng Yin, Fengyun Rao, Minfeng Zhu, Bo Zhang, Wei Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models have demonstrated remarkable reasoning capability in
complex textual tasks. However, multimodal reasoning, which requires
integrating visual and textual information, remains a significant challenge.
Existing visual-language models often struggle to effectively analyze and
reason visual content, resulting in suboptimal performance on complex reasoning
tasks. Moreover, the absence of comprehensive benchmarks hinders the accurate
assessment of multimodal reasoning capabilities. In this paper, we introduce
R1-Onevision, a multimodal reasoning model designed to bridge the gap between
visual perception and deep reasoning. To achieve this, we propose a cross-modal
reasoning pipeline that transforms images into formal textural representations,
enabling precise language-based reasoning. Leveraging this pipeline, we
construct the R1-Onevision dataset which provides detailed, step-by-step
multimodal reasoning annotations across diverse domains. We further develop the
R1-Onevision model through supervised fine-tuning and reinforcement learning to
cultivate advanced reasoning and robust generalization abilities. To
comprehensively evaluate multimodal reasoning performance across different
grades, we introduce R1-Onevision-Bench, a benchmark aligned with human
educational stages, covering exams from junior high school to university and
beyond. Experimental results show that R1-Onevision achieves state-of-the-art
performance, outperforming models such as GPT-4o and Qwen2.5-VL on multiple
challenging multimodal reasoning benchmarks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Code and Model: https://github.com/Fancy-MLLM/R1-onevision</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ConsisLoRA: Enhancing Content and Style Consistency for LoRA-based Style
  Transfer 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10614v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10614v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bolin Chen, Baoquan Zhao, Haoran Xie, Yi Cai, Qing Li, Xudong Mao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Style transfer involves transferring the style from a reference image to the
content of a target image. Recent advancements in LoRA-based (Low-Rank
Adaptation) methods have shown promise in effectively capturing the style of a
single image. However, these approaches still face significant challenges such
as content inconsistency, style misalignment, and content leakage. In this
paper, we comprehensively analyze the limitations of the standard diffusion
parameterization, which learns to predict noise, in the context of style
transfer. To address these issues, we introduce ConsisLoRA, a LoRA-based method
that enhances both content and style consistency by optimizing the LoRA weights
to predict the original image rather than noise. We also propose a two-step
training strategy that decouples the learning of content and style from the
reference image. To effectively capture both the global structure and local
details of the content image, we introduce a stepwise loss transition strategy.
Additionally, we present an inference guidance method that enables continuous
control over content and style strengths during inference. Through both
qualitative and quantitative evaluations, our method demonstrates significant
improvements in content and style consistency while effectively reducing
content leakage.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CoSTA$\ast$: Cost-Sensitive Toolpath Agent for Multi-turn Image Editing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10613v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10613v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Advait Gupta, NandaKiran Velaga, Dang Nguyen, Tianyi Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text-to-image models like stable diffusion and DALLE-3 still struggle with
multi-turn image editing. We decompose such a task as an agentic workflow
(path) of tool use that addresses a sequence of subtasks by AI tools of varying
costs. Conventional search algorithms require expensive exploration to find
tool paths. While large language models (LLMs) possess prior knowledge of
subtask planning, they may lack accurate estimations of capabilities and costs
of tools to determine which to apply in each subtask. Can we combine the
strengths of both LLMs and graph search to find cost-efficient tool paths? We
propose a three-stage approach "CoSTA*" that leverages LLMs to create a subtask
tree, which helps prune a graph of AI tools for the given task, and then
conducts A* search on the small subgraph to find a tool path. To better balance
the total cost and quality, CoSTA* combines both metrics of each tool on every
subtask to guide the A* search. Each subtask's output is then evaluated by a
vision-language model (VLM), where a failure will trigger an update of the
tool's cost and quality on the subtask. Hence, the A* search can recover from
failures quickly to explore other paths. Moreover, CoSTA* can automatically
switch between modalities across subtasks for a better cost-quality trade-off.
We build a novel benchmark of challenging multi-turn image editing, on which
CoSTA* outperforms state-of-the-art image-editing models or agents in terms of
both cost and quality, and performs versatile trade-offs upon user preference.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ OCCUQ: Exploring Efficient Uncertainty Quantification for 3D Occupancy
  Prediction <span class="chip">ICRA 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10605v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10605v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Severin Heidrich, Till Beemelmanns, Alexey Nekrasov, Bastian Leibe, Lutz Eckstein
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Autonomous driving has the potential to significantly enhance productivity
and provide numerous societal benefits. Ensuring robustness in these
safety-critical systems is essential, particularly when vehicles must navigate
adverse weather conditions and sensor corruptions that may not have been
encountered during training. Current methods often overlook uncertainties
arising from adversarial conditions or distributional shifts, limiting their
real-world applicability. We propose an efficient adaptation of an uncertainty
estimation technique for 3D occupancy prediction. Our method dynamically
calibrates model confidence using epistemic uncertainty estimates. Our
evaluation under various camera corruption scenarios, such as fog or missing
cameras, demonstrates that our approach effectively quantifies epistemic
uncertainty by assigning higher uncertainty values to unseen data. We introduce
region-specific corruptions to simulate defects affecting only a single camera
and validate our findings through both scene-level and region-level
assessments. Our results show superior performance in Out-of-Distribution (OoD)
detection and confidence calibration compared to common baselines such as Deep
Ensembles and MC-Dropout. Our approach consistently demonstrates reliable
uncertainty measures, indicating its potential for enhancing the robustness of
autonomous driving systems in real-world scenarios. Code and dataset are
available at https://github.com/ika-rwth-aachen/OCCUQ .
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for publication at ICRA 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MuDG: Taming Multi-modal Diffusion with Gaussian Splatting for Urban
  Scene Reconstruction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10604v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10604v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yingshuang Zou, Yikang Ding, Chuanrui Zhang, Jiazhe Guo, Bohan Li, Xiaoyang Lyu, Feiyang Tan, Xiaojuan Qi, Haoqian Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent breakthroughs in radiance fields have significantly advanced 3D scene
reconstruction and novel view synthesis (NVS) in autonomous driving.
Nevertheless, critical limitations persist: reconstruction-based methods
exhibit substantial performance deterioration under significant viewpoint
deviations from training trajectories, while generation-based techniques
struggle with temporal coherence and precise scene controllability. To overcome
these challenges, we present MuDG, an innovative framework that integrates
Multi-modal Diffusion model with Gaussian Splatting (GS) for Urban Scene
Reconstruction. MuDG leverages aggregated LiDAR point clouds with RGB and
geometric priors to condition a multi-modal video diffusion model, synthesizing
photorealistic RGB, depth, and semantic outputs for novel viewpoints. This
synthesis pipeline enables feed-forward NVS without computationally intensive
per-scene optimization, providing comprehensive supervision signals to refine
3DGS representations for rendering robustness enhancement under extreme
viewpoint changes. Experiments on the Open Waymo Dataset demonstrate that MuDG
outperforms existing methods in both reconstruction and synthesis quality.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Dual-Stage Cross-Modal Network with Dynamic Feature Fusion for Emotional
  Mimicry Intensity Estimation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10603v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10603v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jun Yu, Lingsi Zhu, Yanjun Chi, Yunxiang Zhang, Yang Zheng, Yongqi Wang, Xilong Lu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Emotional Mimicry Intensity (EMI) estimation serves as a critical technology
for understanding human social behavior and enhancing human-computer
interaction experiences, where the core challenge lies in dynamic correlation
modeling and robust fusion of multimodal temporal signals. To address the
limitations of existing methods in insufficient exploitation of modal
synergistic effects, noise sensitivity, and limited fine-grained alignment
capabilities, this paper proposes a dual-stage cross-modal alignment framework.
First, we construct vision-text and audio-text contrastive learning networks
based on an improved CLIP architecture, achieving preliminary alignment in the
feature space through modality-decoupled pre-training. Subsequently, we design
a temporal-aware dynamic fusion module that combines Temporal Convolutional
Networks (TCN) and gated bidirectional LSTM to respectively capture the
macro-evolution patterns of facial expressions and local dynamics of acoustic
features. Innovatively, we introduce a quality-guided modality fusion strategy
that enables modality compensation under occlusion and noisy scenarios through
differentiable weight allocation. Experimental results on the Hume-Vidmimic2
dataset demonstrate that our method achieves an average Pearson correlation
coefficient of 0.35 across six emotion dimensions, outperforming the best
baseline by 40\%. Ablation studies further validate the effectiveness of the
dual-stage training strategy and dynamic fusion mechanism, providing a novel
technical pathway for fine-grained emotion analysis in open environments.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ TruthPrInt: Mitigating LVLM Object Hallucination Via Latent
  Truthful-Guided Pre-Intervention 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10602v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10602v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jinhao Duan, Fei Kong, Hao Cheng, James Diffenderfer, Bhavya Kailkhura, Lichao Sun, Xiaofeng Zhu, Xiaoshuang Shi, Kaidi Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Object Hallucination (OH) has been acknowledged as one of the major
trustworthy challenges in Large Vision-Language Models (LVLMs). Recent
advancements in Large Language Models (LLMs) indicate that internal states,
such as hidden states, encode the "overall truthfulness" of generated
responses. However, it remains under-explored how internal states in LVLMs
function and whether they could serve as "per-token" hallucination indicators,
which is essential for mitigating OH. In this paper, we first conduct an
in-depth exploration of LVLM internal states in relation to OH issues and
discover that (1) LVLM internal states are high-specificity per-token
indicators of hallucination behaviors. Moreover, (2) different LVLMs encode
universal patterns of hallucinations in common latent subspaces, indicating
that there exist "generic truthful directions" shared by various LVLMs. Based
on these discoveries, we propose Truthful-Guided Pre-Intervention (TruthPrInt)
that first learns the truthful direction of LVLM decoding and then applies
truthful-guided inference-time intervention during LVLM decoding. We further
propose ComnHallu to enhance both cross-LVLM and cross-data hallucination
detection transferability by constructing and aligning hallucination latent
subspaces. We evaluate TruthPrInt in extensive experimental settings, including
in-domain and out-of-domain scenarios, over popular LVLMs and OH benchmarks.
Experimental results indicate that TruthPrInt significantly outperforms
state-of-the-art methods. Codes will be available at
https://github.com/jinhaoduan/TruthPrInt.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15 pages, 9 figures, the first two authors contributed equally</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ GroomLight: Hybrid Inverse Rendering for Relightable Human Hair
  Appearance Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10597v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10597v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yang Zheng, Menglei Chai, Delio Vicini, Yuxiao Zhou, Yinghao Xu, Leonidas Guibas, Gordon Wetzstein, Thabo Beeler
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present GroomLight, a novel method for relightable hair appearance
modeling from multi-view images. Existing hair capture methods struggle to
balance photorealistic rendering with relighting capabilities. Analytical
material models, while physically grounded, often fail to fully capture
appearance details. Conversely, neural rendering approaches excel at view
synthesis but generalize poorly to novel lighting conditions. GroomLight
addresses this challenge by combining the strengths of both paradigms. It
employs an extended hair BSDF model to capture primary light transport and a
light-aware residual model to reconstruct the remaining details. We further
propose a hybrid inverse rendering pipeline to optimize both components,
enabling high-fidelity relighting, view synthesis, and material editing.
Extensive evaluations on real-world hair data demonstrate state-of-the-art
performance of our method.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project Page: https://syntec-research.github.io/GroomLight</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ GroundingSuite: Measuring Complex Multi-Granular Pixel Grounding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10596v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10596v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rui Hu, Lianghui Zhu, Yuxuan Zhang, Tianheng Cheng, Lei Liu, Heng Liu, Longjin Ran, Xiaoxin Chen, Wenyu Liu, Xinggang Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Pixel grounding, encompassing tasks such as Referring Expression Segmentation
(RES), has garnered considerable attention due to its immense potential for
bridging the gap between vision and language modalities. However, advancements
in this domain are currently constrained by limitations inherent in existing
datasets, including limited object categories, insufficient textual diversity,
and a scarcity of high-quality annotations. To mitigate these limitations, we
introduce GroundingSuite, which comprises: (1) an automated data annotation
framework leveraging multiple Vision-Language Model (VLM) agents; (2) a
large-scale training dataset encompassing 9.56 million diverse referring
expressions and their corresponding segmentations; and (3) a meticulously
curated evaluation benchmark consisting of 3,800 images. The GroundingSuite
training dataset facilitates substantial performance improvements, enabling
models trained on it to achieve state-of-the-art results. Specifically, a cIoU
of 68.9 on gRefCOCO and a gIoU of 55.3 on RefCOCOm. Moreover, the
GroundingSuite annotation framework demonstrates superior efficiency compared
to the current leading data annotation method, i.e., $4.5 \times$ faster than
the GLaMM.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in progress. Code: https://github.com/hustvl/GroundingSuite</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Poly-MgNet: Polynomial Building Blocks in Multigrid-Inspired ResNets 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10594v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10594v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Antonia van Betteray, Matthias Rottmann, Karsten Kahl
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The structural analogies of ResNets and Multigrid (MG) methods such as common
building blocks like convolutions and poolings where already pointed out by He
et al.\ in 2016. Multigrid methods are used in the context of scientific
computing for solving large sparse linear systems arising from partial
differential equations. MG methods particularly rely on two main concepts:
smoothing and residual restriction / coarsening. Exploiting these analogies, He
and Xu developed the MgNet framework, which integrates MG schemes into the
design of ResNets. In this work, we introduce a novel neural network building
block inspired by polynomial smoothers from MG theory. Our polynomial block
from an MG perspective naturally extends the MgNet framework to Poly-Mgnet and
at the same time reduces the number of weights in MgNet. We present a
comprehensive study of our polynomial block, analyzing the choice of initial
coefficients, the polynomial degree, the placement of activation functions, as
well as of batch normalizations. Our results demonstrate that constructing
(quadratic) polynomial building blocks based on real and imaginary polynomial
roots enhances Poly-MgNet's capacity in terms of accuracy. Furthermore, our
approach achieves an improved trade-off of model accuracy and number of weights
compared to ResNet as well as compared to specific configurations of MgNet.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CameraCtrl II: Dynamic Scene Exploration via Camera-controlled Video
  Diffusion Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10592v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10592v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hao He, Ceyuan Yang, Shanchuan Lin, Yinghao Xu, Meng Wei, Liangke Gui, Qi Zhao, Gordon Wetzstein, Lu Jiang, Hongsheng Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces CameraCtrl II, a framework that enables large-scale
dynamic scene exploration through a camera-controlled video diffusion model.
Previous camera-conditioned video generative models suffer from diminished
video dynamics and limited range of viewpoints when generating videos with
large camera movement. We take an approach that progressively expands the
generation of dynamic scenes -- first enhancing dynamic content within
individual video clip, then extending this capability to create seamless
explorations across broad viewpoint ranges. Specifically, we construct a
dataset featuring a large degree of dynamics with camera parameter annotations
for training while designing a lightweight camera injection module and training
scheme to preserve dynamics of the pretrained models. Building on these
improved single-clip techniques, we enable extended scene exploration by
allowing users to iteratively specify camera trajectories for generating
coherent video sequences. Experiments across diverse scenarios demonstrate that
CameraCtrl Ii enables camera-controlled dynamic scene synthesis with
substantially wider spatial exploration than previous approaches.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project page: https://hehao13.github.io/Projects-CameraCtrl-II/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Long Context Tuning for Video Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10589v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10589v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuwei Guo, Ceyuan Yang, Ziyan Yang, Zhibei Ma, Zhijie Lin, Zhenheng Yang, Dahua Lin, Lu Jiang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in video generation can produce realistic, minute-long
single-shot videos with scalable diffusion transformers. However, real-world
narrative videos require multi-shot scenes with visual and dynamic consistency
across shots. In this work, we introduce Long Context Tuning (LCT), a training
paradigm that expands the context window of pre-trained single-shot video
diffusion models to learn scene-level consistency directly from data. Our
method expands full attention mechanisms from individual shots to encompass all
shots within a scene, incorporating interleaved 3D position embedding and an
asynchronous noise strategy, enabling both joint and auto-regressive shot
generation without additional parameters. Models with bidirectional attention
after LCT can further be fine-tuned with context-causal attention, facilitating
auto-regressive generation with efficient KV-cache. Experiments demonstrate
single-shot models after LCT can produce coherent multi-shot scenes and exhibit
emerging capabilities, including compositional generation and interactive shot
extension, paving the way for more practical visual content creation. See
https://guoyww.github.io/projects/long-context-video/ for more details.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project Page: https://guoyww.github.io/projects/long-context-video/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Unlock the Power of Unlabeled Data in Language Driving Model <span class="chip">ICRA2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10586v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10586v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chaoqun Wang, Jie Yang, Xiaobin Hong, Ruimao Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent Vision-based Large Language Models~(VisionLLMs) for autonomous driving
have seen rapid advancements. However, such promotion is extremely dependent on
large-scale high-quality annotated data, which is costly and labor-intensive.
To address this issue, we propose unlocking the value of abundant yet unlabeled
data to improve the language-driving model in a semi-supervised learning
manner. Specifically, we first introduce a series of template-based prompts to
extract scene information, generating questions that create pseudo-answers for
the unlabeled data based on a model trained with limited labeled data. Next, we
propose a Self-Consistency Refinement method to improve the quality of these
pseudo-annotations, which are later used for further training. By utilizing a
pre-trained VisionLLM (e.g., InternVL), we build a strong Language Driving
Model (LDM) for driving scene question-answering, outperforming previous
state-of-the-art methods. Extensive experiments on the DriveLM benchmark show
that our approach performs well with just 5% labeled data, achieving
competitive performance against models trained with full datasets. In
particular, our LDM achieves 44.85% performance with limited labeled data,
increasing to 54.27% when using unlabeled data, while models trained with full
datasets reach 60.68% on the DriveLM benchmark.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ICRA2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ VisualWebInstruct: Scaling up Multimodal Instruction Data through Web
  Search 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10582v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10582v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yiming Jia, Jiachen Li, Xiang Yue, Bo Li, Ping Nie, Kai Zou, Wenhu Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision-Language Models have made significant progress on many
perception-focused tasks, however, their progress on reasoning-focused tasks
seem to be limited due to the lack of high-quality and diverse training data.
In this work, we aim to address the scarcity issue of reasoning-focused
multimodal datasets. We propose VisualWebInstruct - a novel approach that
leverages search engine to create a diverse, and high-quality dataset spanning
multiple disciplines like math, physics, finance, chemistry, etc. Starting with
meticulously selected 30,000 seed images, we employ Google Image search to
identify websites containing similar images. We collect and process the HTMLs
from over 700K unique URL sources. Through a pipeline of content extraction,
filtering and synthesis, we build a dataset of approximately 900K
question-answer pairs, with 40% being visual QA pairs and the rest as text QA
pairs. Models fine-tuned on VisualWebInstruct demonstrate significant
performance gains: (1) training from Llava-OV-mid shows 10-20% absolute point
gains across benchmarks, (2) training from MAmmoTH-VL shows 5% absoluate gain.
Our best model MAmmoTH-VL2 shows state-of-the-art performance within the 10B
parameter class on MMMU-Pro-std (40.7%), MathVerse (42.6%), and DynaMath
(55.7%). These remarkable results highlight the effectiveness of our dataset in
enhancing VLMs' reasoning capabilities for complex multimodal tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Technical Report</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Semantic-Supervised Spatial-Temporal Fusion for LiDAR-based 3D Object
  Detection <span class="chip">ICRA2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10579v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10579v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chaoqun Wang, Xiaobin Hong, Wenzhong Li, Ruimao Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  LiDAR-based 3D object detection presents significant challenges due to the
inherent sparsity of LiDAR points. A common solution involves long-term
temporal LiDAR data to densify the inputs. However, efficiently leveraging
spatial-temporal information remains an open problem. In this paper, we propose
a novel Semantic-Supervised Spatial-Temporal Fusion (ST-Fusion) method, which
introduces a novel fusion module to relieve the spatial misalignment caused by
the object motion over time and a feature-level semantic supervision to
sufficiently unlock the capacity of the proposed fusion module. Specifically,
the ST-Fusion consists of a Spatial Aggregation (SA) module and a Temporal
Merging (TM) module. The SA module employs a convolutional layer with
progressively expanding receptive fields to aggregate the object features from
the local regions to alleviate the spatial misalignment, the TM module
dynamically extracts object features from the preceding frames based on the
attention mechanism for a comprehensive sequential presentation. Besides, in
the semantic supervision, we propose a Semantic Injection method to enrich the
sparse LiDAR data via injecting the point-wise semantic labels, using it for
training a teacher model and providing a reconstruction target at the feature
level supervised by the proposed object-aware loss. Extensive experiments on
various LiDAR-based detectors demonstrate the effectiveness and universality of
our proposal, yielding an improvement of approximately +2.8% in NDS based on
the nuScenes benchmark.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ICRA2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Autoregressive Image Generation with Randomized Parallel Decoding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10568v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10568v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haopeng Li, Jinyue Yang, Guoqi Li, Huan Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce ARPG, a novel visual autoregressive model that enables
randomized parallel generation, addressing the inherent limitations of
conventional raster-order approaches, which hinder inference efficiency and
zero-shot generalization due to their sequential, predefined token generation
order. Our key insight is that effective random-order modeling necessitates
explicit guidance for determining the position of the next predicted token. To
this end, we propose a novel guided decoding framework that decouples
positional guidance from content representation, encoding them separately as
queries and key-value pairs. By directly incorporating this guidance into the
causal attention mechanism, our approach enables fully random-order training
and generation, eliminating the need for bidirectional attention. Consequently,
ARPG readily generalizes to zero-shot tasks such as image inpainting,
outpainting, and resolution expansion. Furthermore, it supports parallel
inference by concurrently processing multiple queries using a shared KV cache.
On the ImageNet-1K 256 benchmark, our approach attains an FID of 1.94 with only
64 sampling steps, achieving over a 20-fold increase in throughput while
reducing memory consumption by over 75% compared to representative recent
autoregressive models at a similar scale.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MASQUE: A Text-Guided Diffusion-Based Framework for Localized and
  Customized Adversarial Makeup 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10549v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10549v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Youngjin Kwon, Xiao Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As facial recognition is increasingly adopted for government and commercial
services, its potential misuse has raised serious concerns about privacy and
civil rights. To counteract, various anti-facial recognition techniques have
been proposed for privacy protection by adversarially perturbing face images,
among which generative makeup-based approaches are the most popular. However,
these methods, designed primarily to impersonate specific target identities,
can only achieve weak dodging success rates while increasing the risk of
targeted abuse. In addition, they often introduce global visual artifacts or a
lack of adaptability to accommodate diverse makeup prompts, compromising user
satisfaction. To address the above limitations, we develop MASQUE, a novel
diffusion-based framework that generates localized adversarial makeups guided
by user-defined text prompts. Built upon precise null-text inversion,
customized cross-attention fusion with masking, and a pairwise adversarial
guidance mechanism using images of the same individual, MASQUE achieves robust
dodging performance without requiring any external identity. Comprehensive
evaluations on open-source facial recognition models and commercial APIs
demonstrate that MASQUE significantly improves dodging success rates over all
baselines, along with higher perceptual fidelity and stronger adaptability to
various text makeup prompts.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Learning Interpretable Logic Rules from Deep Vision Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10547v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10547v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chuqin Geng, Yuhe Jiang, Ziyu Zhao, Haolin Ye, Zhaoyue Wang, Xujie Si
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose a general framework called VisionLogic to extract interpretable
logic rules from deep vision models, with a focus on image classification
tasks. Given any deep vision model that uses a fully connected layer as the
output head, VisionLogic transforms neurons in the last layer into predicates
and grounds them into vision concepts using causal validation. In this way,
VisionLogic can provide local explanations for single images and global
explanations for specific classes in the form of logic rules. Compared to
existing interpretable visualization tools such as saliency maps, VisionLogic
addresses several key challenges, including the lack of causal explanations,
overconfidence in visualizations, and ambiguity in interpretation. VisionLogic
also facilitates the study of visual concepts encoded by predicates,
particularly how they behave under perturbation -- an area that remains
underexplored in the field of hidden semantics. Apart from providing better
visual explanations and insights into the visual concepts learned by the model,
we show that VisionLogic retains most of the neural network's discriminative
power in an interpretable and transparent manner. We envision it as a bridge
between complex model behavior and human-understandable explanations, providing
trustworthy and actionable insights for real-world applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Lightweight Models for Emotional Analysis in Video 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10530v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10530v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Quoc-Tien Nguyen, Hong-Hai Nguyen, Van-Thong Huynh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this study, we present an approach for efficient spatiotemporal feature
extraction using MobileNetV4 and a multi-scale 3D MLP-Mixer-based temporal
aggregation module. MobileNetV4, with its Universal Inverted Bottleneck (UIB)
blocks, serves as the backbone for extracting hierarchical feature
representations from input image sequences, ensuring both computational
efficiency and rich semantic encoding. To capture temporal dependencies, we
introduce a three-level MLP-Mixer module, which processes spatial features at
multiple resolutions while maintaining structural integrity. Experimental
results on the ABAW 8th competition demonstrate the effectiveness of our
approach, showing promising performance in affective behavior analysis. By
integrating an efficient vision backbone with a structured temporal modeling
mechanism, the proposed framework achieves a balance between computational
efficiency and predictive accuracy, making it well-suited for real-time
applications in mobile and embedded computing environments.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PiSA: A Self-Augmented Data Engine and Training Strategy for 3D
  Understanding with Large Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10529v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10529v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zilu Guo, Hongbin Lin, Zhihao Yuan, Chaoda Zheng, Pengshuo Qiu, Dongzhi Jiang, Renrui Zhang, Chun-Mei Feng, Zhen Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  3D Multimodal Large Language Models (MLLMs) have recently made substantial
advancements. However, their potential remains untapped, primarily due to the
limited quantity and suboptimal quality of 3D datasets. Current approaches
attempt to transfer knowledge from 2D MLLMs to expand 3D instruction data, but
still face modality and domain gaps. To this end, we introduce PiSA-Engine
(Point-Self-Augmented-Engine), a new framework for generating instruction
point-language datasets enriched with 3D spatial semantics. We observe that
existing 3D MLLMs offer a comprehensive understanding of point clouds for
annotation, while 2D MLLMs excel at cross-validation by providing complementary
information. By integrating holistic 2D and 3D insights from off-the-shelf
MLLMs, PiSA-Engine enables a continuous cycle of high-quality data generation.
We select PointLLM as the baseline and adopt this co-evolution training
framework to develop an enhanced 3D MLLM, termed PointLLM-PiSA. Additionally,
we identify limitations in previous 3D benchmarks, which often feature coarse
language captions and insufficient category diversity, resulting in inaccurate
evaluations. To address this gap, we further introduce PiSA-Bench, a
comprehensive 3D benchmark covering six key aspects with detailed and diverse
labels. Experimental results demonstrate PointLLM-PiSA's state-of-the-art
performance in zero-shot 3D object captioning and generative classification on
our PiSA-Bench, achieving significant improvements of 46.45% (+8.33%) and
63.75% (+16.25%), respectively. We will release the code, datasets, and
benchmark.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Technical Report</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ How Should We Evaluate Uncertainty in Accelerated MRI Reconstruction? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10527v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10527v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Luca Trautmann, Peter Wijeratne, Itamar Ronen, Ivor Simpson
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reconstructing accelerated MRI is an ill-posed problem. Machine learning has
recently shown great promise at this task, but current approaches to
quantifying uncertainty focus on measuring the variability in pixelwise
intensity variation. Although these provide interpretable maps, they lack
structural understanding and they do not have a clear relationship to how the
data will be analysed subsequently. In this paper, we propose a new approach to
evaluating reconstruction variability based on apparent anatomical changes in
the reconstruction, which is more tightly related to common downstream tasks.
We use image registration and segmentation to evaluate several common MRI
reconstruction approaches, where uncertainty is measured via ensembling, for
accelerated imaging. We demonstrate the intrinsic variability in reconstructed
images and show that models with high scores on often used quality metrics such
as SSIM and PSNR, can nonetheless display high levels of variance and bias in
anatomical measures.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ NeighborRetr: Balancing Hub Centrality in Cross-Modal Retrieval <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10526v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10526v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zengrong Lin, Zheng Wang, Tianwen Qian, Pan Mu, Sixian Chan, Cong Bai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Cross-modal retrieval aims to bridge the semantic gap between different
modalities, such as visual and textual data, enabling accurate retrieval across
them. Despite significant advancements with models like CLIP that align
cross-modal representations, a persistent challenge remains: the hubness
problem, where a small subset of samples (hubs) dominate as nearest neighbors,
leading to biased representations and degraded retrieval accuracy. Existing
methods often mitigate hubness through post-hoc normalization techniques,
relying on prior data distributions that may not be practical in real-world
scenarios. In this paper, we directly mitigate hubness during training and
introduce NeighborRetr, a novel method that effectively balances the learning
of hubs and adaptively adjusts the relations of various kinds of neighbors. Our
approach not only mitigates the hubness problem but also enhances retrieval
performance, achieving state-of-the-art results on multiple cross-modal
retrieval benchmarks. Furthermore, NeighborRetr demonstrates robust
generalization to new domains with substantial distribution shifts,
highlighting its effectiveness in real-world applications. We make our code
publicly available at: https://github.com/zzezze/NeighborRetr .
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at CVPR 2025, 18 pages, 7 figures, 13 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Interactive Multimodal Fusion with Temporal Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10523v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10523v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jun Yu, Yongqi Wang, Lei Wang, Yang Zheng, Shengfan Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents our method for the estimation of valence-arousal (VA) in
the 8th Affective Behavior Analysis in-the-Wild (ABAW) competition. Our
approach integrates visual and audio information through a multimodal
framework. The visual branch uses a pre-trained ResNet model to extract spatial
features from facial images. The audio branches employ pre-trained VGG models
to extract VGGish and LogMel features from speech signals. These features
undergo temporal modeling using Temporal Convolutional Networks (TCNs). We then
apply cross-modal attention mechanisms, where visual features interact with
audio features through query-key-value attention structures. Finally, the
features are concatenated and passed through a regression layer to predict
valence and arousal. Our method achieves competitive performance on the
Aff-Wild2 dataset, demonstrating effective multimodal fusion for VA estimation
in-the-wild.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ AudioX: Diffusion Transformer for Anything-to-Audio Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10522v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10522v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zeyue Tian, Yizhu Jin, Zhaoyang Liu, Ruibin Yuan, Xu Tan, Qifeng Chen, Wei Xue, Yike Guo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Audio and music generation have emerged as crucial tasks in many
applications, yet existing approaches face significant limitations: they
operate in isolation without unified capabilities across modalities, suffer
from scarce high-quality, multi-modal training data, and struggle to
effectively integrate diverse inputs. In this work, we propose AudioX, a
unified Diffusion Transformer model for Anything-to-Audio and Music Generation.
Unlike previous domain-specific models, AudioX can generate both general audio
and music with high quality, while offering flexible natural language control
and seamless processing of various modalities including text, video, image,
music, and audio. Its key innovation is a multi-modal masked training strategy
that masks inputs across modalities and forces the model to learn from masked
inputs, yielding robust and unified cross-modal representations. To address
data scarcity, we curate two comprehensive datasets: vggsound-caps with 190K
audio captions based on the VGGSound dataset, and V2M-caps with 6 million music
captions derived from the V2M dataset. Extensive experiments demonstrate that
AudioX not only matches or outperforms state-of-the-art specialized models, but
also offers remarkable versatility in handling diverse input modalities and
generation tasks within a unified architecture. The code and datasets will be
available at https://zeyuet.github.io/AudioX/
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The code and datasets will be available at
  https://zeyuet.github.io/AudioX/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CountPath: Automating Fragment Counting in Digital Pathology 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10520v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10520v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ana Beatriz Vieira, Maria Valente, Diana Montezuma, Tomé Albuquerque, Liliana Ribeiro, Domingos Oliveira, João Monteiro, Sofia Gonçalves, Isabel M. Pinto, Jaime S. Cardoso, Arlindo L. Oliveira
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Quality control of medical images is a critical component of digital
pathology, ensuring that diagnostic images meet required standards. A
pre-analytical task within this process is the verification of the number of
specimen fragments, a process that ensures that the number of fragments on a
slide matches the number documented in the macroscopic report. This step is
important to ensure that the slides contain the appropriate diagnostic material
from the grossing process, thereby guaranteeing the accuracy of subsequent
microscopic examination and diagnosis. Traditionally, this assessment is
performed manually, requiring significant time and effort while being subject
to significant variability due to its subjective nature. To address these
challenges, this study explores an automated approach to fragment counting
using the YOLOv9 and Vision Transformer models. Our results demonstrate that
the automated system achieves a level of performance comparable to expert
assessments, offering a reliable and efficient alternative to manual counting.
Additionally, we present findings on interobserver variability, showing that
the automated approach achieves an accuracy of 86%, which falls within the
range of variation observed among experts (82-88%), further supporting its
potential for integration into routine pathology workflows.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Hoi2Anomaly: An Explainable Anomaly Detection Approach Guided by
  Human-Object Interaction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10508v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10508v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuhan Wang, Cheng Liu, Daou Zhang, Weichao Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the domain of Image Anomaly Detection (IAD), Existing methods frequently
exhibit a paucity of fine-grained, interpretable semantic information,
resulting in the detection of anomalous entities or activities that are
susceptible to machine illusions. This deficiency often leads to the detection
of anomalous entities or actions that are susceptible to machine illusions and
lack sufficient explanation. In this thesis, we propose a novel approach to
anomaly detection, termed Hoi2Anomaly, which aims to achieve precise
discrimination and localization of anomalies. The proposed methodology involves
the construction of a multi-modal instruction tuning dataset comprising
human-object interaction (HOI) pairs in anomalous scenarios. Second, we have
trained an HOI extractor in threat scenarios to localize and match anomalous
actions and entities. Finally, explanatory content is generated for the
detected anomalous HOI by fine-tuning the visual language pretraining (VLP)
framework. The experimental results demonstrate that Hoi2Anomaly surpasses
existing generative approaches in terms of precision and explainability. We
will release Hoi2Anomaly for the advancement of the field of anomaly detection.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ TokenCarve: Information-Preserving Visual Token Compression in
  Multimodal Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10501v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10501v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xudong Tan, Peng Ye, Chongjun Tu, Jianjian Cao, Yaoxin Yang, Lin Zhang, Dongzhan Zhou, Tao Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal Large Language Models (MLLMs) are becoming increasingly popular,
while the high computational cost associated with multimodal data input,
particularly from visual tokens, poses a significant challenge. Existing
training-based token compression methods improve inference efficiency but
require costly retraining, while training-free methods struggle to maintain
performance when aggressively reducing token counts. In this study, we reveal
that the performance degradation of MLLM closely correlates with the
accelerated loss of information in the attention output matrix. This insight
introduces a novel information-preserving perspective, making it possible to
maintain performance even under extreme token compression. Based on this
finding, we propose TokenCarve, a training-free, plug-and-play, two-stage token
compression framework. The first stage employs an
Information-Preservation-Guided Selection (IPGS) strategy to prune
low-information tokens, while the second stage further leverages IPGS to guide
token merging, minimizing information loss. Extensive experiments on 11
datasets and 2 model variants demonstrate the effectiveness of TokenCarve. It
can even reduce the number of visual tokens to 22.2% of the original count,
achieving a 1.23x speedup in inference, a 64% reduction in KV cache storage,
and only a 1.54% drop in accuracy. Our code is available at
https://github.com/ShawnTan86/TokenCarve.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ OmniSTVG: Toward Spatio-Temporal Omni-Object Video Grounding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10500v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10500v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiali Yao, Xinran Deng, Xin Gu, Mengrui Dai, Bing Fan, Zhipeng Zhang, Yan Huang, Heng Fan, Libo Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we propose spatio-temporal omni-object video grounding, dubbed
OmniSTVG, a new STVG task that aims at localizing spatially and temporally all
targets mentioned in the textual query from videos. Compared to classic STVG
locating only a single target, OmniSTVG enables localization of not only an
arbitrary number of text-referred targets but also their interacting
counterparts in the query from the video, making it more flexible and practical
in real scenarios for comprehensive understanding. In order to facilitate
exploration of OmniSTVG, we introduce BOSTVG, a large-scale benchmark dedicated
to OmniSTVG. Specifically, our BOSTVG consists of 10,018 videos with 10.2M
frames and covers a wide selection of 287 classes from diverse scenarios. Each
sequence in BOSTVG, paired with a free-form textual query, encompasses a
varying number of targets ranging from 1 to 10. To ensure high quality, each
video is manually annotated with meticulous inspection and refinement. To our
best knowledge, BOSTVG is to date the first and the largest benchmark for
OmniSTVG. To encourage future research, we introduce a simple yet effective
approach, named OmniTube, which, drawing inspiration from Transformer-based
STVG methods, is specially designed for OmniSTVG and demonstrates promising
results. By releasing BOSTVG, we hope to go beyond classic STVG by locating
every object appearing in the query for more comprehensive understanding,
opening up a new direction for STVG. Our benchmark, model, and results will be
released at https://github.com/JellyYao3000/OmniSTVG.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Streaming Generation of Co-Speech Gestures via Accelerated Rolling
  Diffusion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10488v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10488v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Evgeniia Vu, Andrei Boiarov, Dmitry Vetrov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generating co-speech gestures in real time requires both temporal coherence
and efficient sampling. We introduce Accelerated Rolling Diffusion, a novel
framework for streaming gesture generation that extends rolling diffusion
models with structured progressive noise scheduling, enabling seamless
long-sequence motion synthesis while preserving realism and diversity. We
further propose Rolling Diffusion Ladder Acceleration (RDLA), a new approach
that restructures the noise schedule into a stepwise ladder, allowing multiple
frames to be denoised simultaneously. This significantly improves sampling
efficiency while maintaining motion consistency, achieving up to a 2x speedup
with high visual fidelity and temporal coherence. We evaluate our approach on
ZEGGS and BEAT, strong benchmarks for real-world applicability. Our framework
is universally applicable to any diffusion-based gesture generation model,
transforming it into a streaming approach. Applied to three state-of-the-art
methods, it consistently outperforms them, demonstrating its effectiveness as a
generalizable and efficient solution for real-time, high-fidelity co-speech
gesture synthesis.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ World Modeling Makes a Better <span class="highlight-title">Plan</span>ner: Dual Preference <span class="highlight-title">Optimization</span> for
  Embodied Task <span class="highlight-title">Plan</span>ning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10480v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10480v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Siyin Wang, Zhaoye Fei, Qinyuan Cheng, Shiduo Zhang, Panpan Cai, Jinlan Fu, Xipeng Qiu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in large vision-language models (LVLMs) have shown promise
for embodied task planning, yet they struggle with fundamental challenges like
dependency constraints and efficiency. Existing approaches either solely
optimize action selection or leverage world models during inference,
overlooking the benefits of learning to model the world as a way to enhance
planning capabilities. We propose Dual Preference Optimization (D$^2$PO), a new
learning framework that jointly optimizes state prediction and action selection
through preference learning, enabling LVLMs to understand environment dynamics
for better planning. To automatically collect trajectories and stepwise
preference data without human annotation, we introduce a tree search mechanism
for extensive exploration via trial-and-error. Extensive experiments on
VoTa-Bench demonstrate that our D$^2$PO-based method significantly outperforms
existing methods and GPT-4o when applied to Qwen2-VL (7B), LLaVA-1.6 (7B), and
LLaMA-3.2 (11B), achieving superior task success rates with more efficient
execution paths.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ OODD: Test-time Out-of-Distribution Detection with Dynamic Dictionary 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10468v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10468v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yifeng Yang, Lin Zhu, Zewen Sun, Hengyu Liu, Qinying Gu, Nanyang Ye
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Out-of-distribution (OOD) detection remains challenging for deep learning
models, particularly when test-time OOD samples differ significantly from
training outliers. We propose OODD, a novel test-time OOD detection method that
dynamically maintains and updates an OOD dictionary without fine-tuning. Our
approach leverages a priority queue-based dictionary that accumulates
representative OOD features during testing, combined with an informative inlier
sampling strategy for in-distribution (ID) samples. To ensure stable
performance during early testing, we propose a dual OOD stabilization mechanism
that leverages strategically generated outliers derived from ID data. To our
best knowledge, extensive experiments on the OpenOOD benchmark demonstrate that
OODD significantly outperforms existing methods, achieving a 26.0% improvement
in FPR95 on CIFAR-100 Far OOD detection compared to the state-of-the-art
approach. Furthermore, we present an optimized variant of the KNN-based OOD
detection framework that achieves a 3x speedup while maintaining detection
performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Flow-NeRF: Joint Learning of Geometry, Poses, and Dense Flow within
  Unified Neural Representations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10464v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10464v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xunzhi Zheng, Dan Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Learning accurate scene reconstruction without pose priors in neural radiance
fields is challenging due to inherent geometric ambiguity. Recent development
either relies on correspondence priors for regularization or uses off-the-shelf
flow estimators to derive analytical poses. However, the potential for jointly
learning scene geometry, camera poses, and dense flow within a unified neural
representation remains largely unexplored. In this paper, we present Flow-NeRF,
a unified framework that simultaneously optimizes scene geometry, camera poses,
and dense optical flow all on-the-fly. To enable the learning of dense flow
within the neural radiance field, we design and build a bijective mapping for
flow estimation, conditioned on pose. To make the scene reconstruction benefit
from the flow estimation, we develop an effective feature enhancement mechanism
to pass canonical space features to world space representations, significantly
enhancing scene geometry. We validate our model across four important tasks,
i.e., novel view synthesis, depth estimation, camera pose prediction, and dense
optical flow estimation, using several datasets. Our approach surpasses
previous methods in almost all metrics for novel-view view synthesis and depth
estimation and yields both qualitatively sound and quantitatively accurate
novel-view flow. Our project page is https://zhengxunzhi.github.io/flownerf/.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Consistent multi-animal pose estimation in cattle using dynamic Kalman
  filter based tracking 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10450v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10450v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Maarten Perneel, Ines Adriaens, Ben Aernouts, Jan Verwaeren
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Over the past decade, studying animal behaviour with the help of computer
vision has become more popular. Replacing human observers by computer vision
lowers the cost of data collection and therefore allows to collect more
extensive datasets. However, the majority of available computer vision
algorithms to study animal behaviour is highly tailored towards a single
research objective, limiting possibilities for data reuse. In this perspective,
pose-estimation in combination with animal tracking offers opportunities to
yield a higher level representation capturing both the spatial and temporal
component of animal behaviour. Such a higher level representation allows to
answer a wide variety of research questions simultaneously, without the need to
develop repeatedly tailored computer vision algorithms. In this paper, we
therefore first cope with several weaknesses of current pose-estimation
algorithms and thereafter introduce KeySORT (Keypoint Simple and Online
Realtime Tracking). KeySORT deploys an adaptive Kalman filter to construct
tracklets in a bounding-box free manner, significantly improving the temporal
consistency of detected keypoints. In this paper, we focus on pose estimation
in cattle, but our methodology can easily be generalised to any other animal
species. Our test results indicate our algorithm is able to detect up to 80% of
the ground truth keypoints with high accuracy, with only a limited drop in
performance when daylight recordings are compared to nightvision recordings.
Moreover, by using KeySORT to construct skeletons, the temporal consistency of
generated keypoint coordinates was largely improved, offering opportunities
with regard to automated behaviour monitoring of animals.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Learning Disease State from Noisy Ordinal Disease Progression Labels 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10440v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10440v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gustav Schmidt, Holger Heidrich, Philipp Berens, Sarah Müller
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Learning from noisy ordinal labels is a key challenge in medical imaging. In
this work, we ask whether ordinal disease progression labels (better, worse, or
stable) can be used to learn a representation allowing to classify disease
state. For neovascular age-related macular degeneration (nAMD), we cast the
problem of modeling disease progression between medical visits as a
classification task with ordinal ranks. To enhance generalization, we tailor
our model to the problem setting by (1) independent image encoding, (2)
antisymmetric logit space equivariance, and (3) ordinal scale awareness. In
addition, we address label noise by learning an uncertainty estimate for loss
re-weighting. Our approach learns an interpretable disease representation
enabling strong few-shot performance for the related task of nAMD activity
classification from single images, despite being trained only on image pairs
with ordinal disease progression labels.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ EFC++: Elastic Feature Consolidation with Prototype Re-balancing for
  Cold Start Exemplar-free Incremental Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10439v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10439v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Simone Magistri, Tomaso Trinci, Albin Soutif-Cormerais, Joost van de Weijer, Andrew D. Bagdanov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Exemplar-Free Class Incremental Learning (EFCIL) aims to learn from a
sequence of tasks without having access to previous task data. In this paper,
we consider the challenging Cold Start scenario in which insufficient data is
available in the first task to learn a high-quality backbone. This is
especially challenging for EFCIL since it requires high plasticity, resulting
in feature drift which is difficult to compensate for in the exemplar-free
setting. To address this problem, we propose an effective approach to
consolidate feature representations by regularizing drift in directions highly
relevant to previous tasks and employs prototypes to reduce task-recency bias.
Our approach, which we call Elastic Feature Consolidation++ (EFC++) exploits a
tractable second-order approximation of feature drift based on a proposed
Empirical Feature Matrix (EFM). The EFM induces a pseudo-metric in feature
space which we use to regularize feature drift in important directions and to
update Gaussian prototypes. In addition, we introduce a post-training prototype
re-balancing phase that updates classifiers to compensate for feature drift.
Experimental results on CIFAR-100, Tiny-ImageNet, ImageNet-Subset, ImageNet-1K
and DomainNet demonstrate that EFC++ is better able to learn new tasks by
maintaining model plasticity and significantly outperform the state-of-the-art.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted on July 2024. Under Review. arXiv admin note: text overlap
  with arXiv:2402.03917</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ 4D LangSplat: 4D Language Gaussian Splatting via Multimodal Large
  Language Models <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10437v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10437v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wanhua Li, Renping Zhou, Jiawei Zhou, Yingwei Song, Johannes Herter, Minghan Qin, Gao Huang, Hanspeter Pfister
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Learning 4D language fields to enable time-sensitive, open-ended language
queries in dynamic scenes is essential for many real-world applications. While
LangSplat successfully grounds CLIP features into 3D Gaussian representations,
achieving precision and efficiency in 3D static scenes, it lacks the ability to
handle dynamic 4D fields as CLIP, designed for static image-text tasks, cannot
capture temporal dynamics in videos. Real-world environments are inherently
dynamic, with object semantics evolving over time. Building a precise 4D
language field necessitates obtaining pixel-aligned, object-wise video
features, which current vision models struggle to achieve. To address these
challenges, we propose 4D LangSplat, which learns 4D language fields to handle
time-agnostic or time-sensitive open-vocabulary queries in dynamic scenes
efficiently. 4D LangSplat bypasses learning the language field from vision
features and instead learns directly from text generated from object-wise video
captions via Multimodal Large Language Models (MLLMs). Specifically, we propose
a multimodal object-wise video prompting method, consisting of visual and text
prompts that guide MLLMs to generate detailed, temporally consistent,
high-quality captions for objects throughout a video. These captions are
encoded using a Large Language Model into high-quality sentence embeddings,
which then serve as pixel-aligned, object-specific feature supervision,
facilitating open-vocabulary text queries through shared embedding spaces.
Recognizing that objects in 4D scenes exhibit smooth transitions across states,
we further propose a status deformable network to model these continuous
changes over time effectively. Our results across multiple benchmarks
demonstrate that 4D LangSplat attains precise and efficient results for both
time-sensitive and time-agnostic open-vocabulary queries.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>CVPR 2025. Project Page: https://4d-langsplat.github.io</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Finetuning Generative Trajectory Model with Reinforcement Learning from
  Human Feedback 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10434v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10434v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Derun Li, Jianwei Ren, Yue Wang, Xin Wen, Pengxiang Li, Leimeng Xu, Kun Zhan, Zhongpu Xia, Peng Jia, Xianpeng Lang, Ningyi Xu, Hang Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generating human-like and adaptive trajectories is essential for autonomous
driving in dynamic environments. While generative models have shown promise in
synthesizing feasible trajectories, they often fail to capture the nuanced
variability of human driving styles due to dataset biases and distributional
shifts. To address this, we introduce TrajHF, a human feedback-driven
finetuning framework for generative trajectory models, designed to align motion
planning with diverse driving preferences. TrajHF incorporates
multi-conditional denoiser and reinforcement learning with human feedback to
refine multi-modal trajectory generation beyond conventional imitation
learning. This enables better alignment with human driving preferences while
maintaining safety and feasibility constraints. TrajHF achieves PDMS of 93.95
on NavSim benchmark, significantly exceeding other methods. TrajHF sets a new
paradigm for personalized and adaptable trajectory generation in autonomous
driving.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Low Complexity Point Tracking of the Myocardium in 2D Echocardiography 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10431v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10431v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Artem Chernyshov, John Nyberg, Vegard Holmstrøm, Md Abulkalam Azad, Bjørnar Grenne, Håvard Dalen, Svein Arne Aase, Lasse Lovstakken, Andreas Østvik
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep learning methods for point tracking are applicable in 2D
echocardiography, but do not yet take advantage of domain specifics that enable
extremely fast and efficient configurations. We developed MyoTracker, a
low-complexity architecture (0.3M parameters) for point tracking in
echocardiography. It builds on the CoTracker2 architecture by simplifying its
components and extending the temporal context to provide point predictions for
the entire sequence in a single step. We applied MyoTracker to the right
ventricular (RV) myocardium in RV-focused recordings and compared the results
with those of CoTracker2 and EchoTracker, another specialized point tracking
architecture for echocardiography. MyoTracker achieved the lowest average point
trajectory error at 2.00 $\pm$ 0.53 mm. Calculating RV Free Wall Strain (RV
FWS) using MyoTracker's point predictions resulted in a -0.3$\%$ bias with
95$\%$ limits of agreement from -6.1$\%$ to 5.4$\%$ compared to reference
values from commercial software. This range falls within the interobserver
variability reported in previous studies. The limits of agreement were wider
for both CoTracker2 and EchoTracker, worse than the interobserver variability.
At inference, MyoTracker used 67$\%$ less GPU memory than CoTracker2 and 84$\%$
less than EchoTracker on large sequences (100 frames). MyoTracker was 74 times
faster during inference than CoTracker2 and 11 times faster than EchoTracker
with our setup. Maintaining the entire sequence in the temporal context was the
greatest contributor to MyoTracker's accuracy. Slight additional gains can be
made by re-enabling iterative refinement, at the cost of longer processing
time.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Improving Medical Waste Classification with Hybrid Capsule Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10426v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10426v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bennet van den Broek, Javad Pourmostafa Roshan Sharami
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The improper disposal and mismanagement of medical waste pose severe
environmental and public health risks, contributing to greenhouse gas emissions
and the spread of infectious diseases. Efficient and accurate medical waste
classification is crucial for mitigating these risks. We explore the
integration of capsule networks with a pretrained DenseNet model to improve
medical waste classification. To the best of our knowledge, capsule networks
have not yet been applied to this task, making this study the first to assess
their effectiveness.
  A diverse dataset of medical waste images collected from multiple public
sources, is used to evaluate three model configurations: (1) a pretrained
DenseNet model as a baseline, (2) a pretrained DenseNet with frozen layers
combined with a capsule network, and (3) a pretrained DenseNet with unfrozen
layers combined with a capsule network. Experimental results demonstrate that
incorporating capsule networks improves classification performance, with F1
scores increasing from 0.89 (baseline) to 0.92 (hybrid model with unfrozen
layers). This highlights the potential of capsule networks to address the
spatial limitations of traditional convolutional models and improve
classification robustness.
  While the capsule-enhanced model demonstrated improved classification
performance, direct comparisons with prior studies were challenging due to
differences in dataset size and diversity. Previous studies relied on smaller,
domain-specific datasets, which inherently yielded higher accuracy. In
contrast, our study employs a significantly larger and more diverse dataset,
leading to better generalization but introducing additional classification
challenges. This highlights the trade-off between dataset complexity and model
performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Category Prompt Mamba Network for Nuclei Segmentation and Classification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10422v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10422v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ye Zhang, Zijie Fang, Yifeng Wang, Lingbo Zhang, Xianchao Guan, Yongbing Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Nuclei segmentation and classification provide an essential basis for tumor
immune microenvironment analysis. The previous nuclei segmentation and
classification models require splitting large images into smaller patches for
training, leading to two significant issues. First, nuclei at the borders of
adjacent patches often misalign during inference. Second, this patch-based
approach significantly increases the model's training and inference time.
Recently, Mamba has garnered attention for its ability to model large-scale
images with linear time complexity and low memory consumption. It offers a
promising solution for training nuclei segmentation and classification models
on full-sized images. However, the Mamba orientation-based scanning method
lacks account for category-specific features, resulting in sub-optimal
performance in scenarios with imbalanced class distributions. To address these
challenges, this paper introduces a novel scanning strategy based on category
probability sorting, which independently ranks and scans features for each
category according to confidence from high to low. This approach enhances the
feature representation of uncertain samples and mitigates the issues caused by
imbalanced distributions. Extensive experiments conducted on four public
datasets demonstrate that our method outperforms state-of-the-art approaches,
delivering superior performance in nuclei segmentation and classification
tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ RoCo-Sim: Enhancing Roadside Collaborative Perception through Foreground
  Simulation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10410v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10410v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuwen Du, Anning Hu, Zichen Chao, Yifan Lu, Junhao Ge, Genjia Liu, Weitao Wu, Lanjun Wang, Siheng Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Roadside Collaborative Perception refers to a system where multiple roadside
units collaborate to pool their perceptual data, assisting vehicles in
enhancing their environmental awareness. Existing roadside perception methods
concentrate on model design but overlook data issues like calibration errors,
sparse information, and multi-view consistency, leading to poor performance on
recent published datasets. To significantly enhance roadside collaborative
perception and address critical data issues, we present the first simulation
framework RoCo-Sim for road-side collaborative perception. RoCo-Sim is capable
of generating diverse, multi-view consistent simulated roadside data through
dynamic foreground editing and full-scene style transfer of a single image.
RoCo-Sim consists of four components: (1) Camera Extrinsic Optimization ensures
accurate 3D to 2D projection for roadside cameras; (2) A novel Multi-View
Occlusion-Aware Sampler (MOAS) determines the placement of diverse digital
assets within 3D space; (3) DepthSAM innovatively models foreground-background
relationships from single-frame fixed-view images, ensuring multi-view
consistency of foreground; and (4) Scalable Post-Processing Toolkit generates
more realistic and enriched scenes through style transfer and other
enhancements. RoCo-Sim significantly improves roadside 3D object detection,
outperforming SOTA methods by 83.74 on Rcooper-Intersection and 83.12 on
TUMTraf-V2X for AP70. RoCo-Sim fills a critical gap in roadside perception
simulation. Code and pre-trained models will be released soon:
https://github.com/duyuwen-duen/RoCo-Sim
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ RealGeneral: Unifying Visual Generation via Temporal In-Context Learning
  with Video Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10406v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10406v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yijing Lin, Mengqi Huang, Shuhan Zhuang, Zhendong Mao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Unifying diverse image generation tasks within a single framework remains a
fundamental challenge in visual generation. While large language models (LLMs)
achieve unification through task-agnostic data and generation, existing visual
generation models fail to meet these principles. Current approaches either rely
on per-task datasets and large-scale training or adapt pre-trained image models
with task-specific modifications, limiting their generalizability. In this
work, we explore video models as a foundation for unified image generation,
leveraging their inherent ability to model temporal correlations. We introduce
RealGeneral, a novel framework that reformulates image generation as a
conditional frame prediction task, analogous to in-context learning in LLMs. To
bridge the gap between video models and condition-image pairs, we propose (1) a
Unified Conditional Embedding module for multi-modal alignment and (2) a
Unified Stream DiT Block with decoupled adaptive LayerNorm and attention mask
to mitigate cross-modal interference. RealGeneral demonstrates effectiveness in
multiple important visual generation tasks, e.g., it achieves a 14.5%
improvement in subject similarity for customized generation and a 10%
enhancement in image quality for canny-to-image task. Project page:
https://lyne1.github.io/RealGeneral/
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Architecture-Aware Minimization (A$^2$M): How to Find Flat Minima in
  Neural Architecture Search 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10404v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10404v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Matteo Gambella, Fabrizio Pittorino, Manuel Roveri
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Neural Architecture Search (NAS) has become an essential tool for designing
effective and efficient neural networks. In this paper, we investigate the
geometric properties of neural architecture spaces commonly used in
differentiable NAS methods, specifically NAS-Bench-201 and DARTS. By defining
flatness metrics such as neighborhoods and loss barriers along paths in
architecture space, we reveal locality and flatness characteristics analogous
to the well-known properties of neural network loss landscapes in weight space.
In particular, we find that highly accurate architectures cluster together in
flat regions, while suboptimal architectures remain isolated, unveiling the
detailed geometrical structure of the architecture search landscape. Building
on these insights, we propose Architecture-Aware Minimization (A$^2$M), a novel
analytically derived algorithmic framework that explicitly biases, for the
first time, the gradient of differentiable NAS methods towards flat minima in
architecture space. A$^2$M consistently improves generalization over
state-of-the-art DARTS-based algorithms on benchmark datasets including
CIFAR-10, CIFAR-100, and ImageNet16-120, across both NAS-Bench-201 and DARTS
search spaces. Notably, A$^2$M is able to increase the test accuracy, on
average across different differentiable NAS methods, by +3.60\% on CIFAR-10,
+4.60\% on CIFAR-100, and +3.64\% on ImageNet16-120, demonstrating its superior
effectiveness in practice. A$^2$M can be easily integrated into existing
differentiable NAS frameworks, offering a versatile tool for future research
and applications in automated machine learning. We open-source our code at
https://github.com/AI-Tech-Research-Lab/AsquaredM.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>22 pages, 11 figures, 3 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Hyper3D: Efficient 3D Representation via Hybrid Tri<span class="highlight-title">plan</span>e and Octree
  Feature for Enhanced 3D Shape Variational Auto-Encoders 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10403v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10403v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jingyu Guo, Sensen Gao, Jia-Wang Bian, Wanhu Sun, Heliang Zheng, Rongfei Jia, Mingming Gong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent 3D content generation pipelines often leverage Variational
Autoencoders (VAEs) to encode shapes into compact latent representations,
facilitating diffusion-based generation. Efficiently compressing 3D shapes
while preserving intricate geometric details remains a key challenge. Existing
3D shape VAEs often employ uniform point sampling and 1D/2D latent
representations, such as vector sets or triplanes, leading to significant
geometric detail loss due to inadequate surface coverage and the absence of
explicit 3D representations in the latent space. Although recent work explores
3D latent representations, their large scale hinders high-resolution encoding
and efficient training. Given these challenges, we introduce Hyper3D, which
enhances VAE reconstruction through efficient 3D representation that integrates
hybrid triplane and octree features. First, we adopt an octree-based feature
representation to embed mesh information into the network, mitigating the
limitations of uniform point sampling in capturing geometric distributions
along the mesh surface. Furthermore, we propose a hybrid latent space
representation that integrates a high-resolution triplane with a low-resolution
3D grid. This design not only compensates for the lack of explicit 3D
representations but also leverages a triplane to preserve high-resolution
details. Experimental results demonstrate that Hyper3D outperforms traditional
representations by reconstructing 3D shapes with higher fidelity and finer
details, making it well-suited for 3D generation pipelines.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HSEmotion Team at ABAW-8 Competition: Audiovisual Ambivalence/Hesitancy,
  Emotional Mimicry Intensity and Facial Expression Recognition <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10399v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10399v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Andrey V. Savchenko
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This article presents our results for the eighth Affective Behavior Analysis
in-the-Wild (ABAW) competition. We combine facial emotional descriptors
extracted by pre-trained models, namely, our EmotiEffLib library, with acoustic
features and embeddings of texts recognized from speech. The frame-level
features are aggregated and fed into simple classifiers, e.g., multi-layered
perceptron (feed-forward neural network with one hidden layer), to predict
ambivalence/hesitancy and facial expressions. In the latter case, we also use
the pre-trained facial expression recognition model to select high-score video
frames and prevent their processing with a domain-specific video classifier.
The video-level prediction of emotional mimicry intensity is implemented by
simply aggregating frame-level features and training a multi-layered
perceptron. Experimental results for three tasks from the ABAW challenge
demonstrate that our approach significantly increases validation metrics
compared to existing baselines.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>submitted to ABAW CVPR 2025 Workshop</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ RoMA: Scaling up Mamba-based Foundation Models for Remote Sensing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10392v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10392v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fengxiang Wang, Hongzhen Wang, Yulin Wang, Di Wang, Mingshuo Chen, Haiyan Zhao, Yangang Sun, Shuo Wang, Long Lan, Wenjing Yang, Jing Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in self-supervised learning for Vision Transformers (ViTs)
have fueled breakthroughs in remote sensing (RS) foundation models. However,
the quadratic complexity of self-attention poses a significant barrier to
scalability, particularly for large models and high-resolution images. While
the linear-complexity Mamba architecture offers a promising alternative,
existing RS applications of Mamba remain limited to supervised tasks on small,
domain-specific datasets. To address these challenges, we propose RoMA, a
framework that enables scalable self-supervised pretraining of Mamba-based RS
foundation models using large-scale, diverse, unlabeled data. RoMA enhances
scalability for high-resolution images through a tailored auto-regressive
learning strategy, incorporating two key innovations: 1) a rotation-aware
pretraining mechanism combining adaptive cropping with angular embeddings to
handle sparsely distributed objects with arbitrary orientations, and 2)
multi-scale token prediction objectives that address the extreme variations in
object scales inherent to RS imagery. Systematic empirical studies validate
that Mamba adheres to RS data and parameter scaling laws, with performance
scaling reliably as model and data size increase. Furthermore, experiments
across scene classification, object detection, and semantic segmentation tasks
demonstrate that RoMA-pretrained Mamba models consistently outperform ViT-based
counterparts in both accuracy and computational efficiency. The source code and
pretrained models will be released at https://github.com/MiliLab/RoMA.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CINEMA: Coherent Multi-Subject Video Generation via MLLM-Based Guidance 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10391v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10391v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yufan Deng, Xun Guo, Yizhi Wang, Jacob Zhiyuan Fang, Angtian Wang, Shenghai Yuan, Yiding Yang, Bo Liu, Haibin Huang, Chongyang Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Video generation has witnessed remarkable progress with the advent of deep
generative models, particularly diffusion models. While existing methods excel
in generating high-quality videos from text prompts or single images,
personalized multi-subject video generation remains a largely unexplored
challenge. This task involves synthesizing videos that incorporate multiple
distinct subjects, each defined by separate reference images, while ensuring
temporal and spatial consistency. Current approaches primarily rely on mapping
subject images to keywords in text prompts, which introduces ambiguity and
limits their ability to model subject relationships effectively. In this paper,
we propose CINEMA, a novel framework for coherent multi-subject video
generation by leveraging Multimodal Large Language Model (MLLM). Our approach
eliminates the need for explicit correspondences between subject images and
text entities, mitigating ambiguity and reducing annotation effort. By
leveraging MLLM to interpret subject relationships, our method facilitates
scalability, enabling the use of large and diverse datasets for training.
Furthermore, our framework can be conditioned on varying numbers of subjects,
offering greater flexibility in personalized content creation. Through
extensive evaluations, we demonstrate that our approach significantly improves
subject consistency, and overall video coherence, paving the way for advanced
applications in storytelling, interactive media, and personalized video
generation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Multimodal Fusion Model Leveraging MLP Mixer and Handcrafted
  Features-based Deep Learning Networks for Facial Palsy Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10371v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10371v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Heng Yim Nicole Oo, Min Hun Lee, Jeong Hoon Lim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Algorithmic detection of facial palsy offers the potential to improve current
practices, which usually involve labor-intensive and subjective assessments by
clinicians. In this paper, we present a multimodal fusion-based deep learning
model that utilizes an MLP mixer-based model to process unstructured data (i.e.
RGB images or images with facial line segments) and a feed-forward neural
network to process structured data (i.e. facial landmark coordinates, features
of facial expressions, or handcrafted features) for detecting facial palsy. We
then contribute to a study to analyze the effect of different data modalities
and the benefits of a multimodal fusion-based approach using videos of 20
facial palsy patients and 20 healthy subjects. Our multimodal fusion model
achieved 96.00 F1, which is significantly higher than the feed-forward neural
network trained on handcrafted features alone (82.80 F1) and an MLP mixer-based
model trained on raw RGB images (89.00 F1).
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>PAKDD 2025. arXiv admin note: text overlap with arXiv:2405.16496</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LUMOS: Language-Conditioned Imitation Learning with World Models <span class="chip">ICRA</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10370v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10370v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Iman Nematollahi, Branton DeMoss, Akshay L Chandra, Nick Hawes, Wolfram Burgard, Ingmar Posner
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce LUMOS, a language-conditioned multi-task imitation learning
framework for robotics. LUMOS learns skills by practicing them over many
long-horizon rollouts in the latent space of a learned world model and
transfers these skills zero-shot to a real robot. By learning on-policy in the
latent space of the learned world model, our algorithm mitigates policy-induced
distribution shift which most offline imitation learning methods suffer from.
LUMOS learns from unstructured play data with fewer than 1% hindsight language
annotations but is steerable with language commands at test time. We achieve
this coherent long-horizon performance by combining latent planning with both
image- and language-based hindsight goal relabeling during training, and by
optimizing an intrinsic reward defined in the latent space of the world model
over multiple time steps, effectively reducing covariate shift. In experiments
on the difficult long-horizon CALVIN benchmark, LUMOS outperforms prior
learning-based methods with comparable approaches on chained multi-task
evaluations. To the best of our knowledge, we are the first to learn a
language-conditioned continuous visuomotor control for a real-world robot
within an offline world model. Videos, dataset and code are available at
http://lumos.cs.uni-freiburg.de.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at the 2025 IEEE International Conference on Robotics and
  Automation (ICRA)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Piece it Together: Part-Based Concepting with IP-Priors 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10365v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10365v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Elad Richardson, Kfir Goldberg, Yuval Alaluf, Daniel Cohen-Or
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Advanced generative models excel at synthesizing images but often rely on
text-based conditioning. Visual designers, however, often work beyond language,
directly drawing inspiration from existing visual elements. In many cases,
these elements represent only fragments of a potential concept-such as an
uniquely structured wing, or a specific hairstyle-serving as inspiration for
the artist to explore how they can come together creatively into a coherent
whole. Recognizing this need, we introduce a generative framework that
seamlessly integrates a partial set of user-provided visual components into a
coherent composition while simultaneously sampling the missing parts needed to
generate a plausible and complete concept. Our approach builds on a strong and
underexplored representation space, extracted from IP-Adapter+, on which we
train IP-Prior, a lightweight flow-matching model that synthesizes coherent
compositions based on domain-specific priors, enabling diverse and
context-aware generations. Additionally, we present a LoRA-based fine-tuning
strategy that significantly improves prompt adherence in IP-Adapter+ for a
given task, addressing its common trade-off between reconstruction quality and
prompt adherence.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project page available at https://eladrich.github.io/PiT/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ConceptGuard: Continual Personalized Text-to-Image Generation with
  Forgetting and Confusion Mitigation <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10358v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10358v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zirun Guo, Tao Jin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diffusion customization methods have achieved impressive results with only a
minimal number of user-provided images. However, existing approaches customize
concepts collectively, whereas real-world applications often require sequential
concept integration. This sequential nature can lead to catastrophic
forgetting, where previously learned concepts are lost. In this paper, we
investigate concept forgetting and concept confusion in the continual
customization. To tackle these challenges, we present ConceptGuard, a
comprehensive approach that combines shift embedding, concept-binding prompts
and memory preservation regularization, supplemented by a priority queue which
can adaptively update the importance and occurrence order of different
concepts. These strategies can dynamically update, unbind and learn the
relationship of the previous concepts, thus alleviating concept forgetting and
confusion. Through comprehensive experiments, we show that our approach
outperforms all the baseline methods consistently and significantly in both
quantitative and qualitative analyses.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at CVPR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Do I look like a `cat.n.01` to you? A Taxonomy Image Generation
  <span class="highlight-title">Benchmark</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10357v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10357v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Viktor Moskvoretskii, Alina Lobanova, Ekaterina Neminova, Chris Biemann, Alexander Panchenko, Irina Nikishina
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper explores the feasibility of using text-to-image models in a
zero-shot setup to generate images for taxonomy concepts. While text-based
methods for taxonomy enrichment are well-established, the potential of the
visual dimension remains unexplored. To address this, we propose a
comprehensive benchmark for Taxonomy Image Generation that assesses models'
abilities to understand taxonomy concepts and generate relevant, high-quality
images. The benchmark includes common-sense and randomly sampled WordNet
concepts, alongside the LLM generated predictions. The 12 models are evaluated
using 9 novel taxonomy-related text-to-image metrics and human feedback.
Moreover, we pioneer the use of pairwise evaluation with GPT-4 feedback for
image generation. Experimental results show that the ranking of models differs
significantly from standard T2I tasks. Playground-v2 and FLUX consistently
outperform across metrics and subsets and the retrieval-based approach performs
poorly. These findings highlight the potential for automating the curation of
structured data resources.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Labeled data and generated image Wordnet are published at
  https://huggingface.co/collections/VityaVitalich/generated-image-wordnet-67d2c868ff1414ec2f8e0d3d</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Object detection characteristics in a learning factory environment using
  YOLOv8 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10356v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10356v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Toni Schneidereit, Stefan Gohrenz, Michael Breuß
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  AI-based object detection, and efforts to explain and investigate their
characteristics, is a topic of high interest. The impact of, e.g., complex
background structures with similar appearances as the objects of interest, on
the detection accuracy and, beforehand, the necessary dataset composition are
topics of ongoing research. In this paper, we present a systematic
investigation of background influences and different features of the object to
be detected. The latter includes various materials and surfaces, partially
transparent and with shiny reflections in the context of an Industry 4.0
learning factory. Different YOLOv8 models have been trained for each of the
materials on different sized datasets, where the appearance was the only
changing parameter. In the end, similar characteristics tend to show different
behaviours and sometimes unexpected results. While some background components
tend to be detected, others with the same features are not part of the
detection. Additionally, some more precise conclusions can be drawn from the
results. Therefore, we contribute a challenging dataset with detailed
investigations on 92 trained YOLO models, addressing some issues on the
detection accuracy and possible overfitting.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhancing Facial Privacy Protection via Weakening Diffusion Purification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10350v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10350v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ali Salar, Qing Liu, Yingli Tian, Guoying Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid growth of social media has led to the widespread sharing of
individual portrait images, which pose serious privacy risks due to the
capabilities of automatic face recognition (AFR) systems for mass surveillance.
Hence, protecting facial privacy against unauthorized AFR systems is essential.
Inspired by the generation capability of the emerging diffusion models, recent
methods employ diffusion models to generate adversarial face images for privacy
protection. However, they suffer from the diffusion purification effect,
leading to a low protection success rate (PSR). In this paper, we first propose
learning unconditional embeddings to increase the learning capacity for
adversarial modifications and then use them to guide the modification of the
adversarial latent code to weaken the diffusion purification effect. Moreover,
we integrate an identity-preserving structure to maintain structural
consistency between the original and generated images, allowing human observers
to recognize the generated image as having the same identity as the original.
Extensive experiments conducted on two public datasets, i.e., CelebA-HQ and
LADN, demonstrate the superiority of our approach. The protected faces
generated by our method outperform those produced by existing facial privacy
protection approaches in terms of transferability and natural appearance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DreamInsert: Zero-Shot Image-to-Video Object Insertion from A Single
  Image 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10342v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10342v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qi Zhao, Zhan Ma, Pan Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent developments in generative diffusion models have turned many dreams
into realities. For video object insertion, existing methods typically require
additional information, such as a reference video or a 3D asset of the object,
to generate the synthetic motion. However, inserting an object from a single
reference photo into a target background video remains an uncharted area due to
the lack of unseen motion information. We propose DreamInsert, which achieves
Image-to-Video Object Insertion in a training-free manner for the first time.
By incorporating the trajectory of the object into consideration, DreamInsert
can predict the unseen object movement, fuse it harmoniously with the
background video, and generate the desired video seamlessly. More
significantly, DreamInsert is both simple and effective, achieving zero-shot
insertion without end-to-end training or additional fine-tuning on
well-designed image-video data pairs. We demonstrated the effectiveness of
DreamInsert through a variety of experiments. Leveraging this capability, we
present the first results for Image-to-Video object insertion in a
training-free manner, paving exciting new directions for future content
creation and synthesis. The code will be released soon.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Generative Binary Memory: Pseudo-Replay Class-Incremental Learning on
  Binarized Embeddings 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10333v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10333v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yanis Basso-Bert, Anca Molnos, Romain Lemaire, William Guicquero, Antoine Dupret
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In dynamic environments where new concepts continuously emerge, Deep Neural
Networks (DNNs) must adapt by learning new classes while retaining previously
acquired ones. This challenge is addressed by Class-Incremental Learning (CIL).
This paper introduces Generative Binary Memory (GBM), a novel CIL pseudo-replay
approach which generates synthetic binary pseudo-exemplars. Relying on
Bernoulli Mixture Models (BMMs), GBM effectively models the multi-modal
characteristics of class distributions, in a latent, binary space. With a
specifically-designed feature binarizer, our approach applies to any
conventional DNN. GBM also natively supports Binary Neural Networks (BNNs) for
highly-constrained model sizes in embedded systems. The experimental results
demonstrate that GBM achieves higher than state-of-the-art average accuracy on
CIFAR100 (+2.9%) and TinyImageNet (+1.5%) for a ResNet-18 equipped with our
binarizer. GBM also outperforms emerging CIL methods for BNNs, with +3.1% in
final accuracy and x4.7 memory reduction, on CORE50.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ OSMa-Bench: Evaluating Open Semantic Mapping Under Varying Lighting
  Conditions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10331v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10331v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Maxim Popov, Regina Kurkova, Mikhail Iumanov, Jaafar Mahmoud, Sergey Kolyubin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Open Semantic Mapping (OSM) is a key technology in robotic perception,
combining semantic segmentation and SLAM techniques. This paper introduces a
dynamically configurable and highly automated LLM/LVLM-powered pipeline for
evaluating OSM solutions called OSMa-Bench (Open Semantic Mapping Benchmark).
The study focuses on evaluating state-of-the-art semantic mapping algorithms
under varying indoor lighting conditions, a critical challenge in indoor
environments. We introduce a novel dataset with simulated RGB-D sequences and
ground truth 3D reconstructions, facilitating the rigorous analysis of mapping
performance across different lighting conditions. Through experiments on
leading models such as ConceptGraphs, BBQ and OpenScene, we evaluate the
semantic fidelity of object recognition and segmentation. Additionally, we
introduce a Scene Graph evaluation method to analyze the ability of models to
interpret semantic structure. The results provide insights into the robustness
of these models, forming future research directions for developing resilient
and adaptable robotic systems. Our code is available at
https://be2rlab.github.io/OSMa-Bench/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project page: https://be2rlab.github.io/OSMa-Bench/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ IDEA: Inverted Text with Cooperative Deformable Aggregation for
  Multi-modal Object Re-Identification <span class="chip">CVPR2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10324v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10324v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuhao Wang, Yongfeng Lv, Pingping Zhang, Huchuan Lu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multi-modal object Re-IDentification (ReID) aims to retrieve specific objects
by utilizing complementary information from various modalities. However,
existing methods focus on fusing heterogeneous visual features, neglecting the
potential benefits of text-based semantic information. To address this issue,
we first construct three text-enhanced multi-modal object ReID benchmarks. To
be specific, we propose a standardized multi-modal caption generation pipeline
for structured and concise text annotations with Multi-modal Large Language
Models (MLLMs). Besides, current methods often directly aggregate multi-modal
information without selecting representative local features, leading to
redundancy and high complexity. To address the above issues, we introduce IDEA,
a novel feature learning framework comprising the Inverted Multi-modal Feature
Extractor (IMFE) and Cooperative Deformable Aggregation (CDA). The IMFE
utilizes Modal Prefixes and an InverseNet to integrate multi-modal information
with semantic guidance from inverted text. The CDA adaptively generates
sampling positions, enabling the model to focus on the interplay between global
features and discriminative local features. With the constructed benchmarks and
the proposed modules, our framework can generate more robust multi-modal
features under complex scenarios. Extensive experiments on three multi-modal
object ReID benchmarks demonstrate the effectiveness of our proposed method.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This work is accepted by CVPR2025. More modifications may be
  performed</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Fast, Memory-based and Data-Efficient Vision-Language Policy 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10322v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10322v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haoxuan Li, Sixu Yan, Yuhan Li, Xinggang Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision Language Models (VLMs) pretrained on Internet-scale vision-language
data have demonstrated the potential to transfer their knowledge to robotic
learning. However, the existing paradigm encounters three critical challenges:
(1) expensive inference cost resulting from large-scale model parameters, (2)
frequent domain shifts caused by mismatched data modalities, and (3) limited
capacity to handle past or future experiences. In this work, we propose
LiteVLP, a lightweight, memory-based, and general-purpose vision-language
policy generation model. LiteVLP is built upon a pre-trained 1B-parameter VLM
and fine-tuned on a tiny-scale and conversation-style robotic dataset. Through
extensive experiments, we demonstrate that LiteVLP outperforms state-of-the-art
vision-language policy on VIMA-Bench, with minimal training time. Furthermore,
LiteVLP exhibits superior inference speed while maintaining exceptional high
accuracy. In long-horizon manipulation tasks, LiteVLP also shows remarkable
memory ability, outperforming the best-performing baseline model by 18.8%.
These results highlight LiteVLP as a promising model to integrating the
intelligence of VLMs into robotic learning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 7 figures, 6 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PS3C: An Ensemble-Based Two-Step Framework for Classification of Pep
  Smear Cell Images 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10312v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10312v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Theo Di Piazza, Loic Boussel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Early detection of cervical cancer is crucial for improving patient outcomes
and reducing mortality by identifying precancerous lesions as soon as possible.
As a result, the use of pap smear screening has significantly increased,
leading to a growing demand for automated tools that can assist cytologists
managing their rising workload. To address this, the Pep Smear Cell
Classification Challenge (PS3C) has been organized in association with ISBI in
2025. This project aims to promote the development of automated tools for pep
smear images classification. The analyzed images are grouped into four
categories: healthy, unhealthy, both, and rubbish images which are considered
as unsuitable for diagnosis. In this work, we propose a two-stage ensemble
approach: first, a neural network determines whether an image is rubbish or
not. If not, a second neural network classifies the image as containing a
healthy cell, an unhealthy cell, or both.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>7 pages, 3 figures, Grand Challenge paper accepted at ISBI 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ 6D Object Pose Tracking in Internet Videos for Robotic <span class="highlight-title">Manipulation</span> <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10307v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10307v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Georgy Ponimatkin, Martin Cífka, Tomáš Souček, Médéric Fourmy, Yann Labbé, Vladimir Petrik, Josef Sivic
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We seek to extract a temporally consistent 6D pose trajectory of a
manipulated object from an Internet instructional video. This is a challenging
set-up for current 6D pose estimation methods due to uncontrolled capturing
conditions, subtle but dynamic object motions, and the fact that the exact mesh
of the manipulated object is not known. To address these challenges, we present
the following contributions. First, we develop a new method that estimates the
6D pose of any object in the input image without prior knowledge of the object
itself. The method proceeds by (i) retrieving a CAD model similar to the
depicted object from a large-scale model database, (ii) 6D aligning the
retrieved CAD model with the input image, and (iii) grounding the absolute
scale of the object with respect to the scene. Second, we extract smooth 6D
object trajectories from Internet videos by carefully tracking the detected
objects across video frames. The extracted object trajectories are then
retargeted via trajectory optimization into the configuration space of a
robotic manipulator. Third, we thoroughly evaluate and ablate our 6D pose
estimation method on YCB-V and HOPE-Video datasets as well as a new dataset of
instructional videos manually annotated with approximate 6D object
trajectories. We demonstrate significant improvements over existing
state-of-the-art RGB 6D pose estimation methods. Finally, we show that the 6D
object motion estimated from Internet videos can be transferred to a 7-axis
robotic manipulator both in a virtual simulator as well as in a real world
set-up. We also successfully apply our method to egocentric videos taken from
the EPIC-KITCHENS dataset, demonstrating potential for Embodied AI
applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ICLR 2025. Project page available at
  https://ponimatkin.github.io/wildpose/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Eye on the Target: Eye Tracking Meets Rodent Tracking 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10305v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10305v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Emil Mededovic, Yuli Wu, Henning Konermann, Marcin Kopaczka, Mareike Schulz, Rene Tolba, Johannes Stegmaier
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Analyzing animal behavior from video recordings is crucial for scientific
research, yet manual annotation remains labor-intensive and prone to
subjectivity. Efficient segmentation methods are needed to automate this
process while maintaining high accuracy. In this work, we propose a novel
pipeline that utilizes eye-tracking data from Aria glasses to generate prompt
points, which are then used to produce segmentation masks via a fast zero-shot
segmentation model. Additionally, we apply post-processing to refine the
prompts, leading to improved segmentation quality. Through our approach, we
demonstrate that combining eye-tracking-based annotation with smart prompt
refinement can enhance segmentation accuracy, achieving an improvement of 70.6%
from 38.8 to 66.2 in the Jaccard Index for segmentation results in the rats
dataset.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CODEI: Resource-Efficient Task-Driven Co-Design of Perception and
  Decision Making for Mobile Robots Applied to Autonomous Vehicles 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10296v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10296v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dejan Milojevic, Gioele Zardini, Miriam Elser, Andrea Censi, Emilio Frazzoli
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper discusses the integration challenges and strategies for designing
mobile robots, by focusing on the task-driven, optimal selection of hardware
and software to balance safety, efficiency, and minimal usage of resources such
as costs, energy, computational requirements, and weight. We emphasize the
interplay between perception and motion planning in decision-making by
introducing the concept of occupancy queries to quantify the perception
requirements for sampling-based motion planners. Sensor and algorithm
performance are evaluated using False Negative Rates (FPR) and False Positive
Rates (FPR) across various factors such as geometric relationships, object
properties, sensor resolution, and environmental conditions. By integrating
perception requirements with perception performance, an Integer Linear
Programming (ILP) approach is proposed for efficient sensor and algorithm
selection and placement. This forms the basis for a co-design optimization that
includes the robot body, motion planner, perception pipeline, and computing
unit. We refer to this framework for solving the co-design problem of mobile
robots as CODEI, short for Co-design of Embodied Intelligence. A case study on
developing an Autonomous Vehicle (AV) for urban scenarios provides actionable
information for designers, and shows that complex tasks escalate resource
demands, with task performance affecting choices of the autonomy stack. The
study demonstrates that resource prioritization influences sensor choice:
cameras are preferred for cost-effective and lightweight designs, while lidar
sensors are chosen for better energy and computational efficiency.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages, 33 images, IEEE Transactions on Robotics</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ VisualPRM: An Effective Process Reward Model for Multimodal Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10291v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10291v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Weiyun Wang, Zhangwei Gao, Lianjie Chen, Zhe Chen, Jinguo Zhu, Xiangyu Zhao, Yangzhou Liu, Yue Cao, Shenglong Ye, Xizhou Zhu, Lewei Lu, Haodong Duan, Yu Qiao, Jifeng Dai, Wenhai Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce VisualPRM, an advanced multimodal Process Reward Model (PRM)
with 8B parameters, which improves the reasoning abilities of existing
Multimodal Large Language Models (MLLMs) across different model scales and
families with Best-of-N (BoN) evaluation strategies. Specifically, our model
improves the reasoning performance of three types of MLLMs and four different
model scales. Even when applied to the highly capable InternVL2.5-78B, it
achieves a 5.9-point improvement across seven multimodal reasoning benchmarks.
Experimental results show that our model exhibits superior performance compared
to Outcome Reward Models and Self-Consistency during BoN evaluation. To
facilitate the training of multimodal PRMs, we construct a multimodal process
supervision dataset VisualPRM400K using an automated data pipeline. For the
evaluation of multimodal PRMs, we propose VisualProcessBench, a benchmark with
human-annotated step-wise correctness labels, to measure the abilities of PRMs
to detect erroneous steps in multimodal reasoning tasks. We hope that our work
can inspire more future research and contribute to the development of MLLMs.
Our model, data, and benchmark are released in
https://internvl.github.io/blog/2025-03-13-VisualPRM/.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MaterialMVP: Illumination-Invariant Material Generation via Multi-view
  PBR Diffusion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10289v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10289v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zebin He, Mingxin Yang, Shuhui Yang, Yixuan Tang, Tao Wang, Kaihao Zhang, Guanying Chen, Yuhong Liu, Jie Jiang, Chunchao Guo, Wenhan Luo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Physically-based rendering (PBR) has become a cornerstone in modern computer
graphics, enabling realistic material representation and lighting interactions
in 3D scenes. In this paper, we present MaterialMVP, a novel end-to-end model
for generating PBR textures from 3D meshes and image prompts, addressing key
challenges in multi-view material synthesis. Our approach leverages Reference
Attention to extract and encode informative latent from the input reference
images, enabling intuitive and controllable texture generation. We also
introduce a Consistency-Regularized Training strategy to enforce stability
across varying viewpoints and illumination conditions, ensuring
illumination-invariant and geometrically consistent results. Additionally, we
propose Dual-Channel Material Generation, which separately optimizes albedo and
metallic-roughness (MR) textures while maintaining precise spatial alignment
with the input images through Multi-Channel Aligned Attention. Learnable
material embeddings are further integrated to capture the distinct properties
of albedo and MR. Experimental results demonstrate that our model generates PBR
textures with realistic behavior across diverse lighting scenarios,
outperforming existing methods in both consistency and quality for scalable 3D
asset creation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MACS: Multi-source Audio-to-image Generation with Contextual
  Significance and Semantic Alignment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10287v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10287v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hao Zhou, Xiaobao Guo, Yuzhe Zhu, Adams Wai-Kin Kong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Propelled by the breakthrough in deep generative models, audio-to-image
generation has emerged as a pivotal cross-model task that converts complex
auditory signals into rich visual representations. However, previous works only
focus on single-source audio inputs for image generation, ignoring the
multi-source characteristic in natural auditory scenes, thus limiting the
performance in generating comprehensive visual content. To bridge this gap, a
method called MACS is proposed to conduct multi-source audio-to-image
generation. This is the first work that explicitly separates multi-source audio
to capture the rich audio components before image generation. MACS is a
two-stage method. In the first stage, multi-source audio inputs are separated
by a weakly supervised method, where the audio and text labels are semantically
aligned by casting into a common space using the large pre-trained CLAP model.
We introduce a ranking loss to consider the contextual significance of the
separated audio signals. In the second stage, efficient image generation is
achieved by mapping the separated audio signals to the generation condition
using only a trainable adapter and a MLP layer. We preprocess the LLP dataset
as the first full multi-source audio-to-image generation benchmark. The
experiments are conducted on multi-source, mixed-source, and single-source
audio-to-image generation tasks. The proposed MACS outperforms the current
state-of-the-art methods in 17 of the 21 evaluation indexes on all tasks and
delivers superior visual quality. The code will be publicly available.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ VicaSplat: A Single Run is All You Need for 3D Gaussian Splatting and
  Camera Estimation from Unposed Video Frames 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10286v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10286v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhiqi Li, Chengrui Dong, Yiming Chen, Zhangchi Huang, Peidong Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present VicaSplat, a novel framework for joint 3D Gaussians reconstruction
and camera pose estimation from a sequence of unposed video frames, which is a
critical yet underexplored task in real-world 3D applications. The core of our
method lies in a novel transformer-based network architecture. In particular,
our model starts with an image encoder that maps each image to a list of visual
tokens. All visual tokens are concatenated with additional inserted learnable
camera tokens. The obtained tokens then fully communicate with each other
within a tailored transformer decoder. The camera tokens causally aggregate
features from visual tokens of different views, and further modulate them
frame-wisely to inject view-dependent features. 3D Gaussian splats and camera
pose parameters can then be estimated via different prediction heads.
Experiments show that VicaSplat surpasses baseline methods for multi-view
inputs, and achieves comparable performance to prior two-view approaches.
Remarkably, VicaSplat also demonstrates exceptional cross-dataset
generalization capability on the ScanNet benchmark, achieving superior
performance without any fine-tuning. Project page:
https://lizhiqi49.github.io/VicaSplat.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ EEdit : Rethinking the Spatial and Temporal Redundancy for Efficient
  Image Editing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10270v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10270v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zexuan Yan, Yue Ma, Chang Zou, Wenteng Chen, Qifeng Chen, Linfeng Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Inversion-based image editing is rapidly gaining momentum while suffering
from significant computation overhead, hindering its application in real-time
interactive scenarios. In this paper, we rethink that the redundancy in
inversion-based image editing exists in both the spatial and temporal
dimensions, such as the unnecessary computation in unedited regions and the
redundancy in the inversion progress. To tackle these challenges, we propose a
practical framework, named EEdit, to achieve efficient image editing.
Specifically, we introduce three techniques to solve them one by one. For
spatial redundancy, spatial locality caching is introduced to compute the
edited region and its neighboring regions while skipping the unedited regions,
and token indexing preprocessing is designed to further accelerate the caching.
For temporal redundancy, inversion step skipping is proposed to reuse the
latent for efficient editing. Our experiments demonstrate an average of 2.46
$\times$ acceleration without performance drop in a wide range of editing tasks
including prompt-guided image editing, dragging and image composition. Our
codes are available at https://github.com/yuriYanZeXuan/EEdit
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Multi-Modal Federated Learning Framework for Remote Sensing Image
  Classification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10262v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10262v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Barış Büyüktaş, Gencer Sumbul, Begüm Demir
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Federated learning (FL) enables the collaborative training of deep neural
networks across decentralized data archives (i.e., clients) without sharing the
local data of the clients. Most of the existing FL methods assume that the data
distributed across all clients is associated with the same data modality.
However, remote sensing (RS) images present in different clients can be
associated with diverse data modalities. The joint use of the multi-modal RS
data can significantly enhance classification performance. To effectively
exploit decentralized and unshared multi-modal RS data, our paper introduces a
novel multi-modal FL framework for RS image classification problems. The
proposed framework comprises three modules: 1) multi-modal fusion (MF); 2)
feature whitening (FW); and 3) mutual information maximization (MIM). The MF
module employs iterative model averaging to facilitate learning without
accessing multi-modal training data on clients. The FW module aims to address
the limitations of training data heterogeneity by aligning data distributions
across clients. The MIM module aims to model mutual information by maximizing
the similarity between images from different modalities. For the experimental
analyses, we focus our attention on multi-label classification and pixel-based
classification tasks in RS. The results obtained using two benchmark archives
show the effectiveness of the proposed framework when compared to
state-of-the-art algorithms in the literature. The code of the proposed
framework will be available at https://git.tu-berlin.de/rsim/multi-modal-FL.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Markerless Tracking-Based Registration for Medical Image Motion
  Correction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10260v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10260v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Luisa Neubig, Deirdre Larsen, Takeshi Ikuma, Markus Kopp, Melda Kunduk, Andreas M. Kist
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Our study focuses on isolating swallowing dynamics from interfering patient
motion in videofluoroscopy, an X-ray technique that records patients swallowing
a radiopaque bolus. These recordings capture multiple motion sources, including
head movement, anatomical displacements, and bolus transit. To enable precise
analysis of swallowing physiology, we aim to eliminate distracting motion,
particularly head movement, while preserving essential swallowing-related
dynamics. Optical flow methods fail due to artifacts like flickering and
instability, making them unreliable for distinguishing different motion groups.
We evaluated markerless tracking approaches (CoTracker, PIPs++, TAP-Net) and
quantified tracking accuracy in key medical regions of interest. Our findings
show that even sparse tracking points generate morphing displacement fields
that outperform leading registration methods such as ANTs, LDDMM, and
VoxelMorph. To compare all approaches, we assessed performance using MSE and
SSIM metrics post-registration. We introduce a novel motion correction pipeline
that effectively removes disruptive motion while preserving swallowing dynamics
and surpassing competitive registration techniques. Code will be available
after review.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ KVQ: Boosting Video Quality Assessment via Saliency-guided Local
  Perception 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10259v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10259v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yunpeng Qu, Kun Yuan, Qizhi Xie, Ming Sun, Chao Zhou, Jian Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Video Quality Assessment (VQA), which intends to predict the perceptual
quality of videos, has attracted increasing attention. Due to factors like
motion blur or specific distortions, the quality of different regions in a
video varies. Recognizing the region-wise local quality within a video is
beneficial for assessing global quality and can guide us in adopting
fine-grained enhancement or transcoding strategies. Due to the heavy cost of
annotating region-wise quality, the lack of ground truth constraints from
relevant datasets further complicates the utilization of local perception.
Inspired by the Human Visual System (HVS) that links global quality to the
local texture of different regions and their visual saliency, we propose a
Kaleidoscope Video Quality Assessment (KVQ) framework, which aims to
effectively assess both saliency and local texture, thereby facilitating the
assessment of global quality. Our framework extracts visual saliency and
allocates attention using Fusion-Window Attention (FWA) while incorporating a
Local Perception Constraint (LPC) to mitigate the reliance of regional texture
perception on neighboring areas. KVQ obtains significant improvements across
multiple scenarios on five VQA benchmarks compared to SOTA methods.
Furthermore, to assess local perception, we establish a new Local Perception
Visual Quality (LPVQ) dataset with region-wise annotations. Experimental
results demonstrate the capability of KVQ in perceiving local distortions. KVQ
models and the LPVQ dataset will be available at
https://github.com/qyp2000/KVQ.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 7 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ROODI: Reconstructing Occluded Objects with Denoising Inpainters 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10256v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10256v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yeonjin Chang, Erqun Dong, Seunghyeon Seo, Nojun Kwak, Kwang Moo Yi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While the quality of novel-view images has improved dramatically with 3D
Gaussian Splatting, extracting specific objects from scenes remains
challenging. Isolating individual 3D Gaussian primitives for each object and
handling occlusions in scenes remain far from being solved. We propose a novel
object extraction method based on two key principles: (1) being object-centric
by pruning irrelevant primitives; and (2) leveraging generative inpainting to
compensate for missing observations caused by occlusions. For pruning, we
analyze the local structure of primitives using K-nearest neighbors, and retain
only relevant ones. For inpainting, we employ an off-the-shelf diffusion-based
inpainter combined with occlusion reasoning, utilizing the 3D representation of
the entire scene. Our findings highlight the crucial synergy between pruning
and inpainting, both of which significantly enhance extraction performance. We
evaluate our method on a standard real-world dataset and introduce a synthetic
dataset for quantitative analysis. Our approach outperforms the
state-of-the-art, demonstrating its effectiveness in object extraction from
complex scenes.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project page: https://yeonjin-chang.github.io/ROODI/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SVIP: Semantically Contextualized Visual Patches for Zero-Shot Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10252v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10252v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhi Chen, Zecheng Zhao, Jingcai Guo, Jingjing Li, Zi Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Zero-shot learning (ZSL) aims to recognize unseen classes without labeled
training examples by leveraging class-level semantic descriptors such as
attributes. A fundamental challenge in ZSL is semantic misalignment, where
semantic-unrelated information involved in visual features introduce ambiguity
to visual-semantic interaction. Unlike existing methods that suppress
semantic-unrelated information post hoc either in the feature space or the
model space, we propose addressing this issue at the input stage, preventing
semantic-unrelated patches from propagating through the network. To this end,
we introduce Semantically contextualized VIsual Patches (SVIP) for ZSL, a
transformer-based framework designed to enhance visual-semantic alignment.
Specifically, we propose a self-supervised patch selection mechanism that
preemptively learns to identify semantic-unrelated patches in the input space.
This is trained with the supervision from aggregated attention scores across
all transformer layers, which estimate each patch's semantic score. As removing
semantic-unrelated patches from the input sequence may disrupt object
structure, we replace them with learnable patch embeddings. With initialization
from word embeddings, we can ensure they remain semantically meaningful
throughout feature extraction. Extensive experiments on ZSL benchmarks
demonstrate that SVIP achieves state-of-the-art performance results while
providing more interpretable and semantically rich feature representations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Pre-print</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Interpretable Image Classification via Non-parametric Part Prototype
  Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10247v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10247v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhijie Zhu, Lei Fan, Maurice Pagnucco, Yang Song
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Classifying images with an interpretable decision-making process is a
long-standing problem in computer vision. In recent years, Prototypical Part
Networks has gained traction as an approach for self-explainable neural
networks, due to their ability to mimic human visual reasoning by providing
explanations based on prototypical object parts. However, the quality of the
explanations generated by these methods leaves room for improvement, as the
prototypes usually focus on repetitive and redundant concepts. Leveraging
recent advances in prototype learning, we present a framework for part-based
interpretable image classification that learns a set of semantically
distinctive object parts for each class, and provides diverse and comprehensive
explanations. The core of our method is to learn the part-prototypes in a
non-parametric fashion, through clustering deep features extracted from
foundation vision models that encode robust semantic information. To
quantitatively evaluate the quality of explanations provided by ProtoPNets, we
introduce Distinctiveness Score and Comprehensiveness Score. Through evaluation
on CUB-200-2011, Stanford Cars and Stanford Dogs datasets, we show that our
framework compares favourably against existing ProtoPNets while achieving
better interpretability. Code is available at:
https://github.com/zijizhu/proto-non-param.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Unveiling the Invisible: Reasoning Complex Occlusions Amodally with AURA 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10225v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10225v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhixuan Li, Hyunse Yoon, Sanghoon Lee, Weisi Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Amodal segmentation aims to infer the complete shape of occluded objects,
even when the occluded region's appearance is unavailable. However, current
amodal segmentation methods lack the capability to interact with users through
text input and struggle to understand or reason about implicit and complex
purposes. While methods like LISA integrate multi-modal large language models
(LLMs) with segmentation for reasoning tasks, they are limited to predicting
only visible object regions and face challenges in handling complex occlusion
scenarios. To address these limitations, we propose a novel task named amodal
reasoning segmentation, aiming to predict the complete amodal shape of occluded
objects while providing answers with elaborations based on user text input. We
develop a generalizable dataset generation pipeline and introduce a new dataset
focusing on daily life scenarios, encompassing diverse real-world occlusions.
Furthermore, we present AURA (Amodal Understanding and Reasoning Assistant), a
novel model with advanced global and spatial-level designs specifically
tailored to handle complex occlusions. Extensive experiments validate AURA's
effectiveness on the proposed dataset. The code, model, and dataset will be
publicly released.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 5 figures, 5 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CoStoDet-DDPM: Collaborative Training of Stochastic and Deterministic
  Models Improves Surgical Workflow Anticipation and Recognition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10216v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10216v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kaixiang Yang, Xin Li, Qiang Li, Zhiwei Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Anticipating and recognizing surgical workflows are critical for intelligent
surgical assistance systems. However, existing methods rely on deterministic
decision-making, struggling to generalize across the large anatomical and
procedural variations inherent in real-world surgeries.In this paper, we
introduce an innovative framework that incorporates stochastic modeling through
a denoising diffusion probabilistic model (DDPM) into conventional
deterministic learning for surgical workflow analysis. At the heart of our
approach is a collaborative co-training paradigm: the DDPM branch captures
procedural uncertainties to enrich feature representations, while the task
branch focuses on predicting surgical phases and instrument
usage.Theoretically, we demonstrate that this mutual refinement mechanism
benefits both branches: the DDPM reduces prediction errors in uncertain
scenarios, and the task branch directs the DDPM toward clinically meaningful
representations. Notably, the DDPM branch is discarded during inference,
enabling real-time predictions without sacrificing accuracy.Experiments on the
Cholec80 dataset show that for the anticipation task, our method achieves a 16%
reduction in eMAE compared to state-of-the-art approaches, and for phase
recognition, it improves the Jaccard score by 1.0%. Additionally, on the
AutoLaparo dataset, our method achieves a 1.5% improvement in the Jaccard score
for phase recognition, while also exhibiting robust generalization to
patient-specific variations. Our code and weight are available at
https://github.com/kk42yy/CoStoDet-DDPM.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Singular Value Fine-tuning for Few-Shot Class-Incremental Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10214v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10214v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhiwu Wang, Yichen Wu, Renzhen Wang, Haokun Lin, Quanziang Wang, Qian Zhao, Deyu Meng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Class-Incremental Learning (CIL) aims to prevent catastrophic forgetting of
previously learned classes while sequentially incorporating new ones. The more
challenging Few-shot CIL (FSCIL) setting further complicates this by providing
only a limited number of samples for each new class, increasing the risk of
overfitting in addition to standard CIL challenges. While catastrophic
forgetting has been extensively studied, overfitting in FSCIL, especially with
large foundation models, has received less attention. To fill this gap, we
propose the Singular Value Fine-tuning for FSCIL (SVFCL) and compared it with
existing approaches for adapting foundation models to FSCIL, which primarily
build on Parameter Efficient Fine-Tuning (PEFT) methods like prompt tuning and
Low-Rank Adaptation (LoRA). Specifically, SVFCL applies singular value
decomposition to the foundation model weights, keeping the singular vectors
fixed while fine-tuning the singular values for each task, and then merging
them. This simple yet effective approach not only alleviates the forgetting
problem but also mitigates overfitting more effectively while significantly
reducing trainable parameters. Extensive experiments on four benchmark
datasets, along with visualizations and ablation studies, validate the
effectiveness of SVFCL. The code will be made available.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 8 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MouseGPT: A Large-scale Vision-Language Model for Mouse Behavior
  Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10212v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10212v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Teng Xu, Taotao Zhou, Youjia Wang, Peng Yang, Simin Tang, Kuixiang Shao, Zifeng Tang, Yifei Liu, Xinyuan Chen, Hongshuang Wang, Xiaohui Wang, Huoqing Luo, Jingya Wang, Ji Hu, Jingyi Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Analyzing animal behavior is crucial in advancing neuroscience, yet
quantifying and deciphering its intricate dynamics remains a significant
challenge. Traditional machine vision approaches, despite their ability to
detect spontaneous behaviors, fall short due to limited interpretability and
reliance on manual labeling, which restricts the exploration of the full
behavioral spectrum. Here, we introduce MouseGPT, a Vision-Language Model (VLM)
that integrates visual cues with natural language to revolutionize mouse
behavior analysis. Built upon our first-of-its-kind dataset - incorporating
pose dynamics and open-vocabulary behavioral annotations across over 42 million
frames of diverse psychiatric conditions - MouseGPT provides a novel,
context-rich method for comprehensive behavior interpretation. Our holistic
analysis framework enables detailed behavior profiling, clustering, and novel
behavior discovery, offering deep insights without the need for labor -
intensive manual annotation. Evaluations reveal that MouseGPT surpasses
existing models in precision, adaptability, and descriptive richness,
positioning it as a transformative tool for ethology and for unraveling complex
behavioral dynamics in animal models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>53 pages, 5 figures, 7 extended figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ TARS: Traffic-Aware Radar Scene Flow Estimation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10210v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10210v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jialong Wu, Marco Braun, Dominic Spata, Matthias Rottmann
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Scene flow provides crucial motion information for autonomous driving. Recent
LiDAR scene flow models utilize the rigid-motion assumption at the instance
level, assuming objects are rigid bodies. However, these instance-level methods
are not suitable for sparse radar point clouds. In this work, we present a
novel $\textbf{T}$raffic-$\textbf{A}$ware $\textbf{R}$adar $\textbf{S}$cene
flow estimation method, named $\textbf{TARS}$, which utilizes the motion
rigidity at the traffic level. To address the challenges in radar scene flow,
we perform object detection and scene flow jointly and boost the latter. We
incorporate the feature map from the object detector, trained with detection
losses, to make radar scene flow aware of the environment and road users.
Therefrom, we construct a Traffic Vector Field (TVF) in the feature space,
enabling a holistic traffic-level scene understanding in our scene flow branch.
When estimating the scene flow, we consider both point-level motion cues from
point neighbors and traffic-level consistency of rigid motion within the space.
TARS outperforms the state of the art on a proprietary dataset and the
View-of-Delft dataset, improving the benchmarks by 23% and 15%, respectively.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LVAgent: Long Video Understanding by Multi-Round Dynamical Collaboration
  of MLLM Agents 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10200v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10200v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Boyu Chen, Zhengrong Yue, Siran Chen, Zikang Wang, Yang Liu, Peng Li, Yali Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing Multimodal Large Language Models (MLLMs) encounter significant
challenges in modeling the temporal context within long videos. Currently,
mainstream Agent-based methods use external tools (e.g., search engine, memory
banks, OCR, retrieval models) to assist a single MLLM in answering long video
questions. Despite such tool-based support, a solitary MLLM still offers only a
partial understanding of long videos, resulting in limited performance. In
order to better address long video tasks, we introduce LVAgent, the first
framework enabling multi-round dynamic collaboration of MLLM agents in long
video understanding. Our methodology consists of four key steps: 1. Selection:
We pre-select appropriate agents from the model library to form optimal agent
teams based on different tasks. 2. Perception: We design an effective retrieval
scheme for long videos, improving the coverage of critical temporal segments
while maintaining computational efficiency. 3. Action: Agents answer long
video-related questions and exchange reasons. 4. Reflection: We evaluate the
performance of each agent in each round of discussion and optimize the agent
team for dynamic collaboration. The agents iteratively refine their answers by
multi-round dynamical collaboration of MLLM agents. LVAgent is the first agent
system method that outperforms all closed-source models (including GPT-4o) and
open-source models (including InternVL-2.5 and Qwen2-VL) in the long video
understanding tasks. Our LVAgent achieves an accuracy of 80% on four mainstream
long video understanding tasks. Notably, on the LongVideoBench dataset, LVAgent
improves accuracy by up to 14.3% compared with SOTA.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ST-FlowNet: An Efficient Spiking Neural Network for Event-Based Optical
  Flow Estimation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10195v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10195v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hongze Sun, Jun Wang, Wuque Cai, Duo Chen, Qianqian Liao, Jiayi He, Yan Cui, Dezhong Yao, Daqing Guo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Spiking Neural Networks (SNNs) have emerged as a promising tool for
event-based optical flow estimation tasks due to their ability to leverage
spatio-temporal information and low-power capabilities. However, the
performance of SNN models is often constrained, limiting their application in
real-world scenarios. In this work, we address this gap by proposing a novel
neural network architecture, ST-FlowNet, specifically tailored for optical flow
estimation from event-based data. The ST-FlowNet architecture integrates
ConvGRU modules to facilitate cross-modal feature augmentation and temporal
alignment of the predicted optical flow, improving the network's ability to
capture complex motion dynamics. Additionally, to overcome the challenges
associated with training SNNs, we introduce a novel approach to derive SNN
models from pre-trained artificial neural networks (ANNs) through ANN-to-SNN
conversion or our proposed BISNN method. Notably, the BISNN method alleviates
the complexities involved in biological parameter selection, further enhancing
the robustness of SNNs in optical flow estimation tasks. Extensive evaluations
on three benchmark event-based datasets demonstrate that the SNN-based
ST-FlowNet model outperforms state-of-the-art methods, delivering superior
performance in accurate optical flow estimation across a diverse range of
dynamic visual scenes. Furthermore, the inherent energy efficiency of SNN
models is highlighted, establishing a compelling advantage for their practical
deployment. Overall, our work presents a novel framework for optical flow
estimation using SNNs and event-based data, contributing to the advancement of
neuromorphic vision applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 5 figures, 5 tables; This work has been submitted for
  possible publication</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Robustness Tokens: Towards Adversarial Robustness of Transformers <span class="chip">ECCV</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10191v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10191v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Brian Pulfer, Yury Belousov, Slava Voloshynovskiy
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, large pre-trained foundation models have become widely adopted by
machine learning practitioners for a multitude of tasks. Given that such models
are publicly available, relying on their use as backbone models for downstream
tasks might result in high vulnerability to adversarial attacks crafted with
the same public model. In this work, we propose Robustness Tokens, a novel
approach specific to the transformer architecture that fine-tunes a few
additional private tokens with low computational requirements instead of tuning
model parameters as done in traditional adversarial training. We show that
Robustness Tokens make Vision Transformer models significantly more robust to
white-box adversarial attacks while also retaining the original downstream
performances.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This paper has been accepted for publication at the European
  Conference on Computer Vision (ECCV), 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Through the Magnifying Glass: Adaptive Perception Magnification for
  Hallucination-Free VLM Decoding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10183v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10183v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shunqi Mao, Chaoyi Zhang, Weidong Cai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing vision-language models (VLMs) often suffer from visual
hallucination, where the generated responses contain inaccuracies that are not
grounded in the visual input. Efforts to address this issue without model
finetuning primarily mitigate hallucination by reducing biases contrastively or
amplifying the weights of visual embedding during decoding. However, these
approaches improve visual perception at the cost of impairing the language
reasoning capability. In this work, we propose the Perception Magnifier (PM), a
novel visual decoding method that iteratively isolates relevant visual tokens
based on attention and magnifies the corresponding regions, spurring the model
to concentrate on fine-grained visual details during decoding. Specifically, by
magnifying critical regions while preserving the structural and contextual
information at each decoding step, PM allows the VLM to enhance its scrutiny of
the visual input, hence producing more accurate and faithful responses.
Extensive experimental results demonstrate that PM not only achieves superior
hallucination mitigation but also enhances language generation while preserving
strong reasoning capabilities.Code is available at
https://github.com/ShunqiM/PM .
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages, 5 figures, 9 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         <span class="highlight-title">★</span> GS-SDF: LiDAR-Augmented Gaussian Splatting and Neural SDF for
  Geometrically Consistent Rendering and Reconstruction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10170v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10170v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jianheng Liu, Yunfei Wan, Bowen Wang, Chunran Zheng, Jiarong Lin, <span class="highlight-author">Fu Zhang</span>
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Digital twins are fundamental to the development of autonomous driving and
embodied artificial intelligence. However, achieving high-granularity surface
reconstruction and high-fidelity rendering remains a challenge. Gaussian
splatting offers efficient photorealistic rendering but struggles with
geometric inconsistencies due to fragmented primitives and sparse observational
data in robotics applications. Existing regularization methods, which rely on
render-derived constraints, often fail in complex environments. Moreover,
effectively integrating sparse LiDAR data with Gaussian splatting remains
challenging. We propose a unified LiDAR-visual system that synergizes Gaussian
splatting with a neural signed distance field. The accurate LiDAR point clouds
enable a trained neural signed distance field to offer a manifold geometry
field, This motivates us to offer an SDF-based Gaussian initialization for
physically grounded primitive placement and a comprehensive geometric
regularization for geometrically consistent rendering and reconstruction.
Experiments demonstrate superior reconstruction accuracy and rendering quality
across diverse trajectories. To benefit the community, the codes will be
released at https://github.com/hku-mars/GS-SDF.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Complexity Experts are Task-Discriminative Learners for Any Image
  Restoration <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.18466v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.18466v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Eduard Zamfir, Zongwei Wu, Nancy Mehta, Yuedong Tan, Danda Pani Paudel, Yulun Zhang, Radu Timofte
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in all-in-one image restoration models have
revolutionized the ability to address diverse degradations through a unified
framework. However, parameters tied to specific tasks often remain inactive for
other tasks, making mixture-of-experts (MoE) architectures a natural extension.
Despite this, MoEs often show inconsistent behavior, with some experts
unexpectedly generalizing across tasks while others struggle within their
intended scope. This hinders leveraging MoEs' computational benefits by
bypassing irrelevant experts during inference. We attribute this undesired
behavior to the uniform and rigid architecture of traditional MoEs. To address
this, we introduce ``complexity experts" -- flexible expert blocks with varying
computational complexity and receptive fields. A key challenge is assigning
tasks to each expert, as degradation complexity is unknown in advance. Thus, we
execute tasks with a simple bias toward lower complexity. To our surprise, this
preference effectively drives task-specific allocation, assigning tasks to
experts with the appropriate complexity. Extensive experiments validate our
approach, demonstrating the ability to bypass irrelevant experts during
inference while maintaining superior performance. The proposed MoCE-IR model
outperforms state-of-the-art methods, affirming its efficiency and practical
applicability. The source code and models are publicly available at
\href{https://eduardzamfir.github.io/moceir/}{\texttt{eduardzamfir.github.io/MoCE-IR/}}
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at CVPR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ BIMBA: Selective-Scan Compression for Long-Range Video Question
  Answering <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09590v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09590v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Md Mohaiminul Islam, Tushar Nagarajan, Huiyu Wang, Gedas Bertasius, Lorenzo Torresani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Video Question Answering (VQA) in long videos poses the key challenge of
extracting relevant information and modeling long-range dependencies from many
redundant frames. The self-attention mechanism provides a general solution for
sequence modeling, but it has a prohibitive cost when applied to a massive
number of spatiotemporal tokens in long videos. Most prior methods rely on
compression strategies to lower the computational cost, such as reducing the
input length via sparse frame sampling or compressing the output sequence
passed to the large language model (LLM) via space-time pooling. However, these
naive approaches over-represent redundant information and often miss salient
events or fast-occurring space-time patterns. In this work, we introduce BIMBA,
an efficient state-space model to handle long-form videos. Our model leverages
the selective scan algorithm to learn to effectively select critical
information from high-dimensional video and transform it into a reduced token
sequence for efficient LLM processing. Extensive experiments demonstrate that
BIMBA achieves state-of-the-art accuracy on multiple long-form VQA benchmarks,
including PerceptionTest, NExT-QA, EgoSchema, VNBench, LongVideoBench, and
Video-MME. Code, and models are publicly available at
https://sites.google.com/view/bimba-mllm.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by CVPR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Tiled Diffusion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.15185v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.15185v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Or Madar, Ohad Fried
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Image tiling -- the seamless connection of disparate images to create a
coherent visual field -- is crucial for applications such as texture creation,
video game asset development, and digital art. Traditionally, tiles have been
constructed manually, a method that poses significant limitations in
scalability and flexibility. Recent research has attempted to automate this
process using generative models. However, current approaches primarily focus on
tiling textures and manipulating models for single-image generation, without
inherently supporting the creation of multiple interconnected tiles across
diverse domains. This paper presents Tiled Diffusion, a novel approach that
extends the capabilities of diffusion models to accommodate the generation of
cohesive tiling patterns across various domains of image synthesis that require
tiling. Our method supports a wide range of tiling scenarios, from self-tiling
to complex many-to-many connections, enabling seamless integration of multiple
images. Tiled Diffusion automates the tiling process, eliminating the need for
manual intervention and enhancing creative possibilities in various
applications, such as seamlessly tiling of existing images, tiled texture
creation, and 360$^\circ$ synthesis.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Please visit our website for more information and the code:
  https://madaror.github.io/tiled-diffusion.github.io/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ACDiT: Interpolating Autoregressive Conditional Modeling and Diffusion
  Transformer 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.07720v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.07720v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jinyi Hu, Shengding Hu, Yuxuan Song, Yufei Huang, Mingxuan Wang, Hao Zhou, Zhiyuan Liu, Wei-Ying Ma, Maosong Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present ACDiT, a novel Autoregressive blockwise Conditional Diffusion
Transformer, that innovatively combines autoregressive and diffusion paradigms
for modeling continuous visual information. By introducing a block-wise
autoregressive unit, ACDiT offers a flexible interpolation between token-wise
autoregression and full-sequence diffusion, bypassing the limitations of
discrete tokenization. The generation of each block is formulated as a
conditional diffusion process, conditioned on prior blocks. ACDiT is easy to
implement, as simple as creating a Skip-Causal Attention Mask (SCAM) on
standard diffusion transformer during training. During inference, the process
iterates between diffusion denoising and autoregressive decoding that can make
full use of KV-Cache. We show that ACDiT performs best among all autoregressive
baselines under similar model scales on image and video generation tasks. We
also demonstrate that benefiting from autoregressive modeling, pretrained ACDiT
can be transferred in visual understanding tasks despite being trained with the
diffusion objective. The analysis of the trade-off between autoregressive
modeling and diffusion demonstrates the potential of ACDiT to be used in
long-horizon visual generation tasks. We hope that ACDiT offers a novel
perspective on visual autoregressive generation and unlocks new avenues for
unified models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Video Super-Resolution: All You Need is a Video Diffusion Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03355v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03355v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhihao Zhan, Wang Pang, Xiang Zhu, Yechao Bai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a generic video super-resolution algorithm in this paper, based on
the Diffusion Posterior Sampling framework with an unconditional video
generation model in latent space. The video generation model, a diffusion
transformer, functions as a space-time model. We argue that a powerful model,
which learns the physics of the real world, can easily handle various kinds of
motion patterns as prior knowledge, thus eliminating the need for explicit
estimation of optical flows or motion parameters for pixel alignment.
Furthermore, a single instance of the proposed video diffusion transformer
model can adapt to different sampling conditions without re-training. Empirical
results on synthetic and real-world datasets demonstrate that our method has
strong capabilities to address video super-resolution challenges.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ UniGaze: Towards Universal Gaze Estimation via Large-scale Pre-Training 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.02307v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.02307v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiawei Qin, Xucong Zhang, Yusuke Sugano
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite decades of research on data collection and model architectures,
current gaze estimation models encounter significant challenges in generalizing
across diverse data domains. Recent advances in self-supervised pre-training
have shown remarkable performances in generalization across various vision
tasks. However, their effectiveness in gaze estimation remains unexplored. We
propose UniGaze, for the first time, leveraging large-scale in-the-wild facial
datasets for gaze estimation through self-supervised pre-training. Through
systematic investigation, we clarify critical factors that are essential for
effective pretraining in gaze estimation. Our experiments reveal that
self-supervised approaches designed for semantic tasks fail when applied to
gaze estimation, while our carefully designed pre-training pipeline
consistently improves cross-domain performance. Through comprehensive
experiments of challenging cross-dataset evaluation and novel protocols
including leave-one-dataset-out and joint-dataset settings, we demonstrate that
UniGaze significantly improves generalization across multiple data domains
while minimizing reliance on costly labeled data. source code and model are
available at https://github.com/ut-vision/UniGaze.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Fast MRI for All: Bridging Equity Gaps via Training without Raw Data
  Access 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.13022v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.13022v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yaşar Utku Alçalar, Merve Gülle, Mehmet Akçakaya
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Physics-driven deep learning (PD-DL) approaches have become popular for
improved reconstruction of fast magnetic resonance imaging (MRI) scans. Though
PD-DL offers higher acceleration rates than existing clinical fast MRI
techniques, their use has been limited outside specialized MRI centers. A key
challenge is generalization to underrepresented pathologies or populations,
noted in multiple studies, with fine-tuning on target populations suggested for
improvement. However, current approaches for PD-DL training require access to
raw k-space measurements, which is typically only available at specialized MRI
centers that have research agreements for such data access. This is especially
an issue for rural and underserved areas, where commercial MRI scanners only
provide access to a final reconstructed image. To tackle these challenges, we
propose Compressibility-inspired Unsupervised Learning via Parallel Imaging
Fidelity (CUPID) for high-quality PD-DL training using only routine clinical
reconstructed images exported from an MRI scanner. CUPID evaluates output
quality with a compressibility-based approach while ensuring that the output
stays consistent with the clinical parallel imaging reconstruction through
well-designed perturbations. Our results show CUPID achieves similar quality to
established PD-DL training that requires k-space data while outperforming
compressed sensing (CS) and diffusion-based generative methods. We further
demonstrate its effectiveness in a zero-shot training setup for retrospectively
and prospectively sub-sampled acquisitions, attesting to its minimal training
burden. As an approach that radically deviates from existing strategies, CUPID
presents an opportunity to provide equitable access to fast MRI for underserved
populations in an attempt to reduce the inequalities associated with this
expensive imaging modality.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SpotLight: Shadow-Guided Object Relighting via Diffusion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.18665v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.18665v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Frédéric Fortier-Chouinard, Zitian Zhang, Louis-Etienne Messier, Mathieu Garon, Anand Bhattad, Jean-François Lalonde
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent work has shown that diffusion models can serve as powerful neural
rendering engines that can be leveraged for inserting virtual objects into
images. However, unlike typical physics-based renderers, these neural rendering
engines are limited by the lack of manual control over the lighting, which is
often essential for improving or personalizing the desired image outcome. In
this paper, we show that precise lighting control can be achieved for object
relighting simply by providing a coarse shadow of the object. Indeed, we show
that injecting only the desired shadow of the object into a pre-trained
diffusion-based neural renderer enables it to accurately shade the object
according to the desired light position, while properly harmonizing the object
(and its shadow) within the target background image. Our method, SpotLight,
leverages existing neural rendering approaches and achieves controllable
relighting results with no additional training. We show that SpotLight achieves
superior object compositing results, both quantitatively and perceptually, as
confirmed by a user study, outperforming existing diffusion-based models
specifically designed for relighting. We also demonstrate other applications,
such as hand-scribbling shadows and full-image relighting, demonstrating its
versatility.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project page: https://lvsn.github.io/spotlight</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ WonderVerse: Extendable 3D Scene Generation with Video Generative Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09160v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09160v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hao Feng, Zhi Zuo, Jia-Hui Pan, Ka-Hei Hui, Yihua Shao, Qi Dou, Wei Xie, Zhengzhe Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce \textit{WonderVerse}, a simple but effective framework for
generating extendable 3D scenes. Unlike existing methods that rely on iterative
depth estimation and image inpainting, often leading to geometric distortions
and inconsistencies, WonderVerse leverages the powerful world-level priors
embedded within video generative foundation models to create highly immersive
and geometrically coherent 3D environments. Furthermore, we propose a new
technique for controllable 3D scene extension to substantially increase the
scale of the generated environments. Besides, we introduce a novel abnormal
sequence detection module that utilizes camera trajectory to address geometric
inconsistency in the generated videos. Finally, WonderVerse is compatible with
various 3D reconstruction methods, allowing both efficient and high-quality
generation. Extensive experiments on 3D scene generation demonstrate that our
WonderVerse, with an elegant and simple pipeline, delivers extendable and
highly-realistic 3D scenes, markedly outperforming existing works that rely on
more complex architectures.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ HecVL: Hierarchical Video-Language Pretraining for Zero-shot Surgical
  Phase Recognition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.10075v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.10075v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kun Yuan, Vinkle Srivastav, Nassir Navab, Nicolas Padoy
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Natural language could play an important role in developing generalist
surgical models by providing a broad source of supervision from raw texts. This
flexible form of supervision can enable the model's transferability across
datasets and tasks as natural language can be used to reference learned visual
concepts or describe new ones. In this work, we present HecVL, a novel
hierarchical video-language pretraining approach for building a generalist
surgical model. Specifically, we construct a hierarchical video-text paired
dataset by pairing the surgical lecture video with three hierarchical levels of
texts: at clip-level, atomic actions using transcribed audio texts; at
phase-level, conceptual text summaries; and at video-level, overall abstract
text of the surgical procedure. Then, we propose a novel fine-to-coarse
contrastive learning framework that learns separate embedding spaces for the
three video-text hierarchies using a single model. By disentangling embedding
spaces of different hierarchical levels, the learned multi-modal
representations encode short-term and long-term surgical concepts in the same
model. Thanks to the injected textual semantics, we demonstrate that the HecVL
approach can enable zero-shot surgical phase recognition without any human
annotation. Furthermore, we show that the same HecVL model for surgical phase
recognition can be transferred across different surgical procedures and medical
centers. The code is available at https://github.com/CAMMA-public/SurgVLP
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by MICCAI2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Procedure-Aware Surgical Video-language Pretraining with Hierarchical
  Knowledge Augmentation <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00263v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00263v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kun Yuan, Vinkle Srivastav, Nassir Navab, Nicolas Padoy
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Surgical video-language pretraining (VLP) faces unique challenges due to the
knowledge domain gap and the scarcity of multi-modal data. This study aims to
bridge the gap by addressing issues regarding textual information loss in
surgical lecture videos and the spatial-temporal challenges of surgical VLP. We
propose a hierarchical knowledge augmentation approach and a novel
Procedure-Encoded Surgical Knowledge-Augmented Video-Language Pretraining
(PeskaVLP) framework to tackle these issues. The knowledge augmentation uses
large language models (LLM) for refining and enriching surgical concepts, thus
providing comprehensive language supervision and reducing the risk of
overfitting. PeskaVLP combines language supervision with visual
self-supervision, constructing hard negative samples and employing a Dynamic
Time Warping (DTW) based loss function to effectively comprehend the
cross-modal procedural alignment. Extensive experiments on multiple public
surgical scene understanding and cross-modal retrieval datasets show that our
proposed method significantly improves zero-shot transferring performance and
offers a generalist visual representation for further advancements in surgical
scene understanding.The code is available at
https://github.com/CAMMA-public/SurgVLP
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at the 38th Conference on Neural Information Processing
  Systems (NeurIPS 2024 Spolight)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Making Every Frame Matter: Continuous Activity Recognition in Streaming
  Video via Adaptive Video Context Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14993v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14993v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hao Wu, Donglin Bai, Shiqi Jiang, Qianxi Zhang, Yifan Yang, Xin Ding, Ting Cao, Yunxin Liu, Fengyuan Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Video activity recognition has become increasingly important in robots and
embodied AI. Recognizing continuous video activities poses considerable
challenges due to the fast expansion of streaming video, which contains
multi-scale and untrimmed activities. We introduce a novel system, CARS, to
overcome these issues through adaptive video context modeling. Adaptive video
context modeling refers to selectively maintaining activity-related features in
temporal and spatial dimensions. CARS has two key designs. The first is an
activity spatial feature extraction by eliminating irrelevant visual features
while maintaining recognition accuracy. The second is an activity-aware state
update introducing dynamic adaptability to better preserve the video context
for multi-scale activity recognition. Our CARS runs at speeds $>$30 FPS on
typical edge devices and outperforms all baselines by 1.2\% to 79.7\% in
accuracy. Moreover, we explore applying CARS to a large video model as a video
encoder. Experimental results show that our CARS can result in a 0.46-point
enhancement (on a 5-point scale) on the in-distribution video activity dataset,
and an improvement ranging from 1.19\% to 4\% on zero-shot video activity
datasets.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Meissonic: Revitalizing Masked Generative Transformers for Efficient
  High-Resolution Text-to-Image Synthesis <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.08261v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.08261v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jinbin Bai, Tian Ye, Wei Chow, Enxin Song, Xiangtai Li, Zhen Dong, Lei Zhu, Shuicheng Yan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present Meissonic, which elevates non-autoregressive masked image modeling
(MIM) text-to-image to a level comparable with state-of-the-art diffusion
models like SDXL. By incorporating a comprehensive suite of architectural
innovations, advanced positional encoding strategies, and optimized sampling
conditions, Meissonic substantially improves MIM's performance and efficiency.
Additionally, we leverage high-quality training data, integrate
micro-conditions informed by human preference scores, and employ feature
compression layers to further enhance image fidelity and resolution. Our model
not only matches but often exceeds the performance of existing models like SDXL
in generating high-quality, high-resolution images. Extensive experiments
validate Meissonic's capabilities, demonstrating its potential as a new
standard in text-to-image synthesis. We release a model checkpoint capable of
producing $1024 \times 1024$ resolution images.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ICLR 2025. Codes and Supplementary Material:
  https://github.com/viiika/Meissonic</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MVGSR: Multi-View Consistency Gaussian Splatting for Robust Surface
  Reconstruction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08093v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08093v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chenfeng Hou, Qi Xun Yeo, Mengqi Guo, Yongxin Su, Yanyan Li, Gim Hee Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  3D Gaussian Splatting (3DGS) has gained significant attention for its
high-quality rendering capabilities, ultra-fast training, and inference speeds.
However, when we apply 3DGS to surface reconstruction tasks, especially in
environments with dynamic objects and distractors, the method suffers from
floating artifacts and color errors due to inconsistency from different
viewpoints. To address this challenge, we propose Multi-View Consistency
Gaussian Splatting for the domain of Robust Surface Reconstruction
(\textbf{MVGSR}), which takes advantage of lightweight Gaussian models and a
{heuristics-guided distractor masking} strategy for robust surface
reconstruction in non-static environments. Compared to existing methods that
rely on MLPs for distractor segmentation strategies, our approach separates
distractors from static scene elements by comparing multi-view feature
consistency, allowing us to obtain precise distractor masks early in training.
Furthermore, we introduce a pruning measure based on multi-view contributions
to reset transmittance, effectively reducing floating artifacts. Finally, a
multi-view consistency loss is applied to achieve high-quality performance in
surface reconstruction tasks. Experimental results demonstrate that MVGSR
achieves competitive geometric accuracy and rendering fidelity compared to the
state-of-the-art surface reconstruction algorithms. More information is
available on our project page (https://mvgsr.github.io).
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>project page https://mvgsr.github.io</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ COMBO: Compositional World Models for Embodied Multi-Agent Cooperation <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.10775v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.10775v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hongxin Zhang, Zeyuan Wang, Qiushi Lyu, Zheyuan Zhang, Sunli Chen, Tianmin Shu, Behzad Dariush, Kwonjoon Lee, Yilun Du, Chuang Gan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we investigate the problem of embodied multi-agent
cooperation, where decentralized agents must cooperate given only egocentric
views of the world. To effectively plan in this setting, in contrast to
learning world dynamics in a single-agent scenario, we must simulate world
dynamics conditioned on an arbitrary number of agents' actions given only
partial egocentric visual observations of the world. To address this issue of
partial observability, we first train generative models to estimate the overall
world state given partial egocentric observations. To enable accurate
simulation of multiple sets of actions on this world state, we then propose to
learn a compositional world model for multi-agent cooperation by factorizing
the naturally composable joint actions of multiple agents and compositionally
generating the video conditioned on the world state. By leveraging this
compositional world model, in combination with Vision Language Models to infer
the actions of other agents, we can use a tree search procedure to integrate
these modules and facilitate online cooperative planning. We evaluate our
methods on three challenging benchmarks with 2-4 agents. The results show our
compositional world model is effective and the framework enables the embodied
agents to cooperate efficiently with different agents across various tasks and
an arbitrary number of agents, showing the promising future of our proposed
methods. More videos can be found at https://embodied-agi.cs.umass.edu/combo/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published at ICLR 2025. 24 pages. The first three authors contributed
  equally</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ <span class="highlight-title">★</span> EMOVA: Empowering Language Models to See, Hear and Speak with Vivid
  Emotions <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.18042v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.18042v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kai Chen, Yunhao Gou, Runhui Huang, Zhili Liu, Daxin Tan, Jing Xu, Chunwei Wang, Yi Zhu, Yihan Zeng, Kuo Yang, Dingdong Wang, Kun Xiang, Haoyuan Li, Haoli Bai, Jianhua Han, Xiaohui Li, Weike Jin, Nian Xie, Yu Zhang, James T. Kwok, Hengshuang Zhao, Xiaodan Liang, Dit-Yan Yeung, Xiao Chen, Zhenguo Li, <span class="highlight-author">Wei Zhang</span>, Qun Liu, Jun Yao, Lanqing Hong, Lu Hou, Hang Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  GPT-4o, an omni-modal model that enables vocal conversations with diverse
emotions and tones, marks a milestone for omni-modal foundation models.
However, empowering Large Language Models to perceive and generate images,
texts, and speeches end-to-end with publicly available data remains challenging
for the open-source community. Existing vision-language models rely on external
tools for speech processing, while speech-language models still suffer from
limited or totally without vision-understanding capabilities. To address this
gap, we propose the EMOVA (EMotionally Omni-present Voice Assistant), to enable
Large Language Models with end-to-end speech abilities while maintaining the
leading vision-language performance. With a semantic-acoustic disentangled
speech tokenizer, we surprisingly notice that omni-modal alignment can further
enhance vision-language and speech abilities compared with the bi-modal aligned
counterparts. Moreover, a lightweight style module is introduced for the
flexible speech style controls including emotions and pitches. For the first
time, EMOVA achieves state-of-the-art performance on both the vision-language
and speech benchmarks, and meanwhile, supporting omni-modal spoken dialogue
with vivid emotions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by CVPR 2025. Project Page: https://emova-ollm.github.io/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SplatAD: Real-Time Lidar and Camera Rendering with 3D Gaussian Splatting
  for Autonomous Driving 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.16816v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.16816v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Georg Hess, Carl Lindström, Maryam Fatemi, Christoffer Petersson, Lennart Svensson
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Ensuring the safety of autonomous robots, such as self-driving vehicles,
requires extensive testing across diverse driving scenarios. Simulation is a
key ingredient for conducting such testing in a cost-effective and scalable
way. Neural rendering methods have gained popularity, as they can build
simulation environments from collected logs in a data-driven manner. However,
existing neural radiance field (NeRF) methods for sensor-realistic rendering of
camera and lidar data suffer from low rendering speeds, limiting their
applicability for large-scale testing. While 3D Gaussian Splatting (3DGS)
enables real-time rendering, current methods are limited to camera data and are
unable to render lidar data essential for autonomous driving. To address these
limitations, we propose SplatAD, the first 3DGS-based method for realistic,
real-time rendering of dynamic scenes for both camera and lidar data. SplatAD
accurately models key sensor-specific phenomena such as rolling shutter
effects, lidar intensity, and lidar ray dropouts, using purpose-built
algorithms to optimize rendering efficiency. Evaluation across three autonomous
driving datasets demonstrates that SplatAD achieves state-of-the-art rendering
quality with up to +2 PSNR for NVS and +3 PSNR for reconstruction while
increasing rendering speed over NeRF-based methods by an order of magnitude.
See https://research.zenseact.com/publications/splatad/ for our project page.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ PEMF-VTO: Point-Enhanced Video Virtual Try-on via Mask-free Paradigm 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.03021v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.03021v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tianyu Chang, Xiaohao Chen, Zhichao Wei, Xuanpu Zhang, Qing-Guo Chen, Weihua Luo, Peipei Song, Xun Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Video Virtual Try-on aims to seamlessly transfer a reference garment onto a
target person in a video while preserving both visual fidelity and temporal
coherence. Existing methods typically rely on inpainting masks to define the
try-on area, enabling accurate garment transfer for simple scenes (e.g.,
in-shop videos). However, these mask-based approaches struggle with complex
real-world scenarios, as overly large and inconsistent masks often destroy
spatial-temporal information, leading to distorted results. Mask-free methods
alleviate this issue but face challenges in accurately determining the try-on
area, especially for videos with dynamic body movements. To address these
limitations, we propose PEMF-VTO, a novel Point-Enhanced Mask-Free Video
Virtual Try-On framework that leverages sparse point alignments to explicitly
guide garment transfer. Our key innovation is the introduction of
point-enhanced guidance, which provides flexible and reliable control over both
spatial-level garment transfer and temporal-level video coherence.
Specifically, we design a Point-Enhanced Transformer (PET) with two core
components: Point-Enhanced Spatial Attention (PSA), which uses frame-cloth
point alignments to precisely guide garment transfer, and Point-Enhanced
Temporal Attention (PTA), which leverages frame-frame point correspondences to
enhance temporal coherence and ensure smooth transitions across frames.
Extensive experiments demonstrate that our PEMF-VTO outperforms
state-of-the-art methods, generating more natural, coherent, and visually
appealing try-on videos, particularly for challenging in-the-wild scenarios.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Semi-supervised Semantic Segmentation for Remote Sensing Images via
  Multi-scale Uncertainty Consistency and Cross-Teacher-Student Attention 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.10736v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.10736v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shanwen Wang, Xin Sun, Changrui Chen, Danfeng Hong, Jungong Han
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Semi-supervised learning offers an appealing solution for remote sensing (RS)
image segmentation to relieve the burden of labor-intensive pixel-level
labeling. However, RS images pose unique challenges, including rich multi-scale
features and high inter-class similarity. To address these problems, this paper
proposes a novel semi-supervised Multi-Scale Uncertainty and
Cross-Teacher-Student Attention (MUCA) model for RS image semantic segmentation
tasks. Specifically, MUCA constrains the consistency among feature maps at
different layers of the network by introducing a multi-scale uncertainty
consistency regularization. It improves the multi-scale learning capability of
semi-supervised algorithms on unlabeled data. Additionally, MUCA utilizes a
Cross-Teacher-Student attention mechanism to guide the student network, guiding
the student network to construct more discriminative feature representations
through complementary features from the teacher network. This design
effectively integrates weak and strong augmentations (WA and SA) to further
boost segmentation performance. To verify the effectiveness of our model, we
conduct extensive experiments on ISPRS-Potsdam and LoveDA datasets. The
experimental results show the superiority of our method over state-of-the-art
semi-supervised methods. Notably, our model excels in distinguishing highly
similar objects, showcasing its potential for advancing semi-supervised RS
image segmentation tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Are you Struggling? Dataset and Baselines for Struggle Determination in
  Assembly Videos 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.11057v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.11057v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shijia Feng, Michael Wray, Brian Sullivan, Youngkyoon Jang, Casimir Ludwig, Iain Gilchrist, Walterio Mayol-Cuevas
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Determining when people are struggling from video enables a finer-grained
understanding of actions and opens opportunities for building intelligent
support visual interfaces. In this paper, we present a new dataset with three
assembly activities and corresponding performance baselines for the
determination of struggle from video. Three real-world problem-solving
activities including assembling plumbing pipes (Pipes-Struggle), pitching
camping tents (Tent-Struggle) and solving the Tower of Hanoi puzzle
(Tower-Struggle) are introduced. Video segments were scored w.r.t. the level of
struggle as perceived by annotators using a forced choice 4-point scale. Each
video segment was annotated by a single expert annotator in addition to
crowd-sourced annotations. The dataset is the first struggle annotation dataset
and contains 5.1 hours of video and 725,100 frames from 73 participants in
total. We evaluate three decision-making tasks: struggle classification,
struggle level regression, and struggle label distribution learning. We provide
baseline results for each of the tasks utilising several mainstream deep neural
networks, along with an ablation study and visualisation of results. Our work
is motivated toward assistive systems that analyze struggle, support users
during manual activities and encourage learning, as well as other video
understanding competencies.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Reasoning to Attend: Try to Understand How <SEG> Token Works <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.17741v6">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.17741v6.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rui Qian, Xin Yin, Dejing Dou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Current Large Multimodal Models (LMMs) empowered visual grounding typically
rely on $\texttt{<SEG>}$ tokens as a text prompt to jointly optimize the
vision-language model (e.g., LLaVA) and the downstream task-specific model
(e.g., SAM). However, we observe that little research has looked into how it
works.In this work, we first visualize the similarity maps, which are obtained
by computing the semantic similarity between the $\texttt{<SEG>}$ token and the
image token embeddings derived from the last hidden layer in both the LLaVA
encoder and SAM decoder. Intriguingly, we have found that a striking
consistency holds in terms of activation responses in the similarity map, which
reveals that what the $\texttt{<SEG>}$ token contributes to is semantic
similarity within image-text pairs. Specifically, the $\texttt{<SEG>}$ token, a
placeholder expanded in text vocabulary, extensively queries among individual
tokenized image patches to match the semantics of an object from text to the
paired image, while the Large Language Models (LLMs) are being fine-tuned. Upon
the above findings, we present READ, which facilitates LMMs' resilient
$\textbf{REA}$soning capability of where to atten$\textbf{D}$ under the
guidance of highly activated points borrowed from similarity maps. Remarkably,
READ features an intuitive design, Similarity as Points module (SasP), which
can be seamlessly applied to $\texttt{<SEG>}$-like paradigms in a plug-and-play
fashion. Also, extensive experiments have been conducted on ReasonSeg and
RefCOCO(+/g) datasets. To validate whether READ suffers from catastrophic
forgetting of previous skills after fine-tuning, we further assess its
generation ability on an augmented FP-RefCOCO(+/g) dataset. All codes and
models are publicly available at https://github.com/rui-qian/READ.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This work has been accepted to CVPR 2025, please refer to
  https://github.com/rui-qian/READ</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Exploring a Multimodal Fusion-based Deep Learning Network for Detecting
  Facial Palsy 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.16496v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.16496v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Heng Yim Nicole Oo, Min Hun Lee, Jeong Hoon Lim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Algorithmic detection of facial palsy offers the potential to improve current
practices, which usually involve labor-intensive and subjective assessment by
clinicians. In this paper, we present a multimodal fusion-based deep learning
model that utilizes unstructured data (i.e. an image frame with facial line
segments) and structured data (i.e. features of facial expressions) to detect
facial palsy. We then contribute to a study to analyze the effect of different
data modalities and the benefits of a multimodal fusion-based approach using
videos of 21 facial palsy patients. Our experimental results show that among
various data modalities (i.e. unstructured data - RGB images and images of
facial line segments and structured data - coordinates of facial landmarks and
features of facial expressions), the feed-forward neural network using features
of facial expression achieved the highest precision of 76.22 while the
ResNet-based model using images of facial line segments achieved the highest
recall of 83.47. When we leveraged both images of facial line segments and
features of facial expressions, our multimodal fusion-based deep learning model
slightly improved the precision score to 77.05 at the expense of a decrease in
the recall score.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>IJCAI 2024 4th AI for Ageless Aging Workshop (AIAA)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Towards Generalizable Scene Change Detection <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06214v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06214v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jaewoo Kim, Uehwan Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While current state-of-the-art Scene Change Detection (SCD) approaches
achieve impressive results in well-trained research data, they become
unreliable under unseen environments and different temporal conditions;
in-domain performance drops from 77.6% to 8.0% in a previously unseen
environment and to 4.6% under a different temporal condition -- calling for
generalizable SCD and benchmark. In this work, we propose the Generalizable
Scene Change Detection Framework (GeSCF), which addresses unseen domain
performance and temporal consistency -- to meet the growing demand for anything
SCD. Our method leverages the pre-trained Segment Anything Model (SAM) in a
zero-shot manner. For this, we design Initial Pseudo-mask Generation and
Geometric-Semantic Mask Matching -- seamlessly turning user-guided prompt and
single-image based segmentation into scene change detection for a pair of
inputs without guidance. Furthermore, we define the Generalizable Scene Change
Detection (GeSCD) benchmark along with novel metrics and an evaluation protocol
to facilitate SCD research in generalizability. In the process, we introduce
the ChangeVPR dataset, a collection of challenging image pairs with diverse
environmental scenarios -- including urban, suburban, and rural settings.
Extensive experiments across various datasets demonstrate that GeSCF achieves
an average performance gain of 19.2% on existing SCD datasets and 30.0% on the
ChangeVPR dataset, nearly doubling the prior art performance. We believe our
work can lay a solid foundation for robust and generalizable SCD research.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Camera-ready version. Accepted to CVPR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ RewardSDS: Aligning Score Distillation via Reward-Weighted Sampling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09601v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09601v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Itay Chachy, Guy Yariv, Sagie Benaim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Score Distillation Sampling (SDS) has emerged as an effective technique for
leveraging 2D diffusion priors for tasks such as text-to-3D generation. While
powerful, SDS struggles with achieving fine-grained alignment to user intent.
To overcome this, we introduce RewardSDS, a novel approach that weights noise
samples based on alignment scores from a reward model, producing a weighted SDS
loss. This loss prioritizes gradients from noise samples that yield aligned
high-reward output. Our approach is broadly applicable and can extend SDS-based
methods. In particular, we demonstrate its applicability to Variational Score
Distillation (VSD) by introducing RewardVSD. We evaluate RewardSDS and
RewardVSD on text-to-image, 2D editing, and text-to-3D generation tasks,
showing significant improvements over SDS and VSD on a diverse set of metrics
measuring generation quality and alignment to desired reward models, enabling
state-of-the-art performance. Project page is available at
https://itaychachy.github.io/reward-sds/.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Arbitrary-steps Image Super-resolution via Diffusion Inversion <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.09013v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.09013v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zongsheng Yue, Kang Liao, Chen Change Loy
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study presents a new image super-resolution (SR) technique based on
diffusion inversion, aiming at harnessing the rich image priors encapsulated in
large pre-trained diffusion models to improve SR performance. We design a
Partial noise Prediction strategy to construct an intermediate state of the
diffusion model, which serves as the starting sampling point. Central to our
approach is a deep noise predictor to estimate the optimal noise maps for the
forward diffusion process. Once trained, this noise predictor can be used to
initialize the sampling process partially along the diffusion trajectory,
generating the desirable high-resolution result. Compared to existing
approaches, our method offers a flexible and efficient sampling mechanism that
supports an arbitrary number of sampling steps, ranging from one to five. Even
with a single sampling step, our method demonstrates superior or comparable
performance to recent state-of-the-art approaches. The code and model are
publicly available at https://github.com/zsyOAOA/InvSR.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by CVPR 2025. Project: https://github.com/zsyOAOA/InvSR</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Towards Class-wise Robustness Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.19853v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.19853v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tejaswini Medi, Julia Grabinski, Margret Keuper
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While being very successful in solving many downstream tasks, the application
of deep neural networks is limited in real-life scenarios because of their
susceptibility to domain shifts such as common corruptions, and adversarial
attacks. The existence of adversarial examples and data corruption
significantly reduces the performance of deep classification models.
Researchers have made strides in developing robust neural architectures to
bolster decisions of deep classifiers. However, most of these works rely on
effective adversarial training methods, and predominantly focus on overall
model robustness, disregarding class-wise differences in robustness, which are
critical. Exploiting weakly robust classes is a potential avenue for attackers
to fool the image recognition models. Therefore, this study investigates
class-to-class biases across adversarially trained robust classification models
to understand their latent space structures and analyze their strong and weak
class-wise properties. We further assess the robustness of classes against
common corruptions and adversarial attacks, recognizing that class
vulnerability extends beyond the number of correct classifications for a
specific class. We find that the number of false positives of classes as
specific target classes significantly impacts their vulnerability to attacks.
Through our analysis on the Class False Positive Score, we assess a fair
evaluation of how susceptible each class is to misclassification.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Revealing Bias Formation in Deep Neural Networks Through the Geometric
  Mechanisms of Human Visual Decoupling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.11809v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.11809v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yanbiao Ma, Bowei Liu, Boyuan Gao, Wei Dai, Jiayi Chen, Shuo Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep neural networks (DNNs) often exhibit biases toward certain categories
during object recognition, even under balanced training data conditions. The
intrinsic mechanisms underlying these biases remain unclear. Inspired by the
human visual system, which decouples object manifolds through hierarchical
processing to achieve object recognition, we propose a geometric analysis
framework linking the geometric complexity of class-specific perceptual
manifolds in DNNs to model bias. Our findings reveal that differences in
geometric complexity can lead to varying recognition capabilities across
categories, introducing biases. To support this analysis, we present the
Perceptual-Manifold-Geometry library, designed for calculating the geometric
properties of perceptual manifolds.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SMIRK: 3D Facial Expressions through Analysis-by-Neural-Synthesis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.04104v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.04104v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        George Retsinas, Panagiotis P. Filntisis, Radek Danecek, Victoria F. Abrevaya, Anastasios Roussos, Timo Bolkart, Petros Maragos
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While existing methods for 3D face reconstruction from in-the-wild images
excel at recovering the overall face shape, they commonly miss subtle, extreme,
asymmetric, or rarely observed expressions. We improve upon these methods with
SMIRK (Spatial Modeling for Image-based Reconstruction of Kinesics), which
faithfully reconstructs expressive 3D faces from images. We identify two key
limitations in existing methods: shortcomings in their self-supervised training
formulation, and a lack of expression diversity in the training images. For
training, most methods employ differentiable rendering to compare a predicted
face mesh with the input image, along with a plethora of additional loss
functions. This differentiable rendering loss not only has to provide
supervision to optimize for 3D face geometry, camera, albedo, and lighting,
which is an ill-posed optimization problem, but the domain gap between
rendering and input image further hinders the learning process. Instead, SMIRK
replaces the differentiable rendering with a neural rendering module that,
given the rendered predicted mesh geometry, and sparsely sampled pixels of the
input image, generates a face image. As the neural rendering gets color
information from sampled image pixels, supervising with neural rendering-based
reconstruction loss can focus solely on the geometry. Further, it enables us to
generate images of the input identity with varying expressions while training.
These are then utilized as input to the reconstruction model and used as
supervision with ground truth geometry. This effectively augments the training
data and enhances the generalization for diverse expressions. Our qualitative,
quantitative and particularly our perceptual evaluations demonstrate that SMIRK
achieves the new state-of-the art performance on accurate expression
reconstruction. Project webpage: https://georgeretsi.github.io/smirk/.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Uni-Sign: Toward Unified Sign Language Understanding at Scale <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.15187v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.15187v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zecheng Li, Wengang Zhou, Weichao Zhao, Kepeng Wu, Hezhen Hu, Houqiang Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sign language pre-training has gained increasing attention for its ability to
enhance performance across various sign language understanding (SLU) tasks.
However, existing methods often suffer from a gap between pre-training and
fine-tuning, leading to suboptimal results. To address this, we propose
Uni-Sign, a unified pre-training framework that eliminates the gap between
pre-training and downstream SLU tasks through a large-scale generative
pre-training strategy and a novel fine-tuning paradigm. First, we introduce
CSL-News, a large-scale Chinese Sign Language (CSL) dataset containing 1,985
hours of video paired with textual annotations, which enables effective
large-scale pre-training. Second, Uni-Sign unifies SLU tasks by treating
downstream tasks as a single sign language translation (SLT) task during
fine-tuning, ensuring seamless knowledge transfer between pre-training and
fine-tuning. Furthermore, we incorporate a prior-guided fusion (PGF) module and
a score-aware sampling strategy to efficiently fuse pose and RGB information,
addressing keypoint inaccuracies and improving computational efficiency.
Extensive experiments across multiple SLU benchmarks demonstrate that Uni-Sign
achieves state-of-the-art performance across multiple downstream SLU tasks.
Dataset and code are available at github.com/ZechengLi19/Uni-Sign.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Ultra-high resolution multimodal MRI dense labelled holistic brain atlas 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.16879v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.16879v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        José V. Manjón, Sergio Morell-Ortega, Marina Ruiz-Perez, Boris Mansencal, Edern Le Bot, Marien Gadea, Enrique Lanuza, Gwenaelle Catheline, Thomas Tourdias, Vincent Planche, Rémi Giraud, Denis Rivière, Jean-François Mangin, Nicole Labra-Avila, Roberto Vivo-Hernando, Gregorio Rubio, Fernando Aparici, Maria de la Iglesia-Vaya, Pierrick Coupé
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we introduce holiAtlas, a holistic, multimodal and
high-resolution human brain atlas. This atlas covers different levels of
details of the human brain anatomy, from the organ to the substructure level,
using a new dense labelled protocol generated from the fusion of multiple local
protocols at different scales. This atlas has been constructed averaging images
and segmentations of 75 healthy subjects from the Human Connectome Project
database. Specifically, MR images of T1, T2 and WMn (White Matter nulled)
contrasts at 0.125 $mm^{3}$ resolution that were nonlinearly registered and
averaged using symmetric group-wise normalisation to construct the atlas. At
the finest level, the holiAtlas protocol has 350 different labels derived from
10 different delineation protocols. These labels were grouped at different
scales to provide a holistic view of the brain at different levels in a
coherent and consistent manner. This multiscale and multimodal atlas can be
used for the development of new ultra-high resolution segmentation methods that
can potentially leverage the early detection of neurological disorders.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>22 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Prompt-SID: Learning Structural Representation Prompt via Latent
  Diffusion for Single-Image Denoising 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.06432v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.06432v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Huaqiu Li, Wang Zhang, Xiaowan Hu, Tao Jiang, Zikang Chen, Haoqian Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Many studies have concentrated on constructing supervised models utilizing
paired datasets for image denoising, which proves to be expensive and
time-consuming. Current self-supervised and unsupervised approaches typically
rely on blind-spot networks or sub-image pairs sampling, resulting in pixel
information loss and destruction of detailed structural information, thereby
significantly constraining the efficacy of such methods. In this paper, we
introduce Prompt-SID, a prompt-learning-based single image denoising framework
that emphasizes preserving of structural details. This approach is trained in a
self-supervised manner using downsampled image pairs. It captures
original-scale image information through structural encoding and integrates
this prompt into the denoiser. To achieve this, we propose a structural
representation generation model based on the latent diffusion process and
design a structural attention module within the transformer-based denoiser
architecture to decode the prompt. Additionally, we introduce a scale replay
training mechanism, which effectively mitigates the scale gap from images of
different resolutions. We conduct comprehensive experiments on synthetic,
real-world, and fluorescence imaging datasets, showcasing the remarkable
effectiveness of Prompt-SID. Our code will be released at
https://github.com/huaqlili/Prompt-SID.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Continuous K-space Recovery Network with Image Guidance for Fast MRI
  Reconstruction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.11282v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.11282v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yucong Meng, Zhiwei Yang, Minghong Duan, Yonghong Shi, Zhijian Song
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Magnetic resonance imaging (MRI) is a crucial tool for clinical diagnosis
while facing the challenge of long scanning time. To reduce the acquisition
time, fast MRI reconstruction aims to restore high-quality images from the
undersampled k-space. Existing methods typically train deep learning models to
map the undersampled data to artifact-free MRI images. However, these studies
often overlook the unique properties of k-space and directly apply general
networks designed for image processing to k-space recovery, leaving the precise
learning of k-space largely underexplored. In this work, we propose a
continuous k-space recovery network from a new perspective of implicit neural
representation with image domain guidance, which boosts the performance of MRI
reconstruction. Specifically, (1) an implicit neural representation based
encoder-decoder structure is customized to continuously query unsampled
k-values. (2) an image guidance module is designed to mine the semantic
information from the low-quality MRI images to further guide the k-space
recovery. (3) a multi-stage training strategy is proposed to recover dense
k-space progressively. Extensive experiments conducted on CC359, fastMRI, and
IXI datasets demonstrate the effectiveness of our method and its superiority
over other competitors.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DeepThalamus: A novel deep learning method for automatic segmentation of
  brain thalamic nuclei from multimodal ultra-high resolution MRI 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.07751v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.07751v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Marina Ruiz-Perez, Sergio Morell-Ortega, Marien Gadea, Roberto Vivo-Hernando, Gregorio Rubio, Fernando Aparici, Mariam de la Iglesia-Vaya, Thomas Tourdias, Pierrick Coupé, José V. Manjón
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The implication of the thalamus in multiple neurological pathologies makes it
a structure of interest for volumetric analysis. In the present work, we have
designed and implemented a multimodal volumetric deep neural network for the
segmentation of thalamic nuclei at ultra-high resolution (0.125 mm3). Current
tools either operate at standard resolution (1 mm3) or use monomodal data. To
achieve the proposed objective, first, a database of semiautomatically
segmented thalamic nuclei was created using ultra-high resolution T1, T2 and
White Matter nulled (WMn) images. Then, a novel Deep learning based strategy
was designed to obtain the automatic segmentations and trained to improve its
robustness and accuaracy using a semisupervised approach. The proposed method
was compared with a related state-of-the-art method showing competitive results
both in terms of segmentation quality and efficiency. To make the proposed
method fully available to the scientific community, a full pipeline able to
work with monomodal standard resolution T1 images is also proposed.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ReVLA: Reverting Visual Domain Limitation of Robotic Foundation Models <span class="chip">ICRA-2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.15250v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.15250v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sombit Dey, Jan-Nico Zaech, Nikolay Nikolov, Luc Van Gool, Danda Pani Paudel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent progress in large language models and access to large-scale robotic
datasets has sparked a paradigm shift in robotics models transforming them into
generalists able to adapt to various tasks, scenes, and robot modalities. A
large step for the community are open Vision Language Action models which
showcase strong performance in a wide variety of tasks. In this work, we study
the visual generalization capabilities of three existing robotic foundation
models, and propose a corresponding evaluation framework.
  Our study shows that the existing models do not exhibit robustness to visual
out-of-domain scenarios. This is potentially caused by limited variations in
the training data and/or catastrophic forgetting, leading to domain limitations
in the vision foundation models. We further explore OpenVLA, which uses two
pre-trained vision foundation models and is, therefore, expected to generalize
to out-of-domain experiments. However, we showcase catastrophic forgetting by
DINO-v2 in OpenVLA through its failure to fulfill the task of depth regression.
  To overcome the aforementioned issue of visual catastrophic forgetting, we
propose a gradual backbone reversal approach founded on model merging. This
enables OpenVLA which requires the adaptation of the visual backbones during
initial training -- to regain its visual generalization ability. Regaining this
capability enables our ReVLA model to improve over OpenVLA by a factor of 77%
and 66% for grasping and lifting in visual OOD tasks .
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at ICRA-2025, Atlanta</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Narrating the Video: Boosting Text-Video Retrieval via Comprehensive
  Utilization of Frame-Level Captions <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.05186v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.05186v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chan Hur, Jeong-hun Hong, Dong-hun Lee, Dabin Kang, Semin Myeong, Sang-hyo Park, Hyeyoung Park
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent text-video retrieval, the use of additional captions from
vision-language models has shown promising effects on the performance. However,
existing models using additional captions often have struggled to capture the
rich semantics, including temporal changes, inherent in the video. In addition,
incorrect information caused by generative models can lead to inaccurate
retrieval. To address these issues, we propose a new framework, Narrating the
Video (NarVid), which strategically leverages the comprehensive information
available from frame-level captions, the narration. The proposed NarVid
exploits narration in multiple ways: 1) feature enhancement through cross-modal
interactions between narration and video, 2) query-aware adaptive filtering to
suppress irrelevant or incorrect information, 3) dual-modal matching score by
adding query-video similarity and query-narration similarity, and 4)
hard-negative loss to learn discriminative features from multiple perspectives
using the two similarities from different views. Experimental results
demonstrate that NarVid achieves state-of-the-art performance on various
benchmark datasets.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at CVPR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ PhysVLM: Enabling Visual Language Models to Understand Robotic Physical
  Reachability 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08481v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08481v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Weijie Zhou, Manli Tao, Chaoyang Zhao, Haiyun Guo, Honghui Dong, Ming Tang, Jinqiao Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Understanding the environment and a robot's physical reachability is crucial
for task execution. While state-of-the-art vision-language models (VLMs) excel
in environmental perception, they often generate inaccurate or impractical
responses in embodied visual reasoning tasks due to a lack of understanding of
robotic physical reachability. To address this issue, we propose a unified
representation of physical reachability across diverse robots, i.e.,
Space-Physical Reachability Map (S-P Map), and PhysVLM, a vision-language model
that integrates this reachability information into visual reasoning.
Specifically, the S-P Map abstracts a robot's physical reachability into a
generalized spatial representation, independent of specific robot
configurations, allowing the model to focus on reachability features rather
than robot-specific parameters. Subsequently, PhysVLM extends traditional VLM
architectures by incorporating an additional feature encoder to process the S-P
Map, enabling the model to reason about physical reachability without
compromising its general vision-language capabilities. To train and evaluate
PhysVLM, we constructed a large-scale multi-robot dataset, Phys100K, and a
challenging benchmark, EQA-phys, which includes tasks for six different robots
in both simulated and real-world environments. Experimental results demonstrate
that PhysVLM outperforms existing models, achieving a 14\% improvement over
GPT-4o on EQA-phys and surpassing advanced embodied VLMs such as RoboMamba and
SpatialVLM on the RoboVQA-val and OpenEQA benchmarks. Additionally, the S-P Map
shows strong compatibility with various VLMs, and its integration into
GPT-4o-mini yields a 7.1\% performance improvement.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Audio-Visual Deepfake Detection With Local Temporal Inconsistencies 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.08137v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.08137v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Marcella Astrid, Enjie Ghorbel, Djamila Aouada
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper proposes an audio-visual deepfake detection approach that aims to
capture fine-grained temporal inconsistencies between audio and visual
modalities. To achieve this, both architectural and data synthesis strategies
are introduced. From an architectural perspective, a temporal distance map,
coupled with an attention mechanism, is designed to capture these
inconsistencies while minimizing the impact of irrelevant temporal
subsequences. Moreover, we explore novel pseudo-fake generation techniques to
synthesize local inconsistencies. Our approach is evaluated against
state-of-the-art methods using the DFDC and FakeAVCeleb datasets, demonstrating
its effectiveness in detecting audio-visual deepfakes.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted in ICASSP 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ATRNet-STAR: A Large Dataset and <span class="highlight-title">Benchmark</span> Towards Remote Sensing Object
  Recognition in the Wild 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.13354v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.13354v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yongxiang Liu, Weijie Li, Li Liu, Jie Zhou, Bowen Peng, Yafei Song, Xuying Xiong, Wei Yang, Tianpeng Liu, Zhen Liu, Xiang Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The absence of publicly available, large-scale, high-quality datasets for
Synthetic Aperture Radar Automatic Target Recognition (SAR ATR) has
significantly hindered the application of rapidly advancing deep learning
techniques, which hold huge potential to unlock new capabilities in this field.
This is primarily because collecting large volumes of diverse target samples
from SAR images is prohibitively expensive, largely due to privacy concerns,
the characteristics of microwave radar imagery perception, and the need for
specialized expertise in data annotation. Throughout the history of SAR ATR
research, there have been only a number of small datasets, mainly including
targets like ships, airplanes, buildings, etc. There is only one vehicle
dataset MSTAR collected in the 1990s, which has been a valuable source for SAR
ATR. To fill this gap, this paper introduces a large-scale, new dataset named
ATRNet-STAR with 40 different vehicle categories collected under various
realistic imaging conditions and scenes. It marks a substantial advancement in
dataset scale and diversity, comprising over 190,000 well-annotated samples, 10
times larger than its predecessor, the famous MSTAR. Building such a large
dataset is a challenging task, and the data collection scheme will be detailed.
Secondly, we illustrate the value of ATRNet-STAR via extensively evaluating the
performance of 15 representative methods with 7 different experimental settings
on challenging classification and detection benchmarks derived from the
dataset. Finally, based on our extensive experiments, we identify valuable
insights for SAR ATR and discuss potential future research directions in this
field. We hope that the scale, diversity, and benchmark of ATRNet-STAR can
significantly facilitate the advancement of SAR ATR.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages, 14 figures; ATRNet-STAR:
  https://github.com/waterdisappear/ATRNet-STAR</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FaVChat: Unlocking Fine-Grained Facial Video Understanding with
  Multimodal Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09158v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09158v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fufangchen Zhao, Ming Li, Linrui Xu, Wenhao Jiang, Jian Gao, Danfeng Yan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Video-based multimodal large language models (VMLLMs) have demonstrated
remarkable potential in cross-modal video understanding. However, their
abilities in fine-grained face comprehension remain largely underexplored.
Given its pivotal role in human-centric intelligence, developing VMLLMs for
facial understanding holds a fundamental problem. To address this gap, we
propose FaVChat, the first VMLLM specifically designed for fine-grained facial
video understanding. To facilitate its training, we construct a large-scale
facial video dataset comprising over 60k videos, with the majority annotated
with 83 fine-grained facial attributes. These attributes are incorporated to
enrich GPT-4o-generated captions, yielding 60k high-quality video-summary pairs
and an additional 170k fine-grained question-answering (QA) pairs. To
effectively capture rich facial clues, we propose a hybrid model architecture
composed of a general visual encoder, a dedicated facial encoder, and a
mixture-of-experts-enhanced adapter for adaptive fusion of multi-source visual
features. To mitigate information loss during feature transformation, we
extract multi-granularity representations from the facial encoder and integrate
them into the subsequent LLM. This design enhances the model's ability to
comprehend and respond to questions involving diverse levels of visual details.
We employ a progressive training paradigm, transitioning from video
summarization to a high-quality subset of video QA, gradually increasing task
complexity to enhance the model's fine-grained visual perception. We conduct
extensive zero-shot evaluation on a couple of public benchmarks, demonstrating
that FaVChat consistently surpasses existing VMLLMs across multiple tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Hidden in the Noise: Two-Stage Robust Watermarking for Images 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.04653v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.04653v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kasra Arabi, Benjamin Feuer, R. Teal Witter, Chinmay Hegde, Niv Cohen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As the quality of image generators continues to improve, deepfakes become a
topic of considerable societal debate. Image watermarking allows responsible
model owners to detect and label their AI-generated content, which can mitigate
the harm. Yet, current state-of-the-art methods in image watermarking remain
vulnerable to forgery and removal attacks. This vulnerability occurs in part
because watermarks distort the distribution of generated images,
unintentionally revealing information about the watermarking techniques.
  In this work, we first demonstrate a distortion-free watermarking method for
images, based on a diffusion model's initial noise. However, detecting the
watermark requires comparing the initial noise reconstructed for an image to
all previously used initial noises. To mitigate these issues, we propose a
two-stage watermarking framework for efficient detection. During generation, we
augment the initial noise with generated Fourier patterns to embed information
about the group of initial noises we used. For detection, we (i) retrieve the
relevant group of noises, and (ii) search within the given group for an initial
noise that might match our image. This watermarking approach achieves
state-of-the-art robustness to forgery and removal against a large battery of
attacks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ GoalFlow: Goal-Driven Flow Matching for Multimodal Trajectories
  Generation in End-to-End Autonomous Driving 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.05689v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.05689v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zebin Xing, Xingyu Zhang, Yang Hu, Bo Jiang, Tong He, Qian Zhang, Xiaoxiao Long, Wei Yin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose GoalFlow, an end-to-end autonomous driving method for generating
high-quality multimodal trajectories. In autonomous driving scenarios, there is
rarely a single suitable trajectory. Recent methods have increasingly focused
on modeling multimodal trajectory distributions. However, they suffer from
trajectory selection complexity and reduced trajectory quality due to high
trajectory divergence and inconsistencies between guidance and scene
information. To address these issues, we introduce GoalFlow, a novel method
that effectively constrains the generative process to produce high-quality,
multimodal trajectories. To resolve the trajectory divergence problem inherent
in diffusion-based methods, GoalFlow constrains the generated trajectories by
introducing a goal point. GoalFlow establishes a novel scoring mechanism that
selects the most appropriate goal point from the candidate points based on
scene information. Furthermore, GoalFlow employs an efficient generative
method, Flow Matching, to generate multimodal trajectories, and incorporates a
refined scoring mechanism to select the optimal trajectory from the candidates.
Our experimental results, validated on the Navsim\cite{Dauner2024_navsim},
demonstrate that GoalFlow achieves state-of-the-art performance, delivering
robust multimodal trajectories for autonomous driving. GoalFlow achieved PDMS
of 90.3, significantly surpassing other methods. Compared with other
diffusion-policy-based methods, our approach requires only a single denoising
step to obtain excellent performance. The code is available at
https://github.com/YvanYin/GoalFlow.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The R2D2 Deep Neural Network Series for Scalable Non-Cartesian Magnetic
  Resonance Imaging 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09559v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09559v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yiwei Chen, Amir Aghabiglou, Shijie Chen, Motahare Torki, Chao Tang, Ruud B. van Heeswijk, Yves Wiaux
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce the R2D2 Deep Neural Network (DNN) series paradigm for fast and
scalable image reconstruction from highly-accelerated non-Cartesian k-space
acquisitions in Magnetic Resonance Imaging (MRI). While unrolled DNN
architectures provide a robust image formation approach via data-consistency
layers, embedding non-uniform fast Fourier transform operators in a DNN can
become impractical to train at large scale, e.g in 2D MRI with a large number
of coils, or for higher-dimensional imaging. Plug-and-play approaches that
alternate a learned denoiser blind to the measurement setting with a
data-consistency step are not affected by this limitation but their highly
iterative nature implies slow reconstruction. To address this scalability
challenge, we leverage the R2D2 paradigm that was recently introduced to enable
ultra-fast reconstruction for large-scale Fourier imaging in radio astronomy.
R2D2's reconstruction is formed as a series of residual images iteratively
estimated as outputs of DNN modules taking the previous iteration's data
residual as input. The method can be interpreted as a learned version of the
Matching Pursuit algorithm. A series of R2D2 DNN modules were sequentially
trained in a supervised manner on the fastMRI dataset and validated for 2D
multi-coil MRI in simulation and on real data, targeting highly under-sampled
radial k-space sampling. Results suggest that a series with only few DNNs
achieves superior reconstruction quality over its unrolled incarnation R2D2-Net
(whose training is also much less scalable), and over the state-of-the-art
diffusion-based "Decomposed Diffusion Sampler" approach (also characterised by
a slower reconstruction process).
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages, 10 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ $ShiftwiseConv:$ Small Convolutional Kernel with Large Kernel Effect <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.12736v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.12736v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dachong Li, Li Li, Zhuangzhuang Chen, Jianqiang Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large kernels make standard convolutional neural networks (CNNs) great again
over transformer architectures in various vision tasks. Nonetheless, recent
studies meticulously designed around increasing kernel size have shown
diminishing returns or stagnation in performance. Thus, the hidden factors of
large kernel convolution that affect model performance remain unexplored. In
this paper, we reveal that the key hidden factors of large kernels can be
summarized as two separate components: extracting features at a certain
granularity and fusing features by multiple pathways. To this end, we leverage
the multi-path long-distance sparse dependency relationship to enhance feature
utilization via the proposed Shiftwise (SW) convolution operator with a pure
CNN architecture. In a wide range of vision tasks such as classification,
segmentation, and detection, SW surpasses state-of-the-art transformers and CNN
architectures, including SLaK and UniRepLKNet. More importantly, our
experiments demonstrate that $3 \times 3$ convolutions can replace large
convolutions in existing large kernel CNNs to achieve comparable effects, which
may inspire follow-up works. Code and all the models at
https://github.com/lidc54/shift-wiseConv.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>CVPR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ AnomalyDINO: Boosting Patch-based Few-shot Anomaly Detection with DINOv2 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.14529v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.14529v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Simon Damm, Mike Laszkiewicz, Johannes Lederer, Asja Fischer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in multimodal foundation models have set new standards in
few-shot anomaly detection. This paper explores whether high-quality visual
features alone are sufficient to rival existing state-of-the-art
vision-language models. We affirm this by adapting DINOv2 for one-shot and
few-shot anomaly detection, with a focus on industrial applications. We show
that this approach does not only rival existing techniques but can even
outmatch them in many settings. Our proposed vision-only approach, AnomalyDINO,
follows the well-established patch-level deep nearest neighbor paradigm, and
enables both image-level anomaly prediction and pixel-level anomaly
segmentation. The approach is methodologically simple and training-free and,
thus, does not require any additional data for fine-tuning or meta-learning.
The approach is methodologically simple and training-free and, thus, does not
require any additional data for fine-tuning or meta-learning. Despite its
simplicity, AnomalyDINO achieves state-of-the-art results in one- and few-shot
anomaly detection (e.g., pushing the one-shot performance on MVTec-AD from an
AUROC of 93.1% to 96.6%). The reduced overhead, coupled with its outstanding
few-shot performance, makes AnomalyDINO a strong candidate for fast deployment,
e.g., in industrial contexts.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at WACV 2025 (Oral)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Reliable Representation Learning for Incomplete Multi-View Missing
  Multi-Label Classification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2303.17117v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2303.17117v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chengliang Liu, Jie Wen, Yong Xu, Bob Zhang, Liqiang Nie, Min Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As a cross-topic of multi-view learning and multi-label classification,
multi-view multi-label classification has gradually gained traction in recent
years. The application of multi-view contrastive learning has further
facilitated this process, however, the existing multi-view contrastive learning
methods crudely separate the so-called negative pair, which largely results in
the separation of samples belonging to the same category or similar ones.
Besides, plenty of multi-view multi-label learning methods ignore the possible
absence of views and labels. To address these issues, in this paper, we propose
an incomplete multi-view missing multi-label classification network named RANK.
In this network, a label-driven multi-view contrastive learning strategy is
proposed to leverage supervised information to preserve the intra-view
structure and perform the cross-view consistency alignment. Furthermore, we
break through the view-level weights inherent in existing methods and propose a
quality-aware sub-network to dynamically assign quality scores to each view of
each sample. The label correlation information is fully utilized in the final
multi-label cross-entropy classification loss, effectively improving the
discriminative power. Last but not least, our model is not only able to handle
complete multi-view multi-label data, but also works on datasets with missing
instances and labels. Extensive experiments confirm that our RANK outperforms
existing state-of-the-art methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by TPAMI. Please contact me if you have any questions:
  liucl1996@163.com</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LatentSync: Taming Audio-Conditioned Latent Diffusion Models for Lip
  Sync with SyncNet Supervision 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.09262v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.09262v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chunyu Li, Chao Zhang, Weikai Xu, Jingyu Lin, Jinghui Xie, Weiguo Feng, Bingyue Peng, Cunjian Chen, Weiwei Xing
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  End-to-end audio-conditioned latent diffusion models (LDMs) have been widely
adopted for audio-driven portrait animation, demonstrating their effectiveness
in generating lifelike and high-resolution talking videos. However, direct
application of audio-conditioned LDMs to lip-synchronization (lip-sync) tasks
results in suboptimal lip-sync accuracy. Through an in-depth analysis, we
identified the underlying cause as the "shortcut learning problem", wherein the
model predominantly learns visual-visual shortcuts while neglecting the
critical audio-visual correlations. To address this issue, we explored
different approaches for integrating SyncNet supervision into audio-conditioned
LDMs to explicitly enforce the learning of audio-visual correlations. Since the
performance of SyncNet directly influences the lip-sync accuracy of the
supervised model, the training of a well-converged SyncNet becomes crucial. We
conducted the first comprehensive empirical studies to identify key factors
affecting SyncNet convergence. Based on our analysis, we introduce
StableSyncNet, with an architecture designed for stable convergence. Our
StableSyncNet achieved a significant improvement in accuracy, increasing from
91% to 94% on the HDTF test set. Additionally, we introduce a novel Temporal
Representation Alignment (TREPA) mechanism to enhance temporal consistency in
the generated videos. Experimental results show that our method surpasses
state-of-the-art lip-sync approaches across various evaluation metrics on the
HDTF and VoxCeleb2 datasets.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ M2IST: Multi-Modal Interactive Side-Tuning for Efficient Referring
  Expression Comprehension 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.01131v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.01131v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xuyang Liu, Ting Liu, Siteng Huang, Yi Xin, Yue Hu, Quanjun Yin, Donglin Wang, Yuanyuan Wu, Honggang Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Referring expression comprehension (REC) is a vision-language task to locate
a target object in an image based on a language expression. Fully fine-tuning
general-purpose pre-trained vision-language foundation models for REC yields
impressive performance but becomes increasingly costly. Parameter-efficient
transfer learning (PETL) methods have shown strong performance with fewer
tunable parameters. However, directly applying PETL to REC faces two
challenges: (1) insufficient multi-modal interaction between pre-trained
vision-language foundation models, and (2) high GPU memory usage due to
gradients passing through the heavy vision-language foundation models. To this
end, we present M2IST: Multi-Modal Interactive Side-Tuning with M3ISAs: Mixture
of Multi-Modal Interactive Side-Adapters. During fine-tuning, we fix the
pre-trained uni-modal encoders and update M3ISAs to enable efficient
vision-language alignment for REC. Empirical results reveal that M2IST achieves
better performance-efficiency trade-off than full fine-tuning and other PETL
methods, requiring only 2.11\% tunable parameters, 39.61\% GPU memory, and
63.46\% training time while maintaining competitive performance. Our code is
released at https://github.com/xuyang-liu16/M2IST.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by IEEE Transactions on Circuits and Systems for Video
  Technology (TCSVT)</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Machine Learning <span class="chip" style="font-size: 60%">150</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Studying Classifier(-Free) Guidance From a Classifier-Centric
  Perspective 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10638v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10638v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaoming Zhao, Alexander G. Schwing
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Classifier-free guidance has become a staple for conditional generation with
denoising diffusion models. However, a comprehensive understanding of
classifier-free guidance is still missing. In this work, we carry out an
empirical study to provide a fresh perspective on classifier-free guidance.
Concretely, instead of solely focusing on classifier-free guidance, we trace
back to the root, i.e., classifier guidance, pinpoint the key assumption for
the derivation, and conduct a systematic study to understand the role of the
classifier. We find that both classifier guidance and classifier-free guidance
achieve conditional generation by pushing the denoising diffusion trajectories
away from decision boundaries, i.e., areas where conditional information is
usually entangled and is hard to learn. Based on this classifier-centric
understanding, we propose a generic postprocessing step built upon
flow-matching to shrink the gap between the learned distribution for a
pre-trained denoising diffusion model and the real data distribution, majorly
around the decision boundaries. Experiments on various datasets verify the
effectiveness of the proposed approach.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The Curse of Conditions: Analyzing and Improving Optimal Transport for
  Conditional Flow-Based Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10636v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10636v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ho Kei Cheng, Alexander Schwing
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Minibatch optimal transport coupling straightens paths in unconditional flow
matching. This leads to computationally less demanding inference as fewer
integration steps and less complex numerical solvers can be employed when
numerically solving an ordinary differential equation at test time. However, in
the conditional setting, minibatch optimal transport falls short. This is
because the default optimal transport mapping disregards conditions, resulting
in a conditionally skewed prior distribution during training. In contrast, at
test time, we have no access to the skewed prior, and instead sample from the
full, unbiased prior distribution. This gap between training and testing leads
to a subpar performance. To bridge this gap, we propose conditional optimal
transport C^2OT that adds a conditional weighting term in the cost matrix when
computing the optimal transport assignment. Experiments demonstrate that this
simple fix works with both discrete and continuous conditions in
8gaussians-to-moons, CIFAR-10, ImageNet-32x32, and ImageNet-256x256. Our method
performs better overall compared to the existing baselines across different
function evaluation budgets. Code is available at
https://hkchengrex.github.io/C2OT
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project page: https://hkchengrex.github.io/C2OT</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Frustratingly Simple Yet Highly Effective Attack Baseline: Over 90%
  Success Rate Against the Strong Black-box Models of GPT-4.5/4o/o1 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10635v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10635v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhaoyi Li, Xiaohan Zhao, Dong-Dong Wu, Jiacheng Cui, Zhiqiang Shen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite promising performance on open-source large vision-language models
(LVLMs), transfer-based targeted attacks often fail against black-box
commercial LVLMs. Analyzing failed adversarial perturbations reveals that the
learned perturbations typically originate from a uniform distribution and lack
clear semantic details, resulting in unintended responses. This critical
absence of semantic information leads commercial LVLMs to either ignore the
perturbation entirely or misinterpret its embedded semantics, thereby causing
the attack to fail. To overcome these issues, we notice that identifying core
semantic objects is a key objective for models trained with various datasets
and methodologies. This insight motivates our approach that refines semantic
clarity by encoding explicit semantic details within local regions, thus
ensuring interoperability and capturing finer-grained features, and by
concentrating modifications on semantically rich areas rather than applying
them uniformly. To achieve this, we propose a simple yet highly effective
solution: at each optimization step, the adversarial image is cropped randomly
by a controlled aspect ratio and scale, resized, and then aligned with the
target image in the embedding space. Experimental results confirm our
hypothesis. Our adversarial examples crafted with local-aggregated
perturbations focused on crucial regions exhibit surprisingly good
transferability to commercial LVLMs, including GPT-4.5, GPT-4o,
Gemini-2.0-flash, Claude-3.5-sonnet, Claude-3.7-sonnet, and even reasoning
models like o1, Claude-3.7-thinking and Gemini-2.0-flash-thinking. Our approach
achieves success rates exceeding 90% on GPT-4.5, 4o, and o1, significantly
outperforming all prior state-of-the-art attack methods. Our optimized
adversarial examples under different configurations and training code are
available at https://github.com/VILA-Lab/M-Attack.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Code at: https://github.com/VILA-Lab/M-Attack</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Charting and Navigating Hugging Face's Model Atlas 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10633v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10633v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Eliahu Horwitz, Nitzan Kurer, Jonathan Kahana, Liel Amar, Yedid Hoshen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As there are now millions of publicly available neural networks, searching
and analyzing large model repositories becomes increasingly important.
Navigating so many models requires an atlas, but as most models are poorly
documented charting such an atlas is challenging. To explore the hidden
potential of model repositories, we chart a preliminary atlas representing the
documented fraction of Hugging Face. It provides stunning visualizations of the
model landscape and evolution. We demonstrate several applications of this
atlas including predicting model attributes (e.g., accuracy), and analyzing
trends in computer vision models. However, as the current atlas remains
incomplete, we propose a method for charting undocumented regions.
Specifically, we identify high-confidence structural priors based on dominant
real-world model training practices. Leveraging these priors, our approach
enables accurate mapping of previously undocumented areas of the atlas. We
publicly release our datasets, code, and interactive atlas.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Kolmogorov-Arnold Attention: Is Learnable Attention Better For Vision
  Transformers? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10632v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10632v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Subhajit Maity, Killian Hitsman, Xin Li, Aritra Dutta
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Kolmogorov-Arnold networks (KANs) are a remarkable innovation consisting of
learnable activation functions with the potential to capture more complex
relationships from data. Although KANs are useful in finding symbolic
representations and continual learning of one-dimensional functions, their
effectiveness in diverse machine learning (ML) tasks, such as vision, remains
questionable. Presently, KANs are deployed by replacing multilayer perceptrons
(MLPs) in deep network architectures, including advanced architectures such as
vision Transformers (ViTs). In this paper, we are the first to design a general
learnable Kolmogorov-Arnold Attention (KArAt) for vanilla ViTs that can operate
on any choice of basis. However, the computing and memory costs of training
them motivated us to propose a more modular version, and we designed particular
learnable attention, called Fourier-KArAt. Fourier-KArAt and its variants
either outperform their ViT counterparts or show comparable performance on
CIFAR-10, CIFAR-100, and ImageNet-1K datasets. We dissect these architectures'
performance and generalization capacity by analyzing their loss landscapes,
weight distributions, optimizer path, attention visualization, and spectral
behavior, and contrast them with vanilla ViTs. The goal of this paper is not to
produce parameter- and compute-efficient attention, but to encourage the
community to explore KANs in conjunction with more advanced architectures that
require a careful understanding of learnable activations. Our open-source code
and implementation details are available on: https://subhajitmaity.me/KArAt
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint, Appendix included</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Uncertainty in Action: Confidence Elicitation in Embodied Agents 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10628v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10628v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tianjiao Yu, Vedant Shah, Muntasir Wahed, Kiet A. Nguyen, Adheesh Juvekar, Tal August, Ismini Lourentzou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Expressing confidence is challenging for embodied agents navigating dynamic
multimodal environments, where uncertainty arises from both perception and
decision-making processes. We present the first work investigating embodied
confidence elicitation in open-ended multimodal environments. We introduce
Elicitation Policies, which structure confidence assessment across inductive,
deductive, and abductive reasoning, along with Execution Policies, which
enhance confidence calibration through scenario reinterpretation, action
sampling, and hypothetical reasoning. Evaluating agents in calibration and
failure prediction tasks within the Minecraft environment, we show that
structured reasoning approaches, such as Chain-of-Thoughts, improve confidence
calibration. However, our findings also reveal persistent challenges in
distinguishing uncertainty, particularly under abductive settings, underscoring
the need for more sophisticated embodied confidence elicitation methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project page: https://plan-lab.github.io/ece/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ NIL: No-data Imitation Learning by Leveraging Pre-trained Video
  Diffusion Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10626v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10626v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mert Albaba, Chenhao Li, Markos Diomataris, Omid Taheri, Andreas Krause, Michael Black
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Acquiring physically plausible motor skills across diverse and unconventional
morphologies-including humanoid robots, quadrupeds, and animals-is essential
for advancing character simulation and robotics. Traditional methods, such as
reinforcement learning (RL) are task- and body-specific, require extensive
reward function engineering, and do not generalize well. Imitation learning
offers an alternative but relies heavily on high-quality expert demonstrations,
which are difficult to obtain for non-human morphologies. Video diffusion
models, on the other hand, are capable of generating realistic videos of
various morphologies, from humans to ants. Leveraging this capability, we
propose a data-independent approach for skill acquisition that learns 3D motor
skills from 2D-generated videos, with generalization capability to
unconventional and non-human forms. Specifically, we guide the imitation
learning process by leveraging vision transformers for video-based comparisons
by calculating pair-wise distance between video embeddings. Along with
video-encoding distance, we also use a computed similarity between segmented
video frames as a guidance reward. We validate our method on locomotion tasks
involving unique body configurations. In humanoid robot locomotion tasks, we
demonstrate that 'No-data Imitation Learning' (NIL) outperforms baselines
trained on 3D motion-capture data. Our results highlight the potential of
leveraging generative video models for physically plausible skill learning with
diverse morphologies, effectively replacing data collection with data
generation for imitation learning.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         <span class="highlight-title">★</span> Transformers without Normalization <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10622v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10622v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiachen Zhu, Xinlei Chen, <span class="highlight-author">Kaiming He</span>, Yann LeCun, Zhuang Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Normalization layers are ubiquitous in modern neural networks and have long
been considered essential. This work demonstrates that Transformers without
normalization can achieve the same or better performance using a remarkably
simple technique. We introduce Dynamic Tanh (DyT), an element-wise operation
$DyT($x$) = \tanh(\alpha $x$)$, as a drop-in replacement for normalization
layers in Transformers. DyT is inspired by the observation that layer
normalization in Transformers often produces tanh-like, $S$-shaped input-output
mappings. By incorporating DyT, Transformers without normalization can match or
exceed the performance of their normalized counterparts, mostly without
hyperparameter tuning. We validate the effectiveness of Transformers with DyT
across diverse settings, ranging from recognition to generation, supervised to
self-supervised learning, and computer vision to language models. These
findings challenge the conventional understanding that normalization layers are
indispensable in modern neural networks, and offer new insights into their role
in deep networks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>CVPR 2025; Project page: https://jiachenzhu.github.io/DyT/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Poly-MgNet: Polynomial Building Blocks in Multigrid-Inspired ResNets 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10594v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10594v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Antonia van Betteray, Matthias Rottmann, Karsten Kahl
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The structural analogies of ResNets and Multigrid (MG) methods such as common
building blocks like convolutions and poolings where already pointed out by He
et al.\ in 2016. Multigrid methods are used in the context of scientific
computing for solving large sparse linear systems arising from partial
differential equations. MG methods particularly rely on two main concepts:
smoothing and residual restriction / coarsening. Exploiting these analogies, He
and Xu developed the MgNet framework, which integrates MG schemes into the
design of ResNets. In this work, we introduce a novel neural network building
block inspired by polynomial smoothers from MG theory. Our polynomial block
from an MG perspective naturally extends the MgNet framework to Poly-Mgnet and
at the same time reduces the number of weights in MgNet. We present a
comprehensive study of our polynomial block, analyzing the choice of initial
coefficients, the polynomial degree, the placement of activation functions, as
well as of batch normalizations. Our results demonstrate that constructing
(quadratic) polynomial building blocks based on real and imaginary polynomial
roots enhances Poly-MgNet's capacity in terms of accuracy. Furthermore, our
approach achieves an improved trade-off of model accuracy and number of weights
compared to ResNet as well as compared to specific configurations of MgNet.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The Spectral Bias of Shallow Neural Network Learning is Shaped by the
  Choice of Non-linearity 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10587v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10587v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Justin Sahs, Ryan Pyle, Fabio Anselmi, Ankit Patel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite classical statistical theory predicting severe overfitting, modern
massively overparameterized neural networks still generalize well. This
unexpected property is attributed to the network's so-called implicit bias,
which describes its propensity to converge to solutions that generalize
effectively, among the many possible that correctly label the training data.
The aim of our research is to explore this bias from a new perspective,
focusing on how non-linear activation functions contribute to shaping it.
First, we introduce a reparameterization which removes a continuous weight
rescaling symmetry. Second, in the kernel regime, we leverage this
reparameterization to generalize recent findings that relate shallow Neural
Networks to the Radon transform, deriving an explicit formula for the implicit
bias induced by a broad class of activation functions. Specifically, by
utilizing the connection between the Radon transform and the Fourier transform,
we interpret the kernel regime's inductive bias as minimizing a spectral
seminorm that penalizes high-frequency components, in a manner dependent on the
activation function. Finally, in the adaptive regime, we demonstrate the
existence of local dynamical attractors that facilitate the formation of
clusters of hyperplanes where the input to a neuron's activation function is
zero, yielding alignment between many neurons' response functions. We confirm
these theoretical results with simulations. All together, our work provides a
deeper understanding of the mechanisms underlying the generalization
capabilities of overparameterized neural networks and its relation with the
implicit bias, offering potential pathways for designing more efficient and
robust models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>18 pages, 10 figures in main text</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On the Injective Norm of Sums of Random Tensors and the Moments of
  Gaussian Chaoses 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10580v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10580v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ishaq Aden-Ali
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We prove an upper bound on the expected $\ell_p$ injective norm of sums of
subgaussian random tensors. Our proof is simple and does not rely on any
explicit geometric or chaining arguments. Instead, it follows from a simple
application of the PAC-Bayesian lemma, a tool that has proven effective at
controlling the suprema of certain ``smooth'' empirical processes in recent
years. Our bound strictly improves a very recent result of Bandeira, Gopi,
Jiang, Lucca, and Rothvoss. In the Euclidean case ($p=2$), our bound sharpens a
result of Lata{\l}a that was central to proving his estimates on the moments of
Gaussian chaoses. As a consequence, we obtain an elementary proof of this
fundamental result.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Sample and Map from a Single Convex Potential: Generation using
  Conjugate Moment Measures 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10576v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10576v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nina Vesseron, Louis Béthune, Marco Cuturi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A common approach to generative modeling is to split model-fitting into two
blocks: define first how to sample noise (e.g. Gaussian) and choose next what
to do with it (e.g. using a single map or flows). We explore in this work an
alternative route that ties sampling and mapping. We find inspiration in moment
measures, a result that states that for any measure $\rho$ supported on a
compact convex set of $\mathbb{R}^d$, there exists a unique convex potential
$u$ such that $\rho=\nabla u\,\sharp\,e^{-u}$. While this does seem to tie
effectively sampling (from log-concave distribution $e^{-u}$) and action
(pushing particles through $\nabla u$), we observe on simple examples (e.g.,
Gaussians or 1D distributions) that this choice is ill-suited for practical
tasks. We study an alternative factorization, where $\rho$ is factorized as
$\nabla w^*\,\sharp\,e^{-w}$, where $w^*$ is the convex conjugate of $w$. We
call this approach conjugate moment measures, and show far more intuitive
results on these examples. Because $\nabla w^*$ is the Monge map between the
log-concave distribution $e^{-w}$ and $\rho$, we rely on optimal transport
solvers to propose an algorithm to recover $w$ from samples of $\rho$, and
parameterize $w$ as an input-convex neural network.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         <span class="highlight-title">★</span> Unveiling the Mathematical Reasoning in DeepSeek Models: A Comparative
  Study of Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10573v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10573v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Afrar Jahin, Arif Hassan Zidan, Yu Bao, Shizhe Liang, Tian<span class="highlight-author">ming Liu</span>, <span class="highlight-author">Wei Zhang</span>
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the rapid evolution of Artificial Intelligence (AI), Large Language
Models (LLMs) have reshaped the frontiers of various fields, spanning
healthcare, public health, engineering, science, agriculture, education, arts,
humanities, and mathematical reasoning. Among these advancements, DeepSeek
models have emerged as noteworthy contenders, demonstrating promising
capabilities that set them apart from their peers. While previous studies have
conducted comparative analyses of LLMs, few have delivered a comprehensive
evaluation of mathematical reasoning across a broad spectrum of LLMs. In this
work, we aim to bridge this gap by conducting an in-depth comparative study,
focusing on the strengths and limitations of DeepSeek models in relation to
their leading counterparts. In particular, our study systematically evaluates
the mathematical reasoning performance of two DeepSeek models alongside five
prominent LLMs across three independent benchmark datasets. The findings reveal
several key insights: 1). DeepSeek-R1 consistently achieved the highest
accuracy on two of the three datasets, demonstrating strong mathematical
reasoning capabilities. 2). The distilled variant of LLMs significantly
underperformed compared to its peers, highlighting potential drawbacks in using
distillation techniques. 3). In terms of response time, Gemini 2.0 Flash
demonstrated the fastest processing speed, outperforming other models in
efficiency, which is a crucial factor for real-time applications. Beyond these
quantitative assessments, we delve into how architecture, training, and
optimization impact LLMs' mathematical reasoning. Moreover, our study goes
beyond mere performance comparison by identifying key areas for future
advancements in LLM-driven mathematical reasoning. This research enhances our
understanding of LLMs' mathematical reasoning and lays the groundwork for
future advancements
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Radar: Fast Long-Context Decoding for Any Transformer <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10571v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10571v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yongchang Hao, Mengyao Zhai, Hossein Hajimirsadeghi, Sepidehsadat Hosseini, Frederick Tung
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Transformer models have demonstrated exceptional performance across a wide
range of applications. Though forming the foundation of Transformer models, the
dot-product attention does not scale well to long-context data since its time
requirement grows quadratically with context length. In this work, we propose
Radar, a training-free approach that accelerates inference by dynamically
searching for the most important context tokens. For any pre-trained
Transformer, Radar can reduce the decoding time complexity without training or
heuristically evicting tokens. Moreover, we provide theoretical justification
for our approach, demonstrating that Radar can reliably identify the most
important tokens with high probability. We conduct extensive comparisons with
the previous methods on a wide range of tasks. The results demonstrate that
Radar achieves the state-of-the-art performance across different architectures
with reduced time complexity, offering a practical solution for efficient
long-context processing of Transformers.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted @ ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FedPCA: Noise-Robust Fair Federated Learning via Performance-Capacity
  Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10567v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10567v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nannan Wu, Zengqiang Yan, Nong Sang, Li Yu, Chang Wen Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Training a model that effectively handles both common and rare data-i.e.,
achieving performance fairness-is crucial in federated learning (FL). While
existing fair FL methods have shown effectiveness, they remain vulnerable to
mislabeled data. Ensuring robustness in fair FL is therefore essential.
However, fairness and robustness inherently compete, which causes robust
strategies to hinder fairness. In this paper, we attribute this competition to
the homogeneity in loss patterns exhibited by rare and mislabeled data clients,
preventing existing loss-based fair and robust FL methods from effectively
distinguishing and handling these two distinct client types. To address this,
we propose performance-capacity analysis, which jointly considers model
performance on each client and its capacity to handle the dataset, measured by
loss and a newly introduced feature dispersion score. This allows mislabeled
clients to be identified by their significantly deviated performance relative
to capacity while preserving rare data clients. Building on this, we introduce
FedPCA, an FL method that robustly achieves fairness. FedPCA first identifies
mislabeled clients via a Gaussian Mixture Model on loss-dispersion pairs, then
applies fairness and robustness strategies in global aggregation and local
training by adjusting client weights and selectively using reliable data.
Extensive experiments on three datasets demonstrate FedPCA's effectiveness in
tackling this complex challenge. Code will be publicly available upon
acceptance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ASIDE: Architectural Separation of Instructions and Data in Language
  Models <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10566v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10566v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Egor Zverev, Evgenii Kortukov, Alexander Panfilov, Soroush Tabesh, Alexandra Volkova, Sebastian Lapuschkin, Wojciech Samek, Christoph H. Lampert
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite their remarkable performance, large language models lack elementary
safety features, and this makes them susceptible to numerous malicious attacks.
In particular, previous work has identified the absence of an intrinsic
separation between instructions and data as a root cause for the success of
prompt injection attacks. In this work, we propose an architectural change,
ASIDE, that allows the model to clearly separate between instructions and data
by using separate embeddings for them. Instead of training the embeddings from
scratch, we propose a method to convert an existing model to ASIDE form by
using two copies of the original model's embeddings layer, and applying an
orthogonal rotation to one of them. We demonstrate the effectiveness of our
method by showing (1) highly increased instruction-data separation scores
without a loss in model capabilities and (2) competitive results on prompt
injection benchmarks, even without dedicated safety training. Additionally, we
study the working mechanism behind our method through an analysis of model
representations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICLR 2025 Workshop on Building Trust in Language Models and
  Applications</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ From Linear to Spline-Based Classification:Developing and Enhancing SMPA
  for Noisy Non-Linear Datasets 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10545v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10545v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vatsal Srivastava
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Building upon the concepts and mechanisms used for the development in Moving
Points Algorithm, we will now explore how non linear decision boundaries can be
developed for classification tasks. First we will look at the classification
performance of MPA and some minor developments in the original algorithm. We
then discuss the concepts behind using cubic splines for classification with a
similar learning mechanism and finally analyze training results on synthetic
datasets with known properties.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DP-GPL: Differentially Private Graph Prompt Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10544v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10544v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jing Xu, Franziska Boenisch, Iyiola Emmanuel Olatunji, Adam Dziedzic
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Graph Neural Networks (GNNs) have shown remarkable performance in various
applications. Recently, graph prompt learning has emerged as a powerful GNN
training paradigm, inspired by advances in language and vision foundation
models. Here, a GNN is pre-trained on public data and then adapted to sensitive
tasks using lightweight graph prompts. However, using prompts from sensitive
data poses privacy risks. In this work, we are the first to investigate these
practical risks in graph prompts by instantiating a membership inference attack
that reveals significant privacy leakage. We also find that the standard
privacy method, DP-SGD, fails to provide practical privacy-utility trade-offs
in graph prompt learning, likely due to the small number of sensitive data
points used to learn the prompts. As a solution, we propose DP-GPL for
differentially private graph prompt learning based on the PATE framework, that
generates a graph prompt with differential privacy guarantees. Our evaluation
across various graph prompt learning methods, GNN architectures, and
pre-training strategies demonstrates that our algorithm achieves high utility
at strong privacy, effectively mitigating privacy concerns while preserving the
powerful capabilities of prompted GNNs as powerful foundation models in the
graph domain.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Language Models, Graph Searching, and Supervision Adulteration: When
  More Supervision is Less and How to Make More More <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10542v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10542v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Arvid Frydenlund
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This work concerns the path-star task, a minimal example of searching over a
graph. The graph, $G$, is star-shaped with $D$ arms radiating from a start
node, $s$. A language model (LM) is given $G$, $s$, and a target node $t$,
which ends one of the arms and is tasked with generating the arm containing
$t$. The minimal nature of this task means only a single choice needs to be
made: which of the $D$ arms contains $t$?
  Decoder-only LMs fail to solve this elementary task above $1/D$ chance due to
a learned shortcut that absorbs training supervision. We show how this
pathology is caused by excess supervision and we present a series of solutions
demonstrating that the task is solvable via decoder-only LMs. We find that the
task's minimal nature causes its difficulty, as it prevents task decomposition.
Our solutions provide insight into the pathology and its implications for LMs
trained via next-token prediction.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>A reduced version of this work has been accepted to the Workshop on
  Spurious Correlation and Shortcut Learning: Foundations and Solutions (SCSL)
  at ICLR 2025. Full version under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ GBSVR: Granular Ball Support Vector Regression 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10539v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10539v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Reshma Rastogi, Ankush Bisht, Sanjay Kumar, Suresh Chandra
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Support Vector Regression (SVR) and its variants are widely used to handle
regression tasks, however, since their solution involves solving an expensive
quadratic programming problem, it limits its application, especially when
dealing with large datasets. Additionally, SVR uses an epsilon-insensitive loss
function which is sensitive to outliers and therefore can adversely affect its
performance. We propose Granular Ball Support Vector Regression (GBSVR) to
tackle problem of regression by using granular ball concept. These balls are
useful in simplifying complex data spaces for machine learning tasks, however,
to the best of our knowledge, they have not been sufficiently explored for
regression problems. Granular balls group the data points into balls based on
their proximity and reduce the computational cost in SVR by replacing the large
number of data points with far fewer granular balls. This work also suggests a
discretization method for continuous-valued attributes to facilitate the
construction of granular balls. The effectiveness of the proposed approach is
evaluated on several benchmark datasets and it outperforms existing
state-of-the-art approaches
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Structured Preconditioners in Adaptive <span class="highlight-title">Optimization</span>: A Unified Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10537v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10537v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shuo Xie, Tianhao Wang, Sashank Reddi, Sanjiv Kumar, Zhiyuan Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a novel unified analysis for a broad class of adaptive
optimization algorithms with structured (e.g., layerwise, diagonal, and
kronecker-factored) preconditioners for both online regret minimization and
offline convex optimization. Our analysis not only provides matching rate to
several important structured preconditioned algorithms including diagonal
AdaGrad, full-matrix AdaGrad, and AdaGrad-Norm, but also gives an improved
convergence rate for a one-sided variant of Shampoo over that of original
Shampoo. Interestingly, more structured preconditioners (e.g., diagonal
Adagrad, AdaGrad-Norm which use less space and compute) are often presented as
computationally efficient approximations to full-matrix Adagrad, aiming for
improved optimization performance through better approximations. Our unified
analysis challenges this prevailing view and reveals, perhaps surprisingly,
that more structured preconditioners, despite using less space and computation
per step, can outperform their less structured counterparts. To demonstrate
this, we show that one-sided Shampoo, which is relatively much cheaper than
full-matrix AdaGrad could outperform it both theoretically and experimentally.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ AudioX: Diffusion Transformer for Anything-to-Audio Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10522v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10522v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zeyue Tian, Yizhu Jin, Zhaoyang Liu, Ruibin Yuan, Xu Tan, Qifeng Chen, Wei Xue, Yike Guo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Audio and music generation have emerged as crucial tasks in many
applications, yet existing approaches face significant limitations: they
operate in isolation without unified capabilities across modalities, suffer
from scarce high-quality, multi-modal training data, and struggle to
effectively integrate diverse inputs. In this work, we propose AudioX, a
unified Diffusion Transformer model for Anything-to-Audio and Music Generation.
Unlike previous domain-specific models, AudioX can generate both general audio
and music with high quality, while offering flexible natural language control
and seamless processing of various modalities including text, video, image,
music, and audio. Its key innovation is a multi-modal masked training strategy
that masks inputs across modalities and forces the model to learn from masked
inputs, yielding robust and unified cross-modal representations. To address
data scarcity, we curate two comprehensive datasets: vggsound-caps with 190K
audio captions based on the VGGSound dataset, and V2M-caps with 6 million music
captions derived from the V2M dataset. Extensive experiments demonstrate that
AudioX not only matches or outperforms state-of-the-art specialized models, but
also offers remarkable versatility in handling diverse input modalities and
generation tasks within a unified architecture. The code and datasets will be
available at https://zeyuet.github.io/AudioX/
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The code and datasets will be available at
  https://zeyuet.github.io/AudioX/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CountPath: Automating Fragment Counting in Digital Pathology 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10520v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10520v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ana Beatriz Vieira, Maria Valente, Diana Montezuma, Tomé Albuquerque, Liliana Ribeiro, Domingos Oliveira, João Monteiro, Sofia Gonçalves, Isabel M. Pinto, Jaime S. Cardoso, Arlindo L. Oliveira
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Quality control of medical images is a critical component of digital
pathology, ensuring that diagnostic images meet required standards. A
pre-analytical task within this process is the verification of the number of
specimen fragments, a process that ensures that the number of fragments on a
slide matches the number documented in the macroscopic report. This step is
important to ensure that the slides contain the appropriate diagnostic material
from the grossing process, thereby guaranteeing the accuracy of subsequent
microscopic examination and diagnosis. Traditionally, this assessment is
performed manually, requiring significant time and effort while being subject
to significant variability due to its subjective nature. To address these
challenges, this study explores an automated approach to fragment counting
using the YOLOv9 and Vision Transformer models. Our results demonstrate that
the automated system achieves a level of performance comparable to expert
assessments, offering a reliable and efficient alternative to manual counting.
Additionally, we present findings on interobserver variability, showing that
the automated approach achieves an accuracy of 86%, which falls within the
range of variation observed among experts (82-88%), further supporting its
potential for integration into routine pathology workflows.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Conformal Prediction Sets for Deep Generative Models via Reduction to
  Conformal Regression 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10512v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10512v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hooman Shahrokhi, Devjeet Raj Roy, Yan Yan, Venera Arnaoudova, Janaradhan Rao Doppa
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We consider the problem of generating valid and small prediction sets by
sampling outputs (e.g., software code and natural language text) from a
black-box deep generative model for a given input (e.g., textual prompt). The
validity of a prediction set is determined by a user-defined binary
admissibility function depending on the target application. For example,
requiring at least one program in the set to pass all test cases in code
generation application. To address this problem, we develop a simple and
effective conformal inference algorithm referred to as Generative Prediction
Sets (GPS). Given a set of calibration examples and black-box access to a deep
generative model, GPS can generate prediction sets with provable guarantees.
The key insight behind GPS is to exploit the inherent structure within the
distribution over the minimum number of samples needed to obtain an admissible
output to develop a simple conformal regression approach over the minimum
number of samples. Experiments on multiple datasets for code and math word
problems using different large language models demonstrate the efficacy of GPS
over state-of-the-art methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Extreme Learning Machines for Attention-based Multiple Instance Learning
  in Whole-Slide Image Classification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10510v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10510v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rajiv Krishnakumar, Julien Baglio, Frederik F. Flöther, Christian Ruiz, Stefan Habringer, Nicole H. Romano
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Whole-slide image classification represents a key challenge in computational
pathology and medicine. Attention-based multiple instance learning (MIL) has
emerged as an effective approach for this problem. However, the effect of
attention mechanism architecture on model performance is not well-documented
for biomedical imagery. In this work, we compare different methods and
implementations of MIL, including deep learning variants. We introduce a new
method using higher-dimensional feature spaces for deep MIL. We also develop a
novel algorithm for whole-slide image classification where extreme machine
learning is combined with attention-based MIL to improve sensitivity and reduce
training complexity. We apply our algorithms to the problem of detecting
circulating rare cells (CRCs), such as erythroblasts, in peripheral blood. Our
results indicate that nonlinearities play a key role in the classification, as
removing them leads to a sharp decrease in stability in addition to a decrease
in average area under the curve (AUC) of over 4%. We also demonstrate a
considerable increase in robustness of the model with improvements of over 10%
in average AUC when higher-dimensional feature spaces are leveraged. In
addition, we show that extreme learning machines can offer clear improvements
in terms of training efficiency by reducing the number of trained parameters by
a factor of 5 whilst still maintaining the average AUC to within 1.5% of the
deep MIL model. Finally, we discuss options of enriching the classical
computing framework with quantum algorithms in the future. This work can thus
help pave the way towards more accurate and efficient single-cell diagnostics,
one of the building blocks of precision medicine.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SySLLM: Generating Synthesized Policy Summaries for Reinforcement
  Learning Agents Using Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10509v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10509v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sahar Admoni, Omer Ben-Porat, Ofra Amir
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Policies generated by Reinforcement Learning (RL) algorithms can be difficult
to describe to users, as they result from the interplay between complex reward
structures and neural network-based representations. This combination often
leads to unpredictable behaviors, making policies challenging to analyze and
posing significant obstacles to fostering human trust in real-world
applications. Global policy summarization methods aim to describe agent
behavior through a demonstration of actions in a subset of world-states.
However, users can only watch a limited number of demonstrations, restricting
their understanding of policies. Moreover, those methods overly rely on user
interpretation, as they do not synthesize observations into coherent patterns.
In this work, we present SySLLM (Synthesized Summary using LLMs), a novel
method that employs synthesis summarization, utilizing large language models'
(LLMs) extensive world knowledge and ability to capture patterns, to generate
textual summaries of policies. Specifically, an expert evaluation demonstrates
that the proposed approach generates summaries that capture the main insights
generated by experts while not resulting in significant hallucinations.
Additionally, a user study shows that SySLLM summaries are preferred over
demonstration-based policy summaries and match or surpass their performance in
objective agent identification tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Sample Compression for Continual Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10503v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10503v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jacob Comeau, Mathieu Bazinet, Pascal Germain, Cem Subakan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Continual learning algorithms aim to learn from a sequence of tasks, making
the training distribution non-stationary. The majority of existing continual
learning approaches in the literature rely on heuristics and do not provide
learning guarantees for the continual learning setup. In this paper, we present
a new method called 'Continual Pick-to-Learn' (CoP2L), which is able to retain
the most representative samples for each task in an efficient way. The
algorithm is adapted from the Pick-to-Learn algorithm, rooted in the sample
compression theory. This allows us to provide high-confidence upper bounds on
the generalization loss of the learned predictors, numerically computable after
every update of the learned model. We also empirically show on several standard
continual learning benchmarks that our algorithm is able to outperform standard
experience replay, significantly mitigating catastrophic forgetting.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Explainable Bayesian deep learning through input-skip Latent Binary
  Bayesian Neural Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10496v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10496v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Eirik Høyheim, Lars Skaaret-Lund, Solve Sæbø, Aliaksandr Hubin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Modeling natural phenomena with artificial neural networks (ANNs) often
provides highly accurate predictions. However, ANNs often suffer from
over-parameterization, complicating interpretation and raising uncertainty
issues. Bayesian neural networks (BNNs) address the latter by representing
weights as probability distributions, allowing for predictive uncertainty
evaluation. Latent binary Bayesian neural networks (LBBNNs) further handle
structural uncertainty and sparsify models by removing redundant weights. This
article advances LBBNNs by enabling covariates to skip to any succeeding layer
or be excluded, simplifying networks and clarifying input impacts on
predictions. Ultimately, a linear model or even a constant can be found to be
optimal for a specific problem at hand. Furthermore, the input-skip LBBNN
approach reduces network density significantly compared to standard LBBNNs,
achieving over 99% reduction for small networks and over 99.9% for larger ones,
while still maintaining high predictive accuracy and uncertainty measurement.
For example, on MNIST, we reached 97% accuracy and great calibration with just
935 weights, reaching state-of-the-art for compression of neural networks.
Furthermore, the proposed method accurately identifies the true covariates and
adjusts for system non-linearity. The main contribution is the introduction of
active paths, enhancing directly designed global and local explanations within
the LBBNN framework, that have theoretical guarantees and do not require post
hoc external tools for explanations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>44 pages, 19 tables, 25 figures. Code available at
  https://github.com/eirihoyh/ISLaB-LBBNN</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Meta-learning characteristics and dynamics of quantum systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10492v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10492v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lucas Schorling, Pranav Vaidhyanathan, Jonas Schuff, Miguel J. Carballido, Dominik Zumbühl, Gerard Milburn, Florian Marquardt, Jakob Foerster, Michael A. Osborne, Natalia Ares
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While machine learning holds great promise for quantum technologies, most
current methods focus on predicting or controlling a specific quantum system.
Meta-learning approaches, however, can adapt to new systems for which little
data is available, by leveraging knowledge obtained from previous data
associated with similar systems. In this paper, we meta-learn dynamics and
characteristics of closed and open two-level systems, as well as the Heisenberg
model. Based on experimental data of a Loss-DiVincenzo spin-qubit hosted in a
Ge/Si core/shell nanowire for different gate voltage configurations, we predict
qubit characteristics i.e. $g$-factor and Rabi frequency using meta-learning.
The algorithm we introduce improves upon previous state-of-the-art
meta-learning methods for physics-based systems by introducing novel techniques
such as adaptive learning rates and a global optimizer for improved robustness
and increased computational efficiency. We benchmark our method against other
meta-learning methods, a vanilla transformer, and a multilayer perceptron, and
demonstrate improved performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6+1 pages, 4 figures. L. Schorling and P. Vaidhyanathan contributed
  equally to this work</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Representation Learning, Large-Scale 3D Molecular Pretraining, Molecular
  Property 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10489v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10489v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shuqi Lu, Xiaohong Ji, Bohang Zhang, Lin Yao, Siyuan Liu, Zhifeng Gao, Linfeng Zhang, Guolin Ke
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Molecular pretrained representations (MPR) has emerged as a powerful approach
for addressing the challenge of limited supervised data in applications such as
drug discovery and material design. While early MPR methods relied on 1D
sequences and 2D graphs, recent advancements have incorporated 3D
conformational information to capture rich atomic interactions. However, these
prior models treat molecules merely as discrete atom sets, overlooking the
space surrounding them. We argue from a physical perspective that only modeling
these discrete points is insufficient. We first present a simple yet insightful
observation: naively adding randomly sampled virtual points beyond atoms can
surprisingly enhance MPR performance. In light of this, we propose a principled
framework that incorporates the entire 3D space spanned by molecules. We
implement the framework via a novel Transformer-based architecture, dubbed
SpaceFormer, with three key components: (1) grid-based space discretization;
(2) grid sampling/merging; and (3) efficient 3D positional encoding. Extensive
experiments show that SpaceFormer significantly outperforms previous 3D MPR
models across various downstream tasks with limited data, validating the
benefit of leveraging the additional 3D space beyond atoms in MPR models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Streaming Generation of Co-Speech Gestures via Accelerated Rolling
  Diffusion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10488v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10488v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Evgeniia Vu, Andrei Boiarov, Dmitry Vetrov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generating co-speech gestures in real time requires both temporal coherence
and efficient sampling. We introduce Accelerated Rolling Diffusion, a novel
framework for streaming gesture generation that extends rolling diffusion
models with structured progressive noise scheduling, enabling seamless
long-sequence motion synthesis while preserving realism and diversity. We
further propose Rolling Diffusion Ladder Acceleration (RDLA), a new approach
that restructures the noise schedule into a stepwise ladder, allowing multiple
frames to be denoised simultaneously. This significantly improves sampling
efficiency while maintaining motion consistency, achieving up to a 2x speedup
with high visual fidelity and temporal coherence. We evaluate our approach on
ZEGGS and BEAT, strong benchmarks for real-world applicability. Our framework
is universally applicable to any diffusion-based gesture generation model,
transforming it into a streaming approach. Applied to three state-of-the-art
methods, it consistently outperforms them, demonstrating its effectiveness as a
generalizable and efficient solution for real-time, high-fidelity co-speech
gesture synthesis.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Applying Tabular Deep Learning Models to Estimate Crash Injury Types of
  Young Motorcyclists 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10474v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10474v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shriyank Somvanshi, Anannya Ghosh Tusti, Rohit Chakraborty, Subasish Das
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Young motorcyclists, particularly those aged 15 to 24 years old, face a
heightened risk of severe crashes due to factors such as speeding, traffic
violations, and helmet usage. This study aims to identify key factors
influencing crash severity by analyzing 10,726 young motorcyclist crashes in
Texas from 2017 to 2022. Two advanced tabular deep learning models, ARMNet and
MambaNet, were employed, using an advanced resampling technique to address
class imbalance. The models were trained to classify crashes into three
severity levels, Fatal or Severe, Moderate or Minor, and No Injury. ARMNet
achieved an accuracy of 87 percent, outperforming 86 percent of Mambanet, with
both models excelling in predicting severe and no injury crashes while facing
challenges in moderate crash classification. Key findings highlight the
significant influence of demographic, environmental, and behavioral factors on
crash outcomes. The study underscores the need for targeted interventions,
including stricter helmet enforcement and educational programs customized to
young motorcyclists. These insights provide valuable guidance for policymakers
in developing evidence-based strategies to enhance motorcyclist safety and
reduce crash severity.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 6 figures, accepted at IEEE CAI 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Deep Learning based discovery of Integrable Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10469v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10469v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shailesh Lal, Suvajit Majumder, Evgeny Sobko
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce a novel machine learning based framework for discovering
integrable models. Our approach first employs a synchronized ensemble of neural
networks to find high-precision numerical solution to the Yang-Baxter equation
within a specified class. Then, using an auxiliary system of algebraic
equations, [Q_2, Q_3] = 0, and the numerical value of the Hamiltonian obtained
via deep learning as a seed, we reconstruct the entire Hamiltonian family,
forming an algebraic variety. We illustrate our presentation with three- and
four-dimensional spin chains of difference form with local interactions.
Remarkably, all discovered Hamiltonian families form rational varieties.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 2 column text, 3 figures, Mathematica notebook with example
  Hamiltonians</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ OODD: Test-time Out-of-Distribution Detection with Dynamic Dictionary 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10468v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10468v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yifeng Yang, Lin Zhu, Zewen Sun, Hengyu Liu, Qinying Gu, Nanyang Ye
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Out-of-distribution (OOD) detection remains challenging for deep learning
models, particularly when test-time OOD samples differ significantly from
training outliers. We propose OODD, a novel test-time OOD detection method that
dynamically maintains and updates an OOD dictionary without fine-tuning. Our
approach leverages a priority queue-based dictionary that accumulates
representative OOD features during testing, combined with an informative inlier
sampling strategy for in-distribution (ID) samples. To ensure stable
performance during early testing, we propose a dual OOD stabilization mechanism
that leverages strategically generated outliers derived from ID data. To our
best knowledge, extensive experiments on the OpenOOD benchmark demonstrate that
OODD significantly outperforms existing methods, achieving a 26.0% improvement
in FPR95 on CIFAR-100 Far OOD detection compared to the state-of-the-art
approach. Furthermore, we present an optimized variant of the KNN-based OOD
detection framework that achieves a 3x speedup while maintaining detection
performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SortingEnv: An Extendable RL-Environment for an Industrial Sorting
  Process 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10466v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10466v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tom Maus, Nico Zengeler, Tobias Glasmachers
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a novel reinforcement learning (RL) environment designed to both
optimize industrial sorting systems and study agent behavior in evolving
spaces. In simulating material flow within a sorting process our environment
follows the idea of a digital twin, with operational parameters like belt speed
and occupancy level. To reflect real-world challenges, we integrate common
upgrades to industrial setups, like new sensors or advanced machinery. It thus
includes two variants: a basic version focusing on discrete belt speed
adjustments and an advanced version introducing multiple sorting modes and
enhanced material composition observations. We detail the observation spaces,
state update mechanisms, and reward functions for both environments. We further
evaluate the efficiency of common RL algorithms like Proximal Policy
Optimization (PPO), Deep-Q-Networks (DQN), and Advantage Actor Critic (A2C) in
comparison to a classical rule-based agent (RBA). This framework not only aids
in optimizing industrial processes but also provides a foundation for studying
agent behavior and transferability in evolving environments, offering insights
into model performance and practical implications for real-world RL
applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Presented at the 12th International Conference on Industrial
  Engineering and Applications (ICIEA-EU), Munich, 2025. This article has been
  submitted to AIP Conference Proceedings. After it is published, it will be
  available in the AIP Digital Library</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Light-R1: Curriculum SFT, DPO and RL for Long COT from Scratch and
  Beyond 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10460v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10460v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Liang Wen, Yunke Cai, Fenrui Xiao, Xin He, Qi An, Zhenyu Duan, Yimin Du, Junchen Liu, Lifu Tang, Xiaowei Lv, Haosheng Zou, Yongchao Deng, Shousheng Jia, Xiangzheng Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents our work on the Light-R1 series, with models, data, and
code all released.
  We first focus on training long COT models from scratch, specifically
starting from models initially lacking long COT capabilities. Using a
curriculum training recipe consisting of two-stage SFT and semi-on-policy DPO,
we train our model Light-R1-32B from Qwen2.5-32B-Instruct, resulting in
superior math performance compared to DeepSeek-R1-Distill-Qwen-32B. Despite
being trained exclusively on math data, Light-R1-32B shows strong
generalization across other domains. In the subsequent phase of this work, we
highlight the significant benefit of the 3k dataset constructed for the second
SFT stage on enhancing other models. By fine-tuning DeepSeek-R1-Distilled
models using this dataset, we obtain new SOTA models in 7B and 14B, while the
32B model, Light-R1-32B-DS performed comparably to QwQ-32B and DeepSeek-R1.
  Furthermore, we extend our work by applying reinforcement learning,
specifically GRPO, on long-COT models to further improve reasoning performance.
We successfully train our final Light-R1-14B-DS with RL, achieving SOTA
performance among 14B parameter models in math. With AIME24 & 25 scores of 74.0
and 60.2 respectively, Light-R1-14B-DS surpasses even many 32B models and
DeepSeek-R1-Distill-Llama-70B. Its RL training also exhibits well expected
behavior, showing simultaneous increase in response length and reward score.
  The Light-R1 series of work validates training long-COT models from scratch,
showcases the art in SFT data and releases SOTA models from RL.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>all release at https://github.com/Qihoo360/Light-R1</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Sentiment Analysis in SemEval: A <span class="highlight-title">Review</span> of Sentiment Identification
  Approaches 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10457v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10457v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bousselham El Haddaoui, Raddouane Chiheb, Rdouan Faizi, Abdellatif El Afia
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Social media platforms are becoming the foundations of social interactions
including messaging and opinion expression. In this regard, Sentiment Analysis
techniques focus on providing solutions to ensure the retrieval and analysis of
generated data including sentiments, emotions, and discussed topics.
International competitions such as the International Workshop on Semantic
Evaluation (SemEval) have attracted many researchers and practitioners with a
special research interest in building sentiment analysis systems. In our work,
we study top-ranking systems for each SemEval edition during the 2013-2021
period, a total of 658 teams participated in these editions with increasing
interest over years. We analyze the proposed systems marking the evolution of
research trends with a focus on the main components of sentiment analysis
systems including data acquisition, preprocessing, and classification. Our
study shows an active use of preprocessing techniques, an evolution of features
engineering and word representation from lexicon-based approaches to word
embeddings, and the dominance of neural networks and transformers over the
classification phase fostering the use of ready-to-use models. Moreover, we
provide researchers with insights based on experimented systems which will
allow rapid prototyping of new systems and help practitioners build for future
SemEval editions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Learning Disease State from Noisy Ordinal Disease Progression Labels 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10440v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10440v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gustav Schmidt, Holger Heidrich, Philipp Berens, Sarah Müller
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Learning from noisy ordinal labels is a key challenge in medical imaging. In
this work, we ask whether ordinal disease progression labels (better, worse, or
stable) can be used to learn a representation allowing to classify disease
state. For neovascular age-related macular degeneration (nAMD), we cast the
problem of modeling disease progression between medical visits as a
classification task with ordinal ranks. To enhance generalization, we tailor
our model to the problem setting by (1) independent image encoding, (2)
antisymmetric logit space equivariance, and (3) ordinal scale awareness. In
addition, we address label noise by learning an uncertainty estimate for loss
re-weighting. Our approach learns an interpretable disease representation
enabling strong few-shot performance for the related task of nAMD activity
classification from single images, despite being trained only on image pairs
with ordinal disease progression labels.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Finetuning Generative Trajectory Model with Reinforcement Learning from
  Human Feedback 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10434v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10434v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Derun Li, Jianwei Ren, Yue Wang, Xin Wen, Pengxiang Li, Leimeng Xu, Kun Zhan, Zhongpu Xia, Peng Jia, Xianpeng Lang, Ningyi Xu, Hang Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generating human-like and adaptive trajectories is essential for autonomous
driving in dynamic environments. While generative models have shown promise in
synthesizing feasible trajectories, they often fail to capture the nuanced
variability of human driving styles due to dataset biases and distributional
shifts. To address this, we introduce TrajHF, a human feedback-driven
finetuning framework for generative trajectory models, designed to align motion
planning with diverse driving preferences. TrajHF incorporates
multi-conditional denoiser and reinforcement learning with human feedback to
refine multi-modal trajectory generation beyond conventional imitation
learning. This enables better alignment with human driving preferences while
maintaining safety and feasibility constraints. TrajHF achieves PDMS of 93.95
on NavSim benchmark, significantly exceeding other methods. TrajHF sets a new
paradigm for personalized and adaptable trajectory generation in autonomous
driving.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ BeamLLM: Vision-Empowered mmWave Beam Prediction with Large Language
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10432v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10432v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Can Zheng, Jiguang He, Guofa Cai, Zitong Yu, Chung G. Kang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we propose BeamLLM, a vision-aided millimeter-wave (mmWave)
beam prediction framework leveraging large language models (LLMs) to address
the challenges of high training overhead and latency in mmWave communication
systems. By combining computer vision (CV) with LLMs' cross-modal reasoning
capabilities, the framework extracts user equipment (UE) positional features
from RGB images and aligns visual-temporal features with LLMs' semantic space
through reprogramming techniques. Evaluated on a realistic
vehicle-to-infrastructure (V2I) scenario, the proposed method achieves 61.01%
top-1 accuracy and 97.39% top-3 accuracy in standard prediction tasks,
significantly outperforming traditional deep learning models. In few-shot
prediction scenarios, the performance degradation is limited to 12.56% (top-1)
and 5.55% (top-3) from time sample 1 to 10, demonstrating superior prediction
capability.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 7 figures, conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Langevin Monte-Carlo Provably Learns Depth Two Neural Nets at Any Size
  and Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10428v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10428v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dibyakanti Kumar, Samyak Jha, Anirbit Mukherjee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work, we will establish that the Langevin Monte-Carlo algorithm can
learn depth-2 neural nets of any size and for any data and we give
non-asymptotic convergence rates for it. We achieve this via showing that under
Total Variation distance and q-Renyi divergence, the iterates of Langevin Monte
Carlo converge to the Gibbs distribution of Frobenius norm regularized losses
for any of these nets, when using smooth activations and in both classification
and regression settings. Most critically, the amount of regularization needed
for our results is independent of the size of the net. The key observation of
ours is that two layer neural loss functions can always be regularized by a
constant amount such that they satisfy the Villani conditions, and thus their
Gibbs measures satisfy a Poincare inequality.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Improving Medical Waste Classification with Hybrid Capsule Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10426v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10426v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bennet van den Broek, Javad Pourmostafa Roshan Sharami
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The improper disposal and mismanagement of medical waste pose severe
environmental and public health risks, contributing to greenhouse gas emissions
and the spread of infectious diseases. Efficient and accurate medical waste
classification is crucial for mitigating these risks. We explore the
integration of capsule networks with a pretrained DenseNet model to improve
medical waste classification. To the best of our knowledge, capsule networks
have not yet been applied to this task, making this study the first to assess
their effectiveness.
  A diverse dataset of medical waste images collected from multiple public
sources, is used to evaluate three model configurations: (1) a pretrained
DenseNet model as a baseline, (2) a pretrained DenseNet with frozen layers
combined with a capsule network, and (3) a pretrained DenseNet with unfrozen
layers combined with a capsule network. Experimental results demonstrate that
incorporating capsule networks improves classification performance, with F1
scores increasing from 0.89 (baseline) to 0.92 (hybrid model with unfrozen
layers). This highlights the potential of capsule networks to address the
spatial limitations of traditional convolutional models and improve
classification robustness.
  While the capsule-enhanced model demonstrated improved classification
performance, direct comparisons with prior studies were challenging due to
differences in dataset size and diversity. Previous studies relied on smaller,
domain-specific datasets, which inherently yielded higher accuracy. In
contrast, our study employs a significantly larger and more diverse dataset,
leading to better generalization but introducing additional classification
challenges. This highlights the trade-off between dataset complexity and model
performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Constraint-Based Adaptive Hypergraph Learning for Solving
  Vehicle Routing: An End-to-End Solution 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10421v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10421v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhenwei Wang, Ruibin Bai, Tiehua Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The application of learning based methods to vehicle routing problems has
emerged as a pivotal area of research in combinatorial optimization. These
problems are characterized by vast solution spaces and intricate constraints,
making traditional approaches such as exact mathematical models or heuristic
methods prone to high computational overhead or reliant on the design of
complex heuristic operators to achieve optimal or near optimal solutions.
Meanwhile, although some recent learning-based methods can produce good
performance for VRP with straightforward constraint scenarios, they often fail
to effectively handle hard constraints that are common in practice. This study
introduces a novel end-to-end framework that combines constraint-oriented
hypergraphs with reinforcement learning to address vehicle routing problems. A
central innovation of this work is the development of a constraint-oriented
dynamic hyperedge reconstruction strategy within an encoder, which
significantly enhances hypergraph representation learning. Additionally, the
decoder leverages a double-pointer attention mechanism to iteratively generate
solutions. The proposed model is trained by incorporating asynchronous
parameter updates informed by hypergraph constraints and optimizing a dual loss
function comprising constraint loss and policy gradient loss. The experiment
results on benchmark datasets demonstrate that the proposed approach not only
eliminates the need for sophisticated heuristic operators but also achieves
substantial improvements in solution quality.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ dFLMoE: Decentralized Federated Learning via Mixture of Experts for
  Medical Data Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10412v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10412v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Luyuan Xie, Tianyu Luan, Wenyuan Cai, Guochen Yan, Zhaoyu Chen, Nan Xi, Yuejian Fang, Qingni Shen, Zhonghai Wu, Junsong Yuan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Federated learning has wide applications in the medical field. It enables
knowledge sharing among different healthcare institutes while protecting
patients' privacy. However, existing federated learning systems are typically
centralized, requiring clients to upload client-specific knowledge to a central
server for aggregation. This centralized approach would integrate the knowledge
from each client into a centralized server, and the knowledge would be already
undermined during the centralized integration before it reaches back to each
client. Besides, the centralized approach also creates a dependency on the
central server, which may affect training stability if the server malfunctions
or connections are unstable. To address these issues, we propose a
decentralized federated learning framework named dFLMoE. In our framework,
clients directly exchange lightweight head models with each other. After
exchanging, each client treats both local and received head models as
individual experts, and utilizes a client-specific Mixture of Experts (MoE)
approach to make collective decisions. This design not only reduces the
knowledge damage with client-specific aggregations but also removes the
dependency on the central server to enhance the robustness of the framework. We
validate our framework on multiple medical tasks, demonstrating that our method
evidently outperforms state-of-the-art approaches under both model homogeneity
and heterogeneity settings.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Understanding the Logical Capabilities of Large Language Models via
  Out-of-Context Representation Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10408v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10408v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jonathan Shaki, Emanuele La Malfa, Michael Wooldridge, Sarit Kraus
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study the capabilities of Large Language Models (LLM) on binary relations,
a ubiquitous concept in math employed in most reasoning, math and logic
benchmarks. This work focuses on equality, inequality, and inclusion, along
with the properties they satisfy, such as ir/reflexivity, a/symmetry,
transitivity, and logical complexity (e.g., number of reasoning ``hops''). We
propose an alternative to in-context learning that trains only the
representations of newly introduced tokens, namely out-of-context
representation learning. This method mitigates linguistic biases already
present in a model and, differently from in-context learning, does not rely on
external information or illustrations. We argue out-of-context representation
learning as a better alternative to in-context learning and fine-tuning to
evaluate the capabilities of LLMs on logic tasks that are the building blocks
of more complex reasoning benchmarks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Architecture-Aware Minimization (A$^2$M): How to Find Flat Minima in
  Neural Architecture Search 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10404v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10404v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Matteo Gambella, Fabrizio Pittorino, Manuel Roveri
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Neural Architecture Search (NAS) has become an essential tool for designing
effective and efficient neural networks. In this paper, we investigate the
geometric properties of neural architecture spaces commonly used in
differentiable NAS methods, specifically NAS-Bench-201 and DARTS. By defining
flatness metrics such as neighborhoods and loss barriers along paths in
architecture space, we reveal locality and flatness characteristics analogous
to the well-known properties of neural network loss landscapes in weight space.
In particular, we find that highly accurate architectures cluster together in
flat regions, while suboptimal architectures remain isolated, unveiling the
detailed geometrical structure of the architecture search landscape. Building
on these insights, we propose Architecture-Aware Minimization (A$^2$M), a novel
analytically derived algorithmic framework that explicitly biases, for the
first time, the gradient of differentiable NAS methods towards flat minima in
architecture space. A$^2$M consistently improves generalization over
state-of-the-art DARTS-based algorithms on benchmark datasets including
CIFAR-10, CIFAR-100, and ImageNet16-120, across both NAS-Bench-201 and DARTS
search spaces. Notably, A$^2$M is able to increase the test accuracy, on
average across different differentiable NAS methods, by +3.60\% on CIFAR-10,
+4.60\% on CIFAR-100, and +3.64\% on ImageNet16-120, demonstrating its superior
effectiveness in practice. A$^2$M can be easily integrated into existing
differentiable NAS frameworks, offering a versatile tool for future research
and applications in automated machine learning. We open-source our code at
https://github.com/AI-Tech-Research-Lab/AsquaredM.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>22 pages, 11 figures, 3 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Multi-objective Good Arm Identification with Bandit Feedback 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10386v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10386v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xuanke Jiang, Kohei Hatano, Eiji Takimoto
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We consider a good arm identification problem in a stochastic bandit setting
with multi-objectives, where each arm $i\in[K]$ is associated with $M$
distributions $\mathcal{D}_i^{(1)}, \ldots, \mathcal{D}_i^{(M)}$. For each
round $t$, the player/algorithm pulls one arm $i_t$ and receives a vector
feedback, where each component $m$ is sampled according to
$\mathcal{D}_i^{(m)}$. The target is twofold, one is finding one arm whose
means are larger than the predefined thresholds $\xi_1,\ldots,\xi_M$ with a
confidence bound $\delta$ and an accuracy rate $\epsilon$ with a bounded sample
complexity, the other is output $\bot$ to indicate no such arm exists. We
propose an algorithm with a sample complexity bound. When $M=1$ and $\epsilon =
0$, our bound is the same as the one given in the previous work when and novel
bounds for $M > 1$. The proposed algorithm attains better numerical performance
than other baselines in the experiments on synthetic and real datasets.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Subgroup Performance Analysis in Hidden Stratifications 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10382v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10382v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alceu Bissoto, Trung-Dung Hoang, Tim Flühmann, Susu Sun, Christian F. Baumgartner, Lisa M. Koch
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Machine learning (ML) models may suffer from significant performance
disparities between patient groups. Identifying such disparities by monitoring
performance at a granular level is crucial for safely deploying ML to each
patient. Traditional subgroup analysis based on metadata can expose performance
disparities only if the available metadata (e.g., patient sex) sufficiently
reflects the main reasons for performance variability, which is not common.
Subgroup discovery techniques that identify cohesive subgroups based on learned
feature representations appear as a potential solution: They could expose
hidden stratifications and provide more granular subgroup performance reports.
However, subgroup discovery is challenging to evaluate even as a standalone
task, as ground truth stratification labels do not exist in real data. Subgroup
discovery has thus neither been applied nor evaluated for the application of
subgroup performance monitoring. Here, we apply subgroup discovery for
performance monitoring in chest x-ray and skin lesion classification. We
propose novel evaluation strategies and show that a simplified subgroup
discovery method without access to classification labels or metadata can expose
larger performance disparities than traditional metadata-based subgroup
analysis. We provide the first compelling evidence that subgroup discovery can
serve as an important tool for comprehensive performance validation and
monitoring of trustworthy AI in medicine.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Probabilistic Forecasting via Autoregressive Flow Matching 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10375v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10375v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ahmed El-Gazzar, Marcel van Gerven
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work, we propose FlowTime, a generative model for probabilistic
forecasting of multivariate timeseries data. Given historical measurements and
optional future covariates, we formulate forecasting as sampling from a learned
conditional distribution over future trajectories. Specifically, we decompose
the joint distribution of future observations into a sequence of conditional
densities, each modeled via a shared flow that transforms a simple base
distribution into the next observation distribution, conditioned on observed
covariates. To achieve this, we leverage the flow matching (FM) framework,
enabling scalable and simulation-free learning of these transformations. By
combining this factorization with the FM objective, FlowTime retains the
benefits of autoregressive models -- including strong extrapolation
performance, compact model size, and well-calibrated uncertainty estimates --
while also capturing complex multi-modal conditional distributions, as seen in
modern transport-based generative models. We demonstrate the effectiveness of
FlowTime on multiple dynamical systems and real-world forecasting tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Multimodal Fusion Model Leveraging MLP Mixer and Handcrafted
  Features-based Deep Learning Networks for Facial Palsy Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10371v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10371v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Heng Yim Nicole Oo, Min Hun Lee, Jeong Hoon Lim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Algorithmic detection of facial palsy offers the potential to improve current
practices, which usually involve labor-intensive and subjective assessments by
clinicians. In this paper, we present a multimodal fusion-based deep learning
model that utilizes an MLP mixer-based model to process unstructured data (i.e.
RGB images or images with facial line segments) and a feed-forward neural
network to process structured data (i.e. facial landmark coordinates, features
of facial expressions, or handcrafted features) for detecting facial palsy. We
then contribute to a study to analyze the effect of different data modalities
and the benefits of a multimodal fusion-based approach using videos of 20
facial palsy patients and 20 healthy subjects. Our multimodal fusion model
achieved 96.00 F1, which is significantly higher than the feed-forward neural
network trained on handcrafted features alone (82.80 F1) and an MLP mixer-based
model trained on raw RGB images (89.00 F1).
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>PAKDD 2025. arXiv admin note: text overlap with arXiv:2405.16496</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LUMOS: Language-Conditioned Imitation Learning with World Models <span class="chip">ICRA</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10370v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10370v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Iman Nematollahi, Branton DeMoss, Akshay L Chandra, Nick Hawes, Wolfram Burgard, Ingmar Posner
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce LUMOS, a language-conditioned multi-task imitation learning
framework for robotics. LUMOS learns skills by practicing them over many
long-horizon rollouts in the latent space of a learned world model and
transfers these skills zero-shot to a real robot. By learning on-policy in the
latent space of the learned world model, our algorithm mitigates policy-induced
distribution shift which most offline imitation learning methods suffer from.
LUMOS learns from unstructured play data with fewer than 1% hindsight language
annotations but is steerable with language commands at test time. We achieve
this coherent long-horizon performance by combining latent planning with both
image- and language-based hindsight goal relabeling during training, and by
optimizing an intrinsic reward defined in the latent space of the world model
over multiple time steps, effectively reducing covariate shift. In experiments
on the difficult long-horizon CALVIN benchmark, LUMOS outperforms prior
learning-based methods with comparable approaches on chained multi-task
evaluations. To the best of our knowledge, we are the first to learn a
language-conditioned continuous visuomotor control for a real-world robot
within an offline world model. Videos, dataset and code are available at
http://lumos.cs.uni-freiburg.de.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at the 2025 IEEE International Conference on Robotics and
  Automation (ICRA)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ BioSerenity-E1: a self-supervised EEG model for medical applications 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10362v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10362v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ruggero G. Bettinardi, Mohamed Rahmouni, Ulysse Gimenez
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Electroencephalography (EEG) serves as an essential diagnostic tool in
neurology; however, its accurate manual interpretation is a time-intensive
process that demands highly specialized expertise, which remains relatively
scarce and not consistently accessible. To address these limitations, the
implementation of automated pre-screening and analysis systems for EEG data
holds considerable promise. Advances in self-supervised learning made it
possible to pre-train complex deep learning architectures on large volumes of
unlabeled EEG data to learn generalizable representations, that can later be
used to enhance performance on multiple tasks while needing less downstream
data. In the present paper, we introduce BioSerenity-E1, the first of a family
of self-supervised foundation models for clinical EEG applications that
combines spectral tokenization with masked prediction to achieve
state-of-the-art performance across relevant diagnostic tasks. The two-phase
self-supervised pretraining framework initially acquires compressed EEG
representations via a transformer-based VQ-VAE architecture designed to
reconstruct log-multitaper spectral projections, then implements extensive (70%
block) masked token prediction to force the model to learn complex
spatiotemporal dependencies in EEG signals. BioSerenity-E1 achieves strong
performance across three clinical tasks, either in line or above
state-of-the-art methods: seizure detection (AUROC = 0.926, Sensitivity =
0.909), normal/abnormal classification (AUPRC = 0.970 on proprietary data;
0.910 on TUH-Abnormal), and multiclass pathology differentiation on unbalanced
data (Weighted F1 = 0.730). The utility of BioSerenity-E1 is further confirmed
in low-data regimes scenarios, showing clear improvements in AUPRC (from +2% to
17%) when trained on less than 10% of the available data.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ConceptGuard: Continual Personalized Text-to-Image Generation with
  Forgetting and Confusion Mitigation <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10358v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10358v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zirun Guo, Tao Jin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diffusion customization methods have achieved impressive results with only a
minimal number of user-provided images. However, existing approaches customize
concepts collectively, whereas real-world applications often require sequential
concept integration. This sequential nature can lead to catastrophic
forgetting, where previously learned concepts are lost. In this paper, we
investigate concept forgetting and concept confusion in the continual
customization. To tackle these challenges, we present ConceptGuard, a
comprehensive approach that combines shift embedding, concept-binding prompts
and memory preservation regularization, supplemented by a priority queue which
can adaptively update the importance and occurrence order of different
concepts. These strategies can dynamically update, unbind and learn the
relationship of the previous concepts, thus alleviating concept forgetting and
confusion. Through comprehensive experiments, we show that our approach
outperforms all the baseline methods consistently and significantly in both
quantitative and qualitative analyses.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at CVPR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Safe exploration in reproducing kernel Hilbert spaces 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10352v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10352v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Abdullah Tokmak, Kiran G. Krishnan, Thomas B. Schön, Dominik Baumann
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Popular safe Bayesian optimization (BO) algorithms learn control policies for
safety-critical systems in unknown environments. However, most algorithms make
a smoothness assumption, which is encoded by a known bounded norm in a
reproducing kernel Hilbert space (RKHS). The RKHS is a potentially
infinite-dimensional space, and it remains unclear how to reliably obtain the
RKHS norm of an unknown function. In this work, we propose a safe BO algorithm
capable of estimating the RKHS norm from data. We provide statistical
guarantees on the RKHS norm estimation, integrate the estimated RKHS norm into
existing confidence intervals and show that we retain theoretical guarantees,
and prove safety of the resulting safe BO algorithm. We apply our algorithm to
safely optimize reinforcement learning policies on physics simulators and on a
real inverted pendulum, demonstrating improved performance, safety, and
scalability compared to the state-of-the-art.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to AISTATS 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Mirror Online Conformal Prediction with Intermittent Feedback 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10345v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10345v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bowen Wang, Matteo Zecchin, Osvaldo Simeone
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Online conformal prediction enables the runtime calibration of a pre-trained
artificial intelligence model using feedback on its performance. Calibration is
achieved through set predictions that are updated via online rules so as to
ensure long-term coverage guarantees. While recent research has demonstrated
the benefits of incorporating prior knowledge into the calibration process,
this has come at the cost of replacing coverage guarantees with less tangible
regret guarantees based on the quantile loss. This work introduces intermittent
mirror online conformal prediction (IM-OCP), a novel runtime calibration
framework that integrates prior knowledge, while maintaining long-term coverage
and achieving sub-linear regret. IM-OCP features closed-form updates with
minimal memory complexity, and is designed to operate under potentially
intermittent feedback.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Characterizing Nonlinear Dynamics via Smooth Prototype Equivalences 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10336v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10336v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Roy Friedman, Noa Moriel, Matthew Ricci, Guy Pelc, Yair Weiss, Mor Nitzan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Characterizing dynamical systems given limited measurements is a common
challenge throughout the physical and biological sciences. However, this task
is challenging, especially due to transient variability in systems with
equivalent long-term dynamics. We address this by introducing smooth prototype
equivalences (SPE), a framework that fits a diffeomorphism using normalizing
flows to distinct prototypes - simplified dynamical systems that define
equivalence classes of behavior. SPE enables classification by comparing the
deformation loss of the observed sparse, high-dimensional measurements to the
prototype dynamics. Furthermore, our approach enables estimation of the
invariant sets of the observed dynamics through the learned mapping from
prototype space to data space. Our method outperforms existing techniques in
the classification of oscillatory systems and can efficiently identify
invariant structures like limit cycles and fixed points in an equation-free
manner, even when only a small, noisy subset of the phase space is observed.
Finally, we show how our method can be used for the detection of biological
processes like the cell cycle trajectory from high-dimensional single-cell gene
expression data.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Generative Binary Memory: Pseudo-Replay Class-Incremental Learning on
  Binarized Embeddings 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10333v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10333v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yanis Basso-Bert, Anca Molnos, Romain Lemaire, William Guicquero, Antoine Dupret
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In dynamic environments where new concepts continuously emerge, Deep Neural
Networks (DNNs) must adapt by learning new classes while retaining previously
acquired ones. This challenge is addressed by Class-Incremental Learning (CIL).
This paper introduces Generative Binary Memory (GBM), a novel CIL pseudo-replay
approach which generates synthetic binary pseudo-exemplars. Relying on
Bernoulli Mixture Models (BMMs), GBM effectively models the multi-modal
characteristics of class distributions, in a latent, binary space. With a
specifically-designed feature binarizer, our approach applies to any
conventional DNN. GBM also natively supports Binary Neural Networks (BNNs) for
highly-constrained model sizes in embedded systems. The experimental results
demonstrate that GBM achieves higher than state-of-the-art average accuracy on
CIFAR100 (+2.9%) and TinyImageNet (+1.5%) for a ResNet-18 equipped with our
binarizer. GBM also outperforms emerging CIL methods for BNNs, with +3.1% in
final accuracy and x4.7 memory reduction, on CORE50.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Collaborative Speculative Inference for Efficient LLM Inference Serving 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10325v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10325v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Luyao Gao, Jianchun Liu, Hongli Xu, Liusheng Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Speculative inference is a promising paradigm employing small speculative
models (SSMs) as drafters to generate draft tokens, which are subsequently
verified in parallel by the target large language model (LLM). This approach
enhances the efficiency of inference serving by reducing LLM inference latency
and costs while preserving generation quality. However, existing speculative
methods face critical challenges, including inefficient resource utilization
and limited draft acceptance, which constrain their scalability and overall
effectiveness. To overcome these obstacles, we present CoSine, a novel
speculative inference system that decouples sequential speculative decoding
from parallel verification, enabling efficient collaboration among multiple
nodes. Specifically, CoSine routes inference requests to specialized drafters
based on their expertise and incorporates a confidence-based token fusion
mechanism to synthesize outputs from cooperating drafters, ensuring
high-quality draft generation. Additionally, CoSine dynamically orchestrates
the execution of speculative decoding and verification in a pipelined manner,
employing batch scheduling to selectively group requests and adaptive
speculation control to minimize idle periods. By optimizing parallel workflows
through heterogeneous node collaboration, CoSine balances draft generation and
verification throughput in real-time, thereby maximizing resource utilization.
Experimental results demonstrate that CoSine achieves superior performance
compared to state-of-the-art speculative approaches. Notably, with equivalent
resource costs, CoSine achieves up to a 23.2% decrease in latency and a 32.5%
increase in throughput compared to baseline methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhance Exploration in Safe Reinforcement Learning with Contrastive
  Representation Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10318v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10318v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Duc Kien Doan, Bang Giang Le, Viet Cuong Ta
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In safe reinforcement learning, agent needs to balance between exploration
actions and safety constraints. Following this paradigm, domain transfer
approaches learn a prior Q-function from the related environments to prevent
unsafe actions. However, because of the large number of false positives, some
safe actions are never executed, leading to inadequate exploration in
sparse-reward environments. In this work, we aim to learn an efficient state
representation to balance the exploration and safety-prefer action in a
sparse-reward environment. Firstly, the image input is mapped to latent
representation by an auto-encoder. A further contrastive learning objective is
employed to distinguish safe and unsafe states. In the learning phase, the
latent distance is used to construct an additional safety check, which allows
the agent to bias the exploration if it visits an unsafe state. To verify the
effectiveness of our method, the experiment is carried out in three
navigation-based MiniGrid environments. The result highlights that our method
can explore the environment better while maintaining a good balance between
safety and efficiency.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at ACIIDS 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Capturing Semantic Flow of ML-based Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10310v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10310v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shin Yoo, Robert Feldt, Somin Kim, Naryeong Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  ML-based systems are software systems that incorporates machine learning
components such as Deep Neural Networks (DNNs) or Large Language Models (LLMs).
While such systems enable advanced features such as high performance computer
vision, natural language processing, and code generation, their internal
behaviour remain largely opaque to traditional dynamic analysis such as
testing: existing analysis typically concern only what is observable from the
outside, such as input similarity or class label changes. We propose semantic
flow, a concept designed to capture the internal behaviour of ML-based system
and to provide a platform for traditional dynamic analysis techniques to be
adapted to. Semantic flow combines the idea of control flow with internal
states taken from executions of ML-based systems, such as activation values of
a specific layer in a DNN, or embeddings of LLM responses at a specific
inference step of LLM agents. The resulting representation, summarised as
semantic flow graphs, can capture internal decisions that are not explicitly
represented in the traditional control flow of ML-based systems. We propose the
idea of semantic flow, introduce two examples using a DNN and an LLM agent, and
finally sketch its properties and how it can be used to adapt existing dynamic
analysis techniques for use in ML-based software systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Nash Equilibrium Constrained Auto-bidding With Bi-level Reinforcement
  Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10304v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10304v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhiyu Mou, Miao Xu, Rongquan Bai, Zhuoran Yang, Chuan Yu, Jian Xu, Bo Zheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Many online advertising platforms provide advertisers with auto-bidding
services to enhance their advertising performance. However, most existing
auto-bidding algorithms fail to accurately capture the auto-bidding problem
formulation that the platform truly faces, let alone solve it. Actually, we
argue that the platform should try to help optimize each advertiser's
performance to the greatest extent -- which makes $\epsilon$-Nash Equilibrium
($\epsilon$-NE) a necessary solution concept -- while maximizing the social
welfare of all the advertisers for the platform's long-term value. Based on
this, we introduce the \emph{Nash-Equilibrium Constrained Bidding} (NCB), a new
formulation of the auto-bidding problem from the platform's perspective.
Specifically, it aims to maximize the social welfare of all advertisers under
the $\epsilon$-NE constraint. However, the NCB problem presents significant
challenges due to its constrained bi-level structure and the typically large
number of advertisers involved. To address these challenges, we propose a
\emph{Bi-level Policy Gradient} (BPG) framework with theoretical guarantees.
Notably, its computational complexity is independent of the number of
advertisers, and the associated gradients are straightforward to compute.
Extensive simulated and real-world experiments validate the effectiveness of
the BPG framework.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Wikipedia is Not a Dictionary, Delete! Text Classification as a Proxy
  for Analysing Wiki Deletion Discussions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10294v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10294v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hsuvas Borkakoty, Luis Espinosa-Anke
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Automated content moderation for collaborative knowledge hubs like Wikipedia
or Wikidata is an important yet challenging task due to multiple factors. In
this paper, we construct a database of discussions happening around articles
marked for deletion in several Wikis and in three languages, which we then use
to evaluate a range of LMs on different tasks (from predicting the outcome of
the discussion to identifying the implicit policy an individual comment might
be pointing to). Our results reveal, among others, that discussions leading to
deletion are easier to predict, and that, surprisingly, self-produced tags
(keep, delete or redirect) don't always help guiding the classifiers,
presumably because of users' hesitation or deliberation within comments.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to WNUT-2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PyGDA: A Python Library for Graph Domain Adaptation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10284v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10284v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhen Zhang, Meihan Liu, Bingsheng He
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Graph domain adaptation has emerged as a promising approach to facilitate
knowledge transfer across different domains. Recently, numerous models have
been proposed to enhance their generalization capabilities in this field.
However, there is still no unified library that brings together existing
techniques and simplifies their implementation. To fill this gap, we introduce
PyGDA, an open-source Python library tailored for graph domain adaptation. As
the first comprehensive library in this area, PyGDA covers more than 20 widely
used graph domain adaptation methods together with different types of graph
datasets. Specifically, PyGDA offers modular components, enabling users to
seamlessly build custom models with a variety of commonly used utility
functions. To handle large-scale graphs, PyGDA includes support for features
such as sampling and mini-batch processing, ensuring efficient computation. In
addition, PyGDA also includes comprehensive performance benchmarks and
well-documented user-friendly API for both researchers and practitioners. To
foster convenient accessibility, PyGDA is released under the MIT license at
https://github.com/pygda-team/pygda, and the API documentation is
https://pygda.readthedocs.io/en/stable/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under Review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HyperArm Bandit <span class="highlight-title">Optimization</span>: A Novel approach to Hyperparameter
  <span class="highlight-title">Optimization</span> and an Analysis of Bandit Algorithms in Stochastic and
  Adversarial Settings 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10282v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10282v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Samih Karroum, Saad Mazhar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper explores the application of bandit algorithms in both stochastic
and adversarial settings, with a focus on theoretical analysis and practical
applications. The study begins by introducing bandit problems, distinguishing
between stochastic and adversarial variants, and examining key algorithms such
as Explore-Then-Commit (ETC), Upper Confidence Bound (UCB), and
Exponential-Weight Algorithm for Exploration and Exploitation (EXP3).
Theoretical regret bounds are analyzed to compare the performance of these
algorithms. The paper then introduces a novel framework, HyperArm Bandit
Optimization (HABO), which applies EXP3 to hyperparameter tuning in machine
learning models. Unlike traditional methods that treat entire configurations as
arms, HABO treats individual hyperparameters as super-arms, and its potential
configurations as sub-arms, enabling dynamic resource allocation and efficient
exploration. Experimental results demonstrate HABO's effectiveness in
classification and regression tasks, outperforming Bayesian Optimization in
terms of computational efficiency and accuracy. The paper concludes with
insights into the convergence guarantees of HABO and its potential for scalable
and robust hyperparameter optimization.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>41 pages, 9 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Robust Learning-Based Sparse Recovery for Device Activity Detection in
  Grant-Free Random Access Cell-Free Massive MIMO: Enhancing Resilience to
  Impairments 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10280v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10280v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ali Elkeshawy, Haifa Fares, Amor Nafkha
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Massive MIMO is considered a key enabler to support massive machine-type
communication (mMTC). While massive access schemes have been extensively
analyzed for co-located massive MIMO arrays, this paper explores activity
detection in grant-free random access for mMTC within the context of cell-free
massive MIMO systems, employing distributed antenna arrays. This sparse support
recovery of device activity status is performed by a finite cluster of access
points (APs) from a large number of geographically distributed APs
collaborating to serve a larger number of devices. Active devices transmit
non-orthogonal pilot sequences to APs, which forward the received signals to a
central processing unit (CPU) for collaborative activity detection. This paper
proposes a simple and efficient data-driven algorithm tailored for device
activity detection, implemented centrally at the CPU. Furthermore, the study
assesses the algorithm's robustness to input perturbations and examines the
effects of adopting fixed-point representation on its performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Numerically robust Gaussian state estimation with singular observation
  noise 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10279v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10279v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nicholas Krämer, Filip Tronarp
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This article proposes numerically robust algorithms for Gaussian state
estimation with singular observation noise. Our approach combines a series of
basis changes with Bayes' rule, transforming the singular estimation problem
into a nonsingular one with reduced state dimension. In addition to ensuring
low runtime and numerical stability, our proposal facilitates
marginal-likelihood computations and Gauss-Markov representations of the
posterior process. We analyse the proposed method's computational savings and
numerical robustness and validate our findings in a series of simulations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Climate land use and other drivers impacts on island ecosystem services:
  a global <span class="highlight-title">review</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10278v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10278v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aristides Moustakas, Shiri Zemah-Shamir, Mirela Tase, Savvas Zotos, Nazli Demirel, Christos Zoumides, Irene Christoforidi, Turgay Dindaroglu, Tamer Albayrak, Cigdem Kaptan Ayhan, Mauro Fois, Paraskevi Manolaki, Attila D. Sandor, Ina Sieber, Valentini Stamatiadou, Elli Tzirkalli, Ioannis N. Vogiatzakis, Ziv Zemah-Shamir, George Zittis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Islands are diversity hotspots and vulnerable to environmental degradation,
climate variations, land use changes and societal crises. These factors can
exhibit interactive impacts on ecosystem services. The study reviewed a large
number of papers on the climate change-islands-ecosystem services topic
worldwide. Potential inclusion of land use changes and other drivers of impacts
on ecosystem services were sequentially also recorded. The study sought to
investigate the impacts of climate change, land use change, and other
non-climatic driver changes on island ecosystem services. Explanatory variables
examined were divided into two categories: environmental variables and
methodological ones. Environmental variables include sea zone geographic
location, ecosystem, ecosystem services, climate, land use, other driver
variables, Methodological variables include consideration of policy
interventions, uncertainty assessment, cumulative effects of climate change,
synergistic effects of climate change with land use change and other
anthropogenic and environmental drivers, and the diversity of variables used in
the analysis. Machine learning and statistical methods were used to analyze
their effects on island ecosystem services. Negative climate change impacts on
ecosystem services are better quantified by land use change or other
non-climatic driver variables than by climate variables. The synergy of land
use together with climate changes is modulating the impact outcome and critical
for a better impact assessment. Analyzed together, there is little evidence of
more pronounced for a specific sea zone, ecosystem, or ecosystem service.
Climate change impacts may be underestimated due to the use of a single climate
variable deployed in most studies. Policy interventions exhibit low
classification accuracy in quantifying impacts indicating insufficient efficacy
or integration in the studies.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Article published in the journal: Science of the Total Environment.
  Free author's version</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Resource efficient data transmission on animals based on machine
  learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10277v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10277v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wilhelm Kerle-Malcharek, Karsten Klein, Martin Wikelski, Falk Schreiber, Timm A. Wild
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Bio-loggers, electronic devices used to track animal behaviour through
various sensors, have become essential in wildlife research.
  Despite continuous improvements in their capabilities, bio-loggers still face
significant limitations in storage, processing, and data transmission due to
the constraints of size and weight, which are necessary to avoid disturbing the
animals.
  This study aims to explore how selective data transmission, guided by machine
learning, can reduce the energy consumption of bio-loggers, thereby extending
their operational lifespan without requiring hardware modifications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to Scientific Reports but not published, 23 pages, 5
  figures, 3 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Targeted Data Poisoning for Black-Box Audio Datasets Ownership
  Verification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10269v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10269v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wassim Bouaziz, El-Mahdi El-Mhamdi, Nicolas Usunier
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Protecting the use of audio datasets is a major concern for data owners,
particularly with the recent rise of audio deep learning models. While
watermarks can be used to protect the data itself, they do not allow to
identify a deep learning model trained on a protected dataset. In this paper,
we adapt to audio data the recently introduced data taggants approach. Data
taggants is a method to verify if a neural network was trained on a protected
image dataset with top-$k$ predictions access to the model only. This method
relies on a targeted data poisoning scheme by discreetly altering a small
fraction (1%) of the dataset as to induce a harmless behavior on
out-of-distribution data called keys. We evaluate our method on the
Speechcommands and the ESC50 datasets and state of the art transformer models,
and show that we can detect the use of the dataset with high confidence without
loss of performance. We also show the robustness of our method against common
data augmentation techniques, making it a practical method to protect audio
datasets.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published at ICASSP 2025, 5 pages, 7 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ AMR-Transformer: Enabling Efficient Long-range Interaction for Complex
  Neural Fluid Simulation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10257v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10257v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zeyi Xu, Jinfan Liu, Kuangxu Chen, Ye Chen, Zhangli Hu, Bingbing Ni
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Accurately and efficiently simulating complex fluid dynamics is a challenging
task that has traditionally relied on computationally intensive methods. Neural
network-based approaches, such as convolutional and graph neural networks, have
partially alleviated this burden by enabling efficient local feature
extraction. However, they struggle to capture long-range dependencies due to
limited receptive fields, and Transformer-based models, while providing global
context, incur prohibitive computational costs. To tackle these challenges, we
propose AMR-Transformer, an efficient and accurate neural CFD-solving pipeline
that integrates a novel adaptive mesh refinement scheme with a Navier-Stokes
constraint-aware fast pruning module. This design encourages long-range
interactions between simulation cells and facilitates the modeling of global
fluid wave patterns, such as turbulence and shockwaves. Experiments show that
our approach achieves significant gains in efficiency while preserving critical
details, making it suitable for high-resolution physical simulations with
long-range dependencies. On CFDBench, PDEBench and a new shockwave dataset, our
pipeline demonstrates up to an order-of-magnitude improvement in accuracy over
baseline models. Additionally, compared to ViT, our approach achieves a
reduction in FLOPs of up to 60 times.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PIMRL: Physics-Informed Multi-Scale Recurrent Learning for
  Spatiotemporal Prediction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10253v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10253v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Han Wan, Qi Wang, Hao Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Simulation of spatiotemporal systems governed by partial differential
equations is widely applied in fields such as biology, chemistry, aerospace
dynamics, and meteorology. Traditional numerical methods incur high
computational costs due to the requirement of small time steps for accurate
predictions. While machine learning has reduced these costs, long-term
predictions remain challenged by error accumulation, particularly in scenarios
with insufficient data or varying time scales, where stability and accuracy are
compromised. Existing methods often neglect the effective utilization of
multi-scale data, leading to suboptimal robustness in predictions. To address
these issues, we propose a novel multi-scale learning framework, namely, the
Physics-Informed Multi-Scale Recurrent Learning (PIMRL), to effectively
leverage multi-scale data for spatiotemporal dynamics prediction. The PIMRL
framework comprises two modules: the micro-scale module embeds physical
knowledge into neural networks via pretraining, and the macro-scale module
adopts a data-driven approach to learn the temporal evolution of physics in the
latent space. Experimental results demonstrate that the PIMRL framework
consistently achieves state-of-the-art performance across five benchmark
datasets ranging from one to three dimensions, showing average improvements of
over 9\% in both RMSE and MAE evaluation metrics, with maximum enhancements
reaching up to 80%.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Numerical Error Analysis of Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10251v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10251v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Stanislav Budzinskiy, Wenyi Fang, Longbin Zeng, Philipp Petersen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models based on transformer architectures have become integral
to state-of-the-art natural language processing applications. However, their
training remains computationally expensive and exhibits instabilities, some of
which are expected to be caused by finite-precision computations. We provide a
theoretical analysis of the impact of round-off errors within the forward pass
of a transformer architecture which yields fundamental bounds for these
effects. In addition, we conduct a series of numerical experiments which
demonstrate the practical relevance of our bounds. Our results yield concrete
guidelines for choosing hyperparameters that mitigate round-off errors, leading
to more robust and stable inference.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Spherical dimension 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10240v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10240v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bogdan Chornomaz, Shay Moran, Tom Waknine
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce and study the spherical dimension, a natural topological
relaxation of the VC dimension that unifies several results in learning theory
where topology plays a key role in the proofs. The spherical dimension is
defined by extending the set of realizable datasets (used to define the VC
dimension) to the continuous space of realizable distributions. In this space,
a shattered set of size d (in the VC sense) is completed into a continuous
object, specifically a d-dimensional sphere of realizable distributions. The
spherical dimension is then defined as the dimension of the largest sphere in
this space. Thus, the spherical dimension is at least the VC dimension.
  The spherical dimension serves as a common foundation for leveraging the
Borsuk-Ulam theorem and related topological tools. We demonstrate the utility
of the spherical dimension in diverse applications, including disambiguations
of partial concept classes, reductions from classification to stochastic convex
optimization, stability and replicability, and sample compression schemes.
Perhaps surprisingly, we show that the open question posed by Alon, Hanneke,
Holzman, and Moran (FOCS 2021) of whether there exist non-trivial
disambiguations for halfspaces with margin is equivalent to the basic open
question of whether the VC and spherical dimensions are finite together.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Flows on convex polytopes 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10232v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10232v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tomek Diederen, Nicola Zamboni
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a framework for modeling complex, high-dimensional distributions
on convex polytopes by leveraging recent advances in discrete and continuous
normalizing flows on Riemannian manifolds. We show that any full-dimensional
polytope is homeomorphic to a unit ball, and our approach harnesses flows
defined on the ball, mapping them back to the original polytope. Furthermore,
we introduce a strategy to construct flows when only the vertex representation
of a polytope is available, employing maximum entropy barycentric coordinates
and Aitchison geometry. Our experiments take inspiration from applications in
metabolic flux analysis and demonstrate that our methods achieve competitive
density estimation, sampling accuracy, as well as fast training and inference
times.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Policy Teaching via Data Poisoning in Learning from Human Preferences 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10228v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10228v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Andi Nika, Jonathan Nöther, Debmalya Mandal, Parameswaran Kamalaruban, Adish Singla, Goran Radanović
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study data poisoning attacks in learning from human preferences. More
specifically, we consider the problem of teaching/enforcing a target policy
$\pi^\dagger$ by synthesizing preference data. We seek to understand the
susceptibility of different preference-based learning paradigms to poisoned
preference data by analyzing the number of samples required by the attacker to
enforce $\pi^\dagger$. We first propose a general data poisoning formulation in
learning from human preferences and then study it for two popular paradigms,
namely: (a) reinforcement learning from human feedback (RLHF) that operates by
learning a reward model using preferences; (b) direct preference optimization
(DPO) that directly optimizes policy using preferences. We conduct a
theoretical analysis of the effectiveness of data poisoning in a setting where
the attacker is allowed to augment a pre-existing dataset and also study its
special case where the attacker can synthesize the entire preference dataset
from scratch. As our main results, we provide lower/upper bounds on the number
of samples required to enforce $\pi^\dagger$. Finally, we discuss the
implications of our results in terms of the susceptibility of these learning
paradigms under such data poisoning attacks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>In AISTATS 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Assessing the validity of new paradigmatic complexity measures as
  criterial features for proficiency in L2 writings in English 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10220v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10220v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Cyriel Mallart, Andrew Simpkin, Nicolas Ballier, Paula Lissón, Rémi Venant, Jen-Yu Li, Bernardo Stearns, Thomas Gaillat
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This article addresses Second Language (L2) writing development through an
investigation of new grammatical and structural complexity metrics. We explore
the paradigmatic production in learner English by linking language functions to
specific grammatical paradigms. Using the EFCAMDAT as a gold standard and a
corpus of French learners as an external test set, we employ a supervised
learning framework to operationalise and evaluate seven microsystems. We show
that learner levels are associated with the seven microsystems (MS). Using
ordinal regression modelling for evaluation, the results show that all MS are
significant but yield a low impact if taken individually. However, their
influence is shown to be impactful if taken as a group. These microsystems and
their measurement method suggest that it is possible to use them as part of
broader-purpose CALL systems focused on proficiency assessment.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Probability-Flow ODE in Infinite-Dimensional Function Spaces <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10219v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10219v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kunwoo Na, Junghyun Lee, Se-Young Yun, Sungbin Lim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in infinite-dimensional diffusion models have demonstrated
their effectiveness and scalability in function generation tasks where the
underlying structure is inherently infinite-dimensional. To accelerate
inference in such models, we derive, for the first time, an analog of the
probability-flow ODE (PF-ODE) in infinite-dimensional function spaces.
Leveraging this newly formulated PF-ODE, we reduce the number of function
evaluations while maintaining sample quality in function generation tasks,
including applications to PDEs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>26 pages, 8 figures. Accepted to the ICLR 2025 DeLTa Workshop</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Moss: Proxy Model-based Full-Weight Aggregation in Federated Learning
  with Heterogeneous Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10218v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10218v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yifeng Cai, Ziqi Zhang, Ding Li, Yao Guo, Xiangqun Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Modern Federated Learning (FL) has become increasingly essential for handling
highly heterogeneous mobile devices. Current approaches adopt a partial model
aggregation paradigm that leads to sub-optimal model accuracy and higher
training overhead. In this paper, we challenge the prevailing notion of
partial-model aggregation and propose a novel "full-weight aggregation" method
named Moss, which aggregates all weights within heterogeneous models to
preserve comprehensive knowledge. Evaluation across various applications
demonstrates that Moss significantly accelerates training, reduces on-device
training time and energy consumption, enhances accuracy, and minimizes network
bandwidth utilization when compared to state-of-the-art baselines.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ACM IMWUT/Ubicomp 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Efficient Federated Fine-Tuning of Large Language Models with Layer
  Dropout 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10217v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10217v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shilong Wang, Jianchun Liu, Hongli Xu, Jiaming Yan, Xianjun Gao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Fine-tuning plays a crucial role in enabling pre-trained LLMs to evolve from
general language comprehension to task-specific expertise. To preserve user
data privacy, federated fine-tuning is often employed and has emerged as the de
facto paradigm. However, federated fine-tuning is prohibitively inefficient due
to the tension between LLM complexity and the resource constraint of end
devices, incurring unaffordable fine-tuning overhead. Existing literature
primarily utilizes parameter-efficient fine-tuning techniques to mitigate
communication costs, yet computational and memory burdens continue to pose
significant challenges for developers. This work proposes DropPEFT, an
innovative federated PEFT framework that employs a novel stochastic transformer
layer dropout method, enabling devices to deactivate a considerable fraction of
LLMs layers during training, thereby eliminating the associated computational
load and memory footprint. In DropPEFT, a key challenge is the proper
configuration of dropout ratios for layers, as overhead and training
performance are highly sensitive to this setting. To address this challenge, we
adaptively assign optimal dropout-ratio configurations to devices through an
exploration-exploitation strategy, achieving efficient and effective
fine-tuning. Extensive experiments show that DropPEFT can achieve a
1.3-6.3\times speedup in model convergence and a 40%-67% reduction in memory
footprint compared to state-of-the-art methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Deep Learning for Time Series Forecasting: A <span class="highlight-title">Survey</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10198v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10198v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiangjie Kong, Zhenghao Chen, Weiyao Liu, Kaili Ning, Lechao Zhang, Syauqie Muhammad Marier, Yichen Liu, Yuhao Chen, Feng Xia
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Time series forecasting (TSF) has long been a crucial task in both industry
and daily life. Most classical statistical models may have certain limitations
when applied to practical scenarios in fields such as energy, healthcare,
traffic, meteorology, and economics, especially when high accuracy is required.
With the continuous development of deep learning, numerous new models have
emerged in the field of time series forecasting in recent years. However,
existing surveys have not provided a unified summary of the wide range of model
architectures in this field, nor have they given detailed summaries of works in
feature extraction and datasets. To address this gap, in this review, we
comprehensively study the previous works and summarize the general paradigms of
Deep Time Series Forecasting (DTSF) in terms of model architectures. Besides,
we take an innovative approach by focusing on the composition of time series
and systematically explain important feature extraction methods. Additionally,
we provide an overall compilation of datasets from various domains in existing
works. Finally, we systematically emphasize the significant challenges faced
and future research directions in this field.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Robustness Tokens: Towards Adversarial Robustness of Transformers <span class="chip">ECCV</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10191v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10191v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Brian Pulfer, Yury Belousov, Slava Voloshynovskiy
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, large pre-trained foundation models have become widely adopted by
machine learning practitioners for a multitude of tasks. Given that such models
are publicly available, relying on their use as backbone models for downstream
tasks might result in high vulnerability to adversarial attacks crafted with
the same public model. In this work, we propose Robustness Tokens, a novel
approach specific to the transformer architecture that fine-tunes a few
additional private tokens with low computational requirements instead of tuning
model parameters as done in traditional adversarial training. We show that
Robustness Tokens make Vision Transformer models significantly more robust to
white-box adversarial attacks while also retaining the original downstream
performances.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This paper has been accepted for publication at the European
  Conference on Computer Vision (ECCV), 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Data augmentation using diffusion models to enhance inverse Ising
  inference 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10154v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10154v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yechan Lim, Sangwon Lee, Junghyo Jo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Identifying model parameters from observed configurations poses a fundamental
challenge in data science, especially with limited data. Recently, diffusion
models have emerged as a novel paradigm in generative machine learning, capable
of producing new samples that closely mimic observed data. These models learn
the gradient of model probabilities, bypassing the need for cumbersome
calculations of partition functions across all possible configurations. We
explore whether diffusion models can enhance parameter inference by augmenting
small datasets. Our findings demonstrate this potential through a synthetic
task involving inverse Ising inference and a real-world application of
reconstructing missing values in neural activity data. This study serves as a
proof-of-concept for using diffusion models for data augmentation in
physics-related problems, thereby opening new avenues in data science.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Multiplicative Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10144v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10144v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Han Kim, Hyungjoon Soh, Vipul Periwal, Junghyo Jo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Efficient training of artificial neural networks remains a key challenge in
deep learning. Backpropagation (BP), the standard learning algorithm, relies on
gradient descent and typically requires numerous iterations for convergence. In
this study, we introduce Expectation Reflection (ER), a novel learning approach
that updates weights multiplicatively based on the ratio of observed to
predicted outputs. Unlike traditional methods, ER maintains consistency without
requiring ad hoc loss functions or learning rate hyperparameters. We extend ER
to multilayer networks and demonstrate its effectiveness in performing image
classification tasks. Notably, ER achieves optimal weight updates in a single
iteration. Additionally, we reinterpret ER as a modified form of gradient
descent incorporating the inverse mapping of target propagation. These findings
suggest that ER provides an efficient and scalable alternative for training
neural networks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Are Convex <span class="highlight-title">Optimization</span> Curves Convex? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10138v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10138v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guy Barzilai, Ohad Shamir
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we study when we might expect the optimization curve induced
by gradient descent to be \emph{convex} -- precluding, for example, an initial
plateau followed by a sharp decrease, making it difficult to decide when
optimization should stop. Although such undesirable behavior can certainly
occur when optimizing general functions, might it also occur in the benign and
well-studied case of smooth convex functions? As far as we know, this question
has not been tackled in previous work. We show, perhaps surprisingly, that the
answer crucially depends on the choice of the step size. In particular, for the
range of step sizes which are known to result in monotonic convergence to an
optimal value, there is a regime where the optimization curve will be provably
convex, and there is a regime where the curve can be non-convex. We also extend
our results to gradient flow, and to the closely-related but different question
of whether the gradient norm decreases monotonically.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Gumiho: A Hybrid Architecture to Prioritize Early Tokens in Speculative
  Decoding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10135v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10135v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jinze Li, Yixing Xu, Haiduo Huang, Xuanwu Yin, Dong Li, Edith C. H. Ngai, Emad Barsoum
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Speculative decoding (SPD) aims to accelerate the auto-regressive token
generation process of a target Large Language Model (LLM). Some approaches
employ a draft model with multiple heads to predict a sequence of future
tokens, where each head handles a token in the sequence. The target LLM
verifies the predicted sequence and accepts aligned tokens, enabling efficient
multi-token generation. However, existing methods assume that all tokens within
a sequence are equally important, employing identical head structures and
relying on a single-generation paradigm, either serial or parallel. To this
end, we theoretically demonstrate that initial tokens in the draft sequence are
more important than later ones. Building on this insight, we propose Gumiho, a
hybrid model combining serial and parallel heads. Specifically, given the
critical importance of early tokens, we employ a sophisticated Transformer
architecture for the early draft heads in a serial configuration to improve
accuracy. For later tokens, we utilize multiple lightweight MLP heads operating
in parallel to enhance efficiency. By allocating more advanced model structures
and longer running times to the early heads, Gumiho achieves improved overall
performance. The experimental results demonstrate that our method outperforms
existing approaches, fully validating its effectiveness.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Paper under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ An Real-Sim-Real (RSR) Loop Framework for Generalizable Robotic Policy
  Transfer with Differentiable Simulation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10118v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10118v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lu Shi, Yuxuan Xu, Shiyu Wang, Jinhao Huang, Wenhao Zhao, Yufei Jia, Zike Yan, Weibin Gu, Guyue Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The sim-to-real gap remains a critical challenge in robotics, hindering the
deployment of algorithms trained in simulation to real-world systems. This
paper introduces a novel Real-Sim-Real (RSR) loop framework leveraging
differentiable simulation to address this gap by iteratively refining
simulation parameters, aligning them with real-world conditions, and enabling
robust and efficient policy transfer. A key contribution of our work is the
design of an informative cost function that encourages the collection of
diverse and representative real-world data, minimizing bias and maximizing the
utility of each data point for simulation refinement. This cost function
integrates seamlessly into existing reinforcement learning algorithms (e.g.,
PPO, SAC) and ensures a balanced exploration of critical regions in the real
domain. Furthermore, our approach is implemented on the versatile Mujoco MJX
platform, and our framework is compatible with a wide range of robotic systems.
Experimental results on several robotic manipulation tasks demonstrate that our
method significantly reduces the sim-to-real gap, achieving high task
performance and generalizability across diverse scenarios of both explicit and
implicit environmental uncertainties.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Reconsidering Feature Structure Information and Latent Space Alignment
  in Partial Multi-label Feature Selection <span class="chip">AAAI 25</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10115v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10115v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hanlin Pan, Kunpeng Liu, Wanfu Gao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The purpose of partial multi-label feature selection is to select the most
representative feature subset, where the data comes from partial multi-label
datasets that have label ambiguity issues. For label disambiguation, previous
methods mainly focus on utilizing the information inside the labels and the
relationship between the labels and features. However, the information existing
in the feature space is rarely considered, especially in partial multi-label
scenarios where the noises is considered to be concentrated in the label space
while the feature information is correct. This paper proposes a method based on
latent space alignment, which uses the information mined in feature space to
disambiguate in latent space through the structural consistency between labels
and features. In addition, previous methods overestimate the consistency of
features and labels in the latent space after convergence. We comprehensively
consider the similarity of latent space projections to feature space and label
space, and propose new feature selection term. This method also significantly
improves the positive label identification ability of the selected features.
Comprehensive experiments demonstrate the superiority of the proposed method.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9pages,6 figures,accept at AAAI 25</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ IMPACT: Intelligent Motion <span class="highlight-title">Plan</span>ning with Acceptable Contact Trajectories
  via Vision-Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10110v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10110v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yiyang Ling, Karan Owalekar, Oluwatobiloba Adesanya, Erdem Bıyık, Daniel Seita
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Motion planning involves determining a sequence of robot configurations to
reach a desired pose, subject to movement and safety constraints. Traditional
motion planning finds collision-free paths, but this is overly restrictive in
clutter, where it may not be possible for a robot to accomplish a task without
contact. In addition, contacts range from relatively benign (e.g., brushing a
soft pillow) to more dangerous (e.g., toppling a glass vase). Due to this
diversity, it is difficult to characterize which contacts may be acceptable or
unacceptable. In this paper, we propose IMPACT, a novel motion planning
framework that uses Vision-Language Models (VLMs) to infer environment
semantics, identifying which parts of the environment can best tolerate contact
based on object properties and locations. Our approach uses the VLM's outputs
to produce a dense 3D "cost map" that encodes contact tolerances and seamlessly
integrates with standard motion planners. We perform experiments using 20
simulation and 10 real-world scenes and assess using task success rate, object
displacements, and feedback from human evaluators. Our results over 3620
simulation and 200 real-world trials suggest that IMPACT enables efficient
contact-rich motion planning in cluttered settings while outperforming
alternative methods and ablations. Supplementary material is available at
https://impact-planning.github.io/.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         <span class="highlight-title">★</span> Improving Diffusion-based Inverse Algorithms under Few-Step Constraint
  via Learnable Linear Extrapolation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10103v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10103v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jia<span class="highlight-author">wei Zhang</span>, Ziyuan Liu, Leon Yan, Gen Li, Yuantao Gu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diffusion models have demonstrated remarkable performance in modeling complex
data priors, catalyzing their widespread adoption in solving various inverse
problems. However, the inherently iterative nature of diffusion-based inverse
algorithms often requires hundreds to thousands of steps, with performance
degradation occurring under fewer steps which limits their practical
applicability. While high-order diffusion ODE solvers have been extensively
explored for efficient diffusion sampling without observations, their
application to inverse problems remains underexplored due to the diverse forms
of inverse algorithms and their need for repeated trajectory correction based
on observations. To address this gap, we first introduce a canonical form that
decomposes existing diffusion-based inverse algorithms into three modules to
unify their analysis. Inspired by the linear subspace search strategy in the
design of high-order diffusion ODE solvers, we propose the Learnable Linear
Extrapolation (LLE) method, a lightweight approach that universally enhances
the performance of any diffusion-based inverse algorithm that fits the proposed
canonical form. Extensive experiments demonstrate consistent improvements of
the proposed LLE method across multiple algorithms and tasks, indicating its
potential for more efficient solutions and boosted performance of
diffusion-based inverse algorithms with limited steps. Codes for reproducing
our experiments are available at
\href{https://github.com/weigerzan/LLE_inverse_problem}{https://github.com/weigerzan/LLE\_inverse\_problem}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>preprint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Chain-of-Thought Reasoning In The Wild Is Not Always Faithful <span class="chip">ICLR 25</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08679v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08679v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Iván Arcuschin, Jett Janiak, Robert Krzyzanowski, Senthooran Rajamanoharan, Neel Nanda, Arthur Conmy
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Chain-of-Thought (CoT) reasoning has significantly advanced state-of-the-art
AI capabilities. However, recent studies have shown that CoT reasoning is not
always faithful, i.e. CoT reasoning does not always reflect how models arrive
at conclusions. So far, most of these studies have focused on unfaithfulness in
unnatural contexts where an explicit bias has been introduced. In contrast, we
show that unfaithful CoT can occur on realistic prompts with no artificial
bias. Our results reveal non-negligible rates of several forms of unfaithful
reasoning in frontier models: Sonnet 3.7 (16.3%), DeepSeek R1 (5.3%) and
ChatGPT-4o (7.0%) all answer a notable proportion of question pairs
unfaithfully. Specifically, we find that models rationalize their implicit
biases in answers to binary questions ("implicit post-hoc rationalization").
For example, when separately presented with the questions "Is X bigger than Y?"
and "Is Y bigger than X?", models sometimes produce superficially coherent
arguments to justify answering Yes to both questions or No to both questions,
despite such responses being logically contradictory. We also investigate
restoration errors (Dziri et al., 2023), where models make and then silently
correct errors in their reasoning, and unfaithful shortcuts, where models use
clearly illogical reasoning to simplify solving problems in Putnam questions (a
hard benchmark). Our findings raise challenges for AI safety work that relies
on monitoring CoT to detect undesired behavior.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to the Reasoning and Planning for Large Language Models
  Workshop (ICLR 25), 10 main paper pages, 38 appendix pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Correlated Proxies: A New Definition and Improved Mitigation for Reward
  Hacking <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.03185v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.03185v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Cassidy Laidlaw, Shivam Singhal, Anca Dragan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Because it is difficult to precisely specify complex objectives,
reinforcement learning policies are often optimized using proxy reward
functions that only approximate the true goal. However, optimizing proxy
rewards frequently leads to reward hacking: the optimized reward function
ceases to be a good proxy and the resulting policy performs poorly with respect
to the unspecified true reward. Principled solutions to reward hacking have
been impeded by the lack of a good definition for the problem. To address this
gap, we introduce a definition of reward hacking based on the correlation
between proxy and true rewards for states and actions seen by a "reference
policy" that breaks down under optimization. We show that this definition
captures reward hacking behavior across several realistic settings, including
in reinforcement learning from human feedback (RLHF). Using our formulation, we
show theoretically that regularization to the reference policy can effectively
prevent reward hacking. While the current practice in RLHF applies a KL penalty
between action distributions for this purpose, our theory suggests regularizing
the $\chi^2$ divergence between the policies' occupancy measures can be more
effective. We intuitively show the benefits of this type of regularization and
demonstrate that it better mitigates reward hacking in practice across four
realistic settings, including RLHF. Our code is available at
https://github.com/cassidylaidlaw/orpo.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Spotlight at ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DataEnvGym: Data Generation Agents in Teacher Environments with Student
  Feedback <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.06215v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.06215v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zaid Khan, Elias Stengel-Eskin, Jaemin Cho, Mohit Bansal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The process of creating training data to teach models is currently driven by
humans, who manually analyze model weaknesses and plan how to create data that
improves a student model. Approaches using LLMs as annotators reduce human
effort, but still require humans to interpret feedback from evaluations and
control the LLM to produce data the student needs. Automating this
labor-intensive process by creating autonomous data generation agents - or
teachers - is desirable, but requires environments that can simulate the
feedback-driven, iterative, closed loop of data creation. To enable rapid,
scalable testing for such agents and their modules, we introduce DataEnvGym, a
testbed of teacher environments for data generation agents. DataEnvGym frames
data generation as a sequential decision-making task, involving an agent
consisting of a data generation policy (which generates a plan for creating
training data) and a data generation engine (which transforms the plan into
data), inside an environment that provides student feedback. The agent's goal
is to improve student performance. Students are iteratively trained and
evaluated on generated data, and their feedback (in the form of errors or weak
skills) is reported to the agent after each iteration. DataEnvGym includes
multiple teacher environment instantiations across 3 levels of structure in the
state representation and action space. More structured environments are based
on inferred skills and offer more interpretability and curriculum control. We
support 4 domains (math, code, VQA, and tool-use) and test multiple students
and teachers. Example agents in our teaching environments can iteratively
improve students across tasks and settings. Moreover, we show that environments
teach different skill levels and test variants of key modules, pointing to
future work in improving data generation agents, engines, and feedback
mechanisms.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICLR 2025 Spotlight; Project Page: https://DataEnvGym.github.io</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ What is the Alignment Objective of GRPO? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.18548v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.18548v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Milan Vojnovic, Se-Young Yun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this note, we examine the aggregation of preferences achieved by the Group
Policy Optimisation (GRPO) algorithm, a reinforcement learning method used to
train advanced artificial intelligence models such as DeepSeek-R1-Zero and
DeepSeekMath. The GRPO algorithm trains a policy using a reward preference
model, which is computed by sampling a set of outputs for a given context,
observing the corresponding rewards, and applying shift-and-scale normalisation
to these reward values. Additionally, it incorporates a penalty function to
discourage deviations from a reference policy.
  We present a framework that enables us to characterise the stationary
policies of the GRPO algorithm. This analysis reveals that the aggregation of
preferences differs fundamentally from standard logarithmic pooling, which is
implemented by other approaches such as RLHF. The precise form of preference
aggregation arises from the way the reward preference model is defined and from
the penalty function, which we show to essentially correspond to the reverse
Kullback-Leibler (KL) divergence between the aggregation policy and the
reference policy.
  Interestingly, we demonstrate that for groups of size two, the reward
preference model corresponds to pairwise comparison preferences, similar to
those in other alignment methods based on pairwise comparison feedback. We
provide explicit characterisations of the aggregate preference for binary
questions, for groups of size two, and in the limit of large group size. This
provides insights into the dependence of the aggregate preference on parameters
such as the regularisation constant and the confidence margin of question
answers.
  Finally, we discuss the aggregation of preferences obtained by modifying the
GRPO algorithm to use direct KL divergence as the penalty or to use rewards
without scale normalisation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Representation Retrieval Learning for Heterogeneous Data Integration 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09494v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09494v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qi Xu, Annie Qu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the era of big data, large-scale, multi-modal datasets are increasingly
ubiquitous, offering unprecedented opportunities for predictive modeling and
scientific discovery. However, these datasets often exhibit complex
heterogeneity, such as covariate shift, posterior drift, and missing
modalities, that can hinder the accuracy of existing prediction algorithms. To
address these challenges, we propose a novel Representation Retrieval ($R^2$)
framework, which integrates a representation learning module (the representer)
with a sparsity-induced machine learning model (the learner). Moreover, we
introduce the notion of "integrativeness" for representers, characterized by
the effective data sources used in learning representers, and propose a
Selective Integration Penalty (SIP) to explicitly improve the property.
Theoretically, we demonstrate that the $R^2$ framework relaxes the conventional
full-sharing assumption in multi-task learning, allowing for partially shared
structures, and that SIP can improve the convergence rate of the excess risk
bound. Extensive simulation studies validate the empirical performance of our
framework, and applications to two real-world datasets further confirm its
superiority over existing approaches.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Joint Fine-tuning and Conversion of Pretrained Speech and Language
  Models towards Linear Complexity <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.06846v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.06846v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mutian He, Philip N. Garner
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Architectures such as Linformer and Mamba have recently emerged as
competitive linear time replacements for transformers. However, corresponding
large pretrained models are often unavailable, especially in non-text domains.
To remedy this, we present a Cross-Architecture Layerwise Distillation (CALD)
approach that jointly converts a transformer model to a linear time substitute
and fine-tunes it to a target task. We also compare several means to guide the
fine-tuning to optimally retain the desired inference capability from the
original model. The methods differ in their use of the target model and the
trajectory of the parameters. In a series of empirical studies on language
processing, language modeling, and speech processing, we show that CALD can
effectively recover the result of the original model, and that the guiding
strategy contributes to the result. Some reasons for the variation are
suggested.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>18 pages, 5 figures; ICLR 2025 camera ready. Code:
  https://github.com/idiap/linearize-distill-pretrained-transformers</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Latent Space Chain-of-Embedding Enables Output-free LLM Self-Evaluation <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13640v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13640v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yiming Wang, Pei Zhang, Baosong Yang, Derek F. Wong, Rui Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  LLM self-evaluation relies on the LLM's own ability to estimate response
correctness, which can greatly improve its deployment reliability. In this
research track, we propose the Chain-of-Embedding (CoE) in the latent space to
enable LLMs to perform output-free self-evaluation. CoE consists of all
progressive hidden states produced during the inference time, which can be
treated as the latent thinking path of LLMs. We find that when LLMs respond
correctly and incorrectly, their CoE features differ, these discrepancies
assist us in estimating LLM response correctness. Experiments in four diverse
domains and seven LLMs fully demonstrate the effectiveness of our method.
Meanwhile, its label-free design intent without any training and
millisecond-level computational cost ensures real-time feedback in large-scale
scenarios. More importantly, we provide interesting insights into LLM response
correctness from the perspective of hidden state changes inside LLMs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ scMEDAL for the interpretable analysis of single-cell transcriptomics
  data with batch effect visualization using a deep mixed effects autoencoder 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.06635v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.06635v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aixa X. Andrade, Son Nguyen, Albert Montillo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  scRNA-seq data has the potential to provide new insights into cellular
heterogeneity and data acquisition; however, a major challenge is unraveling
confounding from technical and biological batch effects. Existing batch
correction algorithms suppress and discard these effects, rather than
quantifying and modeling them. Here, we present scMEDAL, a framework for
single-cell Mixed Effects Deep Autoencoder Learning, which separately models
batch-invariant and batch-specific effects using two complementary autoencoder
networks. One network is trained through adversarial learning to capture a
batch-invariant representation, while a Bayesian autoencoder learns a
batch-specific representation. Comprehensive evaluations spanning conditions
(e.g., autism, leukemia, and cardiovascular), cell types, and technical and
biological effects demonstrate that scMEDAL suppresses batch effects while
modeling batch-specific variation, enhancing accuracy and interpretability.
Unlike prior approaches, the framework's fixed- and random-effects autoencoders
enable retrospective analyses, including predicting a cell's expression as if
it had been acquired in a different batch via genomap projections at the
cellular level, revealing the impact of biological (e.g., diagnosis) and
technical (e.g., acquisition) effects. By combining scMEDAL's batch-agnostic
and batch-specific latent spaces, it enables more accurate predictions of
disease status, donor group, and cell type, making scMEDAL a valuable framework
for gaining deeper insight into data acquisition and cellular heterogeneity.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Main manuscript: 28 pages, including 8 figures and 1 table.
  Supplemental material: 19 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Confidence-Controlled Exploration: Efficient Sparse-Reward Policy
  Learning for Robot <span class="highlight-title">Navigation</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2306.06192v9">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2306.06192v9.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bhrij Patel, Kasun Weerakoon, Wesley A. Suttle, Alec Koppel, Brian M. Sadler, Tianyi Zhou, Amrit Singh Bedi, Dinesh Manocha
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reinforcement learning (RL) is a promising approach for robotic navigation,
allowing robots to learn through trial and error. However, real-world robotic
tasks often suffer from sparse rewards, leading to inefficient exploration and
suboptimal policies due to sample inefficiency of RL. In this work, we
introduce Confidence-Controlled Exploration (CCE), a novel method that improves
sample efficiency in RL-based robotic navigation without modifying the reward
function. Unlike existing approaches, such as entropy regularization and reward
shaping, which can introduce instability by altering rewards, CCE dynamically
adjusts trajectory length based on policy entropy. Specifically, it shortens
trajectories when uncertainty is high to enhance exploration and extends them
when confidence is high to prioritize exploitation. CCE is a principled and
practical solution inspired by a theoretical connection between policy entropy
and gradient estimation. It integrates seamlessly with on-policy and off-policy
RL methods and requires minimal modifications. We validate CCE across
REINFORCE, PPO, and SAC in both simulated and real-world navigation tasks. CCE
outperforms fixed-trajectory and entropy-regularized baselines, achieving an
18\% higher success rate, 20-38\% shorter paths, and 9.32\% lower elevation
costs under a fixed training sample budget. Finally, we deploy CCE on a
Clearpath Husky robot, demonstrating its effectiveness in complex outdoor
environments.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 6 figures, 2 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Video Super-Resolution: All You Need is a Video Diffusion Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03355v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03355v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhihao Zhan, Wang Pang, Xiang Zhu, Yechao Bai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a generic video super-resolution algorithm in this paper, based on
the Diffusion Posterior Sampling framework with an unconditional video
generation model in latent space. The video generation model, a diffusion
transformer, functions as a space-time model. We argue that a powerful model,
which learns the physics of the real world, can easily handle various kinds of
motion patterns as prior knowledge, thus eliminating the need for explicit
estimation of optical flows or motion parameters for pixel alignment.
Furthermore, a single instance of the proposed video diffusion transformer
model can adapt to different sampling conditions without re-training. Empirical
results on synthetic and real-world datasets demonstrate that our method has
strong capabilities to address video super-resolution challenges.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Fast MRI for All: Bridging Equity Gaps via Training without Raw Data
  Access 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.13022v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.13022v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yaşar Utku Alçalar, Merve Gülle, Mehmet Akçakaya
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Physics-driven deep learning (PD-DL) approaches have become popular for
improved reconstruction of fast magnetic resonance imaging (MRI) scans. Though
PD-DL offers higher acceleration rates than existing clinical fast MRI
techniques, their use has been limited outside specialized MRI centers. A key
challenge is generalization to underrepresented pathologies or populations,
noted in multiple studies, with fine-tuning on target populations suggested for
improvement. However, current approaches for PD-DL training require access to
raw k-space measurements, which is typically only available at specialized MRI
centers that have research agreements for such data access. This is especially
an issue for rural and underserved areas, where commercial MRI scanners only
provide access to a final reconstructed image. To tackle these challenges, we
propose Compressibility-inspired Unsupervised Learning via Parallel Imaging
Fidelity (CUPID) for high-quality PD-DL training using only routine clinical
reconstructed images exported from an MRI scanner. CUPID evaluates output
quality with a compressibility-based approach while ensuring that the output
stays consistent with the clinical parallel imaging reconstruction through
well-designed perturbations. Our results show CUPID achieves similar quality to
established PD-DL training that requires k-space data while outperforming
compressed sensing (CS) and diffusion-based generative methods. We further
demonstrate its effectiveness in a zero-shot training setup for retrospectively
and prospectively sub-sampled acquisitions, attesting to its minimal training
burden. As an approach that radically deviates from existing strategies, CUPID
presents an opportunity to provide equitable access to fast MRI for underserved
populations in an attempt to reduce the inequalities associated with this
expensive imaging modality.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Clifford Algebraic Approach to E(n)-Equivariant High-order Graph
  Neural Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04692v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04692v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Viet-Hoang Tran, Thieu N. Vo, Tho Tran Huu, Tan Minh Nguyen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Designing neural network architectures that can handle data symmetry is
crucial. This is especially important for geometric graphs whose properties are
equivariance under Euclidean transformations. Current equivariant graph neural
networks (EGNNs), particularly those using message passing, have a limitation
in expressive power. Recent high-order graph neural networks can overcome this
limitation, yet they lack equivariance properties, representing a notable
drawback in certain applications in chemistry and physical sciences. In this
paper, we introduce the Clifford Group Equivariant Graph Neural Networks
(CG-EGNNs), a novel EGNN that enhances high-order message passing by
integrating high-order local structures in the context of Clifford algebras. As
a key benefit of using Clifford algebras, CG-EGNN can learn functions that
capture equivariance from positional features. By adopting the high-order
message passing mechanism, CG-EGNN gains richer information from neighbors,
thus improving model performance. Furthermore, we establish the universality
property of the $k$-hop message passing framework, showcasing greater
expressive power of CG-EGNNs with additional $k$-hop message passing mechanism.
We empirically validate that CG-EGNNs outperform previous methods on various
benchmarks including n-body, CMU motion capture, and MD17, highlighting their
effectiveness in geometric deep learning.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Monomial Matrix Group Equivariant Neural Functional Networks <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.11697v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.11697v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Viet-Hoang Tran, Thieu N. Vo, Tho H. Tran, An T. Nguyen, Tan M. Nguyen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Neural functional networks (NFNs) have recently gained significant attention
due to their diverse applications, ranging from predicting network
generalization and network editing to classifying implicit neural
representation. Previous NFN designs often depend on permutation symmetries in
neural networks' weights, which traditionally arise from the unordered
arrangement of neurons in hidden layers. However, these designs do not take
into account the weight scaling symmetries of $\ReLU$ networks, and the weight
sign flipping symmetries of $\sin$ or $\Tanh$ networks. In this paper, we
extend the study of the group action on the network weights from the group of
permutation matrices to the group of monomial matrices by incorporating
scaling/sign-flipping symmetries. Particularly, we encode these
scaling/sign-flipping symmetries by designing our corresponding equivariant and
invariant layers. We name our new family of NFNs the Monomial Matrix Group
Equivariant Neural Functional Networks (Monomial-NFN). Because of the expansion
of the symmetries, Monomial-NFN has much fewer independent trainable parameters
compared to the baseline NFNs in the literature, thus enhancing the model's
efficiency. Moreover, for fully connected and convolutional neural networks, we
theoretically prove that all groups that leave these networks invariant while
acting on their weight spaces are some subgroups of the monomial matrix group.
We provide empirical evidence to demonstrate the advantages of our model over
existing baselines, achieving competitive performance and efficiency.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages in the main text. Published at NeurIPS 2024. The code is
  available at https://github.com/MathematicalAI-NUS/Monomial-NFN</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Class-wise Federated Unlearning: Harnessing Active Forgetting with
  Teacher-Student Memory Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2307.03363v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2307.03363v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuyuan Li, Jiaming Zhang, Yixiu Liu, Chaochao Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Privacy concerns associated with machine learning models have driven research
into machine unlearning, which aims to erase the memory of specific target
training data from already trained models. This issue also arises in federated
learning, creating the need to address the federated unlearning problem.
However, federated unlearning remains a challenging task. On the one hand,
current research primarily focuses on unlearning all data from a client,
overlooking more fine-grained unlearning targets, e.g., class-wise and
sample-wise removal. On the other hand, existing methods suffer from imprecise
estimation of data influence and impose significant computational or storage
burden. To address these issues, we propose a neuro-inspired federated
unlearning framework based on active forgetting, which is independent of model
architectures and suitable for fine-grained unlearning targets. Our framework
distinguishes itself from existing methods by utilizing new memories to
overwrite old ones. These new memories are generated through teacher-student
learning. We further utilize refined elastic weight consolidation to mitigate
catastrophic forgetting of non-target data. Extensive experiments on benchmark
datasets demonstrate the efficiency and effectiveness of our method, achieving
satisfactory unlearning completeness against backdoor attacks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Similarity Equivariant Graph Neural Networks for Homogenization of
  Metamaterials 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.17365v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.17365v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fleur Hendriks, Vlado Menkovski, Martin Doškář, Marc G. D. Geers, Ondřej Rokoš
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Soft, porous mechanical metamaterials exhibit pattern transformations that
may have important applications in soft robotics, sound reduction and
biomedicine. To design these innovative materials, it is important to be able
to simulate them accurately and quickly, in order to tune their mechanical
properties. Since conventional simulations using the finite element method
entail a high computational cost, in this article we aim to develop a machine
learning-based approach that scales favorably to serve as a surrogate model. To
ensure that the model is also able to handle various microstructures, including
those not encountered during training, we include the microstructure as part of
the network input. Therefore, we introduce a graph neural network that predicts
global quantities (energy, stress stiffness) as well as the pattern
transformations that occur (the kinematics). To make our model as accurate and
data-efficient as possible, various symmetries are incorporated into the model.
The starting point is an E(n)-equivariant graph neural network (which respects
translation, rotation and reflection) that has periodic boundary conditions
(i.e., it is in-/equivariant with respect to the choice of RVE), is scale
in-/equivariant, can simulate large deformations, and can predict scalars,
vectors as well as second and fourth order tensors (specifically energy, stress
and stiffness). The incorporation of scale equivariance makes the model
equivariant with respect to the similarities group, of which the Euclidean
group E(n) is a subgroup. We show that this network is more accurate and
data-efficient than graph neural networks with fewer symmetries. To create an
efficient graph representation of the finite element discretization, we use
only the internal geometrical hole boundaries from the finite element mesh to
achieve a better speed-up and scaling with the mesh size.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>60 pages, 22 figures. Published in CMAME (Computer Methods in Applied
  Mechanics and Engineering)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The Federation Strikes Back: A <span class="highlight-title">Survey</span> of Federated Learning Privacy
  Attacks, Defenses, Applications, and Policy Landscape 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.03636v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.03636v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Joshua C. Zhao, Saurabh Bagchi, Salman Avestimehr, Kevin S. Chan, Somali Chaterji, Dimitris Dimitriadis, Jiacheng Li, Ninghui Li, Arash Nourian, Holger R. Roth
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep learning has shown incredible potential across a wide array of tasks,
and accompanied by this growth has been an insatiable appetite for data.
However, a large amount of data needed for enabling deep learning is stored on
personal devices, and recent concerns on privacy have further highlighted
challenges for accessing such data. As a result, federated learning (FL) has
emerged as an important privacy-preserving technology that enables
collaborative training of machine learning models without the need to send the
raw, potentially sensitive, data to a central server. However, the fundamental
premise that sending model updates to a server is privacy-preserving only holds
if the updates cannot be "reverse engineered" to infer information about the
private training data. It has been shown under a wide variety of settings that
this privacy premise does not hold. In this survey paper, we provide a
comprehensive literature review of the different privacy attacks and defense
methods in FL. We identify the current limitations of these attacks and
highlight the settings in which the privacy of ann FL client can be broken. We
further dissect some of the successful industry applications of FL and draw
lessons for future successful adoption. We survey the emerging landscape of
privacy regulation for FL and conclude with future directions for taking FL
toward the cherished goal of generating accurate models while preserving the
privacy of the data from its participants.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ACM Computing Surveys; 35 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Uncertainty-Aware Robust Learning on Noisy Graphs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2306.08210v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2306.08210v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shuyi Chen, Kaize Ding, Shixiang Zhu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Graph neural networks (GNNs) have excelled in various graph learning tasks,
particularly node classification. However, their performance is often hampered
by noisy measurements in real-world graphs, which can corrupt critical patterns
in the data. To address this, we propose a novel uncertainty-aware graph
learning framework inspired by distributionally robust optimization.
Specifically, we use a graph neural network-based encoder to embed the node
features and find the optimal node embeddings by minimizing the worst-case risk
through a minimax formulation. Such an uncertainty-aware learning process leads
to improved node representations and a more robust graph predictive model that
effectively mitigates the impact of uncertainty arising from data noise. Our
experimental results demonstrate superior predictive performance over baselines
across noisy scenarios.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICASSP 2025 camera ready</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Networked Communication for Decentralised Agents in Mean-Field Games 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2306.02766v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2306.02766v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Patrick Benjamin, Alessandro Abate
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce networked communication to the mean-field game framework, in
particular to oracle-free settings where $N$ decentralised agents learn along a
single, non-episodic run of the empirical system. We prove that our
architecture has sample guarantees bounded between those of the centralised-
and independent-learning cases. We provide the order of the difference in these
bounds in terms of network structure and number of communication rounds, and
also contribute a policy-update stability guarantee. We discuss how the sample
guarantees of the three theoretical algorithms do not actually result in
practical convergence. We therefore show that in practical settings where the
theoretical parameters are not observed (leading to poor estimation of the
Q-function), our communication scheme considerably accelerates learning over
the independent case, often performing similarly to a centralised learner while
removing the restrictive assumption of the latter. We contribute further
practical enhancements to all three theoretical algorithms, allowing us to
present their first empirical demonstrations. Our experiments confirm that we
can remove several of the theoretical assumptions of the algorithms, and
display the empirical convergence benefits brought by our new networked
communication. We additionally show that our networked approach has significant
advantages over both alternatives in terms of robustness to update failures and
to changes in population size.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Multilevel Generative Samplers for Investigating Critical Phenomena <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08918v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08918v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ankur Singha, Elia Cellini, Kim A. Nicoli, Karl Jansen, Stefan Kühn, Shinichi Nakajima
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Investigating critical phenomena or phase transitions is of high interest in
physics and chemistry, for which Monte Carlo (MC) simulations, a crucial tool
for numerically analyzing macroscopic properties of given systems, are often
hindered by an emerging divergence of correlation length -- known as scale
invariance at criticality (SIC) in the renormalization group theory. SIC causes
the system to behave the same at any length scale, from which many existing
sampling methods suffer: long-range correlations cause critical slowing down in
Markov chain Monte Carlo (MCMC), and require intractably large receptive fields
for generative samplers. In this paper, we propose a Renormalization-informed
Generative Critical Sampler (RiGCS) -- a novel sampler specialized for
near-critical systems, where SIC is leveraged as an advantage rather than a
nuisance. Specifically, RiGCS builds on MultiLevel Monte Carlo (MLMC) with Heat
Bath (HB) algorithms, which perform ancestral sampling from low-resolution to
high-resolution lattice configurations with site-wise-independent conditional
HB sampling. Although MLMC-HB is highly efficient under exact SIC, it suffers
from a low acceptance rate under slight SIC violation. Notably, SIC violation
always occurs in finite-size systems, and may induce long-range and
higher-order interactions in the renormalized distributions, which are not
considered by independent HB samplers. RiGCS enhances MLMC-HB by replacing a
part of the conditional HB sampler with generative models that capture those
residual interactions and improve the sampling efficiency. Our experiments show
that the effective sample size of RiGCS is a few orders of magnitude higher
than state-of-the-art generative model baselines in sampling configurations for
128x128 two-dimensional Ising systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 4 figures (main text); 13th International Conference on
  Learning Representations (ICLR 2025)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Exploring a Multimodal Fusion-based Deep Learning Network for Detecting
  Facial Palsy 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.16496v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.16496v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Heng Yim Nicole Oo, Min Hun Lee, Jeong Hoon Lim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Algorithmic detection of facial palsy offers the potential to improve current
practices, which usually involve labor-intensive and subjective assessment by
clinicians. In this paper, we present a multimodal fusion-based deep learning
model that utilizes unstructured data (i.e. an image frame with facial line
segments) and structured data (i.e. features of facial expressions) to detect
facial palsy. We then contribute to a study to analyze the effect of different
data modalities and the benefits of a multimodal fusion-based approach using
videos of 21 facial palsy patients. Our experimental results show that among
various data modalities (i.e. unstructured data - RGB images and images of
facial line segments and structured data - coordinates of facial landmarks and
features of facial expressions), the feed-forward neural network using features
of facial expression achieved the highest precision of 76.22 while the
ResNet-based model using images of facial line segments achieved the highest
recall of 83.47. When we leveraged both images of facial line segments and
features of facial expressions, our multimodal fusion-based deep learning model
slightly improved the precision score to 77.05 at the expense of a decrease in
the recall score.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>IJCAI 2024 4th AI for Ageless Aging Workshop (AIAA)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Unlocking Historical Clinical Trial Data with ALIGN: A Compositional
  Large Language Model System for Medical Coding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.13163v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.13163v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nabeel Seedat, Caterina Tozzi, Andrea Hita Ardiaca, Mihaela van der Schaar, James Weatherall, Adam Taylor
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The reuse of historical clinical trial data has significant potential to
accelerate medical research and drug development. However, interoperability
challenges, particularly with missing medical codes, hinders effective data
integration across studies. While Large Language Models (LLMs) offer a
promising solution for automated coding without labeled data, current
approaches face challenges on complex coding tasks. We introduce ALIGN, a novel
compositional LLM-based system for automated, zero-shot medical coding. ALIGN
follows a three-step process: (1) diverse candidate code generation; (2)
self-evaluation of codes and (3) confidence scoring and uncertainty estimation
enabling human deferral to ensure reliability. We evaluate ALIGN on harmonizing
medication terms into Anatomical Therapeutic Chemical (ATC) and medical history
terms into Medical Dictionary for Regulatory Activities (MedDRA) codes
extracted from 22 immunology trials. ALIGN outperformed the LLM baselines,
while also providing capabilities for trustworthy deployment. For MedDRA
coding, ALIGN achieved high accuracy across all levels, matching RAG and
excelling at the most specific levels (87-90% for HLGT). For ATC coding, ALIGN
demonstrated superior performance, particularly at lower hierarchy levels (ATC
Level 4), with 72-73% overall accuracy and 86-89% accuracy for common
medications, outperforming baselines by 7-22%. ALIGN's uncertainty-based
deferral improved accuracy by 17% to 90% accuracy with 30% deferral, notably
enhancing performance on uncommon medications. ALIGN achieves this
cost-efficiently at \$0.0007 and \$0.02 per code for GPT-4o-mini and GPT-4o,
reducing barriers to clinical adoption. ALIGN advances automated medical coding
for clinical trial data, contributing to enhanced data interoperability and
reusability, positioning it as a promising tool to improve clinical research
and accelerate drug development.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Networked Communication for Mean-Field Games with Function Approximation
  and Empirical Mean-Field Estimation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.11607v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.11607v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Patrick Benjamin, Alessandro Abate
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent algorithms allow decentralised agents, possibly connected via a
communication network, to learn equilibria in Mean-Field Games from a
non-episodic run of the empirical system. However, these algorithms are for
tabular settings: this computationally limits the size of agents' observation
space, meaning the algorithms cannot handle anything but small state spaces,
nor generalise beyond policies depending only on the agent's local state to
so-called 'population-dependent' policies. We address this limitation by
introducing function approximation to the existing setting, drawing on the
Munchausen Online Mirror Descent method that has previously been employed only
in finite-horizon, episodic, centralised settings. While this permits us to
include the mean field in the observation for players' policies, it is
unrealistic to assume decentralised agents have access to this global
information: we therefore also provide new algorithms allowing agents to
locally estimate the global empirical distribution, and to improve this
estimate via inter-agent communication. We show theoretically that exchanging
policy information helps networked agents outperform both independent and even
centralised agents in function-approximation settings. Our experiments
demonstrate this happening empirically, by an even greater margin than in
tabular settings, and show that the communication network allows decentralised
agents to estimate the mean field for population-dependent policies.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Adaptive Split Learning over Energy-Constrained Wireless Edge Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.05158v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.05158v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zuguang Li, Wen Wu, Shaohua Wu, Wei Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Split learning (SL) is a promising approach for training artificial
intelligence (AI) models, in which devices collaborate with a server to train
an AI model in a distributed manner, based on a same fixed split point.
However, due to the device heterogeneity and variation of channel conditions,
this way is not optimal in training delay and energy consumption. In this
paper, we design an adaptive split learning (ASL) scheme which can dynamically
select split points for devices and allocate computing resource for the server
in wireless edge networks. We formulate an optimization problem to minimize the
average training latency subject to long-term energy consumption constraint.
The difficulties in solving this problem are the lack of future information and
mixed integer programming (MIP). To solve it, we propose an online algorithm
leveraging the Lyapunov theory, named OPEN, which decomposes it into a new MIP
problem only with the current information. Then, a two-layer optimization
method is proposed to solve the MIP problem. Extensive simulation results
demonstrate that the ASL scheme can reduce the average training delay and
energy consumption by 53.7% and 22.1%, respectively, as compared to the
existing SL schemes.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 5 figures, 20 conferences</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Respecting the limit:Bayesian <span class="highlight-title">optimization</span> with a bound on the optimal
  value 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.04744v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.04744v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hanyang Wang, Juergen Branke, Matthias Poloczek
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In many real-world optimization problems, we have prior information about
what objective function values are achievable. In this paper, we study the
scenario that we have either exact knowledge of the minimum value or a,
possibly inexact, lower bound on its value. We propose bound-aware Bayesian
optimization (BABO), a Bayesian optimization method that uses a new surrogate
model and acquisition function to utilize such prior information. We present
SlogGP, a new surrogate model that incorporates bound information and adapts
the Expected Improvement (EI) acquisition function accordingly. Empirical
results on a variety of benchmarks demonstrate the benefit of taking prior
information about the optimal value into account, and that the proposed
approach significantly outperforms existing techniques. Furthermore, we notice
that even in the absence of prior information on the bound, the proposed SlogGP
surrogate model still performs better than the standard GP model in most cases,
which we explain by its larger expressiveness.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Neuroplastic Expansion in Deep Reinforcement Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.07994v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.07994v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiashun Liu, Johan Obando-Ceron, Aaron Courville, Ling Pan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The loss of plasticity in learning agents, analogous to the solidification of
neural pathways in biological brains, significantly impedes learning and
adaptation in reinforcement learning due to its non-stationary nature. To
address this fundamental challenge, we propose a novel approach, {\it
Neuroplastic Expansion} (NE), inspired by cortical expansion in cognitive
science. NE maintains learnability and adaptability throughout the entire
training process by dynamically growing the network from a smaller initial size
to its full dimension. Our method is designed with three key components:
(\textit{1}) elastic topology generation based on potential gradients,
(\textit{2}) dormant neuron pruning to optimize network expressivity, and
(\textit{3}) neuron consolidation via experience review to strike a balance in
the plasticity-stability dilemma. Extensive experiments demonstrate that NE
effectively mitigates plasticity loss and outperforms state-of-the-art methods
across various tasks in MuJoCo and DeepMind Control Suite environments. NE
enables more adaptive learning in complex, dynamic environments, which
represents a crucial step towards transitioning deep reinforcement learning
from static, one-time training paradigms to more flexible, continually adapting
models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Dark Deceptions in DHCP: Dismantling Network Defenses 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.10646v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.10646v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Robert Dilworth
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper explores vulnerabilities in the Dynamic Host Configuration
Protocol (DHCP) and their implications on the Confidentiality, Integrity, and
Availability (CIA) Triad. Through an analysis of various attacks, including
DHCP Starvation, Rogue DHCP Servers, Replay Attacks, and TunnelVision exploits,
the paper provides a taxonomic classification of threats, assesses risks, and
proposes appropriate controls. The discussion also highlights the dangers of
VPN decloaking through DHCP exploits and underscores the importance of
safeguarding network infrastructures. By bringing awareness to the TunnelVision
exploit, this paper aims to mitigate risks associated with these prevalent
vulnerabilities.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 4 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Diabetica: Adapting Large Language Model to Enhance Multiple Medical
  Tasks in Diabetes Care and Management <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.13191v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.13191v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lai Wei, Zhen Ying, Muyang He, Yutong Chen, Qian Yang, Yanzhe Hong, Jiaping Lu, Kaipeng Zheng, Shaoting Zhang, Xiaoying Li, Weiran Huang, Ying Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diabetes is a chronic disease with a significant global health burden,
requiring multi-stakeholder collaboration for optimal management. Large
language models (LLMs) have shown promise in various healthcare scenarios, but
their effectiveness across diverse diabetes tasks remains unproven. Our study
introduced a framework to train and validate diabetes-specific LLMs. We first
developed a comprehensive data processing pipeline that includes data
collection, filtering, augmentation and refinement. This created a
high-quality, diabetes-specific dataset and evaluation benchmarks from scratch.
Fine-tuned on the collected training dataset, our diabetes-specific LLM family
demonstrated state-of-the-art proficiency in processing various diabetes tasks
compared to other LLMs. Furthermore, clinical studies revealed the potential
applications of our models in diabetes care, including providing personalized
healthcare, assisting medical education, and streamlining clinical tasks.
Generally, our introduced framework helps develop diabetes-specific LLMs and
highlights their potential to enhance clinical practice and provide
personalized, data-driven support for diabetes management across different end
users. Our codes, benchmarks and models are available at
https://github.com/waltonfuture/Diabetica.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ICLR 2025 SCI-FM workshop</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Towards Class-wise Robustness Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.19853v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.19853v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tejaswini Medi, Julia Grabinski, Margret Keuper
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While being very successful in solving many downstream tasks, the application
of deep neural networks is limited in real-life scenarios because of their
susceptibility to domain shifts such as common corruptions, and adversarial
attacks. The existence of adversarial examples and data corruption
significantly reduces the performance of deep classification models.
Researchers have made strides in developing robust neural architectures to
bolster decisions of deep classifiers. However, most of these works rely on
effective adversarial training methods, and predominantly focus on overall
model robustness, disregarding class-wise differences in robustness, which are
critical. Exploiting weakly robust classes is a potential avenue for attackers
to fool the image recognition models. Therefore, this study investigates
class-to-class biases across adversarially trained robust classification models
to understand their latent space structures and analyze their strong and weak
class-wise properties. We further assess the robustness of classes against
common corruptions and adversarial attacks, recognizing that class
vulnerability extends beyond the number of correct classifications for a
specific class. We find that the number of false positives of classes as
specific target classes significantly impacts their vulnerability to attacks.
Through our analysis on the Class False Positive Score, we assess a fair
evaluation of how susceptible each class is to misclassification.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Deep Reinforcement Learning for Dynamic Resource Allocation in Wireless
  Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.01129v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.01129v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shubham Malhotra, Fnu Yashu, Muhammad Saqib, Dipkumar Mehta, Jagdish Jangid, Sachin Dixit
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This report investigates the application of deep reinforcement learning (DRL)
algorithms for dynamic resource allocation in wireless communication systems.
An environment that includes a base station, multiple antennas, and user
equipment is created. Using the RLlib library, various DRL algorithms such as
Deep Q-Network (DQN) and Proximal Policy Optimization (PPO) are then applied.
These algorithms are compared based on their ability to optimize resource
allocation, focusing on the impact of different learning rates and scheduling
policies. The findings demonstrate that the choice of algorithm and learning
rate significantly influences system performance, with DRL providing more
efficient resource allocation compared to traditional methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Upon further review, we found inconsistencies in our analysis and
  decided to conduct additional research before resubmitting a revised version</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Automated Knowledge Concept Annotation and Question Representation
  Learning for Knowledge Tracing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01727v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01727v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yilmazcan Ozyurt, Stefan Feuerriegel, Mrinmaya Sachan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Knowledge tracing (KT) is a popular approach for modeling students' learning
progress over time, which can enable more personalized and adaptive learning.
However, existing KT approaches face two major limitations: (1) they rely
heavily on expert-defined knowledge concepts (KCs) in questions, which is
time-consuming and prone to errors; and (2) KT methods tend to overlook the
semantics of both questions and the given KCs. In this work, we address these
challenges and present KCQRL, a framework for automated knowledge concept
annotation and question representation learning that can improve the
effectiveness of any existing KT model. First, we propose an automated KC
annotation process using large language models (LLMs), which generates question
solutions and then annotates KCs in each solution step of the questions.
Second, we introduce a contrastive learning approach to generate semantically
rich embeddings for questions and solution steps, aligning them with their
associated KCs via a tailored false negative elimination approach. These
embeddings can be readily integrated into existing KT models, replacing their
randomly initialized embeddings. We demonstrate the effectiveness of KCQRL
across 15 KT algorithms on two large real-world Math learning datasets, where
we achieve consistent performance improvements.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Low-Rank Continual Personalization of Diffusion Models <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04891v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04891v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Łukasz Staniszewski, Katarzyna Zaleska, Kamil Deja
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent personalization methods for diffusion models, such as Dreambooth and
LoRA, allow fine-tuning pre-trained models to generate new concepts. However,
applying these techniques across consecutive tasks in order to include, e.g.,
new objects or styles, leads to a forgetting of previous knowledge due to
mutual interference between their adapters. In this work, we tackle the problem
of continual customization under a rigorous regime with no access to past
tasks' adapters. In such a scenario, we investigate how different adapters'
initialization and merging methods can improve the quality of the final model.
To that end, we evaluate the naive continual fine-tuning of customized models
and compare this approach with three methods for consecutive adapters'
training: sequentially merging new adapters, merging orthogonally initialized
adapters, and updating only relevant task-specific weights. In our experiments,
we show that the proposed techniques mitigate forgetting when compared to the
naive approach. In our studies, we show different traits of selected techniques
and their effect on the plasticity and stability of the continually adapted
model. Repository with the code is available at
https://github.com/luk-st/continual-lora.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>SCOPE @ ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Triple-Inertial Accelerated Alternating <span class="highlight-title">Optimization</span> Method for Deep
  Learning Training 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08489v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08489v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chengcheng Yan, Jiawei Xu, Qingsong Wang, Zheng Peng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The stochastic gradient descent (SGD) algorithm has achieved remarkable
success in training deep learning models. However, it has several limitations,
including susceptibility to vanishing gradients, sensitivity to input data, and
a lack of robust theoretical guarantees. In recent years, alternating
minimization (AM) methods have emerged as a promising alternative for model
training by employing gradient-free approaches to iteratively update model
parameters. Despite their potential, these methods often exhibit slow
convergence rates. To address this challenge, we propose a novel
Triple-Inertial Accelerated Alternating Minimization (TIAM) framework for
neural network training. The TIAM approach incorporates a triple-inertial
acceleration strategy with a specialized approximation method, facilitating
targeted acceleration of different terms in each sub-problem optimization. This
integration improves the efficiency of convergence, achieving superior
performance with fewer iterations. Additionally, we provide a convergence
analysis of the TIAM algorithm, including its global convergence properties and
convergence rate. Extensive experiments validate the effectiveness of the TIAM
method, showing significant improvements in generalization capability and
computational efficiency compared to existing approaches, particularly when
applied to the rectified linear unit (ReLU) and its variants.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ AI-Aided Kalman Filters 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12289v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12289v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nir Shlezinger, Guy Revach, Anubhab Ghosh, Saikat Chatterjee, Shuo Tang, Tales Imbiriba, Jindrich Dunik, Ondrej Straka, Pau Closas, Yonina C. Eldar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The Kalman filter (KF) and its variants are among the most celebrated
algorithms in signal processing. These methods are used for state estimation of
dynamic systems by relying on mathematical representations in the form of
simple state-space (SS) models, which may be crude and inaccurate descriptions
of the underlying dynamics. Emerging data-centric artificial intelligence (AI)
techniques tackle these tasks using deep neural networks (DNNs), which are
model-agnostic. Recent developments illustrate the possibility of fusing DNNs
with classic Kalman-type filtering, obtaining systems that learn to track in
partially known dynamics. This article provides a tutorial-style overview of
design approaches for incorporating AI in aiding KF-type algorithms. We review
both generic and dedicated DNN architectures suitable for state estimation, and
provide a systematic presentation of techniques for fusing AI tools with KFs
and for leveraging partial SS modeling and data, categorizing design approaches
into task-oriented and SS model-oriented. The usefulness of each approach in
preserving the individual strengths of model-based KFs and data-driven DNNs is
investigated in a qualitative and quantitative study, whose code is publicly
available, illustrating the gains of hybrid model-based/data-driven designs. We
also discuss existing challenges and future research directions that arise from
fusing AI and Kalman-type algorithms.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to the IEEE Signal Processing Magazine</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Tackling water table depth modeling via machine learning: From proxy
  observations to verifiability 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.04579v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.04579v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Joseph Janssen, Ardalan Tootchi, Ali A. Ameli
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Spatial patterns of water table depth (WTD) play a crucial role in shaping
ecological resilience, hydrological connectivity, and human-centric systems.
Generally, a large-scale (e.g., continental or global) continuous map of static
WTD can be simulated using either physically-based (PB) or machine
learning-based (ML) models. We construct three fine-resolution (500 m) ML
simulations of WTD, using the XGBoost algorithm and more than 20 million real
and proxy observations of WTD, across the United States and Canada. The three
ML models were constrained using known physical relations between WTD's drivers
and WTD and were trained by sequentially adding real and proxy observations of
WTD. Through an extensive (pixel-by-pixel) evaluation across the study region
and within ten major ecoregions of North America, we demonstrate that our
models (corr=0.6-0.75) can more accurately predict unseen real and proxy
observations of WTD compared to two available PB simulations of WTD
(corr=0.21-0.40). However, we still argue that currently-available large-scale
simulations of static WTD could be uncertain within data-scarce regions such as
steep mountainous regions. We reason that biased observational data mainly
collected from low-elevation floodplains and the over-flexibility of available
models can negatively affect the verifiability of large-scale simulations of
WTD. Ultimately, we thoroughly discuss future directions that may help
hydrogeologists decide how to improve machine learning-based WTD estimations.
In particular, we advocate for the use of proxy satellite data, the
incorporation of physical laws, the implementation of better model verification
standards, the development of novel globally-available emergent indices, and
the collection of more reliable observations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ RedChronos: A Large Language Model-Based Log Analysis System for Insider
  Threat Detection in Enterprises 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.02702v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.02702v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chenyu Li, Zhengjia Zhu, Jiyan He, Xiu Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Internal threat detection (IDT) aims to address security threats within
organizations or enterprises by identifying potential or already occurring
malicious threats within vast amounts of logs. Although organizations or
enterprises have dedicated personnel responsible for reviewing these logs, it
is impossible to manually examine all logs entirely.In response to the vast
number of logs, we propose a system called RedChronos, which is a Large
Language Model-Based Log Analysis System. This system incorporates innovative
improvements over previous research by employing Query-Aware Weighted Voting
and a Semantic Expansion-based Genetic Algorithm with LLM-driven Mutations. On
the public datasets CERT 4.2 and 5.2, RedChronos outperforms or matches
existing approaches in terms of accuracy, precision, and detection rate.
Moreover, RedChronos reduces the need for manual intervention in security log
reviews by approximately 90% in the Xiaohongshu Security Operation Center.
Therefore, our RedChronos system demonstrates exceptional performance in
handling IDT tasks, providing innovative solutions for these challenges. We
believe that future research can continue to enhance the system's performance
in IDT tasks while also reducing the response time to internal risk events.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Histogram Approaches for Imbalanced Data Streams Regression 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.17568v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.17568v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ehsan Aminian, Rita P. Ribeiro, Joao Gama
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Imbalanced domains pose a significant challenge in real-world predictive
analytics, particularly in the context of regression. While existing research
has primarily focused on batch learning from static datasets, limited attention
has been given to imbalanced regression in online learning scenarios. Intending
to address this gap, in prior work, we proposed sampling strategies based on
Chebyshevs inequality as the first methodologies designed explicitly for data
streams. However, these approaches operated under the restrictive assumption
that rare instances exclusively reside at distribution extremes. This study
introduces histogram-based sampling strategies to overcome this constraint,
proposing flexible solutions for imbalanced regression in evolving data
streams. The proposed techniques -- Histogram-based Undersampling (HistUS) and
Histogram-based Oversampling (HistOS) -- employ incremental online histograms
to dynamically detect and prioritize rare instances across arbitrary regions of
the target distribution to improve predictions in the rare cases. Comprehensive
experiments on synthetic and real-world benchmarks demonstrate that HistUS and
HistOS substantially improve rare-case prediction accuracy, outperforming
baseline models while maintaining competitiveness with Chebyshev-based
approaches.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Credal Two-Sample Tests of Epistemic Uncertainty 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12921v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12921v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Siu Lun Chau, Antonin Schrab, Arthur Gretton, Dino Sejdinovic, Krikamol Muandet
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce credal two-sample testing, a new hypothesis testing framework
for comparing credal sets -- convex sets of probability measures where each
element captures aleatoric uncertainty and the set itself represents epistemic
uncertainty that arises from the modeller's partial ignorance. Compared to
classical two-sample tests, which focus on comparing precise distributions, the
proposed framework provides a broader and more versatile set of hypotheses.
This approach enables the direct integration of epistemic uncertainty,
effectively addressing the challenges arising from partial ignorance in
hypothesis testing. By generalising two-sample test to compare credal sets, our
framework enables reasoning for equality, inclusion, intersection, and mutual
exclusivity, each offering unique insights into the modeller's epistemic
beliefs. As the first work on nonparametric hypothesis testing for comparing
credal sets, we focus on finitely generated credal sets derived from i.i.d.
samples from multiple distributions -- referred to as credal samples. We
formalise these tests as two-sample tests with nuisance parameters and
introduce the first permutation-based solution for this class of problems,
significantly improving existing methods. Our approach properly incorporates
the modeller's epistemic uncertainty into hypothesis testing, leading to more
robust and credible conclusions, with kernel-based implementations for
real-world applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>64 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Column-wise Quantization of Weights and Partial Sums for Accurate and
  Efficient Compute-In-Memory Accelerators 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.07842v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.07842v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiyoon Kim, Kang Eun Jeon, Yulhwa Kim, Jong Hwan Ko
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Compute-in-memory (CIM) is an efficient method for implementing deep neural
networks (DNNs) but suffers from substantial overhead from analog-to-digital
converters (ADCs), especially as ADC precision increases. Low-precision ADCs
can reduce this overhead but introduce partial-sum quantization errors
degrading accuracy. Additionally, low-bit weight constraints, imposed by cell
limitations and the need for multiple cells for higher-bit weights, present
further challenges. While fine-grained partial-sum quantization has been
studied to lower ADC resolution effectively, weight granularity, which limits
overall partial-sum quantized accuracy, remains underexplored. This work
addresses these challenges by aligning weight and partial-sum quantization
granularities at the column-wise level. Our method improves accuracy while
maintaining dequantization overhead, simplifies training by removing two-stage
processes, and ensures robustness to memory cell variations via independent
column-wise scale factors. We also propose an open-source CIM-oriented
convolution framework to handle fine-grained weights and partial-sums
efficiently, incorporating a novel tiling method and group convolution.
Experimental results on ResNet-20 (CIFAR-10, CIFAR-100) and ResNet-18
(ImageNet) show accuracy improvements of 0.99%, 2.69%, and 1.01%, respectively,
compared to the best-performing related works. Additionally, variation analysis
reveals the robustness of our method against memory cell variations. These
findings highlight the effectiveness of our quantization scheme in enhancing
accuracy and robustness while maintaining hardware efficiency in CIM-based DNN
implementations. Our code is available at
https://github.com/jiyoonkm/ColumnQuant.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Bayesian Experimental Design via Contrastive Diffusions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11826v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11826v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jacopo Iollo, Christophe Heinkelé, Pierre Alliez, Florence Forbes
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Bayesian Optimal Experimental Design (BOED) is a powerful tool to reduce the
cost of running a sequence of experiments. When based on the Expected
Information Gain (EIG), design optimization corresponds to the maximization of
some intractable expected contrast between prior and posterior distributions.
Scaling this maximization to high dimensional and complex settings has been an
issue due to BOED inherent computational complexity. In this work, we introduce
a pooled posterior distribution with cost-effective sampling properties and
provide a tractable access to the EIG contrast maximization via a new EIG
gradient expression. Diffusion-based samplers are used to compute the dynamics
of the pooled posterior and ideas from bi-level optimization are leveraged to
derive an efficient joint sampling-optimization loop. The resulting efficiency
gain allows to extend BOED to the well-tested generative capabilities of
diffusion models. By incorporating generative models into the BOED framework,
we expand its scope and its use in scenarios that were previously impractical.
Numerical experiments and comparison with state-of-the-art methods show the
potential of the approach.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FlashRNN: I/O-Aware <span class="highlight-title">Optimization</span> of Traditional RNNs on modern hardware 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.07752v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.07752v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Korbinian Pöppel, Maximilian Beck, Sepp Hochreiter
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While Transformers and other sequence-parallelizable neural network
architectures seem like the current state of the art in sequence modeling, they
specifically lack state-tracking capabilities. These are important for
time-series tasks and logical reasoning. Traditional RNNs like LSTMs and GRUs,
as well as modern variants like sLSTM do have these capabilities at the cost of
strictly sequential processing. While this is often seen as a strong
limitation, we show how fast these networks can get with our
hardware-optimization FlashRNN in Triton and CUDA, optimizing kernels to the
register level on modern GPUs. We extend traditional RNNs with a
parallelization variant that processes multiple RNNs of smaller hidden state in
parallel, similar to the head-wise processing in Transformers. To enable
flexibility on different GPU variants, we introduce a new optimization
framework for hardware-internal cache sizes, memory and compute handling. It
models the hardware in a setting using polyhedral-like constraints, including
the notion of divisibility. This speeds up the solution process in our
ConstrINT library for general integer constraint satisfaction problems (integer
CSPs). We show that our kernels can achieve 50x speed-ups over a vanilla
PyTorch implementation and allow 40x larger hidden sizes compared to our Triton
implementation. Our open-source kernels and the optimization library are
released here to boost research in the direction of state-tracking enabled RNNs
and sequence modeling: https://github.com/NX-AI/flashrnn
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Hidden in the Noise: Two-Stage Robust Watermarking for Images 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.04653v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.04653v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kasra Arabi, Benjamin Feuer, R. Teal Witter, Chinmay Hegde, Niv Cohen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As the quality of image generators continues to improve, deepfakes become a
topic of considerable societal debate. Image watermarking allows responsible
model owners to detect and label their AI-generated content, which can mitigate
the harm. Yet, current state-of-the-art methods in image watermarking remain
vulnerable to forgery and removal attacks. This vulnerability occurs in part
because watermarks distort the distribution of generated images,
unintentionally revealing information about the watermarking techniques.
  In this work, we first demonstrate a distortion-free watermarking method for
images, based on a diffusion model's initial noise. However, detecting the
watermark requires comparing the initial noise reconstructed for an image to
all previously used initial noises. To mitigate these issues, we propose a
two-stage watermarking framework for efficient detection. During generation, we
augment the initial noise with generated Fourier patterns to embed information
about the group of initial noises we used. For detection, we (i) retrieve the
relevant group of noises, and (ii) search within the given group for an initial
noise that might match our image. This watermarking approach achieves
state-of-the-art robustness to forgery and removal against a large battery of
attacks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Clipping Improves Adam-Norm and AdaGrad-Norm when the Noise Is
  Heavy-Tailed 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.04443v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.04443v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Savelii Chezhegov, Yaroslav Klyukin, Andrei Semenov, Aleksandr Beznosikov, Alexander Gasnikov, Samuel Horváth, Martin Takáč, Eduard Gorbunov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Methods with adaptive stepsizes, such as AdaGrad and Adam, are essential for
training modern Deep Learning models, especially Large Language Models.
Typically, the noise in the stochastic gradients is heavy-tailed for the later
ones. Gradient clipping provably helps to achieve good high-probability
convergence for such noises. However, despite the similarity between
AdaGrad/Adam and Clip-SGD, the current understanding of the high-probability
convergence of AdaGrad/Adam-type methods is limited in this case. In this work,
we prove that AdaGrad/Adam (and their delayed version) can have provably bad
high-probability convergence if the noise is heavy-tailed. We also show that
gradient clipping fixes this issue, i.e., we derive new high-probability
convergence bounds with polylogarithmic dependence on the confidence level for
AdaGrad-Norm and Adam-Norm with clipping and with/without delay for smooth
convex/non-convex stochastic optimization with heavy-tailed noise. Our
empirical evaluations highlight the superiority of clipped versions of
AdaGrad/Adam-Norm in handling the heavy-tailed noise.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>63 pages, 8 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Real-Time Recurrent Reinforcement Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.04830v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.04830v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Julian Lemmel, Radu Grosu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce a biologically plausible RL framework for solving tasks in
partially observable Markov decision processes (POMDPs). The proposed algorithm
combines three integral parts: (1) A Meta-RL architecture, resembling the
mammalian basal ganglia; (2) A biologically plausible reinforcement learning
algorithm, exploiting temporal difference learning and eligibility traces to
train the policy and the value-function; (3) An online automatic
differentiation algorithm for computing the gradients with respect to
parameters of a shared recurrent network backbone. Our experimental results
show that the method is capable of solving a diverse set of partially
observable reinforcement learning tasks. The algorithm we call real-time
recurrent reinforcement learning (RTRRL) serves as a model of learning in
biological neural networks, mimicking reward pathways in the basal ganglia.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages, 9 figures, includes Appendix</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Materials Map Integrating Experimental and Computational Data through
  Graph-Based Machine Learning for Enhanced Materials Discovery 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07378v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07378v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yusuke Hashimoto, Xue Jia, Hao Li, Takaaki Tomai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Materials informatics (MI), which emerges from the integration of materials
science and data science, is expected to greatly streamline the material
discovery and development. The data used for MI are obtained from both
computational and experimental studies, while their integration remains
challenging. In our previous study, we reported the integration of these
datasets by applying a machine learning model that captures trends hidden in
the experimental datasets to compositional data stored in the computational
database. In this study, we use the obtained data to construct materials maps,
which visualize the relation in the structural features of materials, aiming to
support study by the experimental researchers. The map is constructed using the
MatDeepLearn (MDL) framework, which implements the graph-based representation
of material structures, deep learning, and dimensional reduction for the map
construction. We evaluate the obtained materials maps through statistical
analysis and found that the MDL using message passing neural network (MPNN)
enables efficient extraction of features that reflect the structural complexity
of materials. Moreover, we found that this advantage does not necessarily
translate into improved accuracy in predicting material properties. We
attribute this unexpected outcome to the high learning performance inherent in
MPNN, which can contribute to the structuring of data points within the
materials map.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Feasible Policy Iteration for Safe Reinforcement Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2304.08845v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2304.08845v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yujie Yang, Zhilong Zheng, Shengbo Eben Li, Wei Xu, Jingjing Liu, Xianyuan Zhan, Ya-Qin Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Safety is the priority concern when applying reinforcement learning (RL)
algorithms to real-world control problems. While policy iteration provides a
fundamental algorithm for standard RL, an analogous theoretical algorithm for
safe RL remains absent. In this paper, we propose feasible policy iteration
(FPI), the first foundational dynamic programming algorithm for safe RL. FPI
alternates between policy evaluation, region identification and policy
improvement. This follows actor-critic-scenery (ACS) framework where scenery
refers to a feasibility function that represents a feasible region. A
region-wise update rule is developed for the policy improvement step, which
maximizes state-value function inside the feasible region and minimizes
feasibility function outside it. With this update rule, FPI guarantees
monotonic expansion of feasible region, monotonic improvement of state-value
function, and geometric convergence to the optimal safe policy. Experimental
results demonstrate that FPI achieves strictly zero constraint violation on
low-dimensional tasks and outperforms existing methods in constraint adherence
and reward performance on high-dimensional tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The R2D2 Deep Neural Network Series for Scalable Non-Cartesian Magnetic
  Resonance Imaging 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09559v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09559v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yiwei Chen, Amir Aghabiglou, Shijie Chen, Motahare Torki, Chao Tang, Ruud B. van Heeswijk, Yves Wiaux
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce the R2D2 Deep Neural Network (DNN) series paradigm for fast and
scalable image reconstruction from highly-accelerated non-Cartesian k-space
acquisitions in Magnetic Resonance Imaging (MRI). While unrolled DNN
architectures provide a robust image formation approach via data-consistency
layers, embedding non-uniform fast Fourier transform operators in a DNN can
become impractical to train at large scale, e.g in 2D MRI with a large number
of coils, or for higher-dimensional imaging. Plug-and-play approaches that
alternate a learned denoiser blind to the measurement setting with a
data-consistency step are not affected by this limitation but their highly
iterative nature implies slow reconstruction. To address this scalability
challenge, we leverage the R2D2 paradigm that was recently introduced to enable
ultra-fast reconstruction for large-scale Fourier imaging in radio astronomy.
R2D2's reconstruction is formed as a series of residual images iteratively
estimated as outputs of DNN modules taking the previous iteration's data
residual as input. The method can be interpreted as a learned version of the
Matching Pursuit algorithm. A series of R2D2 DNN modules were sequentially
trained in a supervised manner on the fastMRI dataset and validated for 2D
multi-coil MRI in simulation and on real data, targeting highly under-sampled
radial k-space sampling. Results suggest that a series with only few DNNs
achieves superior reconstruction quality over its unrolled incarnation R2D2-Net
(whose training is also much less scalable), and over the state-of-the-art
diffusion-based "Decomposed Diffusion Sampler" approach (also characterised by
a slower reconstruction process).
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages, 10 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MarS: a Financial Market Simulation Engine Powered by Generative
  Foundation Model <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.07486v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.07486v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junjie Li, Yang Liu, Weiqing Liu, Shikai Fang, Lewen Wang, Chang Xu, Jiang Bian
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generative models aim to simulate realistic effects of various actions across
different contexts, from text generation to visual effects. Despite significant
efforts to build real-world simulators, the application of generative models to
virtual worlds, like financial markets, remains under-explored. In financial
markets, generative models can simulate complex market effects of participants
with various behaviors, enabling interaction under different market conditions,
and training strategies without financial risk. This simulation relies on the
finest structured data in financial market like orders thus building the finest
realistic simulation. We propose Large Market Model (LMM), an order-level
generative foundation model, for financial market simulation, akin to language
modeling in the digital world. Our financial Market Simulation engine (MarS),
powered by LMM, addresses the domain-specific need for realistic, interactive
and controllable order generation. Key observations include LMM's strong
scalability across data size and model complexity, and MarS's robust and
practicable realism in controlled generation with market impact. We showcase
MarS as a forecast tool, detection system, analysis platform, and agent
training environment, thus demonstrating MarS's "paradigm shift" potential for
a variety of financial applications. We release the code of MarS at
https://github.com/microsoft/MarS/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>35 pages, 26 figures, ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Score matching for bridges without learning time-reversals 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.15455v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.15455v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Elizabeth L. Baker, Moritz Schauer, Stefan Sommer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose a new algorithm for learning bridged diffusion processes using
score-matching methods. Our method relies on reversing the dynamics of the
forward process and using this to learn a score function, which, via Doob's
$h$-transform, yields a bridged diffusion process; that is, a process
conditioned on an endpoint. In contrast to prior methods, we learn the score
term $\nabla_x \log p(t, x; T, y)$ directly, for given $t, y$, completely
avoiding first learning a time-reversal. We compare the performance of our
algorithm with existing methods and see that it outperforms using the (learned)
time-reversals to learn the score term. The code can be found at
https://github.com/libbylbaker/forward_bridge.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Causal Representation Learning from Multimodal Biomedical Observations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.06518v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.06518v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuewen Sun, Lingjing Kong, Guangyi Chen, Loka Li, Gongxu Luo, Zijian Li, Yixuan Zhang, Yujia Zheng, Mengyue Yang, Petar Stojanov, Eran Segal, Eric P. Xing, Kun Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Prevalent in biomedical applications (e.g., human phenotype research),
multimodal datasets can provide valuable insights into the underlying
physiological mechanisms. However, current machine learning (ML) models
designed to analyze these datasets often lack interpretability and
identifiability guarantees, which are essential for biomedical research. Recent
advances in causal representation learning have shown promise in identifying
interpretable latent causal variables with formal theoretical guarantees.
Unfortunately, most current work on multimodal distributions either relies on
restrictive parametric assumptions or yields only coarse identification
results, limiting their applicability to biomedical research that favors a
detailed understanding of the mechanisms.
  In this work, we aim to develop flexible identification conditions for
multimodal data and principled methods to facilitate the understanding of
biomedical datasets. Theoretically, we consider a nonparametric latent
distribution (c.f., parametric assumptions in previous work) that allows for
causal relationships across potentially different modalities. We establish
identifiability guarantees for each latent component, extending the subspace
identification results from previous work. Our key theoretical contribution is
the structural sparsity of causal connections between modalities, which, as we
will discuss, is natural for a large collection of biomedical systems.
Empirically, we present a practical framework to instantiate our theoretical
insights. We demonstrate the effectiveness of our approach through extensive
experiments on both numerical and synthetic datasets. Results on a real-world
human phenotype dataset are consistent with established biomedical research,
validating our theoretical and methodological framework.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Symmetries, Scaling Laws and Phase Transitions in Consumer Advertising
  Response 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.02175v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.02175v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Javier Marin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Understanding how consumers respond to business advertising efforts is
essential for optimizing marketing investment. This research introduces a new
modeling approach based on the concepts of symmetries and scaling laws in
physics to describe consumer response to advertising dynamics. Drawing from
mathematical frameworks used in physics and social sciences, we propose a model
that accounts for a key aspect: the saturation effect. The model is validated
against commonly used models, including the Michaelis-Menten and Hill
equations, showing its ability to better capture nonlinearities in advertising
effects. We introduce new key parameters like Marketing Sensitivity, Response
Sensitivity, and Behavioral Sensitivit, that offer additional insights into the
drivers of audience engagement and advertising performance. Our model provides
a rigorous yet practical tool for understanding audience behavior, contributing
to the improvement of budget allocation strategies.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Jailbreaking Large Language Models in Infinitely Many Ways 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.10800v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.10800v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Oliver Goldstein, Emanuele La Malfa, Felix Drinkall, Samuele Marro, Michael Wooldridge
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We discuss the ``Infinitely Many Paraphrases'' attacks (IMP), a category of
jailbreaks that leverages the increasing capabilities of a model to handle
paraphrases and encoded communications to bypass their defensive mechanisms.
IMPs' viability pairs and grows with a model's capabilities to handle and bind
the semantics of simple mappings between tokens and work extremely well in
practice, posing a concrete threat to the users of the most powerful LLMs in
commerce. We show how one can bypass the safeguards of the most powerful open-
and closed-source LLMs and generate content that explicitly violates their
safety policies. One can protect against IMPs by improving the guardrails and
making them scale with the LLMs' capabilities. For two categories of attacks
that are straightforward to implement, i.e., bijection and encoding, we discuss
two defensive strategies, one in token and the other in embedding space. We
conclude with some research questions we believe should be prioritised to
enhance the defensive mechanisms of LLMs and our understanding of their safety.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Statistical Deficiency for Task Inclusion Estimation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.05491v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.05491v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Loïc Fosse, Frédéric Béchet, Benoît Favre, Géraldine Damnati, Gwénolé Lecorvé, Maxime Darrin, Philippe Formont, Pablo Piantanida
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Tasks are central in machine learning, as they are the most natural objects
to assess the capabilities of current models. The trend is to build general
models able to address any task. Even though transfer learning and multitask
learning try to leverage the underlying task space, no well-founded tools are
available to study its structure. This study proposes a theoretically grounded
setup to define the notion of task and to compute the {\bf inclusion} between
two tasks from a statistical deficiency point of view. We propose a tractable
proxy as information sufficiency to estimate the degree of inclusion between
tasks, show its soundness on synthetic data, and use it to reconstruct
empirically the classic NLP pipeline.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>34 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Hallo3: Highly Dynamic and Realistic Portrait Image Animation with Video
  Diffusion Transformer 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.00733v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.00733v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiahao Cui, Hui Li, Yun Zhan, Hanlin Shang, Kaihui Cheng, Yuqi Ma, Shan Mu, Hang Zhou, Jingdong Wang, Siyu Zhu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing methodologies for animating portrait images face significant
challenges, particularly in handling non-frontal perspectives, rendering
dynamic objects around the portrait, and generating immersive, realistic
backgrounds. In this paper, we introduce the first application of a pretrained
transformer-based video generative model that demonstrates strong
generalization capabilities and generates highly dynamic, realistic videos for
portrait animation, effectively addressing these challenges. The adoption of a
new video backbone model makes previous U-Net-based methods for identity
maintenance, audio conditioning, and video extrapolation inapplicable. To
address this limitation, we design an identity reference network consisting of
a causal 3D VAE combined with a stacked series of transformer layers, ensuring
consistent facial identity across video sequences. Additionally, we investigate
various speech audio conditioning and motion frame mechanisms to enable the
generation of continuous video driven by speech audio. Our method is validated
through experiments on benchmark and newly proposed wild datasets,
demonstrating substantial improvements over prior methods in generating
realistic portraits characterized by diverse orientations within dynamic and
immersive scenes. Further visualizations and the source code are available at:
https://fudan-generative-vision.github.io/hallo3/.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ HERO: Human-Feedback Efficient Reinforcement Learning for Online
  Diffusion Model Finetuning <span class="chip">ICLR</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05116v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05116v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ayano Hiranaka, Shang-Fu Chen, Chieh-Hsin Lai, Dongjun Kim, Naoki Murata, Takashi Shibuya, Wei-Hsiang Liao, Shao-Hua Sun, Yuki Mitsufuji
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Controllable generation through Stable Diffusion (SD) fine-tuning aims to
improve fidelity, safety, and alignment with human guidance. Existing
reinforcement learning from human feedback methods usually rely on predefined
heuristic reward functions or pretrained reward models built on large-scale
datasets, limiting their applicability to scenarios where collecting such data
is costly or difficult. To effectively and efficiently utilize human feedback,
we develop a framework, HERO, which leverages online human feedback collected
on the fly during model learning. Specifically, HERO features two key
mechanisms: (1) Feedback-Aligned Representation Learning, an online training
method that captures human feedback and provides informative learning signals
for fine-tuning, and (2) Feedback-Guided Image Generation, which involves
generating images from SD's refined initialization samples, enabling faster
convergence towards the evaluator's intent. We demonstrate that HERO is 4x more
efficient in online feedback for body part anomaly correction compared to the
best existing method. Additionally, experiments show that HERO can effectively
handle tasks like reasoning, counting, personalization, and reducing NSFW
content with only 0.5K online feedback. The code and project page are available
at https://hero-dm.github.io/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published in International Conference on Learning Representations
  (ICLR) 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Physics-Informed Diffusion Models <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.14404v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.14404v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jan-Hendrik Bastek, WaiChing Sun, Dennis M. Kochmann
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generative models such as denoising diffusion models are quickly advancing
their ability to approximate highly complex data distributions. They are also
increasingly leveraged in scientific machine learning, where samples from the
implied data distribution are expected to adhere to specific governing
equations. We present a framework that unifies generative modeling and partial
differential equation fulfillment by introducing a first-principle-based loss
term that enforces generated samples to fulfill the underlying physical
constraints. Our approach reduces the residual error by up to two orders of
magnitude compared to previous work in a fluid flow case study and outperforms
task-specific frameworks in relevant metrics for structural topology
optimization. We also present numerical evidence that our extended training
objective acts as a natural regularization mechanism against overfitting. Our
framework is simple to implement and versatile in its applicability for
imposing equality and inequality constraints as well as auxiliary optimization
objectives.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>26 pages, 9 figures, 3 tables; ICLR 2025 camera ready contribution</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The Breakdown of Gaussian Universality in Classification of
  High-dimensional Linear Factor Mixtures <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05609v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05609v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaoyi Mai, Zhenyu Liao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The assumption of Gaussian or Gaussian mixture data has been extensively
exploited in a long series of precise performance analyses of machine learning
(ML) methods, on large datasets having comparably numerous samples and
features. To relax this restrictive assumption, subsequent efforts have been
devoted to establish "Gaussian equivalent principles" by studying scenarios of
Gaussian universality where the asymptotic performance of ML methods on
non-Gaussian data remains unchanged when replaced with Gaussian data having the
same mean and covariance. Beyond the realm of Gaussian universality, there are
few exact results on how the data distribution affects the learning
performance.
  In this article, we provide a precise high-dimensional characterization of
empirical risk minimization, for classification under a general mixture data
setting of linear factor models that extends Gaussian mixtures. The Gaussian
universality is shown to break down under this setting, in the sense that the
asymptotic learning performance depends on the data distribution beyond the
class means and covariances. To clarify the limitations of Gaussian
universality in the classification of mixture data and to understand the impact
of its breakdown, we specify conditions for Gaussian universality and discuss
their implications for the choice of loss function.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>34 pages, 10 figures, accepted by ICLR 2025
  (https://openreview.net/forum?id=UrKbn51HjA)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ECBench: Can Multi-modal Foundation Models Understand the Egocentric
  World? A Holistic Embodied Cognition <span class="highlight-title">Benchmark</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.05031v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.05031v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ronghao Dang, Yuqian Yuan, Wenqi Zhang, Yifei Xin, Boqiang Zhang, Long Li, Liuyi Wang, Qinyang Zeng, Xin Li, Lidong Bing
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The enhancement of generalization in robots by large vision-language models
(LVLMs) is increasingly evident. Therefore, the embodied cognitive abilities of
LVLMs based on egocentric videos are of great interest. However, current
datasets for embodied video question answering lack comprehensive and
systematic evaluation frameworks. Critical embodied cognitive issues, such as
robotic self-cognition, dynamic scene perception, and hallucination, are rarely
addressed. To tackle these challenges, we propose ECBench, a high-quality
benchmark designed to systematically evaluate the embodied cognitive abilities
of LVLMs. ECBench features a diverse range of scene video sources, open and
varied question formats, and 30 dimensions of embodied cognition. To ensure
quality, balance, and high visual dependence, ECBench uses class-independent
meticulous human annotation and multi-round question screening strategies.
Additionally, we introduce ECEval, a comprehensive evaluation system that
ensures the fairness and rationality of the indicators. Utilizing ECBench, we
conduct extensive evaluations of proprietary, open-source, and task-specific
LVLMs. ECBench is pivotal in advancing the embodied cognitive capabilities of
LVLMs, laying a solid foundation for developing reliable core models for
embodied agents. All data and code are available at
https://github.com/Rh-Dang/ECBench.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Reinforcement Learning-Enhanced Procedural Generation for Dynamic
  Narrative-Driven AR Experiences 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.08552v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.08552v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aniruddha Srinivas Joshi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Procedural Content Generation (PCG) is widely used to create scalable and
diverse environments in games. However, existing methods, such as the Wave
Function Collapse (WFC) algorithm, are often limited to static scenarios and
lack the adaptability required for dynamic, narrative-driven applications,
particularly in augmented reality (AR) games. This paper presents a
reinforcement learning-enhanced WFC framework designed for mobile AR
environments. By integrating environment-specific rules and dynamic tile weight
adjustments informed by reinforcement learning (RL), the proposed method
generates maps that are both contextually coherent and responsive to gameplay
needs. Comparative evaluations and user studies demonstrate that the framework
achieves superior map quality and delivers immersive experiences, making it
well-suited for narrative-driven AR games. Additionally, the method holds
promise for broader applications in education, simulation training, and
immersive extended reality (XR) experiences, where dynamic and adaptive
environments are critical.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published in Proceedings of the 20th International Joint Conference
  on Computer Vision, Imaging and Computer Graphics Theory and Applications -
  GRAPP 2025
  https://www.scitepress.org/PublicationsDetail.aspx?ID=LfPv9Lfiya8=&t=1</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Predictive Prompt Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.18883v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.18883v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jae Yong Lee, Sungmin Kang, Shin Yoo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) are machine learning models that have seen
widespread adoption due to their capability of handling previously difficult
tasks. LLMs, due to their training, are sensitive to how exactly a question is
presented, also known as prompting. However, prompting well is challenging, as
it has been difficult to uncover principles behind prompting -- generally,
trial-and-error is the most common way of improving prompts, despite its
significant computational cost. In this context, we argue it would be useful to
perform `predictive prompt analysis', in which an automated technique would
perform a quick analysis of a prompt and predict how the LLM would react to it,
relative to a goal provided by the user. As a demonstration of the concept, we
present Syntactic Prevalence Analyzer (SPA), a predictive prompt analysis
approach based on sparse autoencoders (SAEs). SPA accurately predicted how
often an LLM would generate target syntactic structures during code synthesis,
with up to 0.994 Pearson correlation between the predicted and actual
prevalence of the target structure. At the same time, SPA requires only 0.4\%
of the time it takes to run the LLM on a benchmark. As LLMs are increasingly
used during and integrated into modern software development, our proposed
predictive prompt analysis concept has the potential to significantly ease the
use of LLMs for both practitioners and researchers.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by FSE 2025, 5 pages, 2 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ESTformer: Transformer Utilizing Spatiotemporal Dependencies for
  Electroencaphalogram Super-resolution 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.10052v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.10052v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dongdong Li, Zhongliang Zeng, Zhe Wang, Hai Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Towards practical applications of Electroencephalography (EEG), lightweight
acquisition devices garner significant attention. However, EEG channel
selection methods are commonly data-sensitive and cannot establish a unified
sound paradigm for EEG acquisition devices. Through reverse conceptualisation,
we formulated EEG applications in an EEG super-resolution (SR) manner, but
suffered from high computation costs, extra interpolation bias, and few
insights into spatiotemporal dependency modelling. To this end, we propose
ESTformer, an EEG SR framework that utilises spatiotemporal dependencies based
on the transformer. ESTformer applies positional encoding methods and a
multihead self-attention mechanism to the space and time dimensions, which can
learn spatial structural correlations and temporal functional variations.
ESTformer, with the fixed mask strategy, adopts a mask token to upsample
low-resolution (LR) EEG data in the case of disturbance from mathematical
interpolation methods. On this basis, we designed various transformer blocks to
construct a spatial interpolation module (SIM) and a temporal reconstruction
module (TRM). Finally, ESTformer cascades the SIM and TRM to capture and model
the spatiotemporal dependencies for EEG SR with fidelity. Extensive
experimental results on two EEG datasets show the effectiveness of ESTformer
against previous state-of-the-art methods, demonstrating the versatility of the
Transformer for EEG SR tasks. The superiority of the SR data was verified in an
EEG-based person identification and emotion recognition task, achieving a 2% to
38% improvement compared with the LR data at different sampling scales.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by Knowledge-Based Systems</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ <span class="highlight-title">★</span> AgiBot World Colosseo: A Large-scale <span class="highlight-title">Manipulation</span> Platform for Scalable
  and Intelligent Embodied Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06669v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06669v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                         AgiBot-World-Contributors, Qingwen Bu, Jisong Cai, Li Chen, Xiuqi Cui, Yan Ding, Siyuan Feng, Shenyuan Gao, Xindong He, Xu Huang, Shu Jiang, Yuxin Jiang, Cheng Jing, Hongyang Li, Jialu Li, Chi<span class="highlight-author">ming Liu</span>, Yi Liu, Yuxiang Lu, Jianlan Luo, Ping Luo, Yao Mu, Yuehan Niu, Yixuan Pan, Jiangmiao Pang, Yu Qiao, Guanghui Ren, Cheng Ruan, Jiaqi Shan, Yongjian Shen, Chengshi Shi, Mingkang Shi, Modi Shi, Chonghao Sima, Jianheng Song, Huijie Wang, Wenhao Wang, Dafeng Wei, Chengen Xie, Guo Xu, Junchi Yan, Cunbiao Yang, Lei Yang, Shukai Yang, Maoqing Yao, Jia Zeng, Chi Zhang, Qinglin Zhang, Bin Zhao, Chengyue Zhao, Jiaqi Zhao, Jianchao Zhu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We explore how scalable robot data can address real-world challenges for
generalized robotic manipulation. Introducing AgiBot World, a large-scale
platform comprising over 1 million trajectories across 217 tasks in five
deployment scenarios, we achieve an order-of-magnitude increase in data scale
compared to existing datasets. Accelerated by a standardized collection
pipeline with human-in-the-loop verification, AgiBot World guarantees
high-quality and diverse data distribution. It is extensible from grippers to
dexterous hands and visuo-tactile sensors for fine-grained skill acquisition.
Building on top of data, we introduce Genie Operator-1 (GO-1), a novel
generalist policy that leverages latent action representations to maximize data
utilization, demonstrating predictable performance scaling with increased data
volume. Policies pre-trained on our dataset achieve an average performance
improvement of 30% over those trained on Open X-Embodiment, both in in-domain
and out-of-distribution scenarios. GO-1 exhibits exceptional capability in
real-world dexterous and long-horizon tasks, achieving over 60% success rate on
complex tasks and outperforming prior RDT approach by 32%. By open-sourcing the
dataset, tools, and models, we aim to democratize access to large-scale,
high-quality robot data, advancing the pursuit of scalable and general-purpose
intelligence.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project website: https://agibot-world.com/. Github repo:
  https://github.com/OpenDriveLab/AgiBot-World. The author list is ordered
  alphabetically by surname, with detailed contributions provided in the
  appendix</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Systems and Control <span class="chip" style="font-size: 60%">32</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Low-Rank Matrix Regression via Least-Angle Regression 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10569v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10569v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mingzhou Yin, Matthias A. Müller
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Low-rank matrix regression is a fundamental problem in data science with
various applications in systems and control. Nuclear norm regularization has
been widely applied to solve this problem due to its convexity. However, it
suffers from high computational complexity and the inability to directly
specify the rank. This work introduces a novel framework for low-rank matrix
regression that addresses both unstructured and Hankel matrices. By decomposing
the low-rank matrix into rank-1 bases, the problem is reformulated as an
infinite-dimensional sparse learning problem. The least-angle regression (LAR)
algorithm is then employed to solve this problem efficiently. For unstructured
matrices, a closed-form LAR solution is derived with equivalence to a
normalized nuclear norm regularization problem. For Hankel matrices, a
real-valued polynomial basis reformulation enables effective LAR
implementation. Two numerical examples in network modeling and system
realization demonstrate that the proposed approach significantly outperforms
the nuclear norm method in terms of estimation accuracy and computational
efficiency.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Safety Filter for Limiting the Current of Grid-Forming Matrix Modular
  Multilevel Converters 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10498v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10498v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Michael Schneeberger, Silvia Mastellone, Florian Dörfler
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Grid-forming (GFM) converters face significant challenges in limiting current
during transient grid events while preserving their grid-forming behavior. This
paper offers an elegant solution to the problem with a priori guarantees,
presenting a safety filter approach based on Control Barrier Functions (CBFs)
to enforce current constraints with minimal deviation from the nominal voltage
reference. The safety filter is implemented as a Quadratic Program, enabling
real-time computation of safe voltage adjustments that ensure smooth
transitions and maintain the GFM behavior during nominal operation. To provide
formal safety certificate, the CBF is synthesized offline using a
Sum-of-Squares optimization framework, ensuring that the converter remains
within its allowable operating limits under all conditions. Additionally, a
Control Lyapunov Function is incorporated to facilitate a smooth return to the
nominal operating region following grid events. The proposed method is modular
and can be integrated into many of the GFM control architectures, as
demonstrated with two different GFM implementations. High-fidelity simulations
conducted with an enhanced matrix modular multilevel converter connected to
both high-inertia and low-inertia grid scenarios validate the effectiveness of
the safety filter, showing that it successfully limits current during faults,
preserves GFM behavior, and ensures a seamless recovery to nominal operation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Stratified Topological Autonomy for Long-Range Coordination (STALC) 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10475v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10475v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Cora A. Dimmig, Adam Goertz, Adam Polevoy, Mark Gonzales, Kevin C. Wolfe, Bradley Woosley, John Rogers, Joseph Moore
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Achieving unified multi-robot coordination and motion planning in complex
environments is a challenging problem. In this paper, we present a hierarchical
approach to long-range coordination, which we call Stratified Topological
Autonomy for Long-Range Coordination (STALC). In particular, we look at the
problem of minimizing visibility to observers and maximizing safety with a
multi-robot team navigating through a hazardous environment. At its core, our
approach relies on the notion of a dynamic topological graph, where the edge
weights vary dynamically based on the locations of the robots in the graph. To
create this dynamic topological graph, we evaluate the visibility of the robot
team from a discrete set of observer locations (both adversarial and friendly),
and construct a topological graph whose edge weights depend on both adversary
position and robot team configuration. We then impose temporal constraints on
the evolution of those edge weights based on robot team state and use
Mixed-Integer Programming (MIP) to generate optimal multirobot plans through
the graph. The visibility information also informs the lower layers of the
autonomy stack to plan minimal visibility paths through the environment for the
team of robots. Our approach presents methods to reduce the computational
complexity for a team of robots that interact and coordinate across the team to
accomplish a common goal. We demonstrate our approach in simulated and hardware
experiments in forested and urban environments.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This work has been submitted to the IEEE for possible publication.
  arXiv admin note: text overlap with arXiv:2303.11966</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Optimal Estimation for Continuous-Time Nonlinear Systems Using
  State-Dependent Riccati Equation (SDRE) 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10442v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10442v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Adnan Tahirovic, Azra Redzovic
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces a unified approach for state estimation and control of
nonlinear dynamic systems, employing the State-Dependent Riccati Equation
(SDRE) framework. The proposed approach naturally extends classical linear
quadratic Gaussian (LQG) methods into nonlinear scenarios, avoiding
linearization by using state-dependent coefficient (SDC) matrices. An
SDRE-based Kalman filter (SDRE-KF) is integrated within an SDRE-based control
structure, providing a coherent and intuitive strategy for nonlinear system
analysis and control design. To evaluate the effectiveness and robustness of
the proposed methodology, comparative simulations are conducted on two
benchmark nonlinear systems: a simple pendulum and a Van der Pol oscillator.
Results demonstrate that the SDRE-KF achieves comparable or superior estimation
accuracy compared to traditional methods, including the Extended Kalman Filter
(EKF) and Particle Filter (PF). These findings underline the potential of the
unified SDRE-based approach as a viable alternative for nonlinear state
estimation and control, providing valuable insights for both educational
purposes and practical engineering applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A nonlinear real time capable motion cueing algorithm based on deep
  reinforcement learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10419v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10419v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hendrik Scheidel, Camilo Gonzalez, Houshyar Asadi, Tobias Bellmann, Andreas Seefried, Shady Mohamed, Saeid Nahavandi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In motion simulation, motion cueing algorithms are used for the trajectory
planning of the motion simulator platform, where workspace limitations prevent
direct reproduction of reference trajectories. Strategies such as motion
washout, which return the platform to its center, are crucial in these
settings. For serial robotic MSPs with highly nonlinear workspaces, it is
essential to maximize the efficient utilization of the MSPs kinematic and
dynamic capabilities. Traditional approaches, including classical washout
filtering and linear model predictive control, fail to consider
platform-specific, nonlinear properties, while nonlinear model predictive
control, though comprehensive, imposes high computational demands that hinder
real-time, pilot-in-the-loop application without further simplification. To
overcome these limitations, we introduce a novel approach using deep
reinforcement learning for motion cueing, demonstrated here for the first time
in a 6-degree-of-freedom setting with full consideration of the MSPs kinematic
nonlinearities. Previous work by the authors successfully demonstrated the
application of DRL to a simplified 2-DOF setup, which did not consider
kinematic or dynamic constraints. This approach has been extended to all 6 DOF
by incorporating a complete kinematic model of the MSP into the algorithm, a
crucial step for enabling its application on a real motion simulator. The
training of the DRL-MCA is based on Proximal Policy Optimization in an
actor-critic implementation combined with an automated hyperparameter
optimization. After detailing the necessary training framework and the
algorithm itself, we provide a comprehensive validation, demonstrating that the
DRL MCA achieves competitive performance against established algorithms.
Moreover, it generates feasible trajectories by respecting all system
constraints and meets all real-time requirements with low...
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Compliant Control of Quadruped Robots for Assistive Load Carrying 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10401v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10401v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nimesh Khandelwal, Amritanshu Manu, Shakti S. Gupta, Mangal Kothari, Prashanth Krishnamurthy, Farshad Khorrami
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents a novel method for assistive load carrying using
quadruped robots. The controller uses proprioceptive sensor data to estimate
external base wrench, that is used for precise control of the robot's
acceleration during payload transport. The acceleration is controlled using a
combination of admittance control and Control Barrier Function (CBF) based
quadratic program (QP). The proposed controller rejects disturbances and
maintains consistent performance under varying load conditions. Additionally,
the built-in CBF guarantees collision avoidance with the collaborative agent in
front of the robot. The efficacy of the overall controller is shown by its
implementation on the physical hardware as well as numerical simulations. The
proposed control framework aims to enhance the quadruped robot's ability to
perform assistive tasks in various scenarios, from industrial applications to
search and rescue operations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 20 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Safe exploration in reproducing kernel Hilbert spaces 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10352v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10352v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Abdullah Tokmak, Kiran G. Krishnan, Thomas B. Schön, Dominik Baumann
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Popular safe Bayesian optimization (BO) algorithms learn control policies for
safety-critical systems in unknown environments. However, most algorithms make
a smoothness assumption, which is encoded by a known bounded norm in a
reproducing kernel Hilbert space (RKHS). The RKHS is a potentially
infinite-dimensional space, and it remains unclear how to reliably obtain the
RKHS norm of an unknown function. In this work, we propose a safe BO algorithm
capable of estimating the RKHS norm from data. We provide statistical
guarantees on the RKHS norm estimation, integrate the estimated RKHS norm into
existing confidence intervals and show that we retain theoretical guarantees,
and prove safety of the resulting safe BO algorithm. We apply our algorithm to
safely optimize reinforcement learning policies on physics simulators and on a
real inverted pendulum, demonstrating improved performance, safety, and
scalability compared to the state-of-the-art.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to AISTATS 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Some remarks on robustness of sample-and-hold stabilization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10328v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10328v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Patrick Schmidt, Pavel Osinenko, Stefan Streif
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This work studies robustness to system disturbance and measurement noise of
some popular general practical stabilization techniques, namely, Dini aiming,
optimization-based stabilization and inf-convolution stabilization. Common to
all these techniques is the explicit usage of a (general nonsmooth) control
Lyapunov function, thus allowing to see them as a kind of generalization to the
celebrated Sontag's formula. It turns out that certain details of the above
described robustness properties have not yet received the attention in
literature they deserved. We provide new remarks, formalized in mathematical
propositions, on robustness of selected popular stabilization techniques along
with an extensive statistical case study on a robot parking problem.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at IEEE Control Systems Letters; 8 pages, 5 figures, 4
  tables (extended version)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CODEI: Resource-Efficient Task-Driven Co-Design of Perception and
  Decision Making for Mobile Robots Applied to Autonomous Vehicles 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10296v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10296v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dejan Milojevic, Gioele Zardini, Miriam Elser, Andrea Censi, Emilio Frazzoli
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper discusses the integration challenges and strategies for designing
mobile robots, by focusing on the task-driven, optimal selection of hardware
and software to balance safety, efficiency, and minimal usage of resources such
as costs, energy, computational requirements, and weight. We emphasize the
interplay between perception and motion planning in decision-making by
introducing the concept of occupancy queries to quantify the perception
requirements for sampling-based motion planners. Sensor and algorithm
performance are evaluated using False Negative Rates (FPR) and False Positive
Rates (FPR) across various factors such as geometric relationships, object
properties, sensor resolution, and environmental conditions. By integrating
perception requirements with perception performance, an Integer Linear
Programming (ILP) approach is proposed for efficient sensor and algorithm
selection and placement. This forms the basis for a co-design optimization that
includes the robot body, motion planner, perception pipeline, and computing
unit. We refer to this framework for solving the co-design problem of mobile
robots as CODEI, short for Co-design of Embodied Intelligence. A case study on
developing an Autonomous Vehicle (AV) for urban scenarios provides actionable
information for designers, and shows that complex tasks escalate resource
demands, with task performance affecting choices of the autonomy stack. The
study demonstrates that resource prioritization influences sensor choice:
cameras are preferred for cost-effective and lightweight designs, while lidar
sensors are chosen for better energy and computational efficiency.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages, 33 images, IEEE Transactions on Robotics</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Reach-Avoid-Stay-<span class="highlight-title">Collision</span>-Avoidance Negotiation Framework for
  Multi-Agent Systems via Spatiotemporal Tubes 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10245v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10245v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohd. Faizuddin Faruqui, Ratnangshu Das, Ravi Kumar L, Pushpak Jagtap
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study presents a multi-agent negotiation-based framework to obtain
collision-free paths while performing prescribed-time reach-avoid-stay (RAS)
tasks for agents with unknown dynamics and bounded disturbance. By employing
spatiotemporal tubes to generate time-varying state constraints, we ensure that
all agents adhere to RAS specifications using synthesized controllers. To
prevent inter-agent collisions, a negotiation mechanism is proposed where
successful negotiations result in spatiotemporal tubes for each agent
fulfilling desired tasks. This approach results in a completely distributed,
approximation-free control law for each agent. The effectiveness of this
mechanism was validated through simulations of multi-agent robot navigation and
drone navigation tasks involving prescribed-time RAS specifications and
collision avoidance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted in ECC 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Global synchronization of multi-agent systems with nonlinear
  interactions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10205v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10205v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anthony Couthures, Vineeth S. Varma, Samson Lasaulce, Irinel-Constantin Morarescu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The paper addresses the synchronization of multi-agent systems with
continuous-time dynamics interacting through a very general class of monotonic
continuous signal functions that covers estimation biases, approximation of
discrete quantization, or state-dependent estimation. Our analysis reveals
that, in the setup under consideration, synchronization equilibria are exactly
the fixed points of the signal function. We also derive intuitive stability
conditions based on whether the signal underestimates or overestimates the
state of the agents around these fixed points. Moreover, we show that network
topology plays a crucial role in asymptotic synchronization. These results
provide interesting insights into the interplay between communication
nonlinearity and network connectivity, paving the way for advanced coordination
strategies in complex systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Neural network-based identification of state-space switching nonlinear
  systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10114v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10114v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yanxin Zhang, Chengpu Yu, Filippo Fabiani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We design specific neural networks (NNs) for the identification of switching
nonlinear systems in the state-space form, which explicitly model the switching
behavior and address the inherent coupling between system parameters and
switching modes. This coupling is specifically addressed by leveraging the
expectation-maximization (EM) framework. In particular, our technique will
combine a moving window approach in the E-step to efficiently estimate the
switching sequence, together with an extended Kalman filter (EKF) in the M-step
to train the NNs with a quadratic convergence rate. Extensive numerical
simulations, involving both academic examples and a battery charge management
system case study, illustrate that our technique outperforms available ones in
terms of parameter estimation accuracy, model fitting, and switching sequence
identification.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ One-bit consensus of controllable linear multi-agent systems with
  communication noises 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10062v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10062v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ru An, Ying Wang, Yanlong Zhao, Ji-Feng Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper addresses the one-bit consensus of controllable linear multi-agent
systems (MASs) with communication noises. A consensus algorithm consisting of a
communication protocol and a consensus controller is designed. The
communication protocol introduces a linear compression encoding function to
achieve a one-bit data rate, thereby saving communication costs. The consensus
controller with a stabilization term and a consensus term is proposed to ensure
the consensus of a potentially unstable but controllable MAS. Specifically, in
the consensus term, we adopt an estimation method to overcome the information
loss caused by one-bit communications and a decay step to attenuate the effect
of communication noise. Two combined Lyapunov functions are constructed to
overcome the difficulty arising from the coupling of the control and
estimation. By establishing similar iterative structures of these two
functions, this paper shows that the MAS can achieve consensus in the mean
square sense at the rate of the reciprocal of the iteration number under the
case with a connected fixed topology. Moreover, the theoretical results are
generalized to the case with jointly connected Markovian switching topologies
by establishing a certain equivalence relationship between the Markovian
switching topologies and a fixed topology. Two simulation examples are given to
validate the algorithm.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, 7 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Combining Cooperative Re-Routing with Intersection Coordination for
  Connected and Automated Vehicles in Urban Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10004v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10004v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Panagiotis Typaldos, Andreas A. Malikopoulos
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we present a hierarchical framework that integrates
upper-level routing with low-level optimal trajectory planning for connected
and automated vehicles (CAVs) traveling in an urban network. The upper-level
controller efficiently distributes traffic flows by utilizing a dynamic
re-routing algorithm that leverages real-time density information and the
fundamental diagrams of each network edge. This re-routing approach predicts
when each edge will reach critical density and proactively adjusts the routing
algorithm's weights to prevent congestion before it occurs. The low-level
controller coordinates CAVs as they cross signal-free intersections, generating
optimal, fuel-efficient trajectories while ensuring safe passage by satisfying
all relevant constraints. We formulate the problem as an optimal control
problem and derive an analytical solution. Using the SUMO micro-simulation
platform, we conduct simulation experiments on a realistic network. The results
show that our hierarchical framework significantly enhances network performance
compared to a baseline static routing approach. By dynamically re-routing
vehicles, our approach successfully reduces total travel time and mitigates
congestion before it develops.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Growing Into an Adaptive and Reconfigurable Paradigm for Spectrum
  Sharing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09936v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09936v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Charles Baylis, Douglas Sicker, Austin Egbert, Andrew Clegg, Tom Brooks, Casey Latham, Robert J. Marks II
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A significant movement from rigid use of the wireless spectrum toward
adaptive and reconfigurable spectrum use has been prompted by increasing
spectral crowding. Some bands have moved to an adaptive sharing model, and
proposals are growing for this approach to be applied to additional bands. The
process of moving from a fixed, rigid spectrum paradigm to adaptive and
reconfigurable use involves maturation of policy and technology at multiple
levels within the system of systems. Using the concept of Bloom's Taxonomy from
the education discipline, this paper examines the development of a policy and
technology progression toward a mature, adaptive and reconfigurable paradigm.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>4 pages, 4 figures, submitted to IEEE Wireless and Microwave
  Technology Conference (WAMICON) 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Human Physical Interaction based on UAV Cooperative Payload
  Transportation System using Adaptive Backstepping and FNTSMC 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09930v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09930v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hussein N. Naser, Hashim A. Hashim, Mojtaba Ahmadi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents a nonlinear control strategy for an aerial cooperative
payload transportation system consisting of two quadrotor UAVs rigidly
connected to a payload. The system includes human physical interaction
facilitated by an admittance control. The proposed control framework integrates
an adaptive Backstepping controller for the position subsystem and a Fast
Nonsingular Terminal Sliding Mode Control (FNTSMC) for the attitude subsystem
to ensure asymptotic stabilization. The admittance controller interprets the
interaction forces from the human operator, generating reference trajectories
for the position controller to ensure accurate tracking of the operator's
guidance. The system aims to assist humans in payload transportation, providing
both stability and responsiveness. The robustness and effectiveness of the
proposed control scheme in maintaining system stability and performance under
various conditions are presented.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Proc. of the 2025 IEEE American Control Conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Underapproximating Safe Domains of Attraction for Discrete-Time Systems
  Using Implicit Representations of Backward Reachable Sets 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.10657v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.10657v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohamed Serry, Jun Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Analyzing and certifying stability and attractivity of nonlinear systems is a
topic of research interest that has been extensively investigated by control
theorists and engineers for many years. Despite that, accurately estimating
domains of attraction for nonlinear systems remains a challenging task, where
available estimation approaches are either conservative or limited to
low-dimensional systems. In this work, we propose an iterative approach to
accurately underapproximate safe (i.e., state-constrained) domains of
attraction for general discrete-time autonomous nonlinear systems. Our approach
relies on implicit representations of safe backward reachable sets of safe
regions of attraction, where such regions can be be easily constructed using,
e.g., quadratic Lyapunov functions. The iterations of our approach are
monotonic (in the sense of set inclusion), where each iteration results in a
safe region of attraction, given as a sublevel set, that underapproximates the
safe domain of attraction. The sublevel set representations of the resulting
regions of attraction can be efficiently utilized in verifying the inclusion of
given points of interest in the safe domain of attraction. We illustrate our
approach through two numerical examples, involving two- and four-dimensional
nonlinear systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This updated manuscript corrects errors in the formulas for the
  bounds used in computing ellipsoidal regions of attraction</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Maintaining Strong $r$-Robustness in Reconfigurable Multi-Robot Networks
  using Control Barrier Functions <span class="chip">ICRA</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.14675v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.14675v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haejoon Lee, Dimitra Panagou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In leader-follower consensus, strong $r$-robustness of the communication
graph provides a sufficient condition for followers to achieve consensus in the
presence of misbehaving agents. Previous studies have assumed that robots can
form and/or switch between predetermined network topologies with known
robustness properties. However, robots with distance-based communication models
may not be able to achieve these topologies while moving through spatially
constrained environments, such as narrow corridors, to complete their
objectives. This paper introduces a Control Barrier Function (CBF) that ensures
robots maintain strong $r$-robustness of their communication graph above a
certain threshold without maintaining any fixed topologies. Our CBF directly
addresses robustness, allowing robots to have flexible reconfigurable network
structure while navigating to achieve their objectives. The efficacy of our
method is tested through various simulation and hardware experiments.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted and will appear at IEEE International Conference on Robotics
  and Automation (ICRA) 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Optimal Distribution System Restoration via Tractable Modeling of
  Decision-Dependent Interruption Cost and Cold Load Pickup 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.12353v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.12353v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wei Wang, Minwu Chen, Hongbin Wang, Gaoqiang Peng, Hongzhou Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Developing optimized restoration strategies for power distribution systems
(PDSs) is critical to enhancing resilience. Prior knowledge of customer
interruption cost (CIC) and load restoration behaviors, particularly cold load
pickup (CLPU), is essential for effective decision-making. However, both CIC
and CLPU are reciprocally influenced by the realized customer interruption
duration (CID), making them decision-dependent and challenging to model,
especially given the limited understanding of their underlying physical
mechanisms. This paper proposes a novel and tractable modeling approach to
capture the varying patterns of CIC and CLPU with CID - patterns derived from
data that reflect observable surface - level correlations rather than
underlying mechanisms - thereby enabling practical surrogate modeling of these
decision-dependent factors. Specifically, quadratic functions are employed to
model the increasing rate of CIC with respect to CID according to data fitting
results. For CLPU, several defining characteristics are extracted and modeled
in a piecewise linear form relative to CID, and the actual restored load
accounting for CLPU is subsequently reconstructed. Building on these models, a
PDS restoration optimization framework is developed, incorporating mobile
energy storage systems (MESSs) and network reconfiguration strategies. Case
studies validate the effectiveness of the proposed approach and highlight
MESS's unique potential in accelerating CLPU-related restoration.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 10 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Constrained Learning for Decentralized Multi-Objective Coverage Control 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.11311v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.11311v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Juan Cervino, Saurav Agarwal, Vijay Kumar, Alejandro Ribeiro
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The multi-objective coverage control problem requires a robot swarm to
collaboratively provide sensor coverage to multiple heterogeneous importance
density fields IDFs simultaneously. We pose this as an optimization problem
with constraints and study two different formulations: (1) Fair coverage, where
we minimize the maximum coverage cost for any field, promoting equitable
resource distribution among all fields; and (2) Constrained coverage, where
each field must be covered below a certain cost threshold, ensuring that
critical areas receive adequate coverage according to predefined importance
levels. We study the decentralized setting where robots have limited
communication and local sensing capabilities, making the system more realistic,
scalable, and robust. Given the complexity, we propose a novel decentralized
constrained learning approach that combines primal-dual optimization with a
Learnable Perception-Action-Communication (LPAC) neural network architecture.
We show that the Lagrangian of the dual problem can be reformulated as a linear
combination of the IDFs, enabling the LPAC policy to serve as a primal solver.
We empirically demonstrate that the proposed method (i) significantly
outperforms state-of-the-art decentralized controllers by 30% on average in
terms of coverage cost, (ii) transfers well to larger environments with more
robots, and (iii) scalable in the number of IDFs and robots in the swarm.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Networked Communication for Decentralised Agents in Mean-Field Games 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2306.02766v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2306.02766v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Patrick Benjamin, Alessandro Abate
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce networked communication to the mean-field game framework, in
particular to oracle-free settings where $N$ decentralised agents learn along a
single, non-episodic run of the empirical system. We prove that our
architecture has sample guarantees bounded between those of the centralised-
and independent-learning cases. We provide the order of the difference in these
bounds in terms of network structure and number of communication rounds, and
also contribute a policy-update stability guarantee. We discuss how the sample
guarantees of the three theoretical algorithms do not actually result in
practical convergence. We therefore show that in practical settings where the
theoretical parameters are not observed (leading to poor estimation of the
Q-function), our communication scheme considerably accelerates learning over
the independent case, often performing similarly to a centralised learner while
removing the restrictive assumption of the latter. We contribute further
practical enhancements to all three theoretical algorithms, allowing us to
present their first empirical demonstrations. Our experiments confirm that we
can remove several of the theoretical assumptions of the algorithms, and
display the empirical convergence benefits brought by our new networked
communication. We additionally show that our networked approach has significant
advantages over both alternatives in terms of robustness to update failures and
to changes in population size.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Quantitative Decentralized Stability Certificates for Grid-Forming
  Converter Control 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.05403v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.05403v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Verena Häberle, Xiuqiang He, Linbin Huang, Florian Dörfler, Steven Low
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose a decentralized framework for guaranteeing the small-signal
stability of future power systems with grid-forming converters. Our approach
leverages dynamic loop-shifting techniques to compensate for the lack of
passivity in the network dynamics and establishes decentralized parametric
stability certificates, depending on the local device-level controls and
incorporating the effects of the network dynamics. By following practical
tuning rules, we are able to ensure plug-and-play operation without centralized
coordination. Unlike prior works, our approach accommodates coupled frequency
and voltage dynamics, incorporates network dynamics, and does not rely on
specific network configurations or operating points, offering a general and
scalable solution for the integration of power-electronics-based devices into
future power systems. We validate our theoretical stability results through
numerical case studies in a high-fidelity simulation model.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 13 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Networked Communication for Mean-Field Games with Function Approximation
  and Empirical Mean-Field Estimation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.11607v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.11607v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Patrick Benjamin, Alessandro Abate
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent algorithms allow decentralised agents, possibly connected via a
communication network, to learn equilibria in Mean-Field Games from a
non-episodic run of the empirical system. However, these algorithms are for
tabular settings: this computationally limits the size of agents' observation
space, meaning the algorithms cannot handle anything but small state spaces,
nor generalise beyond policies depending only on the agent's local state to
so-called 'population-dependent' policies. We address this limitation by
introducing function approximation to the existing setting, drawing on the
Munchausen Online Mirror Descent method that has previously been employed only
in finite-horizon, episodic, centralised settings. While this permits us to
include the mean field in the observation for players' policies, it is
unrealistic to assume decentralised agents have access to this global
information: we therefore also provide new algorithms allowing agents to
locally estimate the global empirical distribution, and to improve this
estimate via inter-agent communication. We show theoretically that exchanging
policy information helps networked agents outperform both independent and even
centralised agents in function-approximation settings. Our experiments
demonstrate this happening empirically, by an even greater margin than in
tabular settings, and show that the communication network allows decentralised
agents to estimate the mean field for population-dependent policies.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ AI-Aided Kalman Filters 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12289v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12289v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nir Shlezinger, Guy Revach, Anubhab Ghosh, Saikat Chatterjee, Shuo Tang, Tales Imbiriba, Jindrich Dunik, Ondrej Straka, Pau Closas, Yonina C. Eldar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The Kalman filter (KF) and its variants are among the most celebrated
algorithms in signal processing. These methods are used for state estimation of
dynamic systems by relying on mathematical representations in the form of
simple state-space (SS) models, which may be crude and inaccurate descriptions
of the underlying dynamics. Emerging data-centric artificial intelligence (AI)
techniques tackle these tasks using deep neural networks (DNNs), which are
model-agnostic. Recent developments illustrate the possibility of fusing DNNs
with classic Kalman-type filtering, obtaining systems that learn to track in
partially known dynamics. This article provides a tutorial-style overview of
design approaches for incorporating AI in aiding KF-type algorithms. We review
both generic and dedicated DNN architectures suitable for state estimation, and
provide a systematic presentation of techniques for fusing AI tools with KFs
and for leveraging partial SS modeling and data, categorizing design approaches
into task-oriented and SS model-oriented. The usefulness of each approach in
preserving the individual strengths of model-based KFs and data-driven DNNs is
investigated in a qualitative and quantitative study, whose code is publicly
available, illustrating the gains of hybrid model-based/data-driven designs. We
also discuss existing challenges and future research directions that arise from
fusing AI and Kalman-type algorithms.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to the IEEE Signal Processing Magazine</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Game Theory in Formula 1: Multi-agent Physical and Strategical
  Interactions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.05421v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.05421v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Giona Fieni, Marc-Philippe Neumann, Francesca Furia, Alessandro Caucino, Alberto Cerofolini, Vittorio Ravaglioli, Christopher H. Onder
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents an optimization framework for Formula 1 racing that
integrates multi-agent interactions, aerodynamic wake effects, trajectory
optimization, and energy management. By employing game-theoretic methods, we
formulate the minimum lap time problem as either a Nash or a Stackelberg game.
Exploiting their structural similarities, we compare symmetric and hierarchical
strategies to analyze competitive racing dynamics and strategic dominance.
Additionally, we introduce an algorithm to refine local Stackelberg solutions.
Our findings underscore the importance of jointly optimizing physical
interactions, energy management, and trajectory, highlighting their strong
interdependence. We examine the impact of slipstreaming on trajectory selection
in corners, straights, and high-speed sections, while also identifying optimal
overtaking locations based on energy allocation strategies. By incorporating a
physically accurate interaction model and accounting for the optimal responses
of competing agents, our approach reveals characteristic strategic behaviors
observed in real-world racing. The proposed methodology contributes towards
realistic Formula 1 race strategy optimizations, with potential applications in
motorsport engineering and autonomous racing.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The Algorithmic State Architecture (ASA): An Integrated Framework for
  AI-Enabled Government 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08725v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08725v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zeynep Engin, Jon Crowcroft, David Hand, Philip Treleaven
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As artificial intelligence transforms public sector operations, governments
struggle to integrate technological innovations into coherent systems for
effective service delivery. This paper introduces the Algorithmic State
Architecture (ASA), a novel four-layer framework conceptualising how Digital
Public Infrastructure, Data-for-Policy, Algorithmic Government/Governance, and
GovTech interact as an integrated system in AI-enabled states. Unlike
approaches that treat these as parallel developments, ASA positions them as
interdependent layers with specific enabling relationships and feedback
mechanisms. Through comparative analysis of implementations in Estonia,
Singapore, India, and the UK, we demonstrate how foundational digital
infrastructure enables systematic data collection, which powers algorithmic
decision-making processes, ultimately manifesting in user-facing services. Our
analysis reveals that successful implementations require balanced development
across all layers, with particular attention to integration mechanisms between
them. The framework contributes to both theory and practice by bridging
previously disconnected domains of digital government research, identifying
critical dependencies that influence implementation success, and providing a
structured approach for analysing the maturity and development pathways of
AI-enabled government systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Main text: 25 pages, with references: 35 pages, 2 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Real-Time Recurrent Reinforcement Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.04830v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.04830v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Julian Lemmel, Radu Grosu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce a biologically plausible RL framework for solving tasks in
partially observable Markov decision processes (POMDPs). The proposed algorithm
combines three integral parts: (1) A Meta-RL architecture, resembling the
mammalian basal ganglia; (2) A biologically plausible reinforcement learning
algorithm, exploiting temporal difference learning and eligibility traces to
train the policy and the value-function; (3) An online automatic
differentiation algorithm for computing the gradients with respect to
parameters of a shared recurrent network backbone. Our experimental results
show that the method is capable of solving a diverse set of partially
observable reinforcement learning tasks. The algorithm we call real-time
recurrent reinforcement learning (RTRRL) serves as a model of learning in
biological neural networks, mimicking reward pathways in the basal ganglia.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages, 9 figures, includes Appendix</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Feasible Policy Iteration for Safe Reinforcement Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2304.08845v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2304.08845v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yujie Yang, Zhilong Zheng, Shengbo Eben Li, Wei Xu, Jingjing Liu, Xianyuan Zhan, Ya-Qin Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Safety is the priority concern when applying reinforcement learning (RL)
algorithms to real-world control problems. While policy iteration provides a
fundamental algorithm for standard RL, an analogous theoretical algorithm for
safe RL remains absent. In this paper, we propose feasible policy iteration
(FPI), the first foundational dynamic programming algorithm for safe RL. FPI
alternates between policy evaluation, region identification and policy
improvement. This follows actor-critic-scenery (ACS) framework where scenery
refers to a feasibility function that represents a feasible region. A
region-wise update rule is developed for the policy improvement step, which
maximizes state-value function inside the feasible region and minimizes
feasibility function outside it. With this update rule, FPI guarantees
monotonic expansion of feasible region, monotonic improvement of state-value
function, and geometric convergence to the optimal safe policy. Experimental
results demonstrate that FPI achieves strictly zero constraint violation on
low-dimensional tasks and outperforms existing methods in constraint adherence
and reward performance on high-dimensional tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Coalescing Force of Group Pressure: Consensus in Nonlinear Opinion
  Dynamics 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04301v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04301v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Iryna Zabarianska, Anton V. Proskurnikov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This work extends the recent opinion dynamics model from Cheng et al.,
emphasizing the role of group pressure in consensus formation. We generalize
the findings to incorporate social influence algorithms with general
time-varying, opinion-dependent weights and multidimensional opinions, beyond
bounded confidence dynamics. We demonstrate that, with uniformly positive
conformity levels, group pressure consistently drives consensus and provide a
tighter estimate for the convergence rate. Unlike previous models, the common
public opinion in our framework can assume arbitrary forms within the convex
hull of current opinions, offering flexibility applicable to real-world
scenarios such as opinion polls with random participant selection. This
analysis provides deeper insights into how group pressure mechanisms foster
consensus under diverse conditions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ PCLA: A Framework for Testing Autonomous Agents in the CARLA Simulator 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09385v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09385v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Masoud Jamshidiyan Tehrani, Jinhan Kim, Paolo Tonella
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent research on testing autonomous driving agents has grown significantly,
especially in simulation environments. The CARLA simulator is often the
preferred choice, and the autonomous agents from the CARLA Leaderboard
challenge are regarded as the best-performing agents within this environment.
However, researchers who test these agents, rather than training their own ones
from scratch, often face challenges in utilizing them within customized test
environments and scenarios. To address these challenges, we introduce PCLA
(Pretrained CARLA Leaderboard Agents), an open-source Python testing framework
that includes nine high-performing pre-trained autonomous agents from the
Leaderboard challenges. PCLA is the first infrastructure specifically designed
for testing various autonomous agents in arbitrary CARLA
environments/scenarios. PCLA provides a simple way to deploy Leaderboard agents
onto a vehicle without relying on the Leaderboard codebase, it allows
researchers to easily switch between agents without requiring modifications to
CARLA versions or programming environments, and it is fully compatible with the
latest version of CARLA while remaining independent of the Leaderboard's
specific CARLA version. PCLA is publicly accessible at
https://github.com/MasoudJTehrani/PCLA.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This work will be published at the FSE 2025 demonstration track</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Faithful and Privacy-Preserving Implementation of Average Consensus 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09381v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09381v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kaoru Teranishi, Kiminao Kogiso, Takashi Tanaka
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose a protocol based on mechanism design theory and encrypted control
to solve average consensus problems among rational and strategic agents while
preserving their privacy. The proposed protocol provides a mechanism that
incentivizes the agents to faithfully implement the intended behavior specified
in the protocol. Furthermore, the protocol runs over encrypted data using
homomorphic encryption and secret sharing to protect the privacy of agents. We
also analyze the security of the proposed protocol using a simulation paradigm
in secure multi-party computation. The proposed protocol demonstrates that
mechanism design and encrypted control can complement each other to achieve
security under rational adversaries.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 2 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ HOPS: High-order Polynomials with Self-supervised Dimension Reduction
  for Load Forecasting 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.10637v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.10637v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pengyang Song, Han Feng, Shreyashi Shukla, Jue Wang, Tao Hong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Load forecasting is a fundamental task in smart grid. Many techniques have
been applied to developing load forecasting models. Due to the challenges such
as the Curse of Dimensionality, overfitting, and limited computing resources,
multivariate higher-order polynomial models have received limited attention in
load forecasting, despite their desirable mathematical foundations and
optimization properties. In this paper, we propose low rank approximation and
self-supervised dimension reduction to address the aforementioned issues. To
further improve computational efficiency, we also utilize a fast Conjugate
Gradient based algorithm for the proposed polynomial models. Based on the load
datasets from the ISO New England, the proposed method high-order polynomials
with self-supervised dimension reduction (HOPS) demonstrates higher forecasting
accuracy over several competitive models. Additionally, experimental results
indicate that our approach alleviates redundant variable construction,
achieving better forecasts with fewer input variables.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Optimization and Control <span class="chip" style="font-size: 60%">36</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Representation Theorems for Convex Expectations and Semigroups on Path
  Space 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10572v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10572v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        David Criens, Michael Kupper
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The objective of this paper is to investigate the connection between penalty
functions from stochastic optimal control, convex semigroups from analysis and
convex expectations from probability theory. Our main result provides a
one-to-one relation between these objects. As an application, we use the
representation via penality functions and duality arguments to show that convex
expectations are determined by their finite dimensional distributions. To
illustrate this structural result, we show that Hu and Peng's axiomatic
description of $G$-L\'evy processes in terms of finite dimensional
distributions extends uniquely to the control approach introduced by Neufeld
and Nutz. Finally, we show that convex expectations with a Markovian structure
are fully determined by their one-dimensional distributions, which give rise to
a classical semigroup on the state space.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The Lagrangian Method for Solving Constrained Markov Games 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10561v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10561v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Soham Das, Santiago Paternain, Luiz F. O. Chamon, Ceyhun Eksin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose the concept of a Lagrangian game to solve constrained Markov
games. Such games model scenarios where agents face cost constraints in
addition to their individual rewards, that depend on both agent joint actions
and the evolving environment state over time. Constrained Markov games form the
formal mechanism behind safe multiagent reinforcement learning, providing a
structured model for dynamic multiagent interactions in a multitude of
settings, such as autonomous teams operating under local energy and time
constraints, for example. We develop a primal-dual approach in which agents
solve a Lagrangian game associated with the current Lagrange multiplier,
simulate cost and reward trajectories over a fixed horizon, and update the
multiplier using accrued experience. This update rule generates a new
Lagrangian game, initiating the next iteration. Our key result consists in
showing that the sequence of solutions to these Lagrangian games yields a
nonstationary Nash solution for the original constrained Markov game.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Unified Dual Consensus Approach to Distributed <span class="highlight-title">Optimization</span> with
  Globally-Coupled Constraints 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10534v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10534v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zixuan Liu, Xuyang Wu, Dandan Wang, Jie Lu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This article explores distributed convex optimization with globally-coupled
constraints, where the objective function is a general nonsmooth convex
function, the constraints include nonlinear inequalities and affine equalities,
and the feasible region is possibly unbounded. To address such problems, a
unified DUal Consensus Algorithm (DUCA) and its proximal variant (Pro-DUCA) are
proposed, which are unified frameworks that approximate the method of
multipliers applied to the corresponding dual problem in no need of a
closed-form dual objective. With varied parameter settings, DUCA and Pro-DUCA
not only extend a collection of existing consensus optimization methods to
solve the dual problem that they used to be inapplicable to, but also aid in
offering new efficient algorithms to the literature. The proposed unified
algorithms are shown to achieve $O(1/k)$ convergence rates in terms of
optimality and feasibility, providing new or enhanced convergence results for a
number of existing methods. Simulations demonstrate that these algorithms
outperform several state-of-the-art alternatives in terms of objective and
feasibility errors.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages, 1 figure</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Rank-One-Update Method for the Training of Support Vector Machines 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10482v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10482v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Florian Jarre
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper considers convex quadratic programs
  associated with the training of support vector machines (SVM).
  Exploiting the special structure of the SVM problem a new
  type of active set method with long cycles and stable rank-one-updates
  is proposed and tested (CMU: cycling method with updates).
  The structure of the problem allows for a repeated simple increase
  of the set of inactive constraints while controlling its size. This is
  followed by minimization steps with cheap updates of a matrix factorization.
  A widely used approach for solving SVM problems is the
  alternating direction method SMO,
  a method that is very efficient for low accuracy.
  The new active set approach allows for higher accuracy
  results at moderate computational cost. To relate both approaches,
  the effect of the accuracy on the running time and on the
  predictive quality of the SVM is compared with some numerical examples.
  A surprising result of the numerical examples is that only a
  very small number of cycles (each consisting of less than 2n
  steps) was used for CMU.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>21 pages, 2 Figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ <span class="highlight-title">Optimization</span> techniques for modeling with piecewise-linear functions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10405v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10405v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Péter Dobrovoczki, Tamás Kis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper we aim to construct piecewise-linear (PWL) approximations for
functions of multiple variables and to build compact mixed-integer linear
programming (MILP) formulations to represent the resulting PWL function. On the
one hand, we describe a simple heuristic to iteratively construct a
triangulation with a small number of triangles, while decreasing the error of
the piecewise-linear approximation. On the other hand, we extend known
techniques for modeling PWLs in MILPs more efficiently than state-of-the-art
methods permit. The crux of our method is that the MILP model is a result of
solving some hard combinatorial optimization problems, for which we present
heuristic algorithms. The effectiveness of our techniques is demonstrated by a
series of computational experiments including a short-term hydropower
scheduling problem
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>23 pages, 6 figures, submitted to INFORMS Journal on Computing</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ State-Dependent Uncertainty Modeling in Robust Optimal Control Problems
  through Generalized Semi-Infinite Programming 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10389v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10389v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        J. Wehbeh, E. C. Kerrigan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generalized semi-infinite programs (generalized SIPs) are problems featuring
a finite number of decision variables but an infinite number of constraints.
They differ from standard SIPs in that their constraint set itself depends on
the choice of the decision variable. Generalized SIPs can be used to model
robust optimal control problems where the uncertainty itself is a function of
the state or control input, allowing for a less conservative alternative to
assuming a uniform uncertainty set over the entire decision space. In this
work, we demonstrate how any generalized SIP can be converted to an
existence-constrained SIP through a reformulation of the constraints and solved
using a local reduction approach, which approximates the infinite constraint
set by a finite number of scenarios. This transformation is then exploited to
solve nonlinear robust optimal control problems with state-dependent
uncertainties. We showcase our proposed approach on a planar quadrotor
simulation where it recovers the true generalized SIP solution and outperforms
a SIP-based approach with uniform uncertainty bounds.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to the 2025 Mediteranean Control Conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Stochastic Gradient Descent for Constrained <span class="highlight-title">Optimization</span> based on
  Adaptive Relaxed Barrier Functions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10384v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10384v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Naum Dimitrieski, Jing Cao, Christian Ebenbauer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents a novel stochastic gradient descent algorithm for
constrained optimization. The proposed algorithm randomly samples constraints
and components of the finite sum objective function and relies on a relaxed
logarithmic barrier function that is appropriately adapted in each optimization
iteration. For a strongly convex objective function and affine inequality
constraints, step-size rules and barrier adaptation rules are established that
guarantee asymptotic convergence with probability one. The theoretical results
in the paper are complemented by numerical studies which highlight potential
advantages of the proposed algorithm for optimization problems with a large
number of constraints.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>A short version of this work will be submitted to IEEE Control
  Systems Letters (L-CSS)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Safe exploration in reproducing kernel Hilbert spaces 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10352v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10352v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Abdullah Tokmak, Kiran G. Krishnan, Thomas B. Schön, Dominik Baumann
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Popular safe Bayesian optimization (BO) algorithms learn control policies for
safety-critical systems in unknown environments. However, most algorithms make
a smoothness assumption, which is encoded by a known bounded norm in a
reproducing kernel Hilbert space (RKHS). The RKHS is a potentially
infinite-dimensional space, and it remains unclear how to reliably obtain the
RKHS norm of an unknown function. In this work, we propose a safe BO algorithm
capable of estimating the RKHS norm from data. We provide statistical
guarantees on the RKHS norm estimation, integrate the estimated RKHS norm into
existing confidence intervals and show that we retain theoretical guarantees,
and prove safety of the resulting safe BO algorithm. We apply our algorithm to
safely optimize reinforcement learning policies on physics simulators and on a
real inverted pendulum, demonstrating improved performance, safety, and
scalability compared to the state-of-the-art.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to AISTATS 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Efficient Diffusion Posterior Sampling for Noisy Inverse Problems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10237v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10237v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ji Li, Chao Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The pretrained diffusion model as a strong prior has been leveraged to
address inverse problems in a zero-shot manner without task-specific
retraining. Different from the unconditional generation, the measurement-guided
generation requires estimating the expectation of clean image given the current
image and the measurement. With the theoretical expectation expression, the
crucial task of solving inverse problems is to estimate the noisy likelihood
function at the intermediate image sample. Using the Tweedie's formula and the
known noise model, the existing diffusion posterior sampling methods perform
gradient descent step with backpropagation through the pretrained diffusion
model. To alleviate the costly computation and intensive memory consumption of
the backpropagation, we propose an alternative maximum-a-posteriori (MAP)-based
surrogate estimator to the expectation. With this approach and further density
approximation, the MAP estimator for linear inverse problem is the solution to
a traditional regularized optimization, of which the loss comprises of data
fidelity term and the diffusion model related prior term. Integrating the MAP
estimator into a general denoising diffusion implicit model (DDIM)-like
sampler, we achieve the general solving framework for inverse problems. Our
approach highly resembles the existing $\Pi$GDM without the manifold projection
operation of the gradient descent direction. The developed method is also
extended to nonlinear JPEG decompression. The performance of the proposed
posterior sampling is validated across a series of inverse problems, where both
VP and VE SDE-based pretrained diffusion models are taken into consideration.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Spectral Projected Gradient Method for Computational Protein Design
  problem 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10203v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10203v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yukai Zheng, Qingna Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we consider the computational protein design (CPD) problem,
which is usually modeled as 0/1 programming and is extremely challenging due to
its combinatorial properties. As a quadratic semi-assignment problem (QSAP),
the CPD problem has been proved to be equivalent to its continuous relaxation
problem (RQSAP), in terms of sharing the same optimal objective value. However,
since the current algorithm for solving this RQSAP uses the projected Newton
method, which requires direct computation of the Hessian matrix, its
computational cost remains quite high. Precisely for this reason, we choose to
employ the spectral projected gradient (SPG) method to solve the CPD problem,
whose effectiveness relies on choosing the step lengths according to novel
ideas that are related to the spectrum of the underlying local Hessian.
Specifically, we apply the SPG method in two distinct ways: direct solving the
relaxation problem and applying a penalty method. Numerical results on
benchmark instances verify the superior performance of our approach over the
current algorithms in both quality and efficiency.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Theorems of nonlinear separation of co-radiant sets and optimality
  conditions for approximate and proper approximate solutions of vector
  <span class="highlight-title">optimization</span> problems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10193v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10193v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fernando García-Castaño, Miguel Ángel Melguizo-Padial
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper deals with \(\epsilon\)-efficient and \(\epsilon\)-proper
efficient points with respect to a co-radiant set in a vector optimization
problem. In the first part of the paper, we establish a new nonlinear
separation theorem for co-radiant sets in normed spaces. Subsequently, we
obtain necessary and sufficient conditions by means of scalarization for both
\(\epsilon\)-efficient and \(\epsilon\)-proper efficient points in a general
framework, without any requirements on the co-radiant set or any convexity
assumption on the sets under consideration.Consequently, our results have a
wider range of applicability than previously stated in the literature.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On relationships between symmetric and non-symmetric cone separation
  based on Bishop-Phelps separating cones in real normed spaces 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10184v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10184v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fernando García-Castaño, Christian Günther, M. A. Melguizo-Padial, Christiane Tammer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we study relationships between symmetric and non-symmetric
separation of (not necessarily convex) cones by using separating cones of
Bishop-Phelps type in real normed spaces. Besides extending some known results
for the non-symmetric cone separation approach, we propose a new symmetric cone
separation approach and establish cone separation results for it by using some
cone separation results obtained for the non-symmetric cone separation approach
twice (by swapping the roles of the cones). In addition to specifically
emphasizing the results for the convex case, we also present some existence
results for (bounded) convex bases of convex cones. Finally, we highlight some
applications of symmetric and non-symmetric cone separation in optimization.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Sensitivity-Based Distributed Programming for Non-Convex <span class="highlight-title">Optimization</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10174v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10174v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Maximilian Pierer von Esch, Andreas Völz, Knut Graichen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents a novel sensitivity-based distributed programming (SBDP)
approach for non-convex, large-scale nonlinear programs (NLP). The algorithm
relies on first-order sensitivities to cooperatively solve the central NLP in a
distributed manner with only neighbor-to-neighbor communication and
parallelizable local computations. The scheme is based on primal decomposition
and offers minimal algorithmic complexity. We derive sufficient local
convergence conditions for non-convex problems. Furthermore, we consider the
SBDP method in a distributed optimal control context and derive favorable
convergence properties in this setting. We illustrate these theoretical
findings and the performance of the proposed algorithm with simulations of
various distributed optimization and control problems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Safety Control of Impulsive Systems with Control Barrier Functions and
  Adaptive Gains 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10164v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10164v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zihan Liu, Yuan-Hua Ni
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper addresses the safety challenges in impulsive systems, where abrupt
state jumps introduce significant complexities into system dynamics. A unified
framework is proposed by integrating Quadratic Programming (QP), Control
Barrier Functions (CBFs), and adaptive gain mechanisms to ensure system safety
during impulsive events. The CBFs are constructed to enforce safety constraints
by capturing the system's continuous dynamics and the effects of impulsive
state transitions. An adaptive gain mechanism dynamically adjusts control
inputs based on the magnitudes of the impulses and the system's proximity to
safety boundaries, maintaining safety during instantaneous state jumps. A
tailored QP formulation incorporates CBFs constraints and adaptive gain
adjustments, optimizing control inputs while ensuring compliance with
safety-critical requirements. Theoretical analysis establishes the boundedness,
continuity, and feasibility of the adaptive gain and the overall framework. The
effectiveness of the method is demonstrated through simulations on a robotic
manipulator, showcasing its practical applicability to impulsive systems with
state jumps.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 1 figure</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Asymmetric Long-Step Primal-Dual Interior-Point Methods with Dual
  Centering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10155v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10155v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yurii Nesterov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we develop a new asymmetric framework for solving primal-dual
problems of Conic Optimization by Interior-Point Methods (IPMs). It allows
development of efficient methods for problems, where the dual formulation is
simpler than the primal one. The problems of this type arise, in particular, in
Semidefinite Optimization (SDO), for which we propose a new method with very
attractive computational cost. Our long-step predictor-corrector scheme is
based on centering in the dual space. It computes the affine-scaling predicting
direction by the use of the dual barrier function, controlling the tangent step
size by a functional proximity measure. We show that for symmetric cones, the
search procedure at the predictor step is very cheap.
  In general, we do not need sophisticated Linear Algebra, restricting
ourselves only by Cholesky factorization. However, our complexity bounds
correspond to the best known polynomial-time results. Moreover, for symmetric
cones the bounds automatically depend on the minimal barrier parameter between
the primal or the dual feasible sets. We show by SDO-examples that the
corresponding gain can be very big.
  We argue that the dual framework is more suitable for adjustment to the
actual complexity of the problem. As an example, we discuss some classes of
SDO-problems, where the number of iterations is proportional to the square root
of the number of linear equality constraints. Moreover, the computational cost
of one iteration there is similar to that one for Linear Optimization. We
support our theoretical developments by preliminary but encouraging numerical
results with randomly generated SDO-problems of different size.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>42 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Are Convex <span class="highlight-title">Optimization</span> Curves Convex? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10138v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10138v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guy Barzilai, Ohad Shamir
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we study when we might expect the optimization curve induced
by gradient descent to be \emph{convex} -- precluding, for example, an initial
plateau followed by a sharp decrease, making it difficult to decide when
optimization should stop. Although such undesirable behavior can certainly
occur when optimizing general functions, might it also occur in the benign and
well-studied case of smooth convex functions? As far as we know, this question
has not been tackled in previous work. We show, perhaps surprisingly, that the
answer crucially depends on the choice of the step size. In particular, for the
range of step sizes which are known to result in monotonic convergence to an
optimal value, there is a regime where the optimization curve will be provably
convex, and there is a regime where the curve can be non-convex. We also extend
our results to gradient flow, and to the closely-related but different question
of whether the gradient norm decreases monotonically.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ An LiGME Regularizer of Designated Isolated Minimizers -- An Application
  to Discrete-Valued Signal Estimation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10126v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10126v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Satoshi Shoji, Wataru Yata, Keita Kume, Isao Yamada
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  For a regularized least squares estimation of discrete-valued signals, we
propose an LiGME regularizer, as a nonconvex regularizer, of designated
isolated minimizers. The proposed regularizer is designed as a Generalized
Moreau Enhancement (GME) of the so-called SOAV convex regularizer. Every
candidate vector in the discrete-valued set is aimed to be assigned to an
isolated local minimizer of the proposed regularizer while the overall
convexity of the regularized least squares model is maintained. Moreover, a
global minimizer of the proposed model can be approximated iteratively by using
a variant of cLiGME algorithm. To enhance the accuracy of the proposed
estimation, we also propose a pair of simple modifications, called respectively
an iterative reweighting and a generalized superiorization. Numerical
experiments demonstrate the effectiveness of the proposed model and algorithms
in a scenario of MIMO signal detection.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Revisiting Multi-Agent Asynchronous Online <span class="highlight-title">Optimization</span> with Delays: the
  Strongly Convex Case 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10013v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10013v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lingchan Bao, Tong Wei, Yuanyu Wan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We revisit multi-agent asynchronous online optimization with delays, where
only one of the agents becomes active for making the decision at each round,
and the corresponding feedback is received by all the agents after unknown
delays. Although previous studies have established an $O(\sqrt{dT})$ regret
bound for this problem, they assume that the maximum delay $d$ is knowable or
the arrival order of feedback satisfies a special property, which may not hold
in practice. In this paper, we surprisingly find that when the loss functions
are strongly convex, these assumptions can be eliminated, and the existing
regret bound can be significantly improved to $O(d\log T)$ meanwhile.
Specifically, to exploit the strong convexity of functions, we first propose a
delayed variant of the classical follow-the-leader algorithm, namely FTDL,
which is very simple but requires the full information of functions as
feedback. Moreover, to handle the more general case with only the gradient
feedback, we develop an approximate variant of FTDL by combining it with
surrogate loss functions. Experimental results show that the approximate FTDL
outperforms the existing algorithm in the strongly convex case.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ OR-LLM-Agent: Automating Modeling and Solving of Operations Research
  <span class="highlight-title">Optimization</span> Problem with Reasoning Large Language Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10009v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10009v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bowen Zhang, Pengcheng Luo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Operations Research (OR) has been widely applied in various fields such as
resource allocation, production planning, and supply chain management. However,
addressing real-world OR problems requires OR experts to perform mathematical
modeling and programmers to develop solution algorithms. This traditional
method, heavily reliant on experts, is costly and has long development cycles,
severely limiting the widespread adoption of OR techniques. Few have considered
using Artificial Intelligence (AI) to replace professionals to achieve fully
automated solutions for OR problems. We propose OR-LLM-Agent, the first AI
agent that enables end-to-end automation for solving real-world OR problems.
OR-LLM-Agent leverages the Chain-of-Thought (CoT) reasoning capabilities of
Large Language Models (LLMs) to translate natural language problem descriptions
into formal mathematical models and automatically generate Gurobi solver code.
In OR-LLM-Agent, OR-CodeAgent is designed to automate code execution and repair
within a sandbox environment, facilitating the derivation of the final
solution. Due to the lack of dedicated benchmark datasets for evaluating the
automated solving of OR problems, we construct a benchmark dataset comprising
83 real-world OR problems described in natural language. We conduct comparative
experiments with state-of-the-art (SOTA) reasoning LLMs, including GPT-o3-mini,
DeepSeek-R1, and Gemini 2.0 Flash Thinking. The OR-LLM-Agent achieved the
highest pass rate of 100% and the highest solution accuracy of 85%,
demonstrating the feasibility of automated OR problem-solving. Data and code
have been publicly available at https://github.com/bwz96sco/or_llm_agent.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On Persistently Resetting Learning Integrators: A Framework For
  Model-Free Feedback <span class="highlight-title">Optimization</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10006v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10006v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mahmoud Abdelgalil, Jorge I. Poveda
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study a novel class of algorithms for solving model-free feedback
optimization problems in dynamical systems. The key novelty is the introduction
of \emph{persistent resetting learning integrators} (PRLI), which are
integrators that are reset at the same frequency at which the plant is dithered
using exploratory signals for model-free optimization. It is shown that PRLIs
can serve as core mechanisms for real-time gradient estimation in online
feedback-optimization tasks where only cost function measurements are
available. In particular, unlike existing approaches based on approximation
theory, such as averaging or finite-differences, PRLIs can produce global
real-time gradient estimates of cost functions, with uniformly bounded
perturbations of arbitrarily small magnitude. In this sense, PRLIs function as
robust \emph{hybrid} "Oracles" suitable for interconnection with discrete-time
optimization algorithms that optimize the performance of continuous-time
dynamical plants in closed-loop operation. Compared to existing methods, PRLIs
yield \emph{global} stability properties for a broad class of cost functions,
surpassing the local or semi-global guarantees offered by traditional
approaches based on perturbation and approximation theory. The proposed
framework naturally bridges physical systems, modeled as continuous-time plants
where continuous exploration is essential, with digital algorithms, represented
as discrete-time optimization methods. The main results are illustrated using
different numerical examples.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         <span class="highlight-title">★</span> Adaptive Moment Estimation <span class="highlight-title">Optimization</span> Algorithm Using Projection
  Gradient for Deep Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10005v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10005v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yongqi Li, Xiao<span class="highlight-author">wei Zhang</span>
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Training deep neural networks is challenging. To accelerate training and
enhance performance, we propose PadamP, a novel optimization algorithm. PadamP
is derived by applying the adaptive estimation of the p-th power of the
second-order moments under scale invariance, enhancing projection adaptability
by modifying the projection discrimination condition. It is integrated into
Adam-type algorithms, accelerating training, boosting performance, and
improving generalization in deep learning. Combining projected gradient
benefits with adaptive moment estimation, PadamP tackles unconstrained
non-convex problems. Convergence for the non-convex case is analyzed, focusing
on the decoupling of first-order moment estimation coefficients and
second-order moment estimation coefficients. Unlike prior work relying on , our
proof generalizes the convergence theorem, enhancing practicality. Experiments
using VGG-16 and ResNet-18 on CIFAR-10 and CIFAR-100 show PadamP's
effectiveness, with notable performance on CIFAR-10/100, especially for VGG-16.
The results demonstrate that PadamP outperforms existing algorithms in terms of
convergence speed and generalization ability, making it a valuable addition to
the field of deep learning optimization.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Accuracy of Discretely Sampled Stochastic Policies in Continuous-time
  Reinforcement Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09981v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09981v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yanwei Jia, Du Ouyang, Yufei Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Stochastic policies are widely used in continuous-time reinforcement learning
algorithms. However, executing a stochastic policy and evaluating its
performance in a continuous-time environment remain open challenges. This work
introduces and rigorously analyzes a policy execution framework that samples
actions from a stochastic policy at discrete time points and implements them as
piecewise constant controls. We prove that as the sampling mesh size tends to
zero, the controlled state process converges weakly to the dynamics with
coefficients aggregated according to the stochastic policy. We explicitly
quantify the convergence rate based on the regularity of the coefficients and
establish an optimal first-order convergence rate for sufficiently regular
coefficients. Additionally, we show that the same convergence rates hold with
high probability concerning the sampling noise, and further establish a
$1/2$-order almost sure convergence when the volatility is not controlled.
Building on these results, we analyze the bias and variance of various policy
evaluation and policy gradient estimators based on discrete-time observations.
Our results provide theoretical justification for the exploratory stochastic
control framework in [H. Wang, T. Zariphopoulou, and X.Y. Zhou, J. Mach. Learn.
Res., 21 (2020), pp. 1-34].
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Hovering Flight in Flapping Insects and Hummingbirds: A Natural
  Real-Time and Stable Extremum Seeking Feedback System 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.04985v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.04985v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ahmed A. Elgohary, Sameh A. Eisa
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we take an initial and novel step towards characterizing the
physical phenomenon of hovering flight as an extremum seeking (ES) feedback
system. We anticipate that said novel characterization may start a new line of
research that can potentially solve all the puzzle pieces of hovering flight
that existed for decades in previous literature. Is hovering flight stable? If
so, what is the control mechanism utilized by insects/hummingbirds to achieve
stable hovering? If such a mechanism exists, does it fit the biological
constraints that insects/hummingbirds have limited computational abilities?
Does it fit the experimental biology narrative that insects/hummingbirds rely
mainly on their sensation to stabilize hovering? Our ES characterization and
analysis provide for the first time a simple, model-free, real-time, stable
feedback system of hovering. Consistent with natural observations and
biological experiments, hovering via ES is simply achievable by the natural
oscillations of the wing angle and measuring (sensing) altitude or
acceleration. We provide simulation trials, including comparisons with some
approaches from literature, to demonstrate the effectiveness of our results. We
used literature data for hawkmoth, cranefly, bumblebee, dragonfly, hoverfly,
and a hummingbird.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Differentiation of inertial methods for optimizing smooth parametric
  function 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.00522v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.00522v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jean-Jacques Godeme
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we consider the minimization of a $C^2-$smooth and strongly
convex objective depending on a given parameter, which is usually found in many
practical applications. We suppose that we desire to solve the problem with
some inertial methods which cover a broader existing well-known inertial
methods. Our main goal is to analyze the derivative of this algorithm as an
infinite iterative process in the sense of ``automatic'' differentiation. This
procedure is very common and has gain more attention recently. From a pure
optimization perspective and under some mild premises, we show that any
sequence generated by these inertial methods converge to the unique minimizer
of the problem, which depends on the parameter. Moreover, we show a local
linear convergence rate of the generated sequence. Concerning the
differentiation of the scheme, we prove that the derivative of the sequence
with respect to the parameter converges to the derivative of the limit of the
sequence showing that any sequence is <<derivative stable>>. Finally, we
investigate the rate at which the convergence occurs. We show that, this is
locally linear with an error term tending to zero.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Barrier Function Approach for Bilevel <span class="highlight-title">Optimization</span> with Coupled
  Lower-Level Constraints: Formulation, Approximation and Algorithms 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10670v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10670v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaotian Jiang, Jiaxiang Li, Mingyi Hong, Shuzhong Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we consider bilevel optimization problem where the lower-level
has coupled constraints, i.e. the constraints depend both on the upper- and
lower-level variables. In particular, we consider two settings for the
lower-level problem. The first is when the objective is strongly convex and the
constraints are convex with respect to the lower-level variable; The second is
when the lower-level is a linear program. We propose to utilize a barrier
function reformulation to translate the problem into an unconstrained problem.
By developing a series of new techniques, we proved that both the hyperfunction
value and hypergradient of the barrier reformulated problem (uniformly)
converge to those of the original problem under minimal assumptions. Further,
to overcome the non-Lipschitz smoothness of hyperfunction and lower-level
problem for barrier reformulated problems, we design an adaptive algorithm that
ensures a non-asymptotic convergence guarantee. We also design an algorithm
that converges to the stationary point of the original problem asymptotically
under certain assumptions. The proposed algorithms require minimal assumptions,
and to our knowledge, they are the first with convergence guarantees when the
lower-level problem is a linear program. Numerical experiments are conducted to
show the effectiveness of the proposed method.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Complexity results and active-set identification of a derivative-free
  method for bound-constrained problems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.10801v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.10801v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Andrea Brilli, Andrea Cristofari, Giampaolo Liuzzi, Stefano Lucidi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we analyze a derivative-free line search method designed for
bound-constrained problems. Our analysis demonstrates that this method exhibits
a worst-case complexity comparable to other derivative-free methods for
unconstrained and linearly constrained problems. In particular, when minimizing
a function with $n$ variables, we prove that at most ${\cal O(n\epsilon^{-2})}$
iterations are needed to drive a criticality measure below a predefined
threshold $\epsilon$, requiring at most ${\cal O(n^2\epsilon^{-2})}$ function
evaluations. We also show that the total number of iterations where the
criticality measure is not below $\epsilon$ is upper bounded by ${\cal
O(n^2\epsilon^{-2})}$. Moreover, we investigate the method capability to
identify active constraints at the final solutions. We show that, after a
finite number of iterations, all the active constraints satisfying the strict
complementarity condition are correctly identified.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Underapproximating Safe Domains of Attraction for Discrete-Time Systems
  Using Implicit Representations of Backward Reachable Sets 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.10657v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.10657v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohamed Serry, Jun Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Analyzing and certifying stability and attractivity of nonlinear systems is a
topic of research interest that has been extensively investigated by control
theorists and engineers for many years. Despite that, accurately estimating
domains of attraction for nonlinear systems remains a challenging task, where
available estimation approaches are either conservative or limited to
low-dimensional systems. In this work, we propose an iterative approach to
accurately underapproximate safe (i.e., state-constrained) domains of
attraction for general discrete-time autonomous nonlinear systems. Our approach
relies on implicit representations of safe backward reachable sets of safe
regions of attraction, where such regions can be be easily constructed using,
e.g., quadratic Lyapunov functions. The iterations of our approach are
monotonic (in the sense of set inclusion), where each iteration results in a
safe region of attraction, given as a sublevel set, that underapproximates the
safe domain of attraction. The sublevel set representations of the resulting
regions of attraction can be efficiently utilized in verifying the inclusion of
given points of interest in the safe domain of attraction. We illustrate our
approach through two numerical examples, involving two- and four-dimensional
nonlinear systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This updated manuscript corrects errors in the formulas for the
  bounds used in computing ellipsoidal regions of attraction</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Unified Feedback Linearization for Nonlinear Systems with Dexterous and
  Energy-Saving Modes 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.20524v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.20524v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mirko Mizzoni, Pieter van Goor, Antonio Franchi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Systems with a high number of inputs compared to the degrees of freedom (e.g.
a mobile robot with Mecanum wheels) often have a minimal set of
energy-efficient inputs needed to achieve a main task (e.g. position tracking)
and a set of energy-intense inputs needed to achieve an additional auxiliary
task (e.g. orientation tracking). This letter presents a unified control
scheme, derived through feedback linearization, that can switch between two
modes: an energy-saving mode, which tracks the main task using only the
energy-efficient inputs while forcing the energy-intense inputs to zero, and a
dexterous mode, which also uses the energy-intense inputs to track the
auxiliary task as needed. The proposed control guarantees the exponential
tracking of the main task and that the dynamics associated with the main task
evolve independently of the a priori unknown switching signal. When the control
is operating in dexterous mode, the exponential tracking of the auxiliary task
is also guaranteed. Numerical simulations on an omnidirectional Mecanum wheel
robot validate the effectiveness of the proposed approach and demonstrate the
effect of the switching signal on the exponential tracking behavior of the main
and auxiliary tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Exploring near-optimal energy systems with stakeholders: a novel
  approach for participatory modelling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.05280v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.05280v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Oskar Vågerö, Koen van Greevenbroek, Aleksander Grochowicz, Maximilian Roithner
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Involving people in energy systems planning can increase the legitimacy and
socio-political feasibility of energy transitions. Participatory research in
energy modelling offers the opportunity to engage with stakeholders in a
comprehensive way, but is limited by how results can be generated and presented
without imposing assumptions and discrete scenarios on the participants. To
this end, we present a methodology and a framework, based on near-optimal
modelling results, that can incorporate stakeholders in a holistic and engaging
way. We confront stakeholders with a continuum of modelling-based energy system
designs via an interactive interface allowing them to choose essentially any
combination of components that meet the system requirements. Together with
information on the implications of different technologies, it is possible to
assess how participants prioritise different aspects in energy systems planning
while also facilitating learning in an engaging and stimulating way. We
showcase the methodology for the remote Arctic settlement of Longyearbyen and
illustrate how participants deviate consistently from the cost optimum. At the
same time, they manage to balance different priorities such as emissions,
costs, and system vulnerability leading to a better understanding of the
complexity and intertwined nature of decisions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>24 pages, 7 figures and 3 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Distributed Computing for Huge-Scale Linear Programming 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.06204v6">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.06204v6.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Luoyi Tao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study develops an algorithm for distributed computing of linear
programming problems of huge-scales. Global consensus with single common
variable, multiblocks, and augmented Lagrangian are adopted. The consensus is
used to partition the constraints of equality and inequality into
multi-consensus blocks, and the subblocks of each consensus block are employed
to partition the primal variables into $M$ sets of disjoint subvectors. The
block-coordinate Gauss-Seidel method, the proximal point method, and ADMM are
used to update the primal variables, and descent models used to update the
dual. Convergence of the algorithm to optimal solution is shown and the rate of
convergence of the augmented Lagrangian sequence, of $O(1/k)$ is obtained,
under the dual sequences supposedly bounded. This boundedness of the dual
sequences needs to be ensured through adequate choice of the control parameter
values and initialization of the primal and dual sequences; further to help
resolve the issue, it is to be explored that explicit bounds are imposed for
the dual variables associated with the global consensus equality constraints.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages. Error related to the upper bound for the slack variables
  fixed. The issues of initialization and boundedness of the dual sequences are
  discussed</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Block cubic Newton with greedy selection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.18150v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.18150v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Andrea Cristofari
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A second-order block coordinate descent method is proposed for the
unconstrained minimization of an objective function with Lipschitz continuous
Hessian. At each iteration, a block of variables is selected by means of a
greedy (Gauss-Southwell) rule which considers the amount of first-order
stationarity violation, then an approximate minimizer of a cubic model is
computed for the block update. In the proposed scheme, blocks are not required
to have a prefixed structure and their size is allowed to change during the
iterations. For non-convex objective functions, global convergence to
stationary points is proved and a worst-case iteration complexity analysis is
provided. In particular, given a tolerance $\epsilon$, we show that at most
${\cal O(\epsilon^{-3/2})}$ iterations are needed to drive the stationarity
violation with respect to the selected block of variables below $\epsilon$,
while at most ${\cal O(\epsilon^{-2})}$ iterations are needed to drive the
stationarity violation with respect to all variables below $\epsilon$.
Numerical results are finally given.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Clipping Improves Adam-Norm and AdaGrad-Norm when the Noise Is
  Heavy-Tailed 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.04443v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.04443v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Savelii Chezhegov, Yaroslav Klyukin, Andrei Semenov, Aleksandr Beznosikov, Alexander Gasnikov, Samuel Horváth, Martin Takáč, Eduard Gorbunov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Methods with adaptive stepsizes, such as AdaGrad and Adam, are essential for
training modern Deep Learning models, especially Large Language Models.
Typically, the noise in the stochastic gradients is heavy-tailed for the later
ones. Gradient clipping provably helps to achieve good high-probability
convergence for such noises. However, despite the similarity between
AdaGrad/Adam and Clip-SGD, the current understanding of the high-probability
convergence of AdaGrad/Adam-type methods is limited in this case. In this work,
we prove that AdaGrad/Adam (and their delayed version) can have provably bad
high-probability convergence if the noise is heavy-tailed. We also show that
gradient clipping fixes this issue, i.e., we derive new high-probability
convergence bounds with polylogarithmic dependence on the confidence level for
AdaGrad-Norm and Adam-Norm with clipping and with/without delay for smooth
convex/non-convex stochastic optimization with heavy-tailed noise. Our
empirical evaluations highlight the superiority of clipped versions of
AdaGrad/Adam-Norm in handling the heavy-tailed noise.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>63 pages, 8 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Coalescing Force of Group Pressure: Consensus in Nonlinear Opinion
  Dynamics 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04301v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04301v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Iryna Zabarianska, Anton V. Proskurnikov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This work extends the recent opinion dynamics model from Cheng et al.,
emphasizing the role of group pressure in consensus formation. We generalize
the findings to incorporate social influence algorithms with general
time-varying, opinion-dependent weights and multidimensional opinions, beyond
bounded confidence dynamics. We demonstrate that, with uniformly positive
conformity levels, group pressure consistently drives consensus and provide a
tighter estimate for the convergence rate. Unlike previous models, the common
public opinion in our framework can assume arbitrary forms within the convex
hull of current opinions, offering flexibility applicable to real-world
scenarios such as opinion polls with random participant selection. This
analysis provides deeper insights into how group pressure mechanisms foster
consensus under diverse conditions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Robust SGLD algorithm for solving non-convex distributionally robust
  optimisation problems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.09532v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.09532v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ariel Neufeld, Matthew Ng Cheng En, Ying Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper we develop a Stochastic Gradient Langevin Dynamics (SGLD)
algorithm tailored for solving a certain class of non-convex distributionally
robust optimisation (DRO) problems. By deriving non-asymptotic convergence
bounds, we build an algorithm which for any prescribed accuracy $\varepsilon>0$
outputs an estimator whose expected excess risk is at most $\varepsilon$. As a
concrete application, we consider the problem of identifying the best
non-linear estimator of a given regression model involving a neural network
using adversarially corrupted samples. We formulate this problem as a DRO
problem and demonstrate both theoretically and numerically the applicability of
the proposed robust SGLD algorithm. Moreover, numerical experiments show that
the robust SGLD estimator outperforms the estimator obtained using vanilla SGLD
in terms of test accuracy, which highlights the advantage of incorporating
model uncertainty when optimising with perturbed samples.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Prevailing against Adversarial Noncentral Disturbances: Exact Recovery
  of Linear Systems with the $l_1$-norm Estimator 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03218v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03218v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jihun Kim, Javad Lavaei
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper studies the linear system identification problem in the general
case where the disturbance is sub-Gaussian, correlated, and possibly
adversarial. First, we consider the case with noncentral (nonzero-mean)
disturbances for which the ordinary least-squares (OLS) method fails to
correctly identify the system. We prove that the $l_1$-norm estimator
accurately identifies the system under the condition that each disturbance has
equal probabilities of being positive or negative. This condition restricts the
sign of each disturbance but allows its magnitude to be arbitrary. Second, we
consider the case where each disturbance is adversarial with the model that the
attack times happen occasionally but the distributions of the attack values are
arbitrary. We show that when the probability of having an attack at a given
time is less than 0.5 and each attack spans the entire space in expectation,
the $l_1$-norm estimator prevails against any adversarial noncentral
disturbances and the exact recovery is achieved within a finite time. These
results pave the way to effectively defend against arbitrarily large noncentral
attacks in safety-critical systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 2 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Optimal Mechanisms for Demand Response: An Indifference Set Approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.07655v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.07655v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohammad Mehrabi, Omer Karaduman, Stefan Wager
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The time at which renewable (e.g., solar or wind) energy resources produce
electricity cannot generally be controlled. In many settings, however,
consumers have some flexibility in their energy consumption needs, and there is
growing interest in demand-response programs that leverage this flexibility to
shift energy consumption to better match renewable production -- thus enabling
more efficient utilization of these resources. We study optimal demand response
in a setting where consumers use home energy management systems (HEMS) to
autonomously adjust their electricity consumption. Our core assumption is that
HEMS operationalize flexibility by querying the consumer for their preferences
and computing the ``indifference set'' of all energy consumption profiles that
can be used to satisfy these preferences. Then, given an indifference set, HEMS
can respond to grid signals while guaranteeing user-defined comfort and
functionality; e.g., if a consumer sets a temperature range, a HEMS can precool
and preheat to align with peak renewable production, thus improving efficiency
without sacrificing comfort. We show that while price-based mechanisms are not
generally optimal for demand response, they become asymptotically optimal in
large markets under a mean-field limit. Furthermore, we show that optimal
dynamic prices can be efficiently computed in large markets by only querying
HEMS about their planned consumption under different price signals. Using an
OpenDSS-powered grid simulation for Phoenix, Arizona, we demonstrate that our
approach enables meaningful demand response without creating grid instability.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2025-03-12T00:00:00Z">2025-03-12</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Robotics <span class="chip" style="font-size: 60%">60</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CleverDistiller: Simple and Spatially Consistent Cross-modal
  Distillation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09878v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09878v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hariprasath Govindarajan, Maciej K. Wozniak, Marvin Klingner, Camille Maurice, B Ravi Kiran, Senthil Yogamani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision foundation models (VFMs) such as DINO have led to a paradigm shift in
2D camera-based perception towards extracting generalized features to support
many downstream tasks. Recent works introduce self-supervised cross-modal
knowledge distillation (KD) as a way to transfer these powerful generalization
capabilities into 3D LiDAR-based models. However, they either rely on highly
complex distillation losses, pseudo-semantic maps, or limit KD to features
useful for semantic segmentation only. In this work, we propose
CleverDistiller, a self-supervised, cross-modal 2D-to-3D KD framework
introducing a set of simple yet effective design choices: Unlike contrastive
approaches relying on complex loss design choices, our method employs a direct
feature similarity loss in combination with a multi layer perceptron (MLP)
projection head to allow the 3D network to learn complex semantic dependencies
throughout the projection. Crucially, our approach does not depend on
pseudo-semantic maps, allowing for direct knowledge transfer from a VFM without
explicit semantic supervision. Additionally, we introduce the auxiliary
self-supervised spatial task of occupancy prediction to enhance the semantic
knowledge, obtained from a VFM through KD, with 3D spatial reasoning
capabilities. Experiments on standard autonomous driving benchmarks for
2D-to-3D KD demonstrate that CleverDistiller achieves state-of-the-art
performance in both semantic segmentation and 3D object detection (3DOD) by up
to 10% mIoU, especially when fine tuning on really low data amounts, showing
the effectiveness of our simple yet powerful KD strategy
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Training Human-Robot Teams by Improving Transparency Through a Virtual
  Spectator Interface <span class="chip">ICRA 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09849v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09849v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sean Dallas, Hongjiao Qiang, Motaz AbuHijleh, Wonse Jo, Kayla Riegner, Jon Smereka, Lionel Robert, Wing-Yue Louie, Dawn M. Tilbury
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  After-action reviews (AARs) are professional discussions that help operators
and teams enhance their task performance by analyzing completed missions with
peers and professionals. Previous studies that compared different formats of
AARs have mainly focused on human teams. However, the inclusion of robotic
teammates brings along new challenges in understanding teammate intent and
communication. Traditional AAR between human teammates may not be satisfactory
for human-robot teams. To address this limitation, we propose a new training
review (TR) tool, called the Virtual Spectator Interface (VSI), to enhance
human-robot team performance and situational awareness (SA) in a simulated
search mission. The proposed VSI primarily utilizes visual feedback to review
subjects' behavior. To examine the effectiveness of VSI, we took elements from
AAR to conduct our own TR, designed a 1 x 3 between-subjects experiment with
experimental conditions: TR with (1) VSI, (2) screen recording, and (3)
non-technology (only verbal descriptions). The results of our experiments
demonstrated that the VSI did not result in significantly better team
performance than other conditions. However, the TR with VSI led to more
improvement in the subjects SA over the other conditions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>7 pages, 4 figures, Accepted to ICRA 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SE(3)-Equivariant Robot Learning and Control: A Tutorial <span class="highlight-title">Survey</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09829v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09829v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Joohwan Seo, Soochul Yoo, Junwoo Chang, Hyunseok An, Hyunwoo Ryu, Soomi Lee, Arvind Kruthiventy, Jongeun CHoi, Roberto Horowitz
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in deep learning and Transformers have driven major
breakthroughs in robotics by employing techniques such as imitation learning,
reinforcement learning, and LLM-based multimodal perception and
decision-making. However, conventional deep learning and Transformer models
often struggle to process data with inherent symmetries and invariances,
typically relying on large datasets or extensive data augmentation. Equivariant
neural networks overcome these limitations by explicitly integrating symmetry
and invariance into their architectures, leading to improved efficiency and
generalization. This tutorial survey reviews a wide range of equivariant deep
learning and control methods for robotics, from classic to state-of-the-art,
with a focus on SE(3)-equivariant models that leverage the natural 3D
rotational and translational symmetries in visual robotic manipulation and
control design. Using unified mathematical notation, we begin by reviewing key
concepts from group theory, along with matrix Lie groups and Lie algebras. We
then introduce foundational group-equivariant neural network design and show
how the group-equivariance can be obtained through their structure. Next, we
discuss the applications of SE(3)-equivariant neural networks in robotics in
terms of imitation learning and reinforcement learning. The SE(3)-equivariant
control design is also reviewed from the perspective of geometric control.
Finally, we highlight the challenges and future directions of equivariant
methods in developing more robust, sample-efficient, and multi-modal real-world
robotic systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to International Journcal of Control, Automation and
  Systems (IJCAS), Under Review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Vi-LAD: Vision-Language Attention Distillation for Socially-Aware Robot
  <span class="highlight-title">Navigation</span> in Dynamic Environments 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09820v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09820v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohamed Elnoor, Kasun Weerakoon, Gershom Seneviratne, Jing Liang, Vignesh Rajagopal, Dinesh Manocha
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce Vision-Language Attention Distillation (Vi-LAD), a novel
approach for distilling socially compliant navigation knowledge from a large
Vision-Language Model (VLM) into a lightweight transformer model for real-time
robotic navigation. Unlike traditional methods that rely on expert
demonstrations or human-annotated datasets, Vi-LAD performs knowledge
distillation and fine-tuning at the intermediate layer representation level
(i.e., attention maps) by leveraging the backbone of a pre-trained
vision-action model. These attention maps highlight key navigational regions in
a given scene, which serve as implicit guidance for socially aware motion
planning. Vi-LAD fine-tunes a transformer-based model using intermediate
attention maps extracted from the pre-trained vision-action model, combined
with attention-like semantic maps constructed from a large VLM. To achieve
this, we introduce a novel attention-level distillation loss that fuses
knowledge from both sources, generating augmented attention maps with enhanced
social awareness. These refined attention maps are then utilized as a
traversability costmap within a socially aware model predictive controller
(MPC) for navigation. We validate our approach through real-world experiments
on a Husky wheeled robot, demonstrating significant improvements over
state-of-the-art (SOTA) navigation methods. Our results show up to 14.2% - 50%
improvement in success rate, which highlights the effectiveness of Vi-LAD in
enabling socially compliant and efficient robot navigation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Multi-Agent LLM Actor-Critic Framework for Social Robot <span class="highlight-title">Navigation</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09758v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09758v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Weizheng Wang, Ike Obi, Byung-Cheol Min
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in robotics and large language models (LLMs) have sparked
growing interest in human-robot collaboration and embodied intelligence. To
enable the broader deployment of robots in human-populated environments,
socially-aware robot navigation (SAN) has become a key research area. While
deep reinforcement learning approaches that integrate human-robot interaction
(HRI) with path planning have demonstrated strong benchmark performance, they
often struggle to adapt to new scenarios and environments. LLMs offer a
promising avenue for zero-shot navigation through commonsense inference.
However, most existing LLM-based frameworks rely on centralized
decision-making, lack robust verification mechanisms, and face inconsistencies
in translating macro-actions into precise low-level control signals. To address
these challenges, we propose SAMALM, a decentralized multi-agent LLM
actor-critic framework for multi-robot social navigation. In this framework, a
set of parallel LLM actors, each reflecting distinct robot personalities or
configurations, directly generate control signals. These actions undergo a
two-tier verification process via a global critic that evaluates group-level
behaviors and individual critics that assess each robot's context. An
entropy-based score fusion mechanism further enhances self-verification and
re-query, improving both robustness and coordination. Experimental results
confirm that SAMALM effectively balances local autonomy with global oversight,
yielding socially compliant behaviors and strong adaptability across diverse
multi-robot scenarios. More details and videos about this work are available
at: https://sites.google.com/view/SAMALM.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Distributionally Robust Multi-Agent Reinforcement Learning for Dynamic
  Chute Mapping 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09755v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09755v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guangyi Liu, Suzan Iloglu, Michael Caldara, Joseph W. Durham, Michael M. Zavlanos
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In Amazon robotic warehouses, the destination-to-chute mapping problem is
crucial for efficient package sorting. Often, however, this problem is
complicated by uncertain and dynamic package induction rates, which can lead to
increased package recirculation. To tackle this challenge, we introduce a
Distributionally Robust Multi-Agent Reinforcement Learning (DRMARL) framework
that learns a destination-to-chute mapping policy that is resilient to
adversarial variations in induction rates. Specifically, DRMARL relies on group
distributionally robust optimization (DRO) to learn a policy that performs well
not only on average but also on each individual subpopulation of induction
rates within the group that capture, for example, different seasonality or
operation modes of the system. This approach is then combined with a novel
contextual bandit-based predictor of the worst-case induction distribution for
each state-action pair, significantly reducing the cost of exploration and
thereby increasing the learning efficiency and scalability of our framework.
Extensive simulations demonstrate that DRMARL achieves robust chute mapping in
the presence of varying induction distributions, reducing package recirculation
by an average of 80\% in the simulation scenario.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SimLingo: Vision-Only Closed-Loop Autonomous Driving with
  Language-Action Alignment <span class="chip">CVPR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09594v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09594v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Katrin Renz, Long Chen, Elahe Arani, Oleg Sinavski
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Integrating large language models (LLMs) into autonomous driving has
attracted significant attention with the hope of improving generalization and
explainability. However, existing methods often focus on either driving or
vision-language understanding but achieving both high driving performance and
extensive language understanding remains challenging. In addition, the dominant
approach to tackle vision-language understanding is using visual question
answering. However, for autonomous driving, this is only useful if it is
aligned with the action space. Otherwise, the model's answers could be
inconsistent with its behavior. Therefore, we propose a model that can handle
three different tasks: (1) closed-loop driving, (2) vision-language
understanding, and (3) language-action alignment. Our model SimLingo is based
on a vision language model (VLM) and works using only camera, excluding
expensive sensors like LiDAR. SimLingo obtains state-of-the-art performance on
the widely used CARLA simulator on the Bench2Drive benchmark and is the winning
entry at the CARLA challenge 2024. Additionally, we achieve strong results in a
wide variety of language-related tasks while maintaining high driving
performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>CVPR 2025. 1st Place @ CARLA Challenge 2024. Challenge tech report
  (preliminary version of SimLingo): arXiv:2406.10165</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Action-Aware Pro-Active Safe Exploration for Mobile Robot Mapping 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09515v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09515v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aykut İşleyen, René van de Molengraft, Ömür Arslan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Safe autonomous exploration of unknown environments is an essential skill for
mobile robots to effectively and adaptively perform environmental mapping for
diverse critical tasks. Due to its simplicity, most existing exploration
methods rely on the standard frontier-based exploration strategy, which directs
a robot to the boundary between the known safe and the unknown unexplored
spaces to acquire new information about the environment. This typically follows
a recurrent persistent planning strategy, first selecting an informative
frontier viewpoint, then moving the robot toward the selected viewpoint until
reaching it, and repeating these steps until termination. However, exploration
with persistent planning may lack adaptivity to continuously updated maps,
whereas highly adaptive exploration with online planning often suffers from
high computational costs and potential issues with livelocks. In this paper, as
an alternative to less-adaptive persistent planning and costly online planning,
we introduce a new proactive preventive replanning strategy for effective
exploration using the immediately available actionable information at a
viewpoint to avoid redundant, uninformative last-mile exploration motion. We
also use the actionable information of a viewpoint as a systematic termination
criterion for exploration. To close the gap between perception and action, we
perform safe and informative path planning that minimizes the risk of collision
with detected obstacles and the distance to unexplored regions, and we apply
action-aware viewpoint selection with maximal information utility per total
navigation cost. We demonstrate the effectiveness of our action-aware proactive
exploration method in numerical simulations and hardware experiments.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15 pages, 10 figures, 4 algorithms, preprint version of a paper
  submitted to a journal publication</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Neural reservoir control of a soft bio-hybrid arm 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09477v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09477v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Noel Naughton, Arman Tekinalp, Keshav Shivam, Seung Hung Kim, Volodymyr Kindratenko, Mattia Gazzola
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A long-standing engineering problem, the control of soft robots is difficult
because of their highly non-linear, heterogeneous, anisotropic, and distributed
nature. Here, bridging engineering and biology, a neural reservoir is employed
for the dynamic control of a bio-hybrid model arm made of multiple
muscle-tendon groups enveloping an elastic spine. We show how the use of
reservoirs facilitates simultaneous control and self-modeling across a set of
challenging tasks, outperforming classic neural network approaches. Further, by
implementing a spiking reservoir on neuromorphic hardware, energy efficiency is
achieved, with nearly two-orders of magnitude improvement relative to standard
CPUs, with implications for the on-board control of untethered, small-scale
soft robots.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages; 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Online Language Splatting 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09447v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09447v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Saimouli Katragadda, Cho-Ying Wu, Yuliang Guo, Xinyu Huang, Guoquan Huang, Liu Ren
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  To enable AI agents to interact seamlessly with both humans and 3D
environments, they must not only perceive the 3D world accurately but also
align human language with 3D spatial representations. While prior work has made
significant progress by integrating language features into geometrically
detailed 3D scene representations using 3D Gaussian Splatting (GS), these
approaches rely on computationally intensive offline preprocessing of language
features for each input image, limiting adaptability to new environments. In
this work, we introduce Online Language Splatting, the first framework to
achieve online, near real-time, open-vocabulary language mapping within a
3DGS-SLAM system without requiring pre-generated language features. The key
challenge lies in efficiently fusing high-dimensional language features into 3D
representations while balancing the computation speed, memory usage, rendering
quality and open-vocabulary capability. To this end, we innovatively design:
(1) a high-resolution CLIP embedding module capable of generating detailed
language feature maps in 18ms per frame, (2) a two-stage online auto-encoder
that compresses 768-dimensional CLIP features to 15 dimensions while preserving
open-vocabulary capabilities, and (3) a color-language disentangled
optimization approach to improve rendering quality. Experimental results show
that our online method not only surpasses the state-of-the-art offline methods
in accuracy but also achieves more than 40x efficiency boost, demonstrating the
potential for dynamic and interactive AI applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Neural-Augmented Incremental Nonlinear Dynamic Inversion for Quadrotors
  with Payload Adaptation <span class="chip">IROS 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09441v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09441v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Eckart Cobo-Briesewitz, Khaled Wahba, Wolfgang Hönig
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The increasing complexity of multirotor applications has led to the need of
more accurate flight controllers that can reliably predict all forces acting on
the robot. Traditional flight controllers model a large part of the forces but
do not take so called residual forces into account. A reason for this is that
accurately computing the residual forces can be computationally expensive.
Incremental Nonlinear Dynamic Inversion (INDI) is a method that computes the
difference between different sensor measurements in order to estimate these
residual forces. The main issue with INDI is it's reliance on special sensor
measurements which can be very noisy. Recent work has also shown that residual
forces can be predicted using learning-based methods. In this work, we
demonstrate that a learning algorithm can predict a smoother version of INDI
outputs without requiring additional sensor measurements. In addition, we
introduce a new method that combines learning based predictions with INDI. We
also adapt the two approaches to work on quadrotors carrying a slung-type
payload. The results show that using a neural network to predict residual
forces can outperform INDI while using the combination of neural network and
INDI can yield even better results than each method individually.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to IROS 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         <span class="highlight-title">★</span> Efficient Alignment of Unconditioned Action Prior for
  Language-conditioned Pick and Place in Clutter 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09423v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09423v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kechun Xu, Xunlong Xia, Kaixuan Wang, Yifei Yang, Yunxuan Mao, Bing Deng, <span class="highlight-author">Rong Xiong</span>, Yue Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study the task of language-conditioned pick and place in clutter, where a
robot should grasp a target object in open clutter and move it to a specified
place. Some approaches learn end-to-end policies with features from vision
foundation models, requiring large datasets. Others combine foundation models
in a zero-shot setting, suffering from cascading errors. In addition, they
primarily leverage vision and language foundation models, focusing less on
action priors. In this paper, we aim to develop an effective policy by
integrating foundation priors from vision, language, and action. We propose
A$^2$, an action prior alignment method that aligns unconditioned action priors
with 3D vision-language priors by learning one attention layer. The alignment
formulation enables our policy to train with less data and preserve zero-shot
generalization capabilities. We show that a shared policy for both pick and
place actions enhances the performance for each task, and introduce a policy
adaptation scheme to accommodate the multi-modal nature of actions. Extensive
experiments in simulation and the real-world show that our policy achieves
higher task success rates with fewer steps for both pick and place tasks in
clutter, effectively generalizing to unseen objects and language instructions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ AI-based Framework for Robust Model-Based Connector Mating in Robotic
  Wire Harness Installation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09409v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09409v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Claudius Kienle, Benjamin Alt, Finn Schneider, Tobias Pertlwieser, Rainer Jäkel, Rania Rayyes
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite the widespread adoption of industrial robots in automotive assembly,
wire harness installation remains a largely manual process, as it requires
precise and flexible manipulation. To address this challenge, we design a novel
AI-based framework that automates cable connector mating by integrating force
control with deep visuotactile learning. Our system optimizes
search-and-insertion strategies using first-order optimization over a
multimodal transformer architecture trained on visual, tactile, and
proprioceptive data. Additionally, we design a novel automated data collection
and optimization pipeline that minimizes the need for machine learning
expertise. The framework optimizes robot programs that run natively on standard
industrial controllers, permitting human experts to audit and certify them.
Experimental validations on a center console assembly task demonstrate
significant improvements in cycle times and robustness compared to conventional
robot programming approaches. Videos are available under
https://claudius-kienle.github.io/AppMuTT.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 6 figures, 4 tables, submitted to the 2025 IEEE 21st
  International Conference on Automation Science and Engineering</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Robust Self-Reconfiguration for Fault-Tolerant Control of Modular Aerial
  Robot Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09376v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09376v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rui Huang, Siyu Tang, Zhiqian Cai, Lin Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Modular Aerial Robotic Systems (MARS) consist of multiple drone units
assembled into a single, integrated rigid flying platform. With inherent
redundancy, MARS can self-reconfigure into different configurations to mitigate
rotor or unit failures and maintain stable flight. However, existing works on
MARS self-reconfiguration often overlook the practical controllability of
intermediate structures formed during the reassembly process, which limits
their applicability. In this paper, we address this gap by considering the
control-constrained dynamic model of MARS and proposing a robust and efficient
self-reconstruction algorithm that maximizes the controllability margin at each
intermediate stage. Specifically, we develop algorithms to compute optimal,
controllable disassembly and assembly sequences, enabling robust
self-reconfiguration. Finally, we validate our method in several challenging
fault-tolerant self-reconfiguration scenarios, demonstrating significant
improvements in both controllability and trajectory tracking while reducing the
number of assembly steps. The videos and source code of this work are available
at https://github.com/RuiHuangNUS/MARS-Reconfig/
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Robust Fault-Tolerant Control and Agile Trajectory <span class="highlight-title">Plan</span>ning for Modular
  Aerial Robotic Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09351v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09351v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rui Huang, Zhenyu Zhang, Siyu Tang, Zhiqian Cai, Lin Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Modular Aerial Robotic Systems (MARS) consist of multiple drone units that
can self-reconfigure to adapt to various mission requirements and fault
conditions. However, existing fault-tolerant control methods exhibit
significant oscillations during docking and separation, impacting system
stability. To address this issue, we propose a novel fault-tolerant control
reallocation method that adapts to arbitrary number of modular robots and their
assembly formations. The algorithm redistributes the expected collective force
and torque required for MARS to individual unit according to their moment arm
relative to the center of MARS mass. Furthermore, We propose an agile
trajectory planning method for MARS of arbitrary configurations, which is
collision-avoiding and dynamically feasible. Our work represents the first
comprehensive approach to enable fault-tolerant and collision avoidance flight
for MARS. We validate our method through extensive simulations, demonstrating
improved fault tolerance, enhanced trajectory tracking accuracy, and greater
robustness in cluttered environments. The videos and source code of this work
are available at https://github.com/RuiHuangNUS/MARS-FTCC/
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ NVP-HRI: Zero Shot Natural Voice and Posture-based Human-Robot
  Interaction via Large Language Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09335v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09335v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuzhi Lai, Shenghai Yuan, Youssef Nassar, Mingyu Fan, Thomas Weber, Matthias Rätsch
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Effective Human-Robot Interaction (HRI) is crucial for future service robots
in aging societies. Existing solutions are biased toward only well-trained
objects, creating a gap when dealing with new objects. Currently, HRI systems
using predefined gestures or language tokens for pretrained objects pose
challenges for all individuals, especially elderly ones. These challenges
include difficulties in recalling commands, memorizing hand gestures, and
learning new names. This paper introduces NVP-HRI, an intuitive multi-modal HRI
paradigm that combines voice commands and deictic posture. NVP-HRI utilizes the
Segment Anything Model (SAM) to analyze visual cues and depth data, enabling
precise structural object representation. Through a pre-trained SAM network,
NVP-HRI allows interaction with new objects via zero-shot prediction, even
without prior knowledge. NVP-HRI also integrates with a large language model
(LLM) for multimodal commands, coordinating them with object selection and
scene distribution in real time for collision-free trajectory solutions. We
also regulate the action sequence with the essential control syntax to reduce
LLM hallucination risks. The evaluation of diverse real-world tasks using a
Universal Robot showcased up to 59.2\% efficiency improvement over traditional
gesture control, as illustrated in the video https://youtu.be/EbC7al2wiAc. Our
code and design will be openly available at
https://github.com/laiyuzhi/NVP-HRI.git.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This work has been accepted for publication in ESWA @ 2025 Elsevier.
  Personal use of this material is permitted. Permission from Elsevier must be
  obtained for all other uses, including reprinting/redistribution, creating
  new works, or reuse of any copyrighted components of this work in other media</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MonoSLAM: Robust Monocular SLAM with Global Structure <span class="highlight-title">Optimization</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09296v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09296v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bingzheng Jiang, Jiayuan Wang, Han Ding, Lijun Zhu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents a robust monocular visual SLAM system that simultaneously
utilizes point, line, and vanishing point features for accurate camera pose
estimation and mapping. To address the critical challenge of achieving reliable
localization in low-texture environments, where traditional point-based systems
often fail due to insufficient visual features, we introduce a novel approach
leveraging Global Primitives structural information to improve the system's
robustness and accuracy performance. Our key innovation lies in constructing
vanishing points from line features and proposing a weighted fusion strategy to
build Global Primitives in the world coordinate system. This strategy
associates multiple frames with non-overlapping regions and formulates a
multi-frame reprojection error optimization, significantly improving tracking
accuracy in texture-scarce scenarios. Evaluations on various datasets show that
our system outperforms state-of-the-art methods in trajectory precision,
particularly in challenging environments.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ GarmentPile: Point-Level Visual Affordance Guided Retrieval and
  Adaptation for Cluttered Garments <span class="highlight-title">Manipulation</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09243v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09243v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ruihai Wu, Ziyu Zhu, Yuran Wang, Yue Chen, Jiarui Wang, Hao Dong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Cluttered garments manipulation poses significant challenges due to the
complex, deformable nature of garments and intricate garment relations. Unlike
single-garment manipulation, cluttered scenarios require managing complex
garment entanglements and interactions, while maintaining garment cleanliness
and manipulation stability. To address these demands, we propose to learn
point-level affordance, the dense representation modeling the complex space and
multi-modal manipulation candidates, while being aware of garment geometry,
structure, and inter-object relations. Additionally, as it is difficult to
directly retrieve a garment in some extremely entangled clutters, we introduce
an adaptation module, guided by learned affordance, to reorganize
highly-entangled garments into states plausible for manipulation. Our framework
demonstrates effectiveness over environments featuring diverse garment types
and pile configurations in both simulation and the real world. Project page:
https://garmentpile.github.io/.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MarineGym: A High-Performance Reinforcement Learning Platform for
  Underwater Robotics 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09203v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09203v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shuguang Chu, Zebin Huang, Yutong Li, Mingwei Lin, Ignacio Carlucho, Yvan R. Petillot, Canjun Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This work presents the MarineGym, a high-performance reinforcement learning
(RL) platform specifically designed for underwater robotics. It aims to address
the limitations of existing underwater simulation environments in terms of RL
compatibility, training efficiency, and standardized benchmarking. MarineGym
integrates a proposed GPU-accelerated hydrodynamic plugin based on Isaac Sim,
achieving a rollout speed of 250,000 frames per second on a single NVIDIA RTX
3060 GPU. It also provides five models of unmanned underwater vehicles (UUVs),
multiple propulsion systems, and a set of predefined tasks covering core
underwater control challenges. Additionally, the DR toolkit allows flexible
adjustments of simulation and task parameters during training to improve
Sim2Real transfer. Further benchmark experiments demonstrate that MarineGym
improves training efficiency over existing platforms and supports robust policy
adaptation under various perturbations. We expect this platform could drive
further advancements in RL research for underwater robotics. For more details
about MarineGym and its applications, please visit our project page:
https://marine-gym.com/.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Learning Appearance and Motion Cues for Panoptic Tracking 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09191v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09191v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Juana Valeria Hurtado, Sajad Marvi, Rohit Mohan, Abhinav Valada
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Panoptic tracking enables pixel-level scene interpretation of videos by
integrating instance tracking in panoptic segmentation. This provides robots
with a spatio-temporal understanding of the environment, an essential attribute
for their operation in dynamic environments. In this paper, we propose a novel
approach for panoptic tracking that simultaneously captures general semantic
information and instance-specific appearance and motion features. Unlike
existing methods that overlook dynamic scene attributes, our approach leverages
both appearance and motion cues through dedicated network heads. These
interconnected heads employ multi-scale deformable convolutions that reason
about scene motion offsets with semantic context and motion-enhanced appearance
features to learn tracking embeddings. Furthermore, we introduce a novel
two-step fusion module that integrates the outputs from both heads by first
matching instances from the current time step with propagated instances from
previous time steps and subsequently refines associations using motion-enhanced
appearance embeddings, improving robustness in challenging scenarios. Extensive
evaluations of our proposed \netname model on two benchmark datasets
demonstrate that it achieves state-of-the-art performance in panoptic tracking
accuracy, surpassing prior methods in maintaining object identities over time.
To facilitate future research, we make the code available at
http://panoptictracking.cs.uni-freiburg.de
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Rethinking Bimanual Robotic <span class="highlight-title">Manipulation</span>: Learning with Decoupled
  Interaction Framework 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09186v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09186v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jian-Jian Jiang, Xiao-Ming Wu, Yi-Xiang He, Ling-An Zeng, Yi-Lin Wei, Dandan Zhang, Wei-Shi Zheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Bimanual robotic manipulation is an emerging and critical topic in the
robotics community. Previous works primarily rely on integrated control models
that take the perceptions and states of both arms as inputs to directly predict
their actions. However, we think bimanual manipulation involves not only
coordinated tasks but also various uncoordinated tasks that do not require
explicit cooperation during execution, such as grasping objects with the
closest hand, which integrated control frameworks ignore to consider due to
their enforced cooperation in the early inputs. In this paper, we propose a
novel decoupled interaction framework that considers the characteristics of
different tasks in bimanual manipulation. The key insight of our framework is
to assign an independent model to each arm to enhance the learning of
uncoordinated tasks, while introducing a selective interaction module that
adaptively learns weights from its own arm to improve the learning of
coordinated tasks. Extensive experiments on seven tasks in the RoboTwin dataset
demonstrate that: (1) Our framework achieves outstanding performance, with a
23.5% boost over the SOTA method. (2) Our framework is flexible and can be
seamlessly integrated into existing methods. (3) Our framework can be
effectively extended to multi-agent manipulation tasks, achieving a 28% boost
over the integrated control SOTA. (4) The performance boost stems from the
decoupled design itself, surpassing the SOTA by 16.5% in success rate with only
1/6 of the model size.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages, 8 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Long-Term <span class="highlight-title">Plan</span>ning Around Humans in Domestic Environments with 3D Scene
  Graphs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09173v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09173v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ermanno Bartoli, Dennis Rotondi, Kai O. Arras, Iolanda Leite
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Long-term planning for robots operating in domestic environments poses unique
challenges due to the interactions between humans, objects, and spaces. Recent
advancements in trajectory planning have leveraged vision-language models
(VLMs) to extract contextual information for robots operating in real-world
environments. While these methods achieve satisfying performance, they do not
explicitly model human activities. Such activities influence surrounding
objects and reshape spatial constraints. This paper presents a novel approach
to trajectory planning that integrates human preferences, activities, and
spatial context through an enriched 3D scene graph (3DSG) representation. By
incorporating activity-based relationships, our method captures the spatial
impact of human actions, leading to more context-sensitive trajectory
adaptation. Preliminary results demonstrate that our approach effectively
assigns costs to spaces influenced by human activities, ensuring that the robot
trajectory remains contextually appropriate and sensitive to the ongoing
environment. This balance between task efficiency and social appropriateness
enhances context-aware human-robot interactions in domestic settings. Future
work includes implementing a full planning pipeline and conducting user studies
to evaluate trajectory acceptability.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages, 2 figures, 1 table</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Predictor-Based Time Delay Control of A Hex-Jet Unmanned Aerial Vehicle 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09148v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09148v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junning Liang, Haowen Zheng, Yuying Zhang, Yongzhuo Gao, Wei Dong, Ximin Lyu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Turbojet-powered VTOL UAVs have garnered increased attention in heavy-load
transport and emergency services, due to their superior power density and
thrust-to-weight ratio compared to existing electronic propulsion systems. The
main challenge with jet-powered UAVs lies in the complexity of thrust vectoring
mechanical systems, which aim to mitigate the slow dynamics of the turbojet. In
this letter, we introduce a novel turbojet-powered UAV platform named Hex-Jet.
Our concept integrates thrust vectoring and differential thrust for
comprehensive attitude control. This approach notably simplifies the thrust
vectoring mechanism. We utilize a predictor-based time delay control method
based on the frequency domain model in our Hex-Jet controller design to
mitigate the delay in roll attitude control caused by turbojet dynamics. Our
comparative studies provide valuable insights for the UAV community, and flight
tests on the scaled prototype demonstrate the successful implementation and
verification of the proposed predictor-based time delay control technique.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by IEEE Robotics and Automation Letters. 8 pages, 11 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Tacchi 2.0: A Low Computational Cost and Comprehensive Dynamic Contact
  Simulator for Vision-based Tactile Sensors 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09100v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09100v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuhao Sun, Shixin Zhang, Wenzhuang Li, Jie Zhao, Jianhua Shan, Zirong Shen, Zixi Chen, Fuchun Sun, Di Guo, Bin Fang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the development of robotics technology, some tactile sensors, such as
vision-based sensors, have been applied to contact-rich robotics tasks.
However, the durability of vision-based tactile sensors significantly increases
the cost of tactile information acquisition. Utilizing simulation to generate
tactile data has emerged as a reliable approach to address this issue. While
data-driven methods for tactile data generation lack robustness, finite element
methods (FEM) based approaches require significant computational costs. To
address these issues, we integrated a pinhole camera model into the low
computational cost vision-based tactile simulator Tacchi that used the Material
Point Method (MPM) as the simulated method, completing the simulation of marker
motion images. We upgraded Tacchi and introduced Tacchi 2.0. This simulator can
simulate tactile images, marked motion images, and joint images under different
motion states like pressing, slipping, and rotating. Experimental results
demonstrate the reliability of our method and its robustness across various
vision-based tactile sensors.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Sequential Multi-Object <span class="highlight-title">Grasp</span>ing with One Dexterous Hand 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09078v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09078v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sicheng He, Zeyu Shangguan, Kuanning Wang, Yongchong Gu, Yuqian Fu, Yanwei Fu, Daniel Seita
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sequentially grasping multiple objects with multi-fingered hands is common in
daily life, where humans can fully leverage the dexterity of their hands to
enclose multiple objects. However, the diversity of object geometries and the
complex contact interactions required for high-DOF hands to grasp one object
while enclosing another make sequential multi-object grasping challenging for
robots. In this paper, we propose SeqMultiGrasp, a system for sequentially
grasping objects with a four-fingered Allegro Hand. We focus on sequentially
grasping two objects, ensuring that the hand fully encloses one object before
lifting it and then grasps the second object without dropping the first. Our
system first synthesizes single-object grasp candidates, where each grasp is
constrained to use only a subset of the hand's links. These grasps are then
validated in a physics simulator to ensure stability and feasibility. Next, we
merge the validated single-object grasp poses to construct multi-object grasp
configurations. For real-world deployment, we train a diffusion model
conditioned on point clouds to propose grasp poses, followed by a
heuristic-based execution strategy. We test our system using $8 \times 8$
object combinations in simulation and $6 \times 3$ object combinations in real.
Our diffusion-based grasp model obtains an average success rate of 65.8% over
1600 simulation trials and 56.7% over 90 real-world trials, suggesting that it
is a promising approach for sequential multi-object grasping with
multi-fingered hands. Supplementary material is available on our project
website: https://hesic73.github.io/SeqMultiGrasp.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Motion Blender Gaussian Splatting for Dynamic Reconstruction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09040v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09040v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinyu Zhang, Haonan Chang, Yuhan Liu, Abdeslam Boularias
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Gaussian splatting has emerged as a powerful tool for high-fidelity
reconstruction of dynamic scenes. However, existing methods primarily rely on
implicit motion representations, such as encoding motions into neural networks
or per-Gaussian parameters, which makes it difficult to further manipulate the
reconstructed motions. This lack of explicit controllability limits existing
methods to replaying recorded motions only, which hinders a wider application.
To address this, we propose Motion Blender Gaussian Splatting (MB-GS), a novel
framework that uses motion graph as an explicit and sparse motion
representation. The motion of graph links is propagated to individual Gaussians
via dual quaternion skinning, with learnable weight painting functions
determining the influence of each link. The motion graphs and 3D Gaussians are
jointly optimized from input videos via differentiable rendering. Experiments
show that MB-GS achieves state-of-the-art performance on the iPhone dataset
while being competitive on HyperNeRF. Additionally, we demonstrate the
application potential of our method in generating novel object motions and
robot demonstrations through motion editing. Video demonstrations can be found
at https://mlzxy.github.io/mbgs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ManeuverGPT Agentic Control for Safe Autonomous Stunt Maneuvers <span class="chip">IROS</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09035v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09035v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shawn Azdam, Pranav Doma, Aliasghar Moj Arab
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The next generation of active safety features in autonomous vehicles should
be capable of safely executing evasive hazard-avoidance maneuvers akin to those
performed by professional stunt drivers to achieve high-agility motion at the
limits of vehicle handling. This paper presents a novel framework, ManeuverGPT,
for generating and executing high-dynamic stunt maneuvers in autonomous
vehicles using large language model (LLM)-based agents as controllers. We
target aggressive maneuvers, such as J-turns, within the CARLA simulation
environment and demonstrate an iterative, prompt-based approach to refine
vehicle control parameters, starting tabula rasa without retraining model
weights. We propose an agentic architecture comprised of three specialized
agents (1) a Query Enricher Agent for contextualizing user commands, (2) a
Driver Agent for generating maneuver parameters, and (3) a Parameter Validator
Agent that enforces physics-based and safety constraints. Experimental results
demonstrate successful J-turn execution across multiple vehicle models through
textual prompts that adapt to differing vehicle dynamics. We evaluate
performance via established success criteria and discuss limitations regarding
numeric precision and scenario complexity. Our findings underscore the
potential of LLM-driven control for flexible, high-dynamic maneuvers, while
highlighting the importance of hybrid approaches that combine language-based
reasoning with algorithmic validation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 Pages, Submitted to IROS</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ RFUAV: A <span class="highlight-title">Benchmark</span> Dataset for Unmanned Aerial Vehicle Detection and
  Identification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09033v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09033v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rui Shi, Xiaodong Yu, Shengming Wang, Yijia Zhang, Lu Xu, Peng Pan, Chunlai Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we propose RFUAV as a new benchmark dataset for
radio-frequency based (RF-based) unmanned aerial vehicle (UAV) identification
and address the following challenges: Firstly, many existing datasets feature a
restricted variety of drone types and insufficient volumes of raw data, which
fail to meet the demands of practical applications. Secondly, existing datasets
often lack raw data covering a broad range of signal-to-noise ratios (SNR), or
do not provide tools for transforming raw data to different SNR levels. This
limitation undermines the validity of model training and evaluation. Lastly,
many existing datasets do not offer open-access evaluation tools, leading to a
lack of unified evaluation standards in current research within this field.
RFUAV comprises approximately 1.3 TB of raw frequency data collected from 37
distinct UAVs using the Universal Software Radio Peripheral (USRP) device in
real-world environments. Through in-depth analysis of the RF data in RFUAV, we
define a drone feature sequence called RF drone fingerprint, which aids in
distinguishing drone signals. In addition to the dataset, RFUAV provides a
baseline preprocessing method and model evaluation tools. Rigorous experiments
demonstrate that these preprocessing methods achieve state-of-the-art (SOTA)
performance using the provided evaluation tools. The RFUAV dataset and baseline
implementation are publicly available at https://github.com/kitoweeknd/RFUAV/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>23 pages, 13 figures, conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Traffic Regulation-aware Path <span class="highlight-title">Plan</span>ning with Regulation Databases and
  Vision-Language Models <span class="chip">ICRA</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09024v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09024v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xu Han, Zhiwen Wu, Xin Xia, Jiaqi Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces and tests a framework integrating traffic regulation
compliance into automated driving systems (ADS). The framework enables ADS to
follow traffic laws and make informed decisions based on the driving
environment. Using RGB camera inputs and a vision-language model (VLM), the
system generates descriptive text to support a regulation-aware decision-making
process, ensuring legal and safe driving practices. This information is
combined with a machine-readable ADS regulation database to guide future
driving plans within legal constraints. Key features include: 1) a regulation
database supporting ADS decision-making, 2) an automated process using sensor
input for regulation-aware path planning, and 3) validation in both simulated
and real-world environments. Particularly, the real-world vehicle tests not
only assess the framework's performance but also evaluate the potential and
challenges of VLMs to solve complex driving problems by integrating detection,
reasoning, and planning. This work enhances the legality, safety, and public
trust in ADS, representing a significant step forward in the field.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>7 pages, 7 figures, submitted to ICRA</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Feasibility-aware Imitation Learning from Observations through a
  Hand-mounted Demonstration Interface 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09018v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09018v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kei Takahashi, Hikaru Sasaki, Takamitsu Matsubara
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Imitation learning through a demonstration interface is expected to learn
policies for robot automation from intuitive human demonstrations. However, due
to the differences in human and robot movement characteristics, a human expert
might unintentionally demonstrate an action that the robot cannot execute. We
propose feasibility-aware behavior cloning from observation (FABCO). In the
FABCO framework, the feasibility of each demonstration is assessed using the
robot's pre-trained forward and inverse dynamics models. This feasibility
information is provided as visual feedback to the demonstrators, encouraging
them to refine their demonstrations. During policy learning, estimated
feasibility serves as a weight for the demonstration data, improving both the
data efficiency and the robustness of the learned policy. We experimentally
validated FABCO's effectiveness by applying it to a pipette insertion task
involving a pipette and a vial. Four participants assessed the impact of the
feasibility feedback and the weighted policy learning in FABCO. Additionally,
we used the NASA Task Load Index (NASA-TLX) to evaluate the workload induced by
demonstrations with visual feedback.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Accurate Control under Voltage Drop for Rotor Drones 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09017v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09017v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuhang Liu, Jindou Jia, Zihan Yang, Kexin Guo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This letter proposes an anti-disturbance control scheme for rotor drones to
counteract voltage drop (VD) disturbance caused by voltage drop of the battery,
which is a common case for long-time flight or aggressive maneuvers. Firstly,
the refined dynamics of rotor drones considering VD disturbance are presented.
Based on the dynamics, a voltage drop observer (VDO) is developed to accurately
estimate the VD disturbance by decoupling the disturbance and state information
of the drone, reducing the conservativeness of conventional disturbance
observers. Subsequently, the control scheme integrates the VDO within the
translational loop and a fixed-time sliding mode observer (SMO) within the
rotational loop, enabling it to address force and torque disturbances caused by
voltage drop of the battery. Sufficient real flight experiments are conducted
to demonstrate the effectiveness of the proposed control scheme under VD
disturbance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         <span class="highlight-title">★</span> Natural Humanoid Robot <span class="highlight-title">Locomotion</span> with Generative Motion Prior 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09015v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09015v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haodong Zhang, Liang Zhang, Zhenghan Chen, Lu Chen, Yue Wang, <span class="highlight-author">Rong Xiong</span>
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Natural and lifelike locomotion remains a fundamental challenge for humanoid
robots to interact with human society. However, previous methods either neglect
motion naturalness or rely on unstable and ambiguous style rewards. In this
paper, we propose a novel Generative Motion Prior (GMP) that provides
fine-grained motion-level supervision for the task of natural humanoid robot
locomotion. To leverage natural human motions, we first employ whole-body
motion retargeting to effectively transfer them to the robot. Subsequently, we
train a generative model offline to predict future natural reference motions
for the robot based on a conditional variational auto-encoder. During policy
training, the generative motion prior serves as a frozen online motion
generator, delivering precise and comprehensive supervision at the trajectory
level, including joint angles and keypoint positions. The generative motion
prior significantly enhances training stability and improves interpretability
by offering detailed and dense guidance throughout the learning process.
Experimental results in both simulation and real-world environments demonstrate
that our method achieves superior motion naturalness compared to existing
approaches. Project page can be found at
https://sites.google.com/view/humanoid-gmp
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         <span class="highlight-title">★</span> Unified <span class="highlight-title">Locomotion</span> Transformer with Simultaneous Sim-to-Real Transfer
  for Quadrupeds 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08997v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08997v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dikai Liu, Tian<span class="highlight-author">wei Zhang</span>, Jianxiong Yin, Simon See
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Quadrupeds have gained rapid advancement in their capability of traversing
across complex terrains. The adoption of deep Reinforcement Learning (RL),
transformers and various knowledge transfer techniques can greatly reduce the
sim-to-real gap. However, the classical teacher-student framework commonly used
in existing locomotion policies requires a pre-trained teacher and leverages
the privilege information to guide the student policy. With the implementation
of large-scale models in robotics controllers, especially transformers-based
ones, this knowledge distillation technique starts to show its weakness in
efficiency, due to the requirement of multiple supervised stages. In this
paper, we propose Unified Locomotion Transformer (ULT), a new transformer-based
framework to unify the processes of knowledge transfer and policy optimization
in a single network while still taking advantage of privilege information. The
policies are optimized with reinforcement learning, next state-action
prediction, and action imitation, all in just one training stage, to achieve
zero-shot deployment. Evaluation results demonstrate that with ULT, optimal
teacher and student policies can be obtained at the same time, greatly easing
the difficulty in knowledge transfer, even with complex transformer-based
models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project website for video: https://johnliudk.github.io/ult/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Edge AI-Powered Real-Time Decision-Making for Autonomous Vehicles in
  Adverse Weather Conditions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09638v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09638v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Milad Rahmati
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Autonomous vehicles (AVs) are transforming modern transportation, but their
reliability and safety are significantly challenged by harsh weather conditions
such as heavy rain, fog, and snow. These environmental factors impair the
performance of cameras, LiDAR, and radar, leading to reduced situational
awareness and increased accident risks. Conventional cloud-based AI systems
introduce communication delays, making them unsuitable for the rapid
decision-making required in real-time autonomous navigation. This paper
presents a novel Edge AI-driven real-time decision-making framework designed to
enhance AV responsiveness under adverse weather conditions. The proposed
approach integrates convolutional neural networks (CNNs) and recurrent neural
networks (RNNs) for improved perception, alongside reinforcement learning
(RL)-based strategies to optimize vehicle control in uncertain environments. By
processing data at the network edge, this system significantly reduces decision
latency while improving AV adaptability. The framework is evaluated using
simulated driving scenarios in CARLA and real-world data from the Waymo Open
Dataset, covering diverse weather conditions. Experimental results indicate
that the proposed model achieves a 40% reduction in processing time and a 25%
enhancement in perception accuracy compared to conventional cloud-based
systems. These findings highlight the potential of Edge AI in improving AV
autonomy, safety, and efficiency, paving the way for more reliable self-driving
technology in challenging real-world environments.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ TetraGrip: Sensor-Driven Multi-Suction Reactive Object <span class="highlight-title">Manipulation</span> in
  Cluttered Scenes 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08978v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08978v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Paolo Torrado, Joshua Levin, Markus Grotz, Joshua Smith
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Warehouse robotic systems equipped with vacuum grippers must reliably grasp a
diverse range of objects from densely packed shelves. However, these
environments present significant challenges, including occlusions, diverse
object orientations, stacked and obstructed items, and surfaces that are
difficult to suction. We introduce \tetra, a novel vacuum-based grasping
strategy featuring four suction cups mounted on linear actuators. Each actuator
is equipped with an optical time-of-flight (ToF) proximity sensor, enabling
reactive grasping.
  We evaluate \tetra in a warehouse-style setting, demonstrating its ability to
manipulate objects in stacked and obstructed configurations. Our results show
that our RL-based policy improves picking success in stacked-object scenarios
by 22.86\% compared to a single-suction gripper. Additionally, we demonstrate
that TetraGrip can successfully grasp objects in scenarios where a
single-suction gripper fails due to physical limitations, specifically in two
cases: (1) picking an object occluded by another object and (2) retrieving an
object in a complex scenario. These findings highlight the advantages of
multi-actuated, suction-based grasping in unstructured warehouse environments.
The project website is available at:
\href{https://tetragrip.github.io/}{https://tetragrip.github.io/}.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Robust Deterministic Policy Gradient for Disturbance Attenuation and Its
  Application to Quadrotor Control 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.21057v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.21057v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Taeho Lee, Donghwan Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Practical control systems pose significant challenges in identifying optimal
control policies due to uncertainties in the system model and external
disturbances. While $H_\infty$ control techniques are commonly used to design
robust controllers that mitigate the effects of disturbances, these methods
often require complex and computationally intensive calculations. To address
this issue, this paper proposes a reinforcement learning algorithm called
Robust Deterministic Policy Gradient (RDPG), which formulates the $H_\infty$
control problem as a two-player zero-sum dynamic game. In this formulation, one
player (the user) aims to minimize the cost, while the other player (the
adversary) seeks to maximize it. We then employ deterministic policy gradient
(DPG) and its deep reinforcement learning counterpart to train a robust control
policy with effective disturbance attenuation. In particular, for practical
implementation, we introduce an algorithm called robust deep deterministic
policy gradient (RDDPG), which employs a deep neural network architecture and
integrates techniques from the twin-delayed deep deterministic policy gradient
(TD3) to enhance stability and learning efficiency. To evaluate the proposed
algorithm, we implement it on an unmanned aerial vehicle (UAV) tasked with
following a predefined path in a disturbance-prone environment. The
experimental results demonstrate that the proposed method outperforms other
control approaches in terms of robustness against disturbances, enabling
precise real-time tracking of moving targets even under severe disturbance
conditions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ <span class="highlight-title">Plan</span>ning with Adaptive World Models for Autonomous Driving <span class="chip">ICRA</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.10714v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.10714v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Arun Balajee Vasudevan, Neehar Peri, Jeff Schneider, Deva Ramanan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Motion planning is crucial for safe navigation in complex urban environments.
Historically, motion planners (MPs) have been evaluated with
procedurally-generated simulators like CARLA. However, such synthetic
benchmarks do not capture real-world multi-agent interactions. nuPlan, a
recently released MP benchmark, addresses this limitation by augmenting
real-world driving logs with closed-loop simulation logic, effectively turning
the fixed dataset into a reactive simulator. We analyze the characteristics of
nuPlan's recorded logs and find that each city has its own unique driving
behaviors, suggesting that robust planners must adapt to different
environments. We learn to model such unique behaviors with BehaviorNet, a graph
convolutional neural network (GCNN) that predicts reactive agent behaviors
using features derived from recently-observed agent histories; intuitively,
some aggressive agents may tailgate lead vehicles, while others may not. To
model such phenomena, BehaviorNet predicts the parameters of an agent's motion
controller rather than directly predicting its spacetime trajectory (as most
forecasters do). Finally, we present AdaptiveDriver, a model-predictive control
(MPC) based planner that unrolls different world models conditioned on
BehaviorNet's predictions. Our extensive experiments demonstrate that
AdaptiveDriver achieves state-of-the-art results on the nuPlan closed-loop
planning benchmark, improving over prior work by 2% on Test-14 Hard R-CLS, and
generalizes even when evaluated on never-before-seen cities.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This project has been accepted to the International Conference on
  Robotics and Automation (ICRA) 2025. Project Page:
  https://arunbalajeev.github.io/world_models_planning/world_model_paper.html</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ HiFi-CS: Towards Open Vocabulary Visual Grounding For Robotic <span class="highlight-title">Grasp</span>ing
  Using Vision-Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.10419v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.10419v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vineet Bhat, Prashanth Krishnamurthy, Ramesh Karri, Farshad Khorrami
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Robots interacting with humans through natural language can unlock numerous
applications such as Referring Grasp Synthesis (RGS). Given a text query, RGS
determines a stable grasp pose to manipulate the referred object in the robot's
workspace. RGS comprises two steps: visual grounding and grasp pose estimation.
Recent studies leverage powerful Vision-Language Models (VLMs) for visually
grounding free-flowing natural language in real-world robotic execution.
However, comparisons in complex, cluttered environments with multiple instances
of the same object are lacking. This paper introduces HiFi-CS, featuring
hierarchical application of Featurewise Linear Modulation (FiLM) to fuse image
and text embeddings, enhancing visual grounding for complex attribute rich text
queries encountered in robotic grasping. Visual grounding associates an object
in 2D/3D space with natural language input and is studied in two scenarios:
Closed and Open Vocabulary. HiFi-CS features a lightweight decoder combined
with a frozen VLM and outperforms competitive baselines in closed vocabulary
settings while being 100x smaller in size. Our model can effectively guide
open-set object detectors like GroundedSAM to enhance open-vocabulary
performance. We validate our approach through real-world RGS experiments using
a 7-DOF robotic arm, achieving 90.33\% visual grounding accuracy in 15 tabletop
scenes. Our codebase is provided here: https://github.com/vineet2104/hifics
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MotionScript: Natural Language Descriptions for Expressive 3D Human
  Motions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.12634v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.12634v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Payam Jome Yazdian, Rachel Lagasse, Hamid Mohammadi, Eric Liu, Li Cheng, Angelica Lim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce MotionScript, a novel framework for generating highly detailed,
natural language descriptions of 3D human motions. Unlike existing motion
datasets that rely on broad action labels or generic captions, MotionScript
provides fine-grained, structured descriptions that capture the full complexity
of human movement including expressive actions (e.g., emotions, stylistic
walking) and interactions beyond standard motion capture datasets. MotionScript
serves as both a descriptive tool and a training resource for text-to-motion
models, enabling the synthesis of highly realistic and diverse human motions
from text. By augmenting motion datasets with MotionScript captions, we
demonstrate significant improvements in out-of-distribution motion generation,
allowing large language models (LLMs) to generate motions that extend beyond
existing data. Additionally, MotionScript opens new applications in animation,
virtual human simulation, and robotics, providing an interpretable bridge
between intuitive descriptions and motion synthesis. To the best of our
knowledge, this is the first attempt to systematically translate 3D motion into
structured natural language without requiring training data.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project webpage: https://pjyazdian.github.io/MotionScript</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Extrapolated Urban View Synthesis <span class="highlight-title">Benchmark</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.05256v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.05256v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiangyu Han, Zhen Jia, Boyi Li, Yan Wang, Boris Ivanovic, Yurong You, Lingjie Liu, Yue Wang, Marco Pavone, Chen Feng, Yiming Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Photorealistic simulators are essential for the training and evaluation of
vision-centric autonomous vehicles (AVs). At their core is Novel View Synthesis
(NVS), a crucial capability that generates diverse unseen viewpoints to
accommodate the broad and continuous pose distribution of AVs. Recent advances
in radiance fields, such as 3D Gaussian Splatting, achieve photorealistic
rendering at real-time speeds and have been widely used in modeling large-scale
driving scenes. However, their performance is commonly evaluated using an
interpolated setup with highly correlated training and test views. In contrast,
extrapolation, where test views largely deviate from training views, remains
underexplored, limiting progress in generalizable simulation technology. To
address this gap, we leverage publicly available AV datasets with multiple
traversals, multiple vehicles, and multiple cameras to build the first
Extrapolated Urban View Synthesis (EUVS) benchmark. Meanwhile, we conduct both
quantitative and qualitative evaluations of state-of-the-art NVS methods across
different evaluation settings. Our results show that current NVS methods are
prone to overfitting to training views. Besides, incorporating diffusion priors
and improving geometry cannot fundamentally improve NVS under large view
changes, highlighting the need for more robust approaches and large-scale
training. We will release the data to help advance self-driving and urban
robotics simulation technology.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project page: https://ai4ce.github.io/EUVS-Benchmark/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CMP: Cooperative Motion Prediction with Multi-Agent Communication 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.17916v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.17916v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zehao Wang, Yuping Wang, Zhuoyuan Wu, Hengbo Ma, Zhaowei Li, Hang Qiu, Jiachen Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The confluence of the advancement of Autonomous Vehicles (AVs) and the
maturity of Vehicle-to-Everything (V2X) communication has enabled the
capability of cooperative connected and automated vehicles (CAVs). Building on
top of cooperative perception, this paper explores the feasibility and
effectiveness of cooperative motion prediction. Our method, CMP, takes LiDAR
signals as model input to enhance tracking and prediction capabilities. Unlike
previous work that focuses separately on either cooperative perception or
motion prediction, our framework, to the best of our knowledge, is the first to
address the unified problem where CAVs share information in both perception and
prediction modules. Incorporated into our design is the unique capability to
tolerate realistic V2X transmission delays, while dealing with bulky perception
representations. We also propose a prediction aggregation module, which unifies
the predictions obtained by different CAVs and generates the final prediction.
Through extensive experiments and ablation studies on the OPV2V and V2V4Real
datasets, we demonstrate the effectiveness of our method in cooperative
perception, tracking, and motion prediction. In particular, CMP reduces the
average prediction error by 12.3% compared with the strongest baseline. Our
work marks a significant step forward in the cooperative capabilities of CAVs,
showcasing enhanced performance in complex scenarios. More details can be found
on the project website: https://cmp-cooperative-prediction.github.io.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>IEEE Robotics and Automation Letters; Project website:
  https://cmp-cooperative-prediction.github.io/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Reasoning in visual <span class="highlight-title">navigation</span> of end-to-end trained agents: a dynamical
  systems approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08306v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08306v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Steeven Janny, Hervé Poirier, Leonid Antsfeld, Guillaume Bono, Gianluca Monaci, Boris Chidlovskii, Francesco Giuliari, Alessio Del Bue, Christian Wolf
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Progress in Embodied AI has made it possible for end-to-end-trained agents to
navigate in photo-realistic environments with high-level reasoning and
zero-shot or language-conditioned behavior, but benchmarks are still dominated
by simulation. In this work, we focus on the fine-grained behavior of
fast-moving real robots and present a large-scale experimental study involving
\numepisodes{} navigation episodes in a real environment with a physical robot,
where we analyze the type of reasoning emerging from end-to-end training. In
particular, we study the presence of realistic dynamics which the agent learned
for open-loop forecasting, and their interplay with sensing. We analyze the way
the agent uses latent memory to hold elements of the scene structure and
information gathered during exploration. We probe the planning capabilities of
the agent, and find in its memory evidence for somewhat precise plans over a
limited horizon. Furthermore, we show in a post-hoc analysis that the value
function learned by the agent relates to long-term planning. Put together, our
experiments paint a new picture on how using tools from computer vision and
sequential decision making have led to new capabilities in robotics and
control. An interactive tool is available at
europe.naverlabs.com/research/publications/reasoning-in-visual-navigation-of-end-to-end-trained-agents.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Quantifying Aleatoric and Epistemic Dynamics Uncertainty via Local
  Conformal Calibration 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.08249v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.08249v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Luís Marques, Dmitry Berenson
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Whether learned, simulated, or analytical, approximations of a robot's
dynamics can be inaccurate when encountering novel environments. Many
approaches have been proposed to quantify the aleatoric uncertainty of such
methods, i.e. uncertainty resulting from stochasticity, however these estimates
alone are not enough to properly estimate the uncertainty of a model in a novel
environment, where the actual dynamics can change. Such changes can induce
epistemic uncertainty, i.e. uncertainty due to a lack of information/data.
Accounting for both epistemic and aleatoric dynamics uncertainty in a
theoretically-grounded way remains an open problem. We introduce Local
Uncertainty Conformal Calibration (LUCCa), a conformal prediction-based
approach that calibrates the aleatoric uncertainty estimates provided by
dynamics models to generate probabilistically-valid prediction regions of the
system's state. We account for both epistemic and aleatoric uncertainty
non-asymptotically, without strong assumptions about the form of the true
dynamics or how it changes. The calibration is performed locally in the
state-action space, leading to uncertainty estimates that are useful for
planning. We validate our method by constructing probabilistically-safe plans
for a double-integrator under significant changes in dynamics.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>24 pages, 9 figures. Accepted to the 16th International Workshop on
  the Algorithmic Foundations of Robotics (WAFR) 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Safe and Dynamically-Feasible Motion <span class="highlight-title">Plan</span>ning using Control Lyapunov and
  Barrier Functions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.08364v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.08364v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pol Mestres, Carlos Nieto-Granda, Jorge Cortés
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper considers the problem of designing motion planning algorithms for
control-affine systems that generate collision-free paths from an initial to a
final destination and can be executed using safe and dynamically-feasible
controllers. We introduce the C-CLF-CBF-RRT algorithm, which produces paths
with such properties and leverages rapidly exploring random trees (RRTs),
control Lyapunov functions (CLFs) and control barrier functions (CBFs). We show
that C-CLF-CBF-RRT is computationally efficient for linear systems with
polytopic and ellipsoidal constraints, and establish its probabilistic
completeness. We showcase the performance of C-CLF-CBF-RRT in different
simulation and hardware experiments.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DeformPAM: Data-Efficient Learning for Long-horizon Deformable Object
  <span class="highlight-title">Manipulation</span> via Preference-based Action Alignment <span class="chip">ICRA 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11584v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11584v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wendi Chen, Han Xue, Fangyuan Zhou, Yuan Fang, Cewu Lu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, imitation learning has made progress in the field of robotic
manipulation. However, it still faces challenges when addressing complex
long-horizon tasks with deformable objects, such as high-dimensional state
spaces, complex dynamics, and multimodal action distributions. Traditional
imitation learning methods often require a large amount of data and encounter
distributional shifts and accumulative errors in these tasks. To address these
issues, we propose a data-efficient general learning framework (DeformPAM)
based on preference learning and reward-guided action selection. DeformPAM
decomposes long-horizon tasks into multiple action primitives, utilizes 3D
point cloud inputs and diffusion models to model action distributions, and
trains an implicit reward model using human preference data. During the
inference phase, the reward model scores multiple candidate actions, selecting
the optimal action for execution, thereby reducing the occurrence of anomalous
actions and improving task completion quality. Experiments conducted on three
challenging real-world long-horizon deformable object manipulation tasks
demonstrate the effectiveness of this method. Results show that DeformPAM
improves both task completion quality and efficiency compared to baseline
methods even with limited data. Code and data will be available at
https://deform-pam.robotflow.ai.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ICRA 2025. Project page: https://deform-pam.robotflow.ai</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DeepUKF-VIN: Adaptively-tuned Deep Unscented Kalman Filter for 3D
  Visual-Inertial <span class="highlight-title">Navigation</span> based on IMU-Vision-Net 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.00575v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.00575v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Khashayar Ghanizadegan, Hashim A. Hashim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper addresses the challenge of estimating the orientation, position,
and velocity of a vehicle operating in three-dimensional (3D) space with six
degrees of freedom (6-DoF). A Deep Learning-based Adaptation Mechanism (DLAM)
is proposed to adaptively tune the noise covariance matrices of Kalman-type
filters for the Visual-Inertial Navigation (VIN) problem, leveraging
IMU-Vision-Net. Subsequently, an adaptively tuned Deep Learning Unscented
Kalman Filter for 3D VIN (DeepUKF-VIN) is introduced to utilize the proposed
DLAM, thereby robustly estimating key navigation components, including
orientation, position, and linear velocity. The proposed DeepUKF-VIN integrates
data from onboard sensors, specifically an inertial measurement unit (IMU) and
visual feature points extracted from a camera, and is applicable for GPS-denied
navigation. Its quaternion-based design effectively captures navigation
nonlinearities and avoids the singularities commonly encountered with
Euler-angle-based filters. Implemented in discrete space, the DeepUKF-VIN
facilitates practical filter deployment. The filter's performance is evaluated
using real-world data collected from an IMU and a stereo camera at low sampling
rates. The results demonstrate filter stability and rapid attenuation of
estimation errors, highlighting its high estimation accuracy. Furthermore,
comparative testing against the standard Unscented Kalman Filter (UKF) in two
scenarios consistently shows superior performance across all navigation
components, thereby validating the efficacy and robustness of the proposed
DeepUKF-VIN. Keywords: Deep Learning, Unscented Kalman Filter, Adaptive tuning,
Estimation, Navigation, Unmanned Aerial Vehicle, Sensor-fusion.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Grounding Video Models to Actions through Goal Conditioned Exploration <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.07223v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.07223v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yunhao Luo, Yilun Du
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large video models, pretrained on massive amounts of Internet video, provide
a rich source of physical knowledge about the dynamics and motions of objects
and tasks. However, video models are not grounded in the embodiment of an
agent, and do not describe how to actuate the world to reach the visual states
depicted in a video. To tackle this problem, current methods use a separate
vision-based inverse dynamic model trained on embodiment-specific data to map
image states to actions. Gathering data to train such a model is often
expensive and challenging, and this model is limited to visual settings similar
to the ones in which data are available. In this paper, we investigate how to
directly ground video models to continuous actions through self-exploration in
the embodied environment -- using generated video states as visual goals for
exploration. We propose a framework that uses trajectory level action
generation in combination with video guidance to enable an agent to solve
complex tasks without any external supervision, e.g., rewards, action labels,
or segmentation masks. We validate the proposed approach on 8 tasks in Libero,
6 tasks in MetaWorld, 4 tasks in Calvin, and 12 tasks in iThor Visual
Navigation. We show how our approach is on par with or even surpasses multiple
behavior cloning baselines trained on expert demonstrations while without
requiring any action annotations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICLR 2025 (Spotlight). Project page:
  https://video-to-action.github.io/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Fair Play in the Fast Lane: Integrating Sportsmanship into Autonomous
  Racing Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03774v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03774v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhenmin Huang, Ce Hao, Wei Zhan, Jun Ma, Masayoshi Tomizuka
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Autonomous racing has gained significant attention as a platform for
high-speed decision-making and motion control. While existing methods primarily
focus on trajectory planning and overtaking strategies, the role of
sportsmanship in ensuring fair competition remains largely unexplored. In human
racing, rules such as the one-motion rule and the enough-space rule prevent
dangerous and unsportsmanlike behavior. However, autonomous racing systems
often lack mechanisms to enforce these principles, potentially leading to
unsafe maneuvers. This paper introduces a bi-level game-theoretic framework to
integrate sportsmanship (SPS) into versus racing. At the high level, we model
racing intentions using a Stackelberg game, where Monte Carlo Tree Search
(MCTS) is employed to derive optimal strategies. At the low level, vehicle
interactions are formulated as a Generalized Nash Equilibrium Problem (GNEP),
ensuring that all agents follow sportsmanship constraints while optimizing
their trajectories. Simulation results demonstrate the effectiveness of the
proposed approach in enforcing sportsmanship rules while maintaining
competitive performance. We analyze different scenarios where attackers and
defenders adhere to or disregard sportsmanship rules and show how knowledge of
these constraints influences strategic decision-making. This work highlights
the importance of balancing competition and fairness in autonomous racing and
provides a foundation for developing ethical and safe AI-driven racing systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ReloPush: Multi-object Rearrangement in Confined Spaces with a
  Nonholonomic Mobile Robot Pusher <span class="chip">ICRA 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.18231v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.18231v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jeeho Ahn, Christoforos Mavrogiannis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We focus on push-based multi-object rearrangement planning using a
nonholonomically constrained mobile robot. The simultaneous geometric,
kinematic, and physics constraints make this problem especially challenging.
Prior work on rearrangement planning often relaxes some of these constraints by
assuming dexterous hardware, prehensile manipulation, or sparsely occupied
workspaces. Our key insight is that by capturing these constraints into a
unified representation, we could empower a constrained robot to tackle
difficult problem instances by modifying the environment in its favor. To this
end, we introduce a Push-Traversability graph, whose vertices represent poses
that the robot can push objects from, and edges represent optimal,
kinematically feasible, and stable transitions between them. Based on this
graph, we develop ReloPush, a graph-based planning framework that takes as
input a complex multi-object rearrangement task and breaks it down into a
sequence of single-object pushing tasks. We evaluate ReloPush across a series
of challenging scenarios, involving the rearrangement of densely cluttered
workspaces with up to nine objects, using a 1/10-scale robot racecar. ReloPush
exhibits orders of magnitude faster runtimes and significantly more robust
execution in the real world, evidenced in lower execution times and fewer
losses of object contact, compared to two baselines lacking our proposed graph
structure.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint of final version, accepted to ICRA 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ EHC-MM: Embodied Holistic Control for Mobile <span class="highlight-title">Manipulation</span> <span class="chip">ICRA2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.08527v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.08527v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiawen Wang, Yixiang Jin, Jun Shi, Yong A, Dingzhe Li, Fuchun Sun, Dingsheng Luo, Bin Fang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Mobile manipulation typically entails the base for mobility, the arm for
accurate manipulation, and the camera for perception. The principle of Distant
Mobility, Close Grasping(DMCG) is essential for holistic control. We propose
Embodied Holistic Control for Mobile Manipulation(EHC-MM) with the embodied
function of sig(w): By formulating the DMCG principle as a Quadratic
Programming (QP) problem, sig(w) dynamically balances the robot's emphasis
between movement and manipulation with the consideration of the robot's state
and environment. In addition, we propose the Monitor-Position-Based Servoing
(MPBS) with sig(w), enabling the tracking of the target during the operation.
This approach enables coordinated control among the robot's base, arm, and
camera, enhancing task efficiency. Through extensive simulations and real-world
experiments, our approach significantly improves both the success rate and
efficiency of mobile manipulation tasks, achieving a 95.6% success rate in
real-world scenarios and a 52.8% increase in time efficiency.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>accepted by ICRA2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ RS2V-L: Vehicle-Mounted LiDAR Data Generation from Roadside Sensor
  Observations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07085v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07085v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ruidan Xing, Runyi Huang, Qing Xu, Lei He
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  End-to-end autonomous driving solutions, which process multi-modal sensory
data to directly generate refined control commands, have become a dominant
paradigm in autonomous driving research. However, these approaches
predominantly depend on single-vehicle data collection for model training and
optimization, resulting in significant challenges such as high data acquisition
and annotation costs, the scarcity of critical driving scenarios, and
fragmented datasets that impede model generalization. To mitigate these
limitations, we introduce RS2V-L, a novel framework for reconstructing and
synthesizing vehicle-mounted LiDAR data from roadside sensor observations.
Specifically, our method transforms roadside LiDAR point clouds into the
vehicle-mounted LiDAR coordinate system by leveraging the target vehicle's
relative pose. Subsequently, high-fidelity vehicle-mounted LiDAR data is
synthesized through virtual LiDAR modeling, point cloud classification, and
resampling techniques. To the best of our knowledge, this is the first approach
to reconstruct vehicle-mounted LiDAR data from roadside sensor inputs.
Extensive experimental evaluations demonstrate that incorporating the generated
data into model training-complementing the KITTI dataset-enhances 3D object
detection accuracy by over \text{30\%} while improving the efficiency of
end-to-end autonomous driving data generation by more than an order of
magnitude. These findings strongly validate the effectiveness of the proposed
method and underscore its potential in reducing dependence on costly
vehicle-mounted data collection while improving the robustness of autonomous
driving models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Upon self-examination, we have found that the data in the
  experimental section of our paper is uncertain. To ensure academic rigor, we
  are applying for the withdrawal of the paper. We will resubmit it after
  reconfirming and correcting the data. Thank you for your understanding</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Object-Centric World Model for Language-Guided <span class="highlight-title">Manipulation</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06170v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06170v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Youngjoon Jeong, Junha Chun, Soonwoo Cha, Taesup Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A world model is essential for an agent to predict the future and plan in
domains such as autonomous driving and robotics. To achieve this, recent
advancements have focused on video generation, which has gained significant
attention due to the impressive success of diffusion models. However, these
models require substantial computational resources. To address these
challenges, we propose a world model leveraging object-centric representation
space using slot attention, guided by language instructions. Our model
perceives the current state as an object-centric representation and predicts
future states in this representation space conditioned on natural language
instructions. This approach results in a more compact and computationally
efficient model compared to diffusion-based generative alternatives.
Furthermore, it flexibly predicts future states based on language instructions,
and offers a significant advantage in manipulation tasks where object
recognition is crucial. In this paper, we demonstrate that our latent
predictive world model surpasses generative world models in visuo-linguo-motor
control tasks, achieving superior sample and computation efficiency. We also
investigate the generalization performance of the proposed method and explore
various strategies for predicting actions using object-centric representations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A cheat sheet for probability distributions of orientational data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.08934v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.08934v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        P. C. Lopez-Custodio
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The need for statistical models of orientations arises in many applications
in engineering and computer science. Orientational data appear as sets of
angles, unit vectors, rotation matrices or quaternions. In the field of
directional statistics, a lot of advances have been made in modelling such
types of data. However, only a few of these tools are used in engineering and
computer science applications. Hence, this paper aims to serve as a cheat sheet
for those probability distributions of orientations. Models for 1-DOF, 2-DOF
and 3-DOF orientations are discussed. For each of them, expressions for the
density function, fitting to data, and sampling are presented. The paper is
written with a compromise between engineering and statistics in terms of
notation and terminology. A Python library with functions for some of these
models is provided. Using this library, two examples of applications to real
data are presented.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Added section 7, improved the experiments description (Sec. 8), fixed
  typos</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Flow-Inspired Multi-Robot Real-Time Scheduling <span class="highlight-title">Plan</span>ner 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06952v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06952v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Han Liu, Yu Jin, Tianjiang Hu, Kai Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Collision avoidance and trajectory planning are crucial in multi-robot
systems, particularly in environments with numerous obstacles. Although
extensive research has been conducted in this field, the challenge of rapid
traversal through such environments has not been fully addressed. This paper
addresses this problem by proposing a novel real-time scheduling scheme
designed to optimize the passage of multi-robot systems through complex,
obstacle-rich maps. Inspired from network flow optimization, our scheme
decomposes the environment into a network structure, enabling the efficient
allocation of robots to paths based on real-time congestion data. The proposed
scheduling planner operates on top of existing collision avoidance algorithms,
focusing on minimizing traversal time by balancing robot detours and waiting
times. Our simulation results demonstrate the efficiency of the proposed
scheme. Additionally, we validated its effectiveness through real world flight
tests using ten quadrotors. This work contributes a lightweight, effective
scheduling planner capable of meeting the real-time demands of multi-robot
systems in obstacle-rich environments.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Input-Output Feedback Linearization Preserving Task Priority for
  Multivariate Nonlinear Systems Having Singular Input Gain Matrix 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2305.01903v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2305.01903v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sang-ik An, Dongheui Lee, Gyunghoon Park
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose an extension of the input-output feedback linearization for a
class of multivariate systems that are not input-output linearizable in a
classical manner. The key observation is that the usual input-output
linearization problem can be interpreted as the problem of solving simultaneous
linear equations associated with the input gain matrix: thus, even at points
where the input gain matrix becomes singular, it is still possible to solve a
part of linear equations, by which a subset of input-output relations is made
linear or close to be linear. Based on this observation, we adopt the task
priority-based approach in the input-output linearization problem. First, we
generalize the classical Byrnes-Isidori normal form to a prioritized normal
form having a triangular structure, so that the singularity of a subblock of
the input gain matrix related to lower-priority tasks does not directly
propagate to higher-priority tasks. Next, we present a prioritized input-output
linearization via the multi-objective optimization with the lexicographical
ordering, resulting in a prioritized semilinear form that establishes input
output relations whose subset with higher priority is linear or close to be
linear. Finally, Lyapunov analysis on ultimate boundedness and task achievement
is provided, particularly when the proposed prioritized input-output
linearization is applied to the output tracking problem. This work introduces a
new control framework for complex systems having critical and noncritical
control issues, by assigning higher priority to the critical ones.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>A part of this work has been accepted to be published in the IEEE
  Transactions on Automatic Control</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MAC-VO: Metrics-aware Covariance for Learning-based Stereo Visual
  Odometry 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.09479v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.09479v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuheng Qiu, Yutian Chen, Zihao Zhang, Wenshan Wang, Sebastian Scherer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose the MAC-VO, a novel learning-based stereo VO that leverages the
learned metrics-aware matching uncertainty for dual purposes: selecting
keypoint and weighing the residual in pose graph optimization. Compared to
traditional geometric methods prioritizing texture-affluent features like
edges, our keypoint selector employs the learned uncertainty to filter out the
low-quality features based on global inconsistency. In contrast to the
learning-based algorithms that model the scale-agnostic diagonal weight matrix
for covariance, we design a metrics-aware covariance model to capture the
spatial error during keypoint registration and the correlations between
different axes. Integrating this covariance model into pose graph optimization
enhances the robustness and reliability of pose estimation, particularly in
challenging environments with varying illumination, feature density, and motion
patterns. On public benchmark datasets, MAC-VO outperforms existing VO
algorithms and even some SLAM algorithms in challenging environments. The
covariance map also provides valuable information about the reliability of the
estimated poses, which can benefit decision-making for autonomous systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Intelligent logistics management robot path <span class="highlight-title">plan</span>ning algorithm
  integrating transformer and GCN network 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.02749v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.02749v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hao Luo, Jianjun Wei, Shuchen Zhao, Ankai Liang, Zhongjin Xu, Ruxue Jiang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This research delves into advanced route optimization for robots in smart
logistics, leveraging a fusion of Transformer architectures, Graph Neural
Networks (GNNs), and Generative Adversarial Networks (GANs). The approach
utilizes a graph-based representation encompassing geographical data, cargo
allocation, and robot dynamics, addressing both spatial and resource
limitations to refine route efficiency. Through extensive testing with
authentic logistics datasets, the proposed method achieves notable
improvements, including a 15% reduction in travel distance, a 20% boost in time
efficiency, and a 10% decrease in energy consumption. These findings highlight
the algorithm's effectiveness, promoting enhanced performance in intelligent
logistics operations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>21 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ <span class="highlight-title">★</span> Masked Sensory-Temporal Attention for Sensor Generalization in Quadruped
  <span class="highlight-title">Locomotion</span> <span class="chip">ICRA 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.03332v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.03332v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dikai Liu, Tian<span class="highlight-author">wei Zhang</span>, Jianxiong Yin, Simon See
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the rising focus on quadrupeds, a generalized policy capable of handling
different robot models and sensor inputs becomes highly beneficial. Although
several methods have been proposed to address different morphologies, it
remains a challenge for learning-based policies to manage various combinations
of proprioceptive information. This paper presents Masked Sensory-Temporal
Attention (MSTA), a novel transformer-based mechanism with masking for
quadruped locomotion. It employs direct sensor-level attention to enhance the
sensory-temporal understanding and handle different combinations of sensor
data, serving as a foundation for incorporating unseen information. MSTA can
effectively understand its states even with a large portion of missing
information, and is flexible enough to be deployed on physical systems despite
the long input sequence.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for ICRA 2025. Project website for video:
  https://johnliudk.github.io/msta/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Hierarchical Contact-Rich Trajectory <span class="highlight-title">Optimization</span> for Multi-Modal
  <span class="highlight-title">Manipulation</span> using Tight Convex Relaxations <span class="chip">ICRA</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07963v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07963v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuki Shirai, Arvind Raghunathan, Devesh K. Jha
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Designing trajectories for manipulation through contact is challenging as it
requires reasoning of object \& robot trajectories as well as complex contact
sequences simultaneously. In this paper, we present a novel framework for
simultaneously designing trajectories of robots, objects, and contacts
efficiently for contact-rich manipulation. We propose a hierarchical
optimization framework where Mixed-Integer Linear Program (MILP) selects
optimal contacts between robot \& object using approximate dynamical
constraints, and then a NonLinear Program (NLP) optimizes trajectory of the
robot(s) and object considering full nonlinear constraints. We present a convex
relaxation of bilinear constraints using binary encoding technique such that
MILP can provide tighter solutions with better computational complexity. The
proposed framework is evaluated on various manipulation tasks where it can
reason about complex multi-contact interactions while providing computational
advantages. We also demonstrate our framework in hardware experiments using a
bimanual robot system. The video summarizing this paper and hardware
experiments is found https://youtu.be/s2S1Eg5RsRE?si=chPkftz_a3NAHxLq
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>2025 IEEE International Conference on Robotics and Automation (2025
  ICRA)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ExBody2: Advanced Expressive Humanoid Whole-Body Control 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.13196v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.13196v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mazeyu Ji, Xuanbin Peng, Fangchen Liu, Jialong Li, Ge Yang, Xuxin Cheng, Xiaolong Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper tackles the challenge of enabling real-world humanoid robots to
perform expressive and dynamic whole-body motions while maintaining overall
stability and robustness. We propose Advanced Expressive Whole-Body Control
(Exbody2), a method for producing whole-body tracking controllers that are
trained on both human motion capture and simulated data and then transferred to
the real world. We introduce a technique for decoupling the velocity tracking
of the entire body from tracking body landmarks. We use a teacher policy to
produce intermediate data that better conforms to the robot's kinematics and to
automatically filter away infeasible whole-body motions. This two-step approach
enabled us to produce a student policy that can be deployed on the robot that
can walk, crouch, and dance. We also provide insight into the trade-off between
versatility and the tracking performance on specific motions. We observed
significant improvement of tracking performance after fine-tuning on a small
amount of data, at the expense of the others.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>website: https://exbody2.github.io</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Systems and Control <span class="chip" style="font-size: 60%">40</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Analysis and Mitigation of Cascading Failures Using a Stochastic
  Interaction Graph with Eigen-analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09904v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09904v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhenping Guo, Xiaowen Su, Kai Sun, Byungkwon Park, Srdjan Simunovic
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In studies on complex network systems using graph theory, eigen-analysis is
typically performed on an undirected graph model of the network. However, when
analyzing cascading failures in a power system, the interactions among failures
suggest the need for a directed graph beyond the topology of the power system
to model directions of failure propagation. To accurately quantify failure
interactions for effective mitigation strategies, this paper proposes a
stochastic interaction graph model and associated eigen-analysis. Different
types of modes on failure propagations are defined and characterized by the
eigenvalues of a stochastic interaction matrix, whose absolute values are
unity, zero, or in between. Finding and interpreting these modes helps identify
the probable patterns of failure propagation, either local or widespread, and
the participating components based on eigenvectors. Then, by lowering the
failure probabilities of critical components highly participating in a mode of
widespread failures, cascading can be mitigated. The validity of the proposed
stochastic interaction graph model, eigen-analysis and the resulting mitigation
strategies is demonstrated using simulated cascading failure data on an NPCC
140-bus system.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PI-Controlled Variable Time-Step Power System Simulation Using an
  Adaptive Order Differential Transformation Method 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09898v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09898v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kaiyang Huang, Yang Liu, Kai Sun, Feng Qiu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Dynamic simulation plays a crucial role in power system transient stability
analysis, but traditional numerical integration-based methods are
time-consuming due to the small time step sizes. Other semi-analytical solution
methods, such as the Differential Transformation method, often struggle to
select proper orders and steps, leading to slow performance and numerical
instability. To address these challenges, this paper proposes a novel adaptive
dynamic simulation approach for power system transient
  stability analysis. The approach adds feedback control and optimization to
selecting the step and order, utilizing the Differential Transformation method
and a proportional-integral control strategy to control truncation errors.
Order selection is formulated as an optimization problem resulting in a
variable-step-optimal-order method that achieves significantly larger time step
sizes without violating numerical stability. It is applied to three systems:
the IEEE 9-bus, 3-generator system, IEEE 39-bus, 10-generator system, and a
Polish 2383-bus, 327-generator system, promising computational efficiency and
numerical robustness for large-scale power system is demonstrated in
comprehensive case studies.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Heterogeneous Multiscale Method for Efficient Simulation of Power
  Systems with Inverter-Based Resources 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09892v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09892v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kaiyang Huang, Min Xiong, Yang Liu, Kai Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As inverter-based resources (IBRs) penetrate power systems, the dynamics
become more complex, exhibiting multiple timescales, including electromagnetic
transient (EMT) dynamics of power electronic controllers and electromechanical
dynamics of synchronous generators. Consequently, the power system model
becomes highly stiff, posing a challenge for efficient simulation using
existing methods that focus on dynamics within a single timescale. This paper
proposes a Heterogeneous Multiscale Method for highly efficient multi-timescale
simulation of a power system represented by its EMT model. The new method
alternates between the microscopic EMT model of the system and an automatically
reduced macroscopic model, varying the step size accordingly to achieve
significant acceleration while maintaining accuracy in both fast and slow
dynamics of interests. It also incorporates a semi-analytical solution method
to enable a more adaptive variable-step mechanism. The new simulation method is
illustrated using a two-area system and is then tested on a detailed EMT model
of the IEEE 39-bus system.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>IEEE Transactions on Power Systems, Published in Feb 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Identification and Classification of Human Performance related
  Challenges during Remote Driving 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09865v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09865v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ole Hans, Jürgen Adamy
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Remote driving of vehicles is gaining in importance in the transportation
sector, especially when Automated Driving Systems (ADSs) reach the limits of
their system boundaries. This study investigates the challenges faced by human
Remote Drivers (RDs) during remote driving, particularly focusing on the
identification and classification of human performance-related challenges
through a comprehensive analysis of real-world remote driving data Las Vegas.
For this purpose, a total of 183 RD performance-related Safety Driver (SD)
interventions were analyzed and classified using an introduced severity
classification. As it is essential to prevent the need for SD interventions,
this study identified and analyzed harsh driving events to detect an increased
likelihood of interventions by the SD. In addition, the results of the
subjective RD questionnaire are used to evaluate whether the objective metrics
from SD interventions and harsh driving events can also be confirmed by the RDs
and whether additional challenges can be uncovered. The analysis reveals
learning curves, showing a significant decrease in SD interventions as RD
experience increases. Early phases of remote driving experience, especially
below 200 km of experience, showed the highest frequency of safety-related
events, including braking too late for traffic signs and responding impatiently
to other traffic participants. Over time, RDs follow defined rules for
improving their control, with experience leading to less harsh braking,
acceleration, and steering maneuvers. The study contributes to understanding
the requirements of RDS, emphasizing the importance of targeted training to
address human performance limitations. It further highlights the need for
system improvements to address challenges like latency and the limited haptic
feedback replaced by visual feedback, which affect the RDs' perception and
vehicle control.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Passivity-Based Local Design Conditions for Global Optimality in
  Distributed Convex <span class="highlight-title">Optimization</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09854v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09854v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pol Jane-Soneira, Charles Muller, Felix Strehle, Sören Hohmann
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent times, various distributed optimization algorithms have been
proposed for whose specific agent dynamics global optimality and convergence is
proven. However, there exist no general conditions for the design of such
algorithms. In this paper, we leverage passivity theory to fi rst establish a
distributed optimization framework with local design requirements for the agent
dynamics in both unconstrained and constrained problems with undirected
communication topologies. Under the roof of these requirements, the agents may
use heterogeneous optimization algorithms without compromising global
optimality and convergence. Subsequently, we propose some exemplary agent
systems that comply with the established requirements. Compared to existing
approaches, our algorithms do not require any global initialization nor
communication of multiple variables. Consequently, the agents may leave or
rejoin the networked optimization without compromising convergence to the
correct global optimizer. Furthermore, we show that for unconstrained
optimization, an extension to directed communication topologies is possible.
Simulation results illustrate the plug-and-play capabilities and
interoperability of the proposed agent dynamics.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SE(3)-Equivariant Robot Learning and Control: A Tutorial <span class="highlight-title">Survey</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09829v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09829v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Joohwan Seo, Soochul Yoo, Junwoo Chang, Hyunseok An, Hyunwoo Ryu, Soomi Lee, Arvind Kruthiventy, Jongeun CHoi, Roberto Horowitz
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in deep learning and Transformers have driven major
breakthroughs in robotics by employing techniques such as imitation learning,
reinforcement learning, and LLM-based multimodal perception and
decision-making. However, conventional deep learning and Transformer models
often struggle to process data with inherent symmetries and invariances,
typically relying on large datasets or extensive data augmentation. Equivariant
neural networks overcome these limitations by explicitly integrating symmetry
and invariance into their architectures, leading to improved efficiency and
generalization. This tutorial survey reviews a wide range of equivariant deep
learning and control methods for robotics, from classic to state-of-the-art,
with a focus on SE(3)-equivariant models that leverage the natural 3D
rotational and translational symmetries in visual robotic manipulation and
control design. Using unified mathematical notation, we begin by reviewing key
concepts from group theory, along with matrix Lie groups and Lie algebras. We
then introduce foundational group-equivariant neural network design and show
how the group-equivariance can be obtained through their structure. Next, we
discuss the applications of SE(3)-equivariant neural networks in robotics in
terms of imitation learning and reinforcement learning. The SE(3)-equivariant
control design is also reviewed from the perspective of geometric control.
Finally, we highlight the challenges and future directions of equivariant
methods in developing more robust, sample-efficient, and multi-modal real-world
robotic systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to International Journcal of Control, Automation and
  Systems (IJCAS), Under Review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Data-Driven Distributionally Robust Control for Interacting Agents under
  Logical Constraints 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09816v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09816v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Arash Bahari Kordabad, Eleftherios E. Vlahakis, Lars Lindemann, Sebastien Gros, Dimos V. Dimarogonas, Sadegh Soudjani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we propose a distributionally robust control synthesis for an
agent with stochastic dynamics that interacts with other agents under
uncertainties and constraints expressed by signal temporal logic (STL). We
formulate the control synthesis as a chance-constrained program (CCP) with STL
specifications that must be satisfied with high probability under all
uncertainty tubes induced by the other agents. To tackle the CCP, we propose
two methods based on concentration of measure (CoM) theory and conditional
value at risk (CVaR) and compare the required assumptions and resulting
optimizations. These approaches convert the CCP into an expectation-constrained
program (ECP), which is simpler to solve than the original CCP. To estimate the
expectation using a finite set of observed data, we adopt a distributionally
robust optimization (DRO) approach. The underlying DRO can be approximated as a
robust data-driven optimization that provides a probabilistic
under-approximation to the original ECP, where the probability depends on the
number of samples. Therefore, under feasibility, the original STL constraints
are satisfied with two layers of designed confidence: the confidence of the
chance constraint and the confidence of the approximated data-driven
optimization, which depends on the number of samples. We then provide details
on solving the resulting robust data-driven optimization numerically. Finally,
we compare the two proposed approaches through case studies.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages. arXiv admin note: text overlap with arXiv:2409.03855</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Aerocapture Guidance for Augmented Bank Angle Modulation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09806v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09806v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kyle Sonandres, Thomas Palazzo, Jonathan P. How
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents an optimal control solution for an aerocapture vehicle
with two control inputs, bank angle and angle of attack, referred to as
augmented bank angle modulation (ABAM). We derive the optimal control profiles
using Pontryagin's Minimum Principle, validate the result numerically using the
Gauss pseudospectral method (implemented in GPOPS), and introduce a novel
guidance algorithm, ABAMGuid, for in-flight decision making. High-fidelity
Monte Carlo simulations of a Uranus aerocapture mission demonstrate that
ABAMGuid can greatly improve capture success rates and reduce the propellant
needed for orbital correction following the atmospheric pass.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To appear in 2025 American Control Conference (ACC). 6 pages, 2
  figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Real-Time Risky Fault-Chain Search using Time-Varying Graph RNNs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09775v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09775v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anmol Dwivedi, Ali Tajer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces a data-driven graphical framework for the real-time
search of risky cascading fault chains (FCs) in power-grids, crucial for
enhancing grid resiliency in the face of climate change. As extreme weather
events driven by climate change increase, identifying risky FCs becomes crucial
for mitigating cascading failures and ensuring grid stability. However, the
complexity of the spatio-temporal dependencies among grid components and the
exponential growth of the search space with system size pose significant
challenges to modeling and risky FC search. To tackle this, we model the search
process as a partially observable Markov decision process (POMDP), which is
subsequently solved via a time-varying graph recurrent neural network (GRNN).
This approach captures the spatial and temporal structure induced by the
system's topology and dynamics, while efficiently summarizing the system's
history in the GRNN's latent space, enabling scalable and effective
identification of risky FCs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>arXiv admin note: substantial text overlap with arXiv:2303.08864</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The Pitfalls of Imitation Learning when Actions are Continuous 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09722v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09722v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Max Simchowitz, Daniel Pfrommer, Ali Jadbabaie
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study the problem of imitating an expert demonstrator in a discrete-time,
continuous state-and-action control system. We show that, even if the dynamics
are stable (i.e. contracting exponentially quickly), and the expert is smooth
and deterministic, any smooth, deterministic imitator policy necessarily
suffers error on execution that is exponentially larger, as a function of
problem horizon, than the error under the distribution of expert training data.
Our negative result applies to both behavior cloning and offline-RL algorithms,
unless they produce highly "improper" imitator policies--those which are
non-smooth, non-Markovian, or which exhibit highly state-dependent
stochasticity--or unless the expert trajectory distribution is sufficiently
"spread." We provide experimental evidence of the benefits of these more
complex policy parameterizations, explicating the benefits of today's popular
policy parameterizations in robot learning (e.g. action-chunking and Diffusion
Policies). We also establish a host of complementary negative and positive
results for imitation in control systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>98 pages, 2 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Blockchain-Enabled Management Framework for Federated Coalition Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09666v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09666v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jorge Álvaro González, Ana María Saiz García, Victor Monzon Baeza
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In a globalized and interconnected world, interoperability has become a key
concept for advancing tactical scenarios. Federated Coalition Networks (FCN)
enable cooperation between entities from multiple nations while allowing each
to maintain control over their systems. However, this interoperability
necessitates the sharing of increasing amounts of information between different
tactical assets, raising the need for higher security measures. Emerging
technologies like blockchain drive a revolution in secure communications,
paving the way for new tactical scenarios. In this work, we propose a
blockchain-based framework to enhance the resilience and security of the
management of these networks. We offer a guide to FCN design to help a broad
audience understand the military networks in international missions by a use
case and key functions applied to a proposed architecture. We evaluate its
effectiveness and performance in information encryption to validate this
framework.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Fast computation of the TGOSPA metric for multiple target tracking via
  unbalanced optimal transport 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09449v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09449v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Viktor Nevelius Wernholm, Alfred Wärnsäter, Axel Ringh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In multiple target tracking, it is important to be able to evaluate the
performance of different tracking algorithms. The trajectory generalized
optimal sub-pattern assignment metric (TGOSPA) is a recently proposed metric
for such evaluations. The TGOSPA metric is computed as the solution to an
optimization problem, but for large tracking scenarios, solving this problem
becomes computationally demanding. In this paper, we present an approximation
algorithm for evaluating the TGOSPA metric, based on casting the TGOSPA problem
as an unbalanced multimarginal optimal transport problem. Following recent
advances in computational optimal transport, we introduce an entropy
regularization and derive an iterative scheme for solving the Lagrangian dual
of the regularized problem. Numerical results suggest that our proposed
algorithm is more computationally efficient than the alternative of computing
the exact metric using a linear programming solver, while still providing an
adequate approximation of the metric.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Neural-Augmented Incremental Nonlinear Dynamic Inversion for Quadrotors
  with Payload Adaptation <span class="chip">IROS 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09441v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09441v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Eckart Cobo-Briesewitz, Khaled Wahba, Wolfgang Hönig
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The increasing complexity of multirotor applications has led to the need of
more accurate flight controllers that can reliably predict all forces acting on
the robot. Traditional flight controllers model a large part of the forces but
do not take so called residual forces into account. A reason for this is that
accurately computing the residual forces can be computationally expensive.
Incremental Nonlinear Dynamic Inversion (INDI) is a method that computes the
difference between different sensor measurements in order to estimate these
residual forces. The main issue with INDI is it's reliance on special sensor
measurements which can be very noisy. Recent work has also shown that residual
forces can be predicted using learning-based methods. In this work, we
demonstrate that a learning algorithm can predict a smoother version of INDI
outputs without requiring additional sensor measurements. In addition, we
introduce a new method that combines learning based predictions with INDI. We
also adapt the two approaches to work on quadrotors carrying a slung-type
payload. The results show that using a neural network to predict residual
forces can outperform INDI while using the combination of neural network and
INDI can yield even better results than each method individually.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to IROS 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Model-based Approach for Glucose Control via Physical Activity 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09435v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09435v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pierluigi Francesco De Paola, Alessandro Borri, Alessia Paglialonga, Pasquale Palumbo, Fabrizio Dabbene
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The role played by physical activity in slowing down the progression of
type-2 diabetes is well recognized. However, except for general clinical
guidelines, quantitative real-time estimates of the recommended amount of
physical activity, based on the evolving individual conditions, are {still
missing} in the literature. The aim of this work is to provide a
control-theoretical formulation of the exercise encoding all the
exercise-related features (intensity, duration, period). Specifically, we
design a feedback law in terms of recommended physical activity, following a
model predictive control approach, based on a widespread compact diabetes
progression model, suitably modified to account for the long-term effects of
regular exercise. Preliminary simulations show promising results, well aligned
with clinical evidence. These findings can be the basis for further validation
of the control law on high-dimensional diabetes progression models to
ultimately translate the predictions of the controller into meaningful
recommendations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Precoder Learning by Leveraging Unitary Equivariance Property 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09398v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09398v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yilun Ge, Shuyao Liao, Shengqian Han, Chenyang Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Incorporating mathematical properties of a wireless policy to be learned into
the design of deep neural networks (DNNs) is effective for enhancing learning
efficiency. Multi-user precoding policy in multi-antenna system, which is the
mapping from channel matrix to precoding matrix, possesses a permutation
equivariance property, which has been harnessed to design the parameter sharing
structure of the weight matrix of DNNs. In this paper, we study a stronger
property than permutation equivariance, namely unitary equivariance, for
precoder learning. We first show that a DNN with unitary equivariance designed
by further introducing parameter sharing into a permutation equivariant DNN is
unable to learn the optimal precoder. We proceed to develop a novel non-linear
weighting process satisfying unitary equivariance and then construct a joint
unitary and permutation equivariant DNN. Simulation results demonstrate that
the proposed DNN not only outperforms existing learning methods in learning
performance and generalizability but also reduces training complexity.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Context-aware Constrained Reinforcement Learning Based Energy-Efficient
  Power Scheduling for Non-stationary XR Data Traffic 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09391v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09391v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kexuan Wang, An Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In XR downlink transmission, energy-efficient power scheduling (EEPS) is
essential for conserving power resource while delivering large data packets
within hard-latency constraints. Traditional constrained reinforcement learning
(CRL) algorithms show promise in EEPS but still struggle with non-convex
stochastic constraints, non-stationary data traffic, and sparse delayed packet
dropout feedback (rewards) in XR. To overcome these challenges, this paper
models the EEPS in XR as a dynamic parameter-constrained Markov decision
process (DP-CMDP) with a varying transition function linked to the
non-stationary data traffic and solves it by a proposed context-aware
constrained reinforcement learning (CACRL) algorithm, which consists of a
context inference (CI) module and a CRL module. The CI module trains an encoder
and multiple potential networks to characterize the current transition function
and reshape the packet dropout rewards according to the context, transforming
the original DP-CMDP into a general CMDP with immediate dense rewards. The CRL
module employs a policy network to make EEPS decisions under this CMDP and
optimizes the policy using a constrained stochastic successive convex
approximation (CSSCA) method, which is better suited for non-convex stochastic
constraints. Finally, theoretical analyses provide deep insights into the CADAC
algorithm, while extensive simulations demonstrate that it outperforms advanced
baselines in both power conservation and satisfying packet dropout constraints.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Robust Self-Reconfiguration for Fault-Tolerant Control of Modular Aerial
  Robot Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09376v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09376v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rui Huang, Siyu Tang, Zhiqian Cai, Lin Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Modular Aerial Robotic Systems (MARS) consist of multiple drone units
assembled into a single, integrated rigid flying platform. With inherent
redundancy, MARS can self-reconfigure into different configurations to mitigate
rotor or unit failures and maintain stable flight. However, existing works on
MARS self-reconfiguration often overlook the practical controllability of
intermediate structures formed during the reassembly process, which limits
their applicability. In this paper, we address this gap by considering the
control-constrained dynamic model of MARS and proposing a robust and efficient
self-reconstruction algorithm that maximizes the controllability margin at each
intermediate stage. Specifically, we develop algorithms to compute optimal,
controllable disassembly and assembly sequences, enabling robust
self-reconfiguration. Finally, we validate our method in several challenging
fault-tolerant self-reconfiguration scenarios, demonstrating significant
improvements in both controllability and trajectory tracking while reducing the
number of assembly steps. The videos and source code of this work are available
at https://github.com/RuiHuangNUS/MARS-Reconfig/
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Task Allocation for Multi-agent Systems via Unequal-dimensional Optimal
  Transport 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09369v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09369v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anqi Dong, Karl H. Johansson, Johan Karlsson
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We consider a probabilistic model for large-scale task allocation problems
for multi-agent systems, aiming to determine an optimal deployment strategy
that minimizes the overall transport cost. Specifically, we assign
transportation agents to delivery tasks with given pick-up and drop-off
locations, pairing the spatial distribution of transport resources with the
joint distribution of task origins and destinations. This aligns with the
optimal mass transport framework where the problem and is in the
unequal-dimensional setting. The task allocation problem can be thus seen as a
linear programming problem that minimizes a quadratic transport cost
functional, optimizing the energy of all transport units. The problem is
motivated by time-sensitive medical deliveries using drones, such as emergency
equipment and blood transport. In this paper, we establish the existence,
uniqueness, and smoothness of the optimal solution, and illustrate its
properties through numerical simulations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages,4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Robust Fault-Tolerant Control and Agile Trajectory <span class="highlight-title">Plan</span>ning for Modular
  Aerial Robotic Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09351v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09351v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rui Huang, Zhenyu Zhang, Siyu Tang, Zhiqian Cai, Lin Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Modular Aerial Robotic Systems (MARS) consist of multiple drone units that
can self-reconfigure to adapt to various mission requirements and fault
conditions. However, existing fault-tolerant control methods exhibit
significant oscillations during docking and separation, impacting system
stability. To address this issue, we propose a novel fault-tolerant control
reallocation method that adapts to arbitrary number of modular robots and their
assembly formations. The algorithm redistributes the expected collective force
and torque required for MARS to individual unit according to their moment arm
relative to the center of MARS mass. Furthermore, We propose an agile
trajectory planning method for MARS of arbitrary configurations, which is
collision-avoiding and dynamically feasible. Our work represents the first
comprehensive approach to enable fault-tolerant and collision avoidance flight
for MARS. We validate our method through extensive simulations, demonstrating
improved fault tolerance, enhanced trajectory tracking accuracy, and greater
robustness in cluttered environments. The videos and source code of this work
are available at https://github.com/RuiHuangNUS/MARS-FTCC/
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Large-scale Regional Traffic Signal Control Based on Single-Agent
  Reinforcement Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09252v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09252v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qiang Li, Jin Niu, Qin Luo, Lina Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the context of global urbanization and motorization, traffic congestion
has become a significant issue, severely affecting the quality of life,
environment, and economy. This paper puts forward a single-agent reinforcement
learning (RL)-based regional traffic signal control (TSC) model. Different from
multi - agent systems, this model can coordinate traffic signals across a large
area, with the goals of alleviating regional traffic congestion and minimizing
the total travel time. The TSC environment is precisely defined through
specific state space, action space, and reward functions. The state space
consists of the current congestion state, which is represented by the queue
lengths of each link, and the current signal phase scheme of intersections. The
action space is designed to select an intersection first and then adjust its
phase split. Two reward functions are meticulously crafted. One focuses on
alleviating congestion and the other aims to minimize the total travel time
while considering the congestion level. The experiments are carried out with
the SUMO traffic simulation software. The performance of the TSC model is
evaluated by comparing it with a base case where no signal-timing adjustments
are made. The results show that the model can effectively control congestion.
For example, the queuing length is significantly reduced in the scenarios
tested. Moreover, when the reward is set to both alleviate congestion and
minimize the total travel time, the average travel time is remarkably
decreased, which indicates that the model can effectively improve traffic
conditions. This research provides a new approach for large-scale regional
traffic signal control and offers valuable insights for future urban traffic
management.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, 8 figures. arXiv admin note: text overlap with
  arXiv:2503.02279</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Risk Assessment of Distribution Networks Considering Climate Change and
  Vegetation Management Impacts 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09239v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09239v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Di Zhao, Umar Salman, Zongjie Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents a comprehensive risk assessment model for power
distribution networks with a focus on the influence of climate conditions and
vegetation management on outage risks. Using a dataset comprising outage
records, meteorological indicators, and vegetation metrics, this paper develops
a logistic regression model that outperformed several alternatives, effectively
identifying risk factors in highly imbalanced data. Key features impacting
outages include wind speed, vegetation density, quantified as the enhanced
vegetation index (EVI), and snow type, with wet snow and autumn conditions
exhibiting the strongest positive effects. The analysis also shows complex
interactions, such as the combined effect of wind speed and EVI, suggesting
that vegetation density can moderate the impact of high winds on outages.
Simulation case studies, based on a test dataset of 618 samples, demonstrated
that the model achieved an 80\% match rate with real-world data within an error
tolerance of \(\pm 0.05\), showcasing the effectiveness and robustness of the
proposed model while highlighting its potential to inform preventive strategies
for mitigating outage risks in power distribution networks under high-risk
environmental conditions. Future work will integrate vegetation height data
from Lidar and explore alternative modeling approaches to capture potential
non-linear relationships.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Predictor-Based Time Delay Control of A Hex-Jet Unmanned Aerial Vehicle 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09148v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09148v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junning Liang, Haowen Zheng, Yuying Zhang, Yongzhuo Gao, Wei Dong, Ximin Lyu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Turbojet-powered VTOL UAVs have garnered increased attention in heavy-load
transport and emergency services, due to their superior power density and
thrust-to-weight ratio compared to existing electronic propulsion systems. The
main challenge with jet-powered UAVs lies in the complexity of thrust vectoring
mechanical systems, which aim to mitigate the slow dynamics of the turbojet. In
this letter, we introduce a novel turbojet-powered UAV platform named Hex-Jet.
Our concept integrates thrust vectoring and differential thrust for
comprehensive attitude control. This approach notably simplifies the thrust
vectoring mechanism. We utilize a predictor-based time delay control method
based on the frequency domain model in our Hex-Jet controller design to
mitigate the delay in roll attitude control caused by turbojet dynamics. Our
comparative studies provide valuable insights for the UAV community, and flight
tests on the scaled prototype demonstrate the successful implementation and
verification of the proposed predictor-based time delay control technique.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by IEEE Robotics and Automation Letters. 8 pages, 11 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Reliable Solution to Dynamic <span class="highlight-title">Optimization</span> Problems using Integrated
  Residual Regularized Direct Collocation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09123v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09123v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuanbo Nie, Eric C. Kerrigan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Direct collocation is a widely used method for solving dynamic optimization
problems (DOPs), but its implementation simplicity and computational efficiency
are limited for challenging problems like those involving singular arcs. In
this paper, we introduce the direct transcription method of integrated residual
regularized direct collocation (IRR-DC). This method enforces dynamic
constraints through a combination of explicit constraints and penalty terms
within discretized DOPs. This method retains the implementation simplicity of
direct collocation while significantly improving both solution accuracy and
efficiency, particularly for challenging problem types. Through the examples,
we demonstrate that for difficult problems where traditional direct collocation
results in excessive fluctuations or large errors between collocation points,
IRR-DC effectively suppresses oscillations and yields solutions with greater
accuracy (several magnitudes lower in various error metrics) compared to other
regularization alternatives.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Data-Driven Inverse Optimal Control for Continuous-Time Nonlinear
  Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09090v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09090v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hamed Jabbari Asl, Eiji Uchibe
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces a novel model-free and a partially model-free algorithm
for inverse optimal control (IOC), also known as inverse reinforcement learning
(IRL), aimed at estimating the cost function of continuous-time nonlinear
deterministic systems. Using the input-state trajectories of an expert agent,
the proposed algorithms separately utilize control policy information and the
Hamilton-Jacobi-Bellman equation to estimate different sets of cost function
parameters. This approach allows the algorithms to achieve broader
applicability while maintaining a model-free framework. Also, the model-free
algorithm reduces complexity compared to existing methods, as it requires
solving a forward optimal control problem only once during initialization.
Furthermore, in our partially model-free algorithm, this step can be bypassed
entirely for systems with known input dynamics. Simulation results demonstrate
the effectiveness and efficiency of our algorithms, highlighting their
potential for real-world deployment in autonomous systems and robotics.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Incentive Analysis for Agent Participation in Federated Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09039v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09039v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lihui Yi, Xiaochun Niu, Ermin Wei
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Federated learning offers a decentralized approach to machine learning, where
multiple agents collaboratively train a model while preserving data privacy. In
this paper, we investigate the decision-making and equilibrium behavior in
federated learning systems, where agents choose between participating in global
training or conducting independent local training. The problem is first modeled
as a stage game and then extended to a repeated game to analyze the long-term
dynamics of agent participation. For the stage game, we characterize the
participation patterns and identify Nash equilibrium, revealing how data
heterogeneity influences the equilibrium behavior-specifically, agents with
similar data qualities will participate in FL as a group. We also derive the
optimal social welfare and show that it coincides with Nash equilibrium under
mild assumptions. In the repeated game, we propose a privacy-preserving,
computationally efficient myopic strategy. This strategy enables agents to make
practical decisions under bounded rationality and converges to a neighborhood
of Nash equilibrium of the stage game in finite time. By combining theoretical
insights with practical strategy design, this work provides a realistic and
effective framework for guiding and analyzing agent behaviors in federated
learning systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ManeuverGPT Agentic Control for Safe Autonomous Stunt Maneuvers <span class="chip">IROS</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09035v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09035v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shawn Azdam, Pranav Doma, Aliasghar Moj Arab
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The next generation of active safety features in autonomous vehicles should
be capable of safely executing evasive hazard-avoidance maneuvers akin to those
performed by professional stunt drivers to achieve high-agility motion at the
limits of vehicle handling. This paper presents a novel framework, ManeuverGPT,
for generating and executing high-dynamic stunt maneuvers in autonomous
vehicles using large language model (LLM)-based agents as controllers. We
target aggressive maneuvers, such as J-turns, within the CARLA simulation
environment and demonstrate an iterative, prompt-based approach to refine
vehicle control parameters, starting tabula rasa without retraining model
weights. We propose an agentic architecture comprised of three specialized
agents (1) a Query Enricher Agent for contextualizing user commands, (2) a
Driver Agent for generating maneuver parameters, and (3) a Parameter Validator
Agent that enforces physics-based and safety constraints. Experimental results
demonstrate successful J-turn execution across multiple vehicle models through
textual prompts that adapt to differing vehicle dynamics. We evaluate
performance via established success criteria and discuss limitations regarding
numeric precision and scenario complexity. Our findings underscore the
potential of LLM-driven control for flexible, high-dynamic maneuvers, while
highlighting the importance of hybrid approaches that combine language-based
reasoning with algorithmic validation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 Pages, Submitted to IROS</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Traffic Regulation-aware Path <span class="highlight-title">Plan</span>ning with Regulation Databases and
  Vision-Language Models <span class="chip">ICRA</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09024v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09024v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xu Han, Zhiwen Wu, Xin Xia, Jiaqi Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces and tests a framework integrating traffic regulation
compliance into automated driving systems (ADS). The framework enables ADS to
follow traffic laws and make informed decisions based on the driving
environment. Using RGB camera inputs and a vision-language model (VLM), the
system generates descriptive text to support a regulation-aware decision-making
process, ensuring legal and safe driving practices. This information is
combined with a machine-readable ADS regulation database to guide future
driving plans within legal constraints. Key features include: 1) a regulation
database supporting ADS decision-making, 2) an automated process using sensor
input for regulation-aware path planning, and 3) validation in both simulated
and real-world environments. Particularly, the real-world vehicle tests not
only assess the framework's performance but also evaluate the potential and
challenges of VLMs to solve complex driving problems by integrating detection,
reasoning, and planning. This work enhances the legality, safety, and public
trust in ADS, representing a significant step forward in the field.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>7 pages, 7 figures, submitted to ICRA</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Accurate Control under Voltage Drop for Rotor Drones 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09017v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09017v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuhang Liu, Jindou Jia, Zihan Yang, Kexin Guo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This letter proposes an anti-disturbance control scheme for rotor drones to
counteract voltage drop (VD) disturbance caused by voltage drop of the battery,
which is a common case for long-time flight or aggressive maneuvers. Firstly,
the refined dynamics of rotor drones considering VD disturbance are presented.
Based on the dynamics, a voltage drop observer (VDO) is developed to accurately
estimate the VD disturbance by decoupling the disturbance and state information
of the drone, reducing the conservativeness of conventional disturbance
observers. Subsequently, the control scheme integrates the VDO within the
translational loop and a fixed-time sliding mode observer (SMO) within the
rotational loop, enabling it to address force and torque disturbances caused by
voltage drop of the battery. Sufficient real flight experiments are conducted
to demonstrate the effectiveness of the proposed control scheme under VD
disturbance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ TetraGrip: Sensor-Driven Multi-Suction Reactive Object <span class="highlight-title">Manipulation</span> in
  Cluttered Scenes 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08978v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08978v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Paolo Torrado, Joshua Levin, Markus Grotz, Joshua Smith
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Warehouse robotic systems equipped with vacuum grippers must reliably grasp a
diverse range of objects from densely packed shelves. However, these
environments present significant challenges, including occlusions, diverse
object orientations, stacked and obstructed items, and surfaces that are
difficult to suction. We introduce \tetra, a novel vacuum-based grasping
strategy featuring four suction cups mounted on linear actuators. Each actuator
is equipped with an optical time-of-flight (ToF) proximity sensor, enabling
reactive grasping.
  We evaluate \tetra in a warehouse-style setting, demonstrating its ability to
manipulate objects in stacked and obstructed configurations. Our results show
that our RL-based policy improves picking success in stacked-object scenarios
by 22.86\% compared to a single-suction gripper. Additionally, we demonstrate
that TetraGrip can successfully grasp objects in scenarios where a
single-suction gripper fails due to physical limitations, specifically in two
cases: (1) picking an object occluded by another object and (2) retrieving an
object in a complex scenario. These findings highlight the advantages of
multi-actuated, suction-based grasping in unstructured warehouse environments.
The project website is available at:
\href{https://tetragrip.github.io/}{https://tetragrip.github.io/}.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Real-Time Decision-Making for Digital Twin in Additive Manufacturing
  with <span class="highlight-title">Model Predictive</span> Control using Time-Series Deep Neural Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.07601v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.07601v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yi-Ping Chen, Vispi Karkaria, Ying-Kuan Tsai, Faith Rolark, Daniel Quispe, Robert X. Gao, Jian Cao, Wei Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Digital Twin -- a virtual replica of a physical system enabling real-time
monitoring, model updating, prediction, and decision-making -- combined with
recent advances in machine learning, offers new opportunities for proactive
control strategies in autonomous manufacturing. However, achieving real-time
decision-making with Digital Twins requires efficient optimization driven by
accurate predictions of highly nonlinear manufacturing systems. This paper
presents a simultaneous multi-step Model Predictive Control (MPC) framework for
real-time decision-making, using a multivariate deep neural network, named
Time-Series Dense Encoder (TiDE), as the surrogate model. Unlike conventional
MPC models which only provide one-step ahead prediction, TiDE is capable of
predicting future states within the prediction horizon in one shot
(multi-step), significantly accelerating the MPC. Using Directed Energy
Deposition (DED) additive manufacturing as a case study, we demonstrate the
effectiveness of the proposed MPC in achieving melt pool temperature tracking
to ensure part quality, while reducing porosity defects by regulating laser
power to maintain melt pool depth constraints. In this work, we first show that
TiDE is capable of accurately predicting melt pool temperature and depth.
Second, we demonstrate that the proposed MPC achieves precise temperature
tracking while satisfying melt pool depth constraints within a targeted
dilution range (10\%-30\%), reducing potential porosity defects. Compared to
PID controller, the MPC results in smoother and less fluctuating laser power
profiles with competitive or superior melt pool temperature control
performance. This demonstrates the MPC's proactive control capabilities,
leveraging time-series prediction and real-time optimization, positioning it as
a powerful tool for future Digital Twin applications and real-time process
optimization in manufacturing.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Quantifying Aleatoric and Epistemic Dynamics Uncertainty via Local
  Conformal Calibration 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.08249v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.08249v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Luís Marques, Dmitry Berenson
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Whether learned, simulated, or analytical, approximations of a robot's
dynamics can be inaccurate when encountering novel environments. Many
approaches have been proposed to quantify the aleatoric uncertainty of such
methods, i.e. uncertainty resulting from stochasticity, however these estimates
alone are not enough to properly estimate the uncertainty of a model in a novel
environment, where the actual dynamics can change. Such changes can induce
epistemic uncertainty, i.e. uncertainty due to a lack of information/data.
Accounting for both epistemic and aleatoric dynamics uncertainty in a
theoretically-grounded way remains an open problem. We introduce Local
Uncertainty Conformal Calibration (LUCCa), a conformal prediction-based
approach that calibrates the aleatoric uncertainty estimates provided by
dynamics models to generate probabilistically-valid prediction regions of the
system's state. We account for both epistemic and aleatoric uncertainty
non-asymptotically, without strong assumptions about the form of the true
dynamics or how it changes. The calibration is performed locally in the
state-action space, leading to uncertainty estimates that are useful for
planning. We validate our method by constructing probabilistically-safe plans
for a double-integrator under significant changes in dynamics.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>24 pages, 9 figures. Accepted to the 16th International Workshop on
  the Algorithmic Foundations of Robotics (WAFR) 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Safe and Dynamically-Feasible Motion <span class="highlight-title">Plan</span>ning using Control Lyapunov and
  Barrier Functions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.08364v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.08364v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pol Mestres, Carlos Nieto-Granda, Jorge Cortés
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper considers the problem of designing motion planning algorithms for
control-affine systems that generate collision-free paths from an initial to a
final destination and can be executed using safe and dynamically-feasible
controllers. We introduce the C-CLF-CBF-RRT algorithm, which produces paths
with such properties and leverages rapidly exploring random trees (RRTs),
control Lyapunov functions (CLFs) and control barrier functions (CBFs). We show
that C-CLF-CBF-RRT is computationally efficient for linear systems with
polytopic and ellipsoidal constraints, and establish its probabilistic
completeness. We showcase the performance of C-CLF-CBF-RRT in different
simulation and hardware experiments.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DeepUKF-VIN: Adaptively-tuned Deep Unscented Kalman Filter for 3D
  Visual-Inertial <span class="highlight-title">Navigation</span> based on IMU-Vision-Net 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.00575v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.00575v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Khashayar Ghanizadegan, Hashim A. Hashim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper addresses the challenge of estimating the orientation, position,
and velocity of a vehicle operating in three-dimensional (3D) space with six
degrees of freedom (6-DoF). A Deep Learning-based Adaptation Mechanism (DLAM)
is proposed to adaptively tune the noise covariance matrices of Kalman-type
filters for the Visual-Inertial Navigation (VIN) problem, leveraging
IMU-Vision-Net. Subsequently, an adaptively tuned Deep Learning Unscented
Kalman Filter for 3D VIN (DeepUKF-VIN) is introduced to utilize the proposed
DLAM, thereby robustly estimating key navigation components, including
orientation, position, and linear velocity. The proposed DeepUKF-VIN integrates
data from onboard sensors, specifically an inertial measurement unit (IMU) and
visual feature points extracted from a camera, and is applicable for GPS-denied
navigation. Its quaternion-based design effectively captures navigation
nonlinearities and avoids the singularities commonly encountered with
Euler-angle-based filters. Implemented in discrete space, the DeepUKF-VIN
facilitates practical filter deployment. The filter's performance is evaluated
using real-world data collected from an IMU and a stereo camera at low sampling
rates. The results demonstrate filter stability and rapid attenuation of
estimation errors, highlighting its high estimation accuracy. Furthermore,
comparative testing against the standard Unscented Kalman Filter (UKF) in two
scenarios consistently shows superior performance across all navigation
components, thereby validating the efficacy and robustness of the proposed
DeepUKF-VIN. Keywords: Deep Learning, Unscented Kalman Filter, Adaptive tuning,
Estimation, Navigation, Unmanned Aerial Vehicle, Sensor-fusion.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Fair Play in the Fast Lane: Integrating Sportsmanship into Autonomous
  Racing Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03774v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03774v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhenmin Huang, Ce Hao, Wei Zhan, Jun Ma, Masayoshi Tomizuka
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Autonomous racing has gained significant attention as a platform for
high-speed decision-making and motion control. While existing methods primarily
focus on trajectory planning and overtaking strategies, the role of
sportsmanship in ensuring fair competition remains largely unexplored. In human
racing, rules such as the one-motion rule and the enough-space rule prevent
dangerous and unsportsmanlike behavior. However, autonomous racing systems
often lack mechanisms to enforce these principles, potentially leading to
unsafe maneuvers. This paper introduces a bi-level game-theoretic framework to
integrate sportsmanship (SPS) into versus racing. At the high level, we model
racing intentions using a Stackelberg game, where Monte Carlo Tree Search
(MCTS) is employed to derive optimal strategies. At the low level, vehicle
interactions are formulated as a Generalized Nash Equilibrium Problem (GNEP),
ensuring that all agents follow sportsmanship constraints while optimizing
their trajectories. Simulation results demonstrate the effectiveness of the
proposed approach in enforcing sportsmanship rules while maintaining
competitive performance. We analyze different scenarios where attackers and
defenders adhere to or disregard sportsmanship rules and show how knowledge of
these constraints influences strategic decision-making. This work highlights
the importance of balancing competition and fairness in autonomous racing and
provides a foundation for developing ethical and safe AI-driven racing systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Construction of the Sparsest Maximally $r$-Robust Graphs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.19465v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.19465v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haejoon Lee, Dimitra Panagou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, the notion of r-robustness for the communication graph of
the network has been introduced to address the challenge of achieving consensus
in the presence of misbehaving agents. Higher r-robustness typically implies
higher tolerance to malicious information towards achieving resilient
consensus, but it also implies more edges for the communication graph. This in
turn conflicts with the need to minimize communication due to limited resources
in real-world applications (e.g., multi-robot networks). In this paper, our
contributions are twofold. (a) We provide the necessary subgraph structures and
tight lower bounds on the number of edges required for graphs with a given
number of nodes to achieve maximum robustness. (b) We then use the results of
(a) to introduce two classes of graphs that maintain maximum robustness with
the least number of edges. Our work is validated through a series of
simulations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted and will appear at IEEE CDC 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CommonPower: A Framework for Safe Data-Driven Smart Grid Control 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.03231v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.03231v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Michael Eichelbeck, Hannah Markgraf, Matthias Althoff
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The growing complexity of power system management has led to an increased
interest in reinforcement learning (RL). To validate their effectiveness, RL
algorithms have to be evaluated across multiple case studies. Case study design
is an arduous task requiring the consideration of many aspects, among them the
influence of available forecasts and the level of decentralization in the
control structure. Furthermore, vanilla RL controllers cannot themselves ensure
the satisfaction of system constraints, which makes devising a safeguarding
mechanism a necessary task for every case study before deploying the system. To
address these shortcomings, we introduce the Python tool CommonPower, the first
general framework for the modeling and simulation of power system management
tailored towards machine learning. Its modular architecture enables users to
focus on specific elements without having to implement a simulation
environment. Another unique contribution of CommonPower is the automatic
synthesis of model predictive controllers and safeguards. Beyond offering a
unified interface for single-agent RL, multi-agent RL, and optimal control,
CommonPower includes a training pipeline for machine-learning-based forecasters
as well as a flexible mechanism for incorporating feedback of safeguards into
the learning updates of RL controllers.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>For the corresponding code repository, see
  https://github.com/TUMcps/commonpower</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Hierarchical Neuro-Symbolic Decision Transformer 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07148v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07148v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ali Baheri, Cecilia O. Alm
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a hierarchical neuro-symbolic control framework that couples
classical symbolic planning with transformer-based policies to address complex,
long-horizon decision-making tasks. At the high level, a symbolic planner
constructs an interpretable sequence of operators based on logical
propositions, ensuring systematic adherence to global constraints and goals. At
the low level, each symbolic operator is translated into a sub-goal token that
conditions a decision transformer to generate a fine-grained sequence of
actions in uncertain, high-dimensional environments. We provide theoretical
analysis showing how approximation errors from both the symbolic planner and
the neural execution layer accumulate. Empirical evaluations in grid-worlds
with multiple keys, locked doors, and item-collection tasks show that our
hierarchical approach outperforms purely end-to-end neural approach in success
rates and policy efficiency.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Input-Output Feedback Linearization Preserving Task Priority for
  Multivariate Nonlinear Systems Having Singular Input Gain Matrix 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2305.01903v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2305.01903v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sang-ik An, Dongheui Lee, Gyunghoon Park
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose an extension of the input-output feedback linearization for a
class of multivariate systems that are not input-output linearizable in a
classical manner. The key observation is that the usual input-output
linearization problem can be interpreted as the problem of solving simultaneous
linear equations associated with the input gain matrix: thus, even at points
where the input gain matrix becomes singular, it is still possible to solve a
part of linear equations, by which a subset of input-output relations is made
linear or close to be linear. Based on this observation, we adopt the task
priority-based approach in the input-output linearization problem. First, we
generalize the classical Byrnes-Isidori normal form to a prioritized normal
form having a triangular structure, so that the singularity of a subblock of
the input gain matrix related to lower-priority tasks does not directly
propagate to higher-priority tasks. Next, we present a prioritized input-output
linearization via the multi-objective optimization with the lexicographical
ordering, resulting in a prioritized semilinear form that establishes input
output relations whose subset with higher priority is linear or close to be
linear. Finally, Lyapunov analysis on ultimate boundedness and task achievement
is provided, particularly when the proposed prioritized input-output
linearization is applied to the output tracking problem. This work introduces a
new control framework for complex systems having critical and noncritical
control issues, by assigning higher priority to the critical ones.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>A part of this work has been accepted to be published in the IEEE
  Transactions on Automatic Control</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Koopman Spectral Analysis from Noisy Measurements based on Bayesian
  Learning and Kalman Smoothing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00703v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00703v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhexuan Zeng, Jun Zhou, Yasen Wang, Zuowei Ping
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Koopman spectral analysis plays a crucial role in understanding and modeling
nonlinear dynamical systems as it reveals key system behaviors and long-term
dynamics. However, the presence of measurement noise poses a significant
challenge to accurately extracting spectral properties. In this work, we
propose a robust method for identifying the Koopman operator and extracting its
spectral characteristics in noisy environments. To address the impact of noise,
our approach tackles an identification problem that accounts for both
systematic errors from finite-dimensional approximations and measurement noise
in the data. By incorporating Bayesian learning and Kalman smoothing, the
method simultaneously identifies the Koopman operator and estimates system
states, effectively decoupling these two error sources. The method's efficiency
and robustness are demonstrated through extensive experiments, showcasing its
accuracy across varying noise levels.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Hierarchical Contact-Rich Trajectory <span class="highlight-title">Optimization</span> for Multi-Modal
  <span class="highlight-title">Manipulation</span> using Tight Convex Relaxations <span class="chip">ICRA</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07963v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07963v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuki Shirai, Arvind Raghunathan, Devesh K. Jha
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Designing trajectories for manipulation through contact is challenging as it
requires reasoning of object \& robot trajectories as well as complex contact
sequences simultaneously. In this paper, we present a novel framework for
simultaneously designing trajectories of robots, objects, and contacts
efficiently for contact-rich manipulation. We propose a hierarchical
optimization framework where Mixed-Integer Linear Program (MILP) selects
optimal contacts between robot \& object using approximate dynamical
constraints, and then a NonLinear Program (NLP) optimizes trajectory of the
robot(s) and object considering full nonlinear constraints. We present a convex
relaxation of bilinear constraints using binary encoding technique such that
MILP can provide tighter solutions with better computational complexity. The
proposed framework is evaluated on various manipulation tasks where it can
reason about complex multi-contact interactions while providing computational
advantages. We also demonstrate our framework in hardware experiments using a
bimanual robot system. The video summarizing this paper and hardware
experiments is found https://youtu.be/s2S1Eg5RsRE?si=chPkftz_a3NAHxLq
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>2025 IEEE International Conference on Robotics and Automation (2025
  ICRA)</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Optimization and Control <span class="chip" style="font-size: 60%">49</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Semantic-Loss Function Modeling Framework With Task-Oriented Machine
  Learning Perspectives 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09903v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09903v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ti Ti Nguyen, Thanh-Dung Le, Vu Nguyen Ha, Hong-fu Chou, Geoffrey Eappen, Duc-Dung Tran, Hung Nguyen-Kha, Prabhu Thiruvasagam, Luis M. Garces-Socarras, Jorge L. Gonzalez-Rios, Juan C. Merlano-Duncan, Symeon Chatzinotas
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The integration of machine learning (ML) has significantly enhanced the
capabilities of Earth Observation (EO) systems by enabling the extraction of
actionable insights from complex datasets. However, the performance of
data-driven EO applications is heavily influenced by the data collection and
transmission processes, where limited satellite bandwidth and latency
constraints can hinder the full transmission of original data to the receivers.
To address this issue, adopting the concepts of Semantic Communication (SC)
offers a promising solution by prioritizing the transmission of essential data
semantics over raw information. Implementing SC for EO systems requires a
thorough understanding of the impact of data processing and communication
channel conditions on semantic loss at the processing center. This work
proposes a novel data-fitting framework to empirically model the semantic loss
using real-world EO datasets and domain-specific insights. The framework
quantifies two primary types of semantic loss: (1) source coding loss, assessed
via a data quality indicator measuring the impact of processing on raw source
data, and (2) transmission loss, evaluated by comparing practical transmission
performance against the Shannon limit. Semantic losses are estimated by
evaluating the accuracy of EO applications using four task-oriented ML models,
EfficientViT, MobileViT, ResNet50-DINO, and ResNet8-KD, on lossy image datasets
under varying channel conditions and compression ratios. These results underpin
a framework for efficient semantic-loss modeling in bandwidth-constrained EO
scenarios, enabling more reliable and effective operations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 11 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Heterogeneous Multiscale Method for Efficient Simulation of Power
  Systems with Inverter-Based Resources 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09892v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09892v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kaiyang Huang, Min Xiong, Yang Liu, Kai Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As inverter-based resources (IBRs) penetrate power systems, the dynamics
become more complex, exhibiting multiple timescales, including electromagnetic
transient (EMT) dynamics of power electronic controllers and electromechanical
dynamics of synchronous generators. Consequently, the power system model
becomes highly stiff, posing a challenge for efficient simulation using
existing methods that focus on dynamics within a single timescale. This paper
proposes a Heterogeneous Multiscale Method for highly efficient multi-timescale
simulation of a power system represented by its EMT model. The new method
alternates between the microscopic EMT model of the system and an automatically
reduced macroscopic model, varying the step size accordingly to achieve
significant acceleration while maintaining accuracy in both fast and slow
dynamics of interests. It also incorporates a semi-analytical solution method
to enable a more adaptive variable-step mechanism. The new simulation method is
illustrated using a two-area system and is then tested on a detailed EMT model
of the IEEE 39-bus system.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>IEEE Transactions on Power Systems, Published in Feb 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Passivity-Based Local Design Conditions for Global Optimality in
  Distributed Convex <span class="highlight-title">Optimization</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09854v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09854v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pol Jane-Soneira, Charles Muller, Felix Strehle, Sören Hohmann
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent times, various distributed optimization algorithms have been
proposed for whose specific agent dynamics global optimality and convergence is
proven. However, there exist no general conditions for the design of such
algorithms. In this paper, we leverage passivity theory to fi rst establish a
distributed optimization framework with local design requirements for the agent
dynamics in both unconstrained and constrained problems with undirected
communication topologies. Under the roof of these requirements, the agents may
use heterogeneous optimization algorithms without compromising global
optimality and convergence. Subsequently, we propose some exemplary agent
systems that comply with the established requirements. Compared to existing
approaches, our algorithms do not require any global initialization nor
communication of multiple variables. Consequently, the agents may leave or
rejoin the networked optimization without compromising convergence to the
correct global optimizer. Furthermore, we show that for unconstrained
optimization, an extension to directed communication topologies is possible.
Simulation results illustrate the plug-and-play capabilities and
interoperability of the proposed agent dynamics.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A second order numerical scheme for optimal control of non-linear
  Fokker-<span class="highlight-title">Plan</span>ck equations and applications in social dynamics 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09848v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09848v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Giacomo Albi, Elisa Calzola
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work, we present a second-order numerical scheme to address the
solution of optimal control problems constrained by the evolution of nonlinear
Fokker-Planck equations arising from socio-economic dynamics. In order to
design an appropriate numerical scheme for control realization, a coupled
forward-backward system is derived based on the associated optimality
conditions. The forward equation, corresponding to the Fokker-Planck dynamics,
is discretized using a structure preserving scheme able to capture steady
states. On the other hand, the backward equation, modeled as a
Hamilton-Jacobi-Bellman problem, is solved via a semi-Lagrangian scheme that
supports large time steps while preserving stability. Coupling between the
forward and backward problems is achieved through a gradient descent
optimization strategy, ensuring convergence to the optimal control. Numerical
experiments demonstrate second-order accuracy, computational efficiency, and
effectiveness in controlling different examples across various scenarios in
social dynamics. This approach provides a reliable computational tool for the
study of opinion manipulation and consensus formation in socially structured
systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Data-Driven Distributionally Robust Control for Interacting Agents under
  Logical Constraints 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09816v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09816v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Arash Bahari Kordabad, Eleftherios E. Vlahakis, Lars Lindemann, Sebastien Gros, Dimos V. Dimarogonas, Sadegh Soudjani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we propose a distributionally robust control synthesis for an
agent with stochastic dynamics that interacts with other agents under
uncertainties and constraints expressed by signal temporal logic (STL). We
formulate the control synthesis as a chance-constrained program (CCP) with STL
specifications that must be satisfied with high probability under all
uncertainty tubes induced by the other agents. To tackle the CCP, we propose
two methods based on concentration of measure (CoM) theory and conditional
value at risk (CVaR) and compare the required assumptions and resulting
optimizations. These approaches convert the CCP into an expectation-constrained
program (ECP), which is simpler to solve than the original CCP. To estimate the
expectation using a finite set of observed data, we adopt a distributionally
robust optimization (DRO) approach. The underlying DRO can be approximated as a
robust data-driven optimization that provides a probabilistic
under-approximation to the original ECP, where the probability depends on the
number of samples. Therefore, under feasibility, the original STL constraints
are satisfied with two layers of designed confidence: the confidence of the
chance constraint and the confidence of the approximated data-driven
optimization, which depends on the number of samples. We then provide details
on solving the resulting robust data-driven optimization numerically. Finally,
we compare the two proposed approaches through case studies.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages. arXiv admin note: text overlap with arXiv:2409.03855</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Aerocapture Guidance for Augmented Bank Angle Modulation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09806v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09806v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kyle Sonandres, Thomas Palazzo, Jonathan P. How
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents an optimal control solution for an aerocapture vehicle
with two control inputs, bank angle and angle of attack, referred to as
augmented bank angle modulation (ABAM). We derive the optimal control profiles
using Pontryagin's Minimum Principle, validate the result numerically using the
Gauss pseudospectral method (implemented in GPOPS), and introduce a novel
guidance algorithm, ABAMGuid, for in-flight decision making. High-fidelity
Monte Carlo simulations of a Uranus aerocapture mission demonstrate that
ABAMGuid can greatly improve capture success rates and reduce the propellant
needed for orbital correction following the atmospheric pass.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To appear in 2025 American Control Conference (ACC). 6 pages, 2
  figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Achieving constant regret for dynamic matching via state-independent
  policies 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09762v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09762v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Süleyman Kerimov, Mingwei Yang, Sophie H. Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study a centralized discrete-time dynamic two-way matching model with
finitely many agent types. Agents arrive stochastically over time and join
their type-dedicated queues waiting to be matched. We focus on
state-independent greedy policies that achieve constant regret at all times by
making matching decisions based solely on agent availability across types,
rather than requiring complete queue-length information. Such policies are
particularly appealing for life-saving applications such as kidney exchange, as
they require less information and provide more transparency compared to
state-dependent policies.
  First, for acyclic matching networks, we analyze a deterministic priority
policy proposed by Kerimov et al. [2023] that follows a static priority order
over matches. We derive the first explicit regret bound in terms of the general
position gap (GPG) parameter $\epsilon$, which measures the distance of the
fluid relaxation from degeneracy. Second, for general two-way matching
networks, we design a randomized state-independent greedy policy that achieves
constant regret with optimal scaling $O(\epsilon^{-1})$, matching the existing
lower bound established by Kerimov et al. [2024].
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Unveiling Hidden Pivotal Players with GoalNet: A GNN-Based Soccer Player
  Evaluation System 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09737v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09737v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jacky Hao Jiang, Jerry Cai, Anastasios Kyrillidis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Soccer analysis tools emphasize metrics such as expected goals, leading to an
overrepresentation of attacking players' contributions and overlooking players
who facilitate ball control and link attacks. Examples include Rodri from
Manchester City and Palhinha who just transferred to Bayern Munich. To address
this bias, we aim to identify players with pivotal roles in a soccer team,
incorporating both spatial and temporal features.
  In this work, we introduce a GNN-based framework that assigns individual
credit for changes in expected threat (xT), thus capturing overlooked yet vital
contributions in soccer. Our pipeline encodes both spatial and temporal
features in event-centric graphs, enabling fair attribution of non-scoring
actions such as defensive or transitional plays. We incorporate centrality
measures into the learned player embeddings, ensuring that ball-retaining
defenders and defensive midfielders receive due recognition for their overall
impact. Furthermore, we explore diverse GNN variants-including Graph Attention
Networks and Transformer-based models-to handle long-range dependencies and
evolving match contexts, discussing their relative performance and
computational complexity. Experiments on real match data confirm the robustness
of our approach in highlighting pivotal roles that traditional attacking
metrics typically miss, underscoring the model's utility for more comprehensive
soccer analytics.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages, 4-5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Data-driven geometric parameter <span class="highlight-title">optimization</span> for PD-GMRES 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09728v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09728v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lennart Duvenbeck, Cedric Riethmüller, Christian Rohde
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Restarted GMRES is a robust and widely used iterative solver for linear
systems. The control of the restart parameter is a key task to accelerate
convergence and to prevent the well-known stagnation phenomenon. We focus on
the Proportional-Derivative GMRES (PD-GMRES), which has been derived using
control-theoretic ideas in [Cuevas N\'u\~nez, Schaerer, and Bhaya (2018)] as a
versatile method for modifying the restart parameter. Several variants of a
quadtree-based geometric optimization approach are proposed to find a best
choice of PD-GMRES parameters. We show that the optimized PD-GMRES performs
well across a large number of matrix types and we observe superior performance
as compared to major other GMRES-based iterative solvers. Moreover, we propose
an extension of the PD-GMRES algorithm to further improve performance by
controlling the range of values for the restart parameter.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Hardware-Compatible Single-Shot Feasible-Space Heuristics for Solving
  the Quadratic Assignment Problem 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09676v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09676v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haesol Im, Chan-Woo Yang, Moslem Noori, Dmitrii Dobrynin, Elisabetta Valiante, Giacomo Pedretti, Arne Heittmann, Thomas Van Vaerenbergh, Masoud Mohseni, John Paul Strachan, Dmitri Strukov, Ray Beausoleil, Ignacio Rozada
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Research into the development of special-purpose computing architectures
designed to solve quadratic unconstrained binary optimization (QUBO) problems
has flourished in recent years. It has been demonstrated in the literature that
such special-purpose solvers can outperform traditional CMOS architectures by
orders of magnitude with respect to timing metrics on synthetic problems.
However, they face challenges with constrained problems such as the quadratic
assignment problem (QAP), where mapping to binary formulations such as QUBO
introduces overhead and limits parallelism. In-memory computing (IMC) devices,
such as memristor-based analog Ising machines, offer significant speedups and
efficiency gains over traditional CPU-based solvers, particularly for solving
combinatorial optimization problems. In this work, we present a novel local
search heuristic designed for IMC hardware to tackle the QAP. Our approach
enables massive parallelism that allows for computing of full neighbourhoods
simultaneously to make update decisions. We ensure binary solutions remain
feasible by selecting local moves that lead to neighbouring feasible solutions,
leveraging feasible-space search heuristics and the underlying structure of a
given problem. Our approach is compatible with both digital computers and
analog hardware. We demonstrate its effectiveness in CPU implementations by
comparing it with state-of-the-art heuristics for solving the QAP.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>28 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Global Convergence and Rich Feature Learning in $L$-Layer Infinite-Width
  Neural Networks under $μ$P Parametrization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09565v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09565v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zixiang Chen, Greg Yang, Qingyue Zhao, Quanquan Gu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite deep neural networks' powerful representation learning capabilities,
theoretical understanding of how networks can simultaneously achieve meaningful
feature learning and global convergence remains elusive. Existing approaches
like the neural tangent kernel (NTK) are limited because features stay close to
their initialization in this parametrization, leaving open questions about
feature properties during substantial evolution. In this paper, we investigate
the training dynamics of infinitely wide, $L$-layer neural networks using the
tensor program (TP) framework. Specifically, we show that, when trained with
stochastic gradient descent (SGD) under the Maximal Update parametrization
($\mu$P) and mild conditions on the activation function, SGD enables these
networks to learn linearly independent features that substantially deviate from
their initial values. This rich feature space captures relevant data
information and ensures that any convergent point of the training process is a
global minimum. Our analysis leverages both the interactions among features
across layers and the properties of Gaussian random variables, providing new
insights into deep representation learning. We further validate our theoretical
findings through experiments on real-world datasets.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>29 pages, 5 figures, 2 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The turnpike control in stochastic multi-agent dynamics: a discrete-time
  approach with exponential integrators 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09549v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09549v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fabio Cassini, Chiara Segala
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this manuscript, we study the turnpike property in stochastic
discrete-time optimal control problems for interacting agents. Extending
previous deterministic results, we show that the turnpike effect persists in
the presence of noise under suitable dissipativity and controllability
conditions. To handle the possible stiffness in the system dynamics, we employ
for the time discretization, integrators of exponential type. Numerical
experiments validate our findings, demonstrating the advantages of exponential
integrators over standard explicit schemes and confirming the effectiveness of
the turnpike control even in the stochastic setting.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Sequential Quadratic <span class="highlight-title">Optimization</span> for Solving Expectation Equality
  Constrained Stochastic <span class="highlight-title">Optimization</span> Problems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09490v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09490v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haoming Shen, Yang Zeng, Baoyu Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A sequential quadratic programming method is designed for solving general
smooth nonlinear stochastic optimization problems subject to expectation
equality constraints. We consider the setting where the objective and
constraint function values, as well as their derivatives, are not directly
available. The algorithm applies an adaptive step size policy and only relies
on objective gradient estimates, constraint function estimates, and constraint
derivative estimates to update iterates. Both asymptotic and non-asymptotic
convergence properties of the algorithm are analyzed. Under reasonable
assumptions, the algorithm generates a sequence of iterates whose first-order
stationary measure diminishes in expectation. In addition, we identify the
iteration and sample complexity for obtaining a first-order
$\varepsilon$-stationary iterate in expectation. The results of numerical
experiments demonstrate the efficiency and efficacy of our proposed algorithm
compared to a penalty method and an augmented Lagrangian method.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Learning Spatially Adaptive $\ell_1$-Norms Weights for Convolutional
  Synthesis Regularization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09483v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09483v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Andreas Kofler, Luca Calatroni, Christoph Kolbitsch, Kostas Papafitsoros
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose an unrolled algorithm approach for learning spatially adaptive
parameter maps in the framework of convolutional synthesis-based $\ell_1$
regularization. More precisely, we consider a family of pre-trained
convolutional filters and estimate deeply parametrized spatially varying
parameters applied to the sparse feature maps by means of unrolling a FISTA
algorithm to solve the underlying sparse estimation problem. The proposed
approach is evaluated for image reconstruction of low-field MRI and compared to
spatially adaptive and non-adaptive analysis-type procedures relying on Total
Variation regularization and to a well-established model-based deep learning
approach. We show that the proposed approach produces visually and
quantitatively comparable results with the latter approaches and at the same
time remains highly interpretable. In particular, the inferred parameter maps
quantify
  the local contribution of each filter in the reconstruction, which provides
valuable insight into the algorithm mechanism and could potentially be used to
discard unsuited filters.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To be submitted to the EUSIPCO 2025 conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Multi-objective Sequential Quadratic Programming Algorithm Based on
  Low-order Smooth Penalty Function 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09476v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09476v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zanyang Kong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper,we propose a Multi-Objective Sequential Quadratic Programming
(MOSQP) algorithm for constrained multi-objective optimization problems,basd on
a low-order smooth penalty function as the merit function for line search. The
algorithm constructs single-objective optimization subproblems based on each
objective function, solves quadratic programming (QP) subproblems to obtain
descent directions for expanding the iterative point set within the feasible
region, and filters non-dominated points after expansion. A new QP problem is
then formulated using information from all objective functions to derive
descent directions. The Armijo step size rule is employed for line search,
combined with Powell's correction formula (1978) for B iteration updates. If QP
subproblems is infesible, the negative gradient of the merit function is
adopted as the search direction. The algorithm is proven to converge to an
approximate Pareto front for constrained multi-objective optimization. Finally,
numerical experiments are performed for specific multi-objective optimization
problems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ One-vs-one Threat-Aware Weaponeering with Basic Engagement Zones 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09475v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09475v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alexander Von Moll, Dejan Milutinović, Isaac Weintraub, David W. Casbeer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper we address the problem of 'weaponeering', i.e., placing the
weapon engagement zone (WEZ) of a vehicle on a moving target, while
simultaneously avoiding the target's WEZ. A WEZ describes the lethality region
of a range-limited weapon considering both the range of the weapon along with
the state of the target. The weapons are assumed to have simple motion, while
the vehicles carrying the weapons are modeled with Dubins dynamics. Three
scenarios are investigated and are differentiated in the assumptions that can
be made about the target in the process of the vehicle control design: 1) no
knowledge of target control, 2) avoid unsafe positions assuming the target's
optimal control, 3) full knowledge of target's optimal control. The engagement
is formulated as a stochastic optimal control problem with uncertainty in the
target's control modeled using a noise parameter applied to the target's
control input. After discretizing the Hamilton-Jacobi-Bellman equation, Value
iteration is then used to obtain an approximate solution for the optimal
vehicle control and time-to-go. Simulation results support usage of the first
paradigm: assume no knowledge of the target's control.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 7 figures, submitted to the International Conference on
  Unmanned Aircraft Systems</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Fast computation of the TGOSPA metric for multiple target tracking via
  unbalanced optimal transport 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09449v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09449v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Viktor Nevelius Wernholm, Alfred Wärnsäter, Axel Ringh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In multiple target tracking, it is important to be able to evaluate the
performance of different tracking algorithms. The trajectory generalized
optimal sub-pattern assignment metric (TGOSPA) is a recently proposed metric
for such evaluations. The TGOSPA metric is computed as the solution to an
optimization problem, but for large tracking scenarios, solving this problem
becomes computationally demanding. In this paper, we present an approximation
algorithm for evaluating the TGOSPA metric, based on casting the TGOSPA problem
as an unbalanced multimarginal optimal transport problem. Following recent
advances in computational optimal transport, we introduce an entropy
regularization and derive an iterative scheme for solving the Lagrangian dual
of the regularized problem. Numerical results suggest that our proposed
algorithm is more computationally efficient than the alternative of computing
the exact metric using a linear programming solver, while still providing an
adequate approximation of the metric.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A convex reformulation for speed <span class="highlight-title">plan</span>ning of a vehicle under the travel
  time and energy consumption objectives 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09424v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09424v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Stefano Ardizzoni, Luca Consolini, Mattia Laurini, Marco Locatelli
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper we address the speed planning problem for a vehicle along a
predefined path. A weighted average of two (conflicting) terms, energy
consumption and travel time, is minimized. After deriving a non-convex
mathematical model of the problem, we introduce a convex relaxation of the
model and show that, after the application of a suitable feasibility-based
bound tightening procedure, the convex relaxation shares the same optimal value
and solution of the non-convex problem. We also establish that the feasible
region of the non-convex problem is a lattice and, through that, a necessary
and sufficient condition for the non-emptiness of the feasible region.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages, 1 algorithm</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Benefits of Learning Rate Annealing for Tuning-Robustness in Stochastic
  <span class="highlight-title">Optimization</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09411v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09411v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Amit Attia, Tomer Koren
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The learning rate in stochastic gradient methods is a critical hyperparameter
that is notoriously costly to tune via standard grid search, especially for
training modern large-scale models with billions of parameters. We identify a
theoretical advantage of learning rate annealing schemes that decay the
learning rate to zero at a polynomial rate, such as the widely-used cosine
schedule, by demonstrating their increased robustness to initial parameter
misspecification due to a coarse grid search. We present an analysis in a
stochastic convex optimization setup demonstrating that the convergence rate of
stochastic gradient descent with annealed schedules depends sublinearly on the
multiplicative misspecification factor $\rho$ (i.e., the grid resolution),
achieving a rate of $O(\rho^{1/(2p+1)}/\sqrt{T})$ where $p$ is the degree of
polynomial decay and $T$ is the number of steps, in contrast to the
$O(\rho/\sqrt{T})$ rate that arises with fixed stepsizes and exhibits a linear
dependence on $\rho$. Experiments confirm the increased robustness compared to
tuning with a fixed stepsize, that has significant implications for the
computational overhead of hyperparameter search in practical training
scenarios.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>22 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Task Allocation for Multi-agent Systems via Unequal-dimensional Optimal
  Transport 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09369v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09369v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anqi Dong, Karl H. Johansson, Johan Karlsson
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We consider a probabilistic model for large-scale task allocation problems
for multi-agent systems, aiming to determine an optimal deployment strategy
that minimizes the overall transport cost. Specifically, we assign
transportation agents to delivery tasks with given pick-up and drop-off
locations, pairing the spatial distribution of transport resources with the
joint distribution of task origins and destinations. This aligns with the
optimal mass transport framework where the problem and is in the
unequal-dimensional setting. The task allocation problem can be thus seen as a
linear programming problem that minimizes a quadratic transport cost
functional, optimizing the energy of all transport units. The problem is
motivated by time-sensitive medical deliveries using drones, such as emergency
equipment and blood transport. In this paper, we establish the existence,
uniqueness, and smoothness of the optimal solution, and illustrate its
properties through numerical simulations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages,4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Low-precision first-order method-based fix-and-propagate heuristics for
  large-scale mixed-integer linear <span class="highlight-title">optimization</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.10344v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.10344v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nils-Christian Kempke, Thorsten Koch
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We investigate the use of low-precision first-order methods (FOMs) within a
fix-and-propagate (FP) framework for solving mixed-integer programming problems
(MIPs). FOMs, using only matrix-vector products instead of matrix
factorizations, are well suited for GPU acceleration and have recently gained
more attention for their application to large-scale linear programming problems
(LPs). We employ PDLP, a variant of the Primal-Dual Hybrid Gradient (PDHG)
method specialized to LP problems, to solve the LP-relaxation of our MIPs to
low accuracy. This solution is used to motivate fixings within our
fix-and-propagate framework. We implemented four different FP variants using
primal and dual LP solution information. We evaluate the performance of our
heuristics on MIPLIB 2017, showcasing that the low-accuracy LP solution
produced by the FOM does not lead to a loss in quality of the FP heuristic
solutions when compared to a high-accuracy interior-point method LP solution.
Further, we use our FP framework to produce high-accuracy solutions for
large-scale (up to 243 million non-zeros and 8 million decision variables)
unit-commitment energy-system optimization models created with the modeling
framework REMix. For the largest problems, we can generate solutions with under
2% primal-dual gap in less than 4 hours, whereas commercial solvers cannot
generate feasible solutions within two days of runtime. This study represents
the first successful application of FOMs in large-scale mixed-integer
optimization, demonstrating their efficacy and establishing a foundation for
future research in this domain.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Magnetization control problem for the 2D and 3D evolutionary
  Landau-Lifshitz-Bloch equation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09266v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09266v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sidhartha Patnaik, Kumarasamy Sakthivel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this study, we investigate the optimal control of the
Landau-Lifshitz-Bloch equation within confined domains in $\mathbb R^n$ for $n=
2, 3.$ We establish the existence of strong solutions for dimensions $n=1, 2,
3$ under suitable growth conditions on the control, and analyze the existence
and uniqueness of regular solutions. We formulate the control problem in which
only a fixed set of finite magnetic field coils can constitute the external
magnetic field (control). We define a cost functional by aiming at minimizing
the energy discrepancy between the evolving magnetic moment and the desired
state. We demonstrate the existence of an optimal solution pair and employ the
classical adjoint problem approach to derive a first-order necessary optimality
condition. Given the non-convex nature of the optimal control problem, we
derive a second-order sufficient optimality condition using a cone of critical
directions. Finally, we prove two crucial results, namely, a global optimality
condition and uniqueness of an optimal control.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Optimal Control of Medical Drug in a Nonlocal Model of Solid Tumor
  Growth 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09208v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09208v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bouhamidi Abderrahman, El Harraki Imad, Melouani Yassine
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents a mathematical framework for optimizing drug delivery in
cancer treatment using a nonlocal model of solid tumor growth. We present a
coupled system of partial differential equations that incorporate long-range
cellular interactions through integral terms and drug-induced cell death. The
model accounts for spatial heterogeneity in both tumor cell density and drug
concentration while capturing the complex dynamics of drug resistance
development. We first establish the well-posedness of the coupled system by
proving the existence and uniqueness of a solution under appropriate regularity
conditions. The optimal control problem is then formulated to minimize tumor
size while accounting for drug toxicity constraints. Using variational methods,
we derive the necessary optimality conditions and characterize the optimal
control through an adjoint system. Theoretical results can help to design
effective chemotherapy schedules that balance treatment efficacy with adverse
effects.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Reachability for multiagent control systems via Lyapunov functions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09179v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09179v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Giulia Cavagnari, Marc Quincampoix
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper concerns the problem of reachability of a given state for a
multiagent control system in $\mathbb{R}^d$. In such a system, at every time
each agent can choose his/her velocity which depends both on his/her position
and on the position of the whole crowd of agents (modeled by a probability
measure on $ \mathbb{R}^d$). The main contribution of the paper is to study the
above reachability problem with a given rate of attainability through a
Lyapunov method adapted to the Wasserstein space of probability measures. As a
byproduct we obtain a new comparison result for viscosity solutions of Hamilton
Jacobi equations in the Wasserstein space.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Optimal control for multiagent systems with simultaneous aggregation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09168v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09168v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mauro Bonafini, Giulia Cavagnari, Antonio Marigonda
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we introduce an optimal control problem for multi-agent
systems with non-local cost which favors simultaneous aggregation of particles.
This is done introducing a time-dependent notion of multiplicity whose
intrinsic dynamical nature differs from more established geometric-like
definitions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Reliable Solution to Dynamic <span class="highlight-title">Optimization</span> Problems using Integrated
  Residual Regularized Direct Collocation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09123v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09123v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuanbo Nie, Eric C. Kerrigan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Direct collocation is a widely used method for solving dynamic optimization
problems (DOPs), but its implementation simplicity and computational efficiency
are limited for challenging problems like those involving singular arcs. In
this paper, we introduce the direct transcription method of integrated residual
regularized direct collocation (IRR-DC). This method enforces dynamic
constraints through a combination of explicit constraints and penalty terms
within discretized DOPs. This method retains the implementation simplicity of
direct collocation while significantly improving both solution accuracy and
efficiency, particularly for challenging problem types. Through the examples,
we demonstrate that for difficult problems where traditional direct collocation
results in excessive fluctuations or large errors between collocation points,
IRR-DC effectively suppresses oscillations and yields solutions with greater
accuracy (several magnitudes lower in various error metrics) compared to other
regularization alternatives.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Modeling of Rumor Propagation in Large Populations with Network via
  Graphon Games 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09107v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09107v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Huaning Liu, Gokce Dayanikli
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we propose a graphon game model to understand how rumor (such
as fake news) propagates in large populations that are interacting on a network
and how different policies affect the spread. We extend the SKIR model that is
used to model rumor propagation and implement individual controls and weighted
interactions with other agents to have controlled dynamics. The agents aim to
minimize their own expected costs non-cooperatively. We give the finite player
game model and the limiting graphon game model to approximate the Nash
equilibrium in the population. We give the graphon game Nash equilibrium as a
solution to a continuum of ordinary differential equations (ODEs) and give
existence results. Finally, we give a numerical approach and analyze examples
where we use piecewise constant graphon.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Degradation-based Energy Management for Microgrids in the Presence of
  Energy Storage Elements 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09028v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09028v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Satish Vedula
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Integration of Inverter-based Resources (IBRs) such as solar-powered plants
which lack the intrinsic characteristics such as the inertial response of the
traditional synchronous-generator (SG) based sources presents a new challenge
in the form of analyzing the grid stability under their presence. For example,
solar power is available for approximately from 9 AM-5 PM. However, the result
of the rise in power consumption after 6 PM and the reverting back to the
non-renewable source of power generation during that period puts immense stress
on the grid, testing the ramp limitations of the SGs. Failure to meet the
required power demand due to SG ramp limitations leads to failure of the power
grid and other catastrophes. Numerous mitigation techniques exist in order to
address the ramping issues with adding the energy storage elements (ESE) to the
grid being one. ESEs have higher ramping capabilities compared to the
traditional SGs. Also, the ESEs can store the energy and supply it to the grid
when required making them extremely responsive to high ramp situations.
However, the rate of degradation of the ESEs is faster than the SGs. This
raises an important issue of addressing the degradation of the ESEs while
meeting the required power demand objectives and constraints. This work
proposes a battery degradation-aware model predictive energy management
strategy and it is tested via a numerical simulation on multiple physical
systems such as Shipboard Power Systems (SPS). Moreover, the risk arising due
to the fault in the IBR is also studied by means of a numerical simulation.
Overall, the goal of this study is to make the existing power grid more robust,
resilient, and risk-free from component degradation and eventual failures.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Accelerating Point-Based Value Iteration via Active Sampling of Belief
  Points and Gaussian Process Regression 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08982v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08982v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Siqiong Zhou, Ashif S. Iquebal, Esma S. Gel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Partially Observable Markov Decision Processes (POMDPs) are fundamental to
decision-making under uncertainty. We introduce a novel scalable approach to
accelerate upper bound estimation in Point-Based Value Iteration (PBVI)
algorithms, the leading method to solve large-scale POMDPs. PBVI approximates
the value function using a set of belief points rather than the entire
continuous belief space and relies on lower and upper bounds for convergence.
While lower bounds are straightforward to compute, PVBI requires repeated
sawtooth projection operations to approximate the upper bound convex hull,
significantly increasing the computational burden although many of these
sawtooth projections become redundant as the belief set expands. To address
this, we infer the upper bound using the upper confidence bound of a Gaussian
Process Regression (GP-UCB) fitted over a subset of the most informative
reachable belief points--the ones that exhibit linear independence in some
high-dimensional Hilbert space. This approach reduces the number of sawtooth
projections by 84.3% on average without compromising the solution quality. We
further establish the theoretical consistency of the proposed GP-UCB estimate
of the upper bound and show convergence to the true upper bound convex hull. We
implement GP-UCB and test its performance using five benchmark finite-horizon
POMDPs, demonstrating its effectiveness in estimating upper bounds and
improving PBVI performance. GP-UCB reduces computation time by 30% to 60% on
smaller problems and up to 99.7% on larger ones, while achieving the same gaps
as the pure sawtooth projection method.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>32 pages, 9 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Convex Chance-Constrained Programs with Wasserstein Ambiguity 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2111.02486v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2111.02486v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haoming Shen, Ruiwei Jiang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Chance constraints yield non-convex feasible regions in general. In
particular, when the uncertain parameters are modeled by a Wasserstein ball,
arXiv:1806.07418 and arXiv:1809.00210 showed that the distributionally robust
(pessimistic) chance constraint admits a mixed-integer conic representation.
This paper identifies sufficient conditions that lead to convex feasible
regions of chance constraints with Wasserstein ambiguity. First, when
uncertainty arises from the right-hand side of a pessimistic joint chance
constraint, we show that the ensuing feasible region is convex if the
Wasserstein ball is centered around a log-concave distribution (or, more
generally, an $\alpha$-concave distribution with $\alpha \geq -1$). In
addition, we propose a block coordinate ascent algorithm and prove its
convergence to global optimum, as well as the rate of convergence. Second, when
uncertainty arises from the left-hand side of a pessimistic two-sided chance
constraint, we show the convexity if the Wasserstein ball is centered around an
elliptical and star-unimodal distribution. In addition, we propose a family of
second-order conic inner approximations, and we bound their approximation error
and prove their asymptotic exactness. Furthermore, we extend the convexity
results to optimistic chance constraints.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Keywords: Chance constraints; Convexity; Wasserstein ambiguity;
  Distributionally robust optimization; Distributionally optimistic
  optimization</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ An Optimistic Algorithm for Online Convex <span class="highlight-title">Optimization</span> with Adversarial
  Constraints 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.08060v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.08060v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jordan Lekeufack, Michael I. Jordan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study Online Convex Optimization (OCO) with adversarial constraints, where
an online algorithm must make sequential decisions to minimize both convex loss
functions and cumulative constraint violations. We focus on a setting where the
algorithm has access to predictions of the loss and constraint functions. Our
results show that we can improve the current best bounds of $ O(\sqrt{T}) $
regret and $ \tilde{O}(\sqrt{T}) $ cumulative constraint violations to $
O(\sqrt{E_T(f)}) $ and $ \tilde{O}(\sqrt{E_T(g^+)}) $, respectively, where $
E_T(f) $ and $E_T(g^+)$ represent the cumulative prediction errors of the loss
and constraint functions. In the worst case, where $E_T(f) = O(T) $ and $
E_T(g^+) = O(T) $ (assuming bounded gradients of the loss and constraint
functions), our rates match the prior $ O(\sqrt{T}) $ results. However, when
the loss and constraint predictions are accurate, our approach yields
significantly smaller regret and cumulative constraint violations. Finally, we
apply this to the setting of adversarial contextual bandits with sequential
risk constraints, obtaining optimistic bounds $O (\sqrt{E_T(f)} T^{1/3})$
regret and $O(\sqrt{E_T(g^+)} T^{1/3})$ constraints violation, yielding better
performance than existing results when prediction quality is sufficiently high.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>18 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ On strategies for risk management and decision making under uncertainty
  shared across multiple fields 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2309.03133v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2309.03133v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alexander Gutfraind
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Decision theory recognizes two principal approaches to solving problems under
uncertainty: probabilistic models and cognitive heuristics. However, engineers,
public planners and decision-makers in other fields seem to employ solution
strategies that do not fall into either field, i.e., strategies such as robust
design and contingency planning. In addition, identical strategies appear in
several fields and disciplines, pointing to an important shared toolkit.
  The focus of this paper is to develop a systematic understanding of such
strategies and develop a framework to better employ them in decision making and
risk management. The paper finds more than 110 examples of such strategies and
this approach to risk is termed RDOT: Risk-reducing Design and Operations
Toolkit. RDOT strategies fall into six broad categories: structural, reactive,
formal, adversarial, multi-stage and positive. RDOT strategies provide an
efficient response even to radical uncertainty or unknown unknowns that are
challenging to address with probabilistic methods. RDOT could be incorporated
into decision theory using workflows, multi-objective optimization and
multi-attribute utility theory.
  Overall, RDOT represents an overlooked class of versatile responses to
uncertainty. Because RDOT strategies do not require precise estimation or
forecasting, they are particularly helpful in decision problems affected by
uncertainty and for resource-constrained decision making.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>v2: expanded catalog</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Safe and Dynamically-Feasible Motion <span class="highlight-title">Plan</span>ning using Control Lyapunov and
  Barrier Functions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.08364v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.08364v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pol Mestres, Carlos Nieto-Granda, Jorge Cortés
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper considers the problem of designing motion planning algorithms for
control-affine systems that generate collision-free paths from an initial to a
final destination and can be executed using safe and dynamically-feasible
controllers. We introduce the C-CLF-CBF-RRT algorithm, which produces paths
with such properties and leverages rapidly exploring random trees (RRTs),
control Lyapunov functions (CLFs) and control barrier functions (CBFs). We show
that C-CLF-CBF-RRT is computationally efficient for linear systems with
polytopic and ellipsoidal constraints, and establish its probabilistic
completeness. We showcase the performance of C-CLF-CBF-RRT in different
simulation and hardware experiments.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Tensor train based sampling algorithms for approximating regularized
  Wasserstein proximal operators 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.13125v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.13125v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fuqun Han, Stanley Osher, Wuchen Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a tensor train (TT) based algorithm designed for sampling from a
target distribution and employ TT approximation to capture the high-dimensional
probability density evolution of overdamped Langevin dynamics. This involves
utilizing the regularized Wasserstein proximal operator, which exhibits a
simple kernel integration formulation, i.e., the softmax formula of the
traditional proximal operator. The integration, performed in $\mathbb{R}^d$,
poses a challenge in practical scenarios, making the algorithm practically
implementable only with the aid of TT approximation. In the specific context of
Gaussian distributions, we rigorously establish the unbiasedness and linear
convergence of our sampling algorithm towards the target distribution. To
assess the effectiveness of our proposed methods, we apply them to various
scenarios, including Gaussian families, Gaussian mixtures, bimodal
distributions, and Bayesian inverse problems in numerical examples. The
sampling algorithm exhibits superior accuracy and faster convergence when
compared to classical Langevin dynamics-type sampling algorithms.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Revised version</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Quantum Feasibility Labeling for NP-complete Vertex Coloring Problem 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2301.01589v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2301.01589v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junpeng Zhan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Many important science and engineering problems can be converted into
NP-complete problems which are of significant importance in computer science
and mathematics. Currently, neither existing classical nor quantum algorithms
can solve these problems in polynomial time. To address this difficulty, this
paper proposes a quantum feasibility labeling (QFL) algorithm to label all
possible solutions to the vertex coloring problem, which is a well-known
NP-complete problem. The QFL algorithm converts the vertex coloring problem
into the problem of searching an unstructured database where good and bad
elements are labeled. The recently proposed variational quantum search (VQS)
algorithm was demonstrated to achieve an exponential speedup, in circuit depth,
up to 26 qubits in finding good element(s) from an unstructured database. Using
the labels and the associated possible solutions as input, the VQS can find all
feasible solutions to the vertex coloring problem. The number of qubits and the
circuit depth required by the QFL each is a polynomial function of the number
of vertices, the number of edges, and the number of colors of a vertex coloring
problem. We have implemented the QFL on an IBM Qiskit simulator to solve a
4-colorable 4-vertex 3-edge coloring problem.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 6 figures, this version of the paper has been accepted by
  IEEE Access</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Quantum Global Minimum Finder based on Variational Quantum Search 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.00450v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.00450v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohammadreza Soltaninia, Junpeng Zhan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The search for global minima is a critical challenge across multiple fields
including engineering, finance, and artificial intelligence, particularly with
non-convex functions that feature multiple local optima, complicating
optimization efforts. We introduce the Quantum Global Minimum Finder (QGMF), an
innovative quantum computing approach that efficiently identifies global
minima. QGMF combines binary search techniques to shift the objective function
to a suitable position and then employs Variational Quantum Search to precisely
locate the global minimum within this targeted subspace. Designed with a
low-depth circuit architecture, QGMF is optimized for Noisy Intermediate-Scale
Quantum (NISQ) devices, utilizing the logarithmic benefits of binary search to
enhance scalability and efficiency. This work demonstrates the impact of QGMF
in advancing the capabilities of quantum computing to overcome complex
non-convex optimization challenges effectively.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages, 8 figures, this version of the paper has been accepted by
  Scientific Reports</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Correction to: A Lagrangian dual method for two-stage robust
  <span class="highlight-title">optimization</span> with binary uncertainties 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.04307v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.04307v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Henri Lefebvre, Anirudh Subramanyam
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We provide a correction to the sufficient conditions under which closed-form
expressions for the optimal Lagrange multiplier are provided in
arXiv:2112.13138 [math.OC]. We first present a simple counterexample where the
original conditions are insufficient, highlight where the original proof fails,
and then provide modified conditions along with a correct proof of their
validity. Finally, although the original paper discusses modifications to their
method for problems that may not satisfy any sufficient conditions, we
substantiate that discussion along two directions. We first show that computing
an optimal Lagrange multiplier can still be done in polynomial time. We then
provide complete and correct versions of the corresponding Benders and
column-and-constraint generation algorithms in which the original method is
used. We also discuss the implications of our findings on computational
performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ On a class of interdiction problems with partition matroids: complexity
  and polynomial-time algorithms 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.12010v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.12010v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sergey S. Ketkov, Oleg A. Prokopyev
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this study, we consider a class of linear matroid interdiction problems,
where the feasible sets for the upper-level decision-maker (referred to as a
leader) and the lower-level decision-maker (referred to as a follower) are
induced by two distinct partition matroids with a common weighted ground set.
Unlike classical network interdiction models where the leader is subject to a
single budget constraint, in our setting, both the leader and the follower are
subject to several independent capacity constraints and engage in a zero-sum
game. While the problem of finding a maximum weight independent set in a
partition matroid is known to be polynomially solvable, we prove that the
considered bilevel problem is $NP$-hard even when the weights of ground
elements are all binary. On a positive note, it is revealed that, if the number
of capacity constraints is fixed for either the leader or the follower, then
the considered class of bilevel problems admits several polynomial-time
solution schemes. Specifically, these schemes are based on a single-level dual
reformulation, a dynamic programming-based approach, and a greedy algorithm for
the leader.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The proof of Theorem 4 is refined</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Carrot John domains in variational problems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.08133v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.08133v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Weicong Su, Yi Ru-Ya Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we explore carrot John domains within variational problems,
dividing our examination into two distinct sections. The initial part is
dedicated to establishing the lower semicontinuity of the (optimal) John
constant concerning Hausdorff convergence for bounded John domains. This result
holds promising implications for both shape optimization problems and
Techm\"uller theory.
  In the subsequent section, we demonstrate that an unbounded open set
satisfying the carrot John condition with a center at $\infty$, appearing in
the Mumford-Shah problem, can be covered by a uniformly finite number of
unbounded John domains (defined conventionally through cigars). These domains,
in particular, support Sobolev-Poincar\'e inequalities.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>30 Pages, 5 Figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The Small-Gain Condition for Infinite Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03925v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03925v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Christoph Kawan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, attempts have been made to extend ISS small-gain theorems
from finite networks to countably infinite, locally finite networks. Under
specific assumptions about the interconnection gains and the ISS formulation,
corresponding infinite-dimensional small-gain results have been proven.
However, concerning these assumptions, the results are still too narrow to be
considered a full extension of the state-of-the-art for finite networks. We
take a step to closing this gap by a thorough investigation of various monotone
operators associated with an infinite network and a specific ISS formulation.
Our results shed more light on the theory of finite networks, yield complete
characterizations of the small-gain condition for specific ISS formulations,
and show which obstacles still have to be overcome to obtain a complete theory
for the most general case.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Stochastic <span class="highlight-title">Optimization</span> Using Ricci Flow 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.04292v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.04292v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Varsha Gupta
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper proposes a theoretical framework for modeling and optimizing the
bounded functions based on the Fourier series approximation and Ricci flow.
Specifically, the initial manifold, $\mathcal{M}_0$ is approximated using
Fourier series approximation in conjunction with the center and boundary
sampling procedure introduced in the paper. The manifold is iteratively evolved
using an algorithm that involves sampling along geodesic hyper-sphere defined
by the Riemannian metric tensor. Thus obtained surrogate manifold is optimized
by applying inverse Ricci flow i.e. instead of regularizing the manifold, flow
allows for the high curvature regions to blow into finite time singularities.
This allows for the singularities to occur at potential global optima assuming
the deviation of the manifold at any point is smaller than the optimum. In
addition, the error bound is established on the accuracy of the surrogate
manifold. Finally, the proposed method is tested on stochastic sampling from
five benchmark functions to illustrate the utility of this method.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Constrained Approximate Optimal Transport Maps 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13445v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13445v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Eloi Tanguy, Agnès Desolneux, Julie Delon
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We investigate finding a map $g$ within a function class $G$ that minimises
an Optimal Transport (OT) cost between a target measure $\nu$ and the image by
$g$ of a source measure $\mu$. This is relevant when an OT map from $\mu$ to
$\nu$ does not exist or does not satisfy the desired constraints of $G$. We
address existence and uniqueness for generic subclasses of $L$-Lipschitz
functions, including gradients of (strongly) convex functions and typical
Neural Networks. We explore a variant that approaches a transport plan, showing
equivalence to a map problem in some cases. For the squared Euclidean cost, we
propose alternating minimisation over a transport plan $\pi$ and map $g$, with
the optimisation over $g$ being the $L^2$ projection on $G$ of the barycentric
mapping $\overline{\pi}$. In dimension one, this global problem equates the
$L^2$ projection of $\overline{\pi^*}$ onto $G$ for an OT plan $\pi^*$ between
$\mu$ and $\nu$, but this does not extend to higher dimensions. We introduce a
simple kernel method to find $g$ within a Reproducing Kernel Hilbert Space in
the discrete case. We present numerical methods for $L$-Lipschitz gradients of
$\ell$-strongly convex potentials, and study the convergence of Stochastic
Gradient Descent methods for Neural Networks. We finish with an illustration on
colour transfer, applying learned maps on new images, and showcasing outlier
robustness.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Modular Forms in Combinatorial <span class="highlight-title">Optimization</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.15546v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.15546v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Varsha Gupta
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Modular symmetries hidden in the combinatorial optimization framework remain
mostly unexplored which has hindered any significant improvement in the
solution quality. To unveil the modular structure, we map the cost and decision
variables into complex domain and develop a novel framework for the Asymmetric
Traveling Salesman Problem (ATSP). The transformed formulation is proven to be
translation and inversion invariant, thereby allowing us to establish that
achieving global optimum is equivalent to an infinite number of moment
cancellations for each arc. The underlying idea is to achieve a delicate
balance between cost and decision variables, expressed mathematically as an
equilibrium condition, that allows for very strong modular symmetry to hold.
The infinite moment cancellation is proven to be both necessary and sufficient
condition for global optimality. In fact, we show that for strongly modular
case, the rapid decay of moment contributions shall lead to series truncation
with controllable error, allowing for efficient approximations. In contrast,
weak modularity retains residual error thereby, reinforcing NP-hardness. These
insights can inform the development of sophisticated algorithms that improve
the quality of solutions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ On Distributed Larger-Than-Memory Subset Selection With Pairwise
  Submodular Functions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.16442v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.16442v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Maximilian Böther, Abraham Sebastian, Pranjal Awasthi, Ana Klimovic, Srikumar Ramalingam
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Modern datasets span billions of samples, making training on all available
data infeasible. Selecting a high quality subset helps in reducing training
costs and enhancing model quality. Submodularity, a discrete analogue of
convexity, is commonly used for solving such subset selection problems.
However, existing algorithms for optimizing submodular functions are
sequential, and the prior distributed methods require at least one central
machine to fit the target subset in DRAM. At billion datapoint scale, even the
subset may not fit a single machine, and the sequential algorithms are
prohibitively slow. In this paper, we relax the requirement of having a central
machine for the target subset by proposing a novel distributed bounding
algorithm with provable approximation guarantees. The algorithm iteratively
bounds the minimum and maximum utility values to select high quality points and
discard the unimportant ones. When bounding does not find the complete subset,
we use a multi-round, partition-based distributed greedy algorithm to identify
the remaining subset. We discuss how to implement these algorithms in a
distributed data processing framework and empirically analyze different
configurations. We find high quality subsets on CIFAR-100 and ImageNet with
marginal or no loss in quality compared to centralized methods, and scale to a
dataset with 13 billion points.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>accepted at MLSys 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Finite adaptability in two-stage robust <span class="highlight-title">optimization</span>: asymptotic
  optimality and tractability 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2305.05399v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2305.05399v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Safia Kedad-Sidhoum, Anton Medvedev, Frédéric Meunier
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Two-stage robust optimization is a fundamental paradigm for modeling and
solving optimization problems with uncertain parameters. A now classical method
within this paradigm is finite adaptability, introduced by Bertsimas and
Caramanis (IEEE Transactions on Automatic Control, 2010). It consists in
restricting the recourse to a finite number $k$ of possible values. In this
work, we point out that the continuity assumption they stated to ensure the
convergence of the method when $k$ goes to infinity is not correct, and we
propose an alternative assumption for which we prove the desired convergence.
Bertsimas and Caramanis also established that finite adaptability is NP-hard,
even in the special case when $k=2$, the variables are continuous, and only
specific parameters are subject to uncertainty. We provide a theorem showing
that this special case becomes polynomial when the uncertainty set is a
polytope with a bounded number of vertices, and we extend this theorem for
$k=3$ as well. On our way, we establish new geometric results on coverings of
polytopes with convex sets, which might be interesting for their own sake.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Controlled Diffusions under Full, Partial and Decentralized Information:
  Existence of Optimal Policies and Discrete-Time Approximations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.03254v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.03254v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Somnath Pradhan, Serdar Yüksel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present existence and discrete-time approximation results on optimal
control policies for continuous-time stochastic control problems under a
variety of information structures. These include fully observed models,
partially observed models and multi-agent models with decentralized information
structures. While there exist comprehensive existence and approximations
results for the fully observed setup in the literature, few prior research
exists on discrete-time approximation results for partially observed models.
For decentralized models, even existence results have not received much
attention except for specialized models and approximation has been an open
problem. Our existence and approximations results lead to the applicability of
well-established partially observed Markov decision processes and the
relatively more mature theory of discrete-time decentralized stochastic control
to be applicable for computing near optimal solutions for continuous-time
stochastic control.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>27</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Memory-Efficient 4-bit Preconditioned Stochastic <span class="highlight-title">Optimization</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.10663v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.10663v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jingyang Li, Kuangyu Ding, Kim-Chuan Toh, Pan Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Preconditioned stochastic optimization algorithms, exemplified by Shampoo,
outperform first-order optimizers by offering theoretical convergence benefits
and practical gains in large-scale neural network training. However, they incur
substantial memory overhead due to the storage demands of non-diagonal
preconditioning matrices. To address this, we introduce 4-bit quantization for
Shampoo's preconditioners. We introduce two key methods: First, we apply
Cholesky decomposition followed by quantization of the Cholesky factors,
reducing memory usage by leveraging their lower triangular structure while
better preserving spectral properties to minimize information loss. To our
knowledge, this is the first quantization approach applied to Cholesky factors
of preconditioners. Second, we incorporate error feedback in the quantization
process, efficiently storing Cholesky factor and error state in the lower and
upper triangular parts of the same matrix. Through extensive experiments, we
demonstrate that combining Cholesky quantization with error feedback enhances
memory efficiency and algorithm performance in large-scale deep-learning tasks.
Theoretically, we also provide convergence proofs for quantized Shampoo under
both smooth and non-smooth stochastic optimization settings.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ An Adaptive Sampling-based Progressive Hedging Algorithm for Stochastic
  Programming 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.20944v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.20944v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Di Zhang, Yihang Zhang, Suvrajeet Sen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The progressive hedging algorithm (PHA) is a cornerstone among algorithms for
large-scale stochastic programming problems. However, its traditional
implementation is hindered by some limitations, including the requirement to
solve all scenario subproblems in each iteration, reliance on an explicit
probability distribution, and a convergence process that is highly sensitive to
the choice of certain penalty parameters. This paper introduces a
sampling-based PHA which aims to overcome these limitations. Our approach
employs a dynamic selection process for the number of scenario subproblems
solved per iteration. It incorporates adaptive sequential sampling for
determining sample sizes, a stochastic conjugate subgradient method for
direction finding, and a line-search technique to update the dual variables.
Experimental results demonstrate that this novel algorithm not only addresses
the bottlenecks of the conventional PHA but also potentially surpasses its
scalability, representing a substantial improvement in the field of stochastic
programming.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Input-Output Feedback Linearization Preserving Task Priority for
  Multivariate Nonlinear Systems Having Singular Input Gain Matrix 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2305.01903v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2305.01903v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sang-ik An, Dongheui Lee, Gyunghoon Park
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose an extension of the input-output feedback linearization for a
class of multivariate systems that are not input-output linearizable in a
classical manner. The key observation is that the usual input-output
linearization problem can be interpreted as the problem of solving simultaneous
linear equations associated with the input gain matrix: thus, even at points
where the input gain matrix becomes singular, it is still possible to solve a
part of linear equations, by which a subset of input-output relations is made
linear or close to be linear. Based on this observation, we adopt the task
priority-based approach in the input-output linearization problem. First, we
generalize the classical Byrnes-Isidori normal form to a prioritized normal
form having a triangular structure, so that the singularity of a subblock of
the input gain matrix related to lower-priority tasks does not directly
propagate to higher-priority tasks. Next, we present a prioritized input-output
linearization via the multi-objective optimization with the lexicographical
ordering, resulting in a prioritized semilinear form that establishes input
output relations whose subset with higher priority is linear or close to be
linear. Finally, Lyapunov analysis on ultimate boundedness and task achievement
is provided, particularly when the proposed prioritized input-output
linearization is applied to the output tracking problem. This work introduces a
new control framework for complex systems having critical and noncritical
control issues, by assigning higher priority to the critical ones.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>A part of this work has been accepted to be published in the IEEE
  Transactions on Automatic Control</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2025-03-11T00:00:00Z">2025-03-11</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Robotics <span class="chip" style="font-size: 60%">34</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Real-Time Neuromorphic <span class="highlight-title">Navigation</span>: Guiding Physical Robots with
  Event-Based Sensing and Task-Specific Reconfigurable Autonomy Stack 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09636v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09636v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sourav Sanyal, Amogh Joshi, Adarsh Kosta, Kaushik Roy
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Neuromorphic vision, inspired by biological neural systems, has recently
gained significant attention for its potential in enhancing robotic autonomy.
This paper presents a systematic exploration of a proposed Neuromorphic
Navigation framework that uses event-based neuromorphic vision to enable
efficient, real-time navigation in robotic systems. We discuss the core
concepts of neuromorphic vision and navigation, highlighting their impact on
improving robotic perception and decision-making. The proposed reconfigurable
Neuromorphic Navigation framework adapts to the specific needs of both ground
robots (Turtlebot) and aerial robots (Bebop2 quadrotor), addressing the
task-specific design requirements (algorithms) for optimal performance across
the autonomous navigation stack -- Perception, Planning, and Control. We
demonstrate the versatility and the effectiveness of the framework through two
case studies: a Turtlebot performing local replanning for real-time navigation
and a Bebop2 quadrotor navigating through moving gates. Our work provides a
scalable approach to task-specific, real-time robot autonomy leveraging
neuromorphic systems, paving the way for energy-efficient autonomous
navigation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FP3: A 3D Foundation Policy for Robotic <span class="highlight-title">Manipulation</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08950v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08950v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rujia Yang, Geng Chen, Chuan Wen, Yang Gao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Following its success in natural language processing and computer vision,
foundation models that are pre-trained on large-scale multi-task datasets have
also shown great potential in robotics. However, most existing robot foundation
models rely solely on 2D image observations, ignoring 3D geometric information,
which is essential for robots to perceive and reason about the 3D world. In
this paper, we introduce FP3, a first large-scale 3D foundation policy model
for robotic manipulation. FP3 builds on a scalable diffusion transformer
architecture and is pre-trained on 60k trajectories with point cloud
observations. With the model design and diverse pre-training data, FP3 can be
efficiently fine-tuned for downstream tasks while exhibiting strong
generalization capabilities. Experiments on real robots demonstrate that with
only 80 demonstrations, FP3 is able to learn a new task with over 90% success
rates in novel environments with unseen objects, significantly surpassing
existing robot foundation models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project website: https://3d-foundation-policy.github.io</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Simulator Ensembles for Trustworthy Autonomous Driving Testing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08936v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08936v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lev Sorokin, Matteo Biagiola, Andrea Stocco
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Scenario-based testing with driving simulators is extensively used to
identify failing conditions of automated driving assistance systems (ADAS) and
reduce the amount of in-field road testing. However, existing studies have
shown that repeated test execution in the same as well as in distinct
simulators can yield different outcomes, which can be attributed to sources of
flakiness or different implementations of the physics, among other factors. In
this paper, we present MultiSim, a novel approach to multi-simulation ADAS
testing based on a search-based testing approach that leverages an ensemble of
simulators to identify failure-inducing, simulator-agnostic test scenarios.
During the search, each scenario is evaluated jointly on multiple simulators.
Scenarios that produce consistent results across simulators are prioritized for
further exploration, while those that fail on only a subset of simulators are
given less priority, as they may reflect simulator-specific issues rather than
generalizable failures. Our case study, which involves testing a deep neural
network-based ADAS on different pairs of three widely used simulators,
demonstrates that MultiSim outperforms single-simulator testing by achieving on
average a higher rate of simulator-agnostic failures by 51%. Compared to a
state-of-the-art multi-simulator approach that combines the outcome of
independent test generation campaigns obtained in different simulators,
MultiSim identifies 54% more simulator-agnostic failing tests while showing a
comparable validity rate. An enhancement of MultiSim that leverages surrogate
models to predict simulator disagreements and bypass executions does not only
increase the average number of valid failures but also improves efficiency in
finding the first valid failure.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Acoustic Neural 3D Reconstruction Under Pose Drift 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08930v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08930v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tianxiang Lin, Mohamad Qadri, Kevin Zhang, Adithya Pediredla, Christopher A. Metzler, Michael Kaess
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We consider the problem of optimizing neural implicit surfaces for 3D
reconstruction using acoustic images collected with drifting sensor poses. The
accuracy of current state-of-the-art 3D acoustic modeling algorithms is highly
dependent on accurate pose estimation; small errors in sensor pose can lead to
severe reconstruction artifacts. In this paper, we propose an algorithm that
jointly optimizes the neural scene representation and sonar poses. Our
algorithm does so by parameterizing the 6DoF poses as learnable parameters and
backpropagating gradients through the neural renderer and implicit
representation. We validated our algorithm on both real and simulated datasets.
It produces high-fidelity 3D reconstructions even under significant pose drift.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 8 figures. This paper is under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HessianForge: Scalable LiDAR reconstruction with Physics-Informed Neural
  Representation and Smoothness Energy Constraints 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08929v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08929v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hrishikesh Viswanath, Md Ashiqur Rahman, Chi Lin, Damon Conover, Aniket Bera
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Accurate and efficient 3D mapping of large-scale outdoor environments from
LiDAR measurements is a fundamental challenge in robotics, particularly towards
ensuring smooth and artifact-free surface reconstructions. Although the
state-of-the-art methods focus on memory-efficient neural representations for
high-fidelity surface generation, they often fail to produce artifact-free
manifolds, with artifacts arising due to noisy and sparse inputs. To address
this issue, we frame surface mapping as a physics-informed energy optimization
problem, enforcing surface smoothness by optimizing an energy functional that
penalizes sharp surface ridges. Specifically, we propose a deep learning based
approach that learns the signed distance field (SDF) of the surface manifold
from raw LiDAR point clouds using a physics-informed loss function that
optimizes the $L_2$-Hessian energy of the surface. Our learning framework
includes a hierarchical octree based input feature encoding and a multi-scale
neural network to iteratively refine the signed distance field at different
scales of resolution. Lastly, we introduce a test-time refinement strategy to
correct topological inconsistencies and edge distortions that can arise in the
generated mesh. We propose a \texttt{CUDA}-accelerated least-squares
optimization that locally adjusts vertex positions to enforce
feature-preserving smoothing. We evaluate our approach on large-scale outdoor
datasets and demonstrate that our approach outperforms current state-of-the-art
methods in terms of improved accuracy and smoothness. Our code is available at
\href{https://github.com/HrishikeshVish/HessianForge/}{https://github.com/HrishikeshVish/HessianForge/}
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Mutual Adaptation in Human-Robot Co-Transportation with Human Preference
  Uncertainty 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08895v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08895v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Al Jaber Mahmud, Weizi Li, Xuan Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Mutual adaptation can significantly enhance overall task performance in
human-robot co-transportation by integrating both the robot's and human's
understanding of the environment. While human modeling helps capture humans'
subjective preferences, two challenges persist: (i) the uncertainty of human
preference parameters and (ii) the need to balance adaptation strategies that
benefit both humans and robots. In this paper, we propose a unified framework
to address these challenges and improve task performance through mutual
adaptation. First, instead of relying on fixed parameters, we model a
probability distribution of human choices by incorporating a range of uncertain
human parameters. Next, we introduce a time-varying stubbornness measure and a
coordination mode transition model, which allows either the robot to lead the
team's trajectory or, if a human's preferred path conflicts with the robot's
plan and their stubbornness exceeds a threshold, the robot to transition to
following the human. Finally, we introduce a pose optimization strategy to
mitigate the uncertain human behaviors when they are leading. To validate the
framework, we design and perform experiments with real human feedback. We then
demonstrate, through simulations, the effectiveness of our models in enhancing
task performance with mutual adaptation and pose optimization.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Adaptive Anomaly Recovery for Tele<span class="highlight-title">manipulation</span>: A Diffusion Model
  Approach to Vision-Based Tracking 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09632v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09632v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haoyang Wang, Haoran Guo, Lingfeng Tao, Zhengxiong Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Dexterous telemanipulation critically relies on the continuous and stable
tracking of the human operator's commands to ensure robust operation.
Vison-based tracking methods are widely used but have low stability due to
anomalies such as occlusions, inadequate lighting, and loss of sight.
Traditional filtering, regression, and interpolation methods are commonly used
to compensate for explicit information such as angles and positions. These
approaches are restricted to low-dimensional data and often result in
information loss compared to the original high-dimensional image and video
data. Recent advances in diffusion-based approaches, which can operate on
high-dimensional data, have achieved remarkable success in video reconstruction
and generation. However, these methods have not been fully explored in
continuous control tasks in robotics. This work introduces the
Diffusion-Enhanced Telemanipulation (DET) framework, which incorporates the
Frame-Difference Detection (FDD) technique to identify and segment anomalies in
video streams. These anomalous clips are replaced after reconstruction using
diffusion models, ensuring robust telemanipulation performance under
challenging visual conditions. We validated this approach in various anomaly
scenarios and compared it with the baseline methods. Experiments show that DET
achieves an average RMSE reduction of 17.2% compared to the cubic spline and
51.1% compared to FFT-based interpolation for different occlusion durations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This work has been submitted to the IEEE for possible publication</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Real-time simulation enabled <span class="highlight-title">navigation</span> control of magnetic soft
  continuum robots in confined lumens 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08864v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08864v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dezhong Tong, Zhuonan Hao, Jiyu Li, Boxi Sun, Mingchao Liu, Liu Wang, Weicheng Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Magnetic soft continuum robots (MSCRs) have emerged as a promising technology
for minimally invasive interventions, offering enhanced dexterity and
remote-controlled navigation in confined lumens. Unlike conventional guidewires
with pre-shaped tips, MSCRs feature a magnetic tip that actively bends under
applied magnetic fields. Despite extensive studies in modeling and simulation,
achieving real-time navigation control of MSCRs in confined lumens remains a
significant challenge. The primary reasons are due to robot-lumen contact
interactions and computational limitations in modeling MSCR nonlinear behavior
under magnetic actuation. Existing approaches, such as Finite Element Method
(FEM) simulations and energy-minimization techniques, suffer from high
computational costs and oversimplified contact interactions, making them
impractical for real-world applications. In this work, we develop a real-time
simulation and navigation control framework that integrates hard-magnetic
elastic rod theory, formulated within the Discrete Differential Geometry (DDG)
framework, with an order-reduced contact handling strategy. Our approach
captures large deformations and complex interactions while maintaining
computational efficiency. Next, the navigation control problem is formulated as
an inverse design task, where optimal magnetic fields are computed in real time
by minimizing the constrained forces and enhancing navigation accuracy. We
validate the proposed framework through comprehensive numerical simulations and
experimental studies, demonstrating its robustness, efficiency, and accuracy.
The results show that our method significantly reduces computational costs
while maintaining high-fidelity modeling, making it feasible for real-time
deployment in clinical settings.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>22 pages, 12 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SICNav-Diffusion: Safe and Interactive Crowd <span class="highlight-title">Navigation</span> with Diffusion
  Trajectory Predictions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08858v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08858v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sepehr Samavi, Anthony Lem, Fumiaki Sato, Sirui Chen, Qiao Gu, Keijiro Yano, Angela P. Schoellig, Florian Shkurti
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  To navigate crowds without collisions, robots must interact with humans by
forecasting their future motion and reacting accordingly. While learning-based
prediction models have shown success in generating likely human trajectory
predictions, integrating these stochastic models into a robot controller
presents several challenges. The controller needs to account for interactive
coupling between planned robot motion and human predictions while ensuring both
predictions and robot actions are safe (i.e. collision-free). To address these
challenges, we present a receding horizon crowd navigation method for
single-robot multi-human environments. We first propose a diffusion model to
generate joint trajectory predictions for all humans in the scene. We then
incorporate these multi-modal predictions into a SICNav Bilevel MPC problem
that simultaneously solves for a robot plan (upper-level) and acts as a safety
filter to refine the predictions for non-collision (lower-level). Combining
planning and prediction refinement into one bilevel problem ensures that the
robot plan and human predictions are coupled. We validate the open-loop
trajectory prediction performance of our diffusion model on the commonly used
ETH/UCY benchmark and evaluate the closed-loop performance of our robot
navigation method in simulation and extensive real-robot experiments
demonstrating safe, efficient, and reactive robot motion.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Keypoint Semantic Integration for Improved Feature Matching in Outdoor
  Agricultural Environments 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08843v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08843v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rajitha de Silva, Jonathan Cox, Marija Popovic, Cesar Cadena, Cyrill Stachniss, Riccardo Polvara
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Robust robot navigation in outdoor environments requires accurate perception
systems capable of handling visual challenges such as repetitive structures and
changing appearances. Visual feature matching is crucial to vision-based
pipelines but remains particularly challenging in natural outdoor settings due
to perceptual aliasing. We address this issue in vineyards, where repetitive
vine trunks and other natural elements generate ambiguous descriptors that
hinder reliable feature matching. We hypothesise that semantic information tied
to keypoint positions can alleviate perceptual aliasing by enhancing keypoint
descriptor distinctiveness. To this end, we introduce a keypoint semantic
integration technique that improves the descriptors in semantically meaningful
regions within the image, enabling more accurate differentiation even among
visually similar local features. We validate this approach in two vineyard
perception tasks: (i) relative pose estimation and (ii) visual localisation.
Across all tested keypoint types and descriptors, our method improves matching
accuracy by 12.6%, demonstrating its effectiveness over multiple months in
challenging vineyard conditions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project Page: https://github.com/LCAS/GAIA</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Geometric Data-Driven Multi-Jet <span class="highlight-title">Locomotion</span> Inspired by Salps 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08817v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08817v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yanhao Yang, Nina L. Hecht, Yousef Salaman-Maclara, Nathan Justus, Zachary A. Thomas, Farhan Rozaidi, Ross L. Hatton
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Salps are marine animals consisting of chains of jellyfish-like units. Their
capacity for effective underwater undulatory locomotion through coordinating
multi-jet propulsion has aroused significant interest in the field of robotics
and inspired extensive research including design, modeling, and control. In
this paper, we conduct a comprehensive analysis of the locomotion of salp-like
systems using the robotic platform "LandSalp" based on geometric mechanics,
including mechanism design, dynamic modeling, system identification, and motion
planning and control. Our work takes a step toward a better understanding of
salps' underwater locomotion and provides a clear path for extending these
insights to more complex and capable underwater robotic systems. Furthermore,
this study illustrates the effectiveness of geometric mechanics in bio-inspired
robots for efficient data-driven locomotion modeling, demonstrated by learning
the dynamics of LandSalp from only 3 minutes of experimental data. Lastly, we
extend the geometric mechanics principles to multi-jet propulsion systems with
stability considerations and validate the theory through experiments on the
LandSalp hardware.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages, 13 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         <span class="highlight-title">★</span> Generating Robot Constitutions & <span class="highlight-title">Benchmark</span>s for Semantic Safety 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08663v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08663v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pierre Sermanet, <span class="highlight-author">Anirudha Majumdar</span>, Alex Irpan, Dmitry Kalashnikov, Vikas Sindhwani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Until recently, robotics safety research was predominantly about collision
avoidance and hazard reduction in the immediate vicinity of a robot. Since the
advent of large vision and language models (VLMs), robots are now also capable
of higher-level semantic scene understanding and natural language interactions
with humans. Despite their known vulnerabilities (e.g. hallucinations or
jail-breaking), VLMs are being handed control of robots capable of physical
contact with the real world. This can lead to dangerous behaviors, making
semantic safety for robots a matter of immediate concern. Our contributions in
this paper are two fold: first, to address these emerging risks, we release the
ASIMOV Benchmark, a large-scale and comprehensive collection of datasets for
evaluating and improving semantic safety of foundation models serving as robot
brains. Our data generation recipe is highly scalable: by leveraging text and
image generation techniques, we generate undesirable situations from real-world
visual scenes and human injury reports from hospitals. Secondly, we develop a
framework to automatically generate robot constitutions from real-world data to
steer a robot's behavior using Constitutional AI mechanisms. We propose a novel
auto-amending process that is able to introduce nuances in written rules of
behavior; this can lead to increased alignment with human preferences on
behavior desirability and safety. We explore trade-offs between generality and
specificity across a diverse set of constitutions of different lengths, and
demonstrate that a robot is able to effectively reject unconstitutional
actions. We measure a top alignment rate of 84.3% on the ASIMOV Benchmark using
generated constitutions, outperforming no-constitution baselines and
human-written constitutions. Data is available at asimov-benchmark.github.io
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Cross-Embodiment Robotic <span class="highlight-title">Manipulation</span> Synthesis via Guided
  Demonstrations through CycleVAE and Human Behavior Transformer <span class="chip">IROS 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08622v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08622v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Apan Dastider, Hao Fang, Mingjie Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Cross-embodiment robotic manipulation synthesis for complicated tasks is
challenging, partially due to the scarcity of paired cross-embodiment datasets
and the impediment of designing intricate controllers. Inspired by robotic
learning via guided human expert demonstration, we here propose a novel
cross-embodiment robotic manipulation algorithm via CycleVAE and human behavior
transformer. First, we utilize unsupervised CycleVAE together with a
bidirectional subspace alignment algorithm to align latent motion sequences
between cross-embodiments. Second, we propose a casual human behavior
transformer design to learn the intrinsic motion dynamics of human expert
demonstrations. During the test case, we leverage the proposed transformer for
the human expert demonstration generation, which will be aligned using CycleVAE
for the final human-robotic manipulation synthesis. We validated our proposed
algorithm through extensive experiments using a dexterous robotic manipulator
with the robotic hand. Our results successfully generate smooth trajectories
across intricate tasks, outperforming prior learning-based robotic motion
planning algorithms. These results have implications for performing
unsupervised cross-embodiment alignment and future autonomous robotics design.
Complete video demonstrations of our experiments can be found in
https://sites.google.com/view/humanrobots/home.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under Review in IROS 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HiP-AD: Hierarchical and Multi-Granularity <span class="highlight-title">Plan</span>ning with Deformable
  Attention for Autonomous Driving in a Single Decoder 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08612v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08612v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yingqi Tang, Zhuoran Xu, Zhaotie Meng, Erkang Cheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Although end-to-end autonomous driving (E2E-AD) technologies have made
significant progress in recent years, there remains an unsatisfactory
performance on closed-loop evaluation. The potential of leveraging planning in
query design and interaction has not yet been fully explored. In this paper, we
introduce a multi-granularity planning query representation that integrates
heterogeneous waypoints, including spatial, temporal, and driving-style
waypoints across various sampling patterns. It provides additional supervision
for trajectory prediction, enhancing precise closed-loop control for the ego
vehicle. Additionally, we explicitly utilize the geometric properties of
planning trajectories to effectively retrieve relevant image features based on
physical locations using deformable attention. By combining these strategies,
we propose a novel end-to-end autonomous driving framework, termed HiP-AD,
which simultaneously performs perception, prediction, and planning within a
unified decoder. HiP-AD enables comprehensive interaction by allowing planning
queries to iteratively interact with perception queries in the BEV space while
dynamically extracting image features from perspective views. Experiments
demonstrate that HiP-AD outperforms all existing end-to-end autonomous driving
methods on the closed-loop benchmark Bench2Drive and achieves competitive
performance on the real-world dataset nuScenes.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ EMMOE: A Comprehensive <span class="highlight-title">Benchmark</span> for Embodied Mobile <span class="highlight-title">Manipulation</span> in
  Open Environments 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08604v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08604v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dongping Li, Tielong Cai, Tianci Tang, Wenhao Chai, Katherine Rose Driggs-Campbell, Gaoang Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Developing autonomous home robots controlled by natural language has long
been a pursuit of human. While advancements in large language models (LLMs) and
embodied intelligence make this goal closer, several challenges persist: the
lack of a unified benchmark for more complex robot tasks, limited evaluation
methods and metrics, data incompatibility between LLMs and mobile manipulation
trajectories. To address these issues, we introduce Embodied Mobile
Manipulation in Open Environments (EMMOE), which requires agents to interpret
user instructions and execute long-horizon everyday tasks in continuous space.
EMMOE seamlessly integrates high-level and low-level embodied tasks into a
unified framework, along with three new metrics for more diverse assessment.
Additionally, we collect EMMOE-100, which features in various task attributes,
detailed process annotations, re-plans after failures, and two sub-datasets for
LLM training. Furthermore, we design HomieBot, a sophisticated agent system
consists of LLM with Direct Preference Optimization (DPO), light weighted
navigation and manipulation models, and multiple error detection mechanisms.
Finally, we demonstrate HomieBot's performance and the evaluation of different
models and policies.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Proc4Gem: Foundation models for physical agency through procedural
  generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08593v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08593v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yixin Lin, Jan Humplik, Sandy H. Huang, Leonard Hasenclever, Francesco Romano, Stefano Saliceti, Daniel Zheng, Jose Enrique Chen, Catarina Barros, Adrian Collister, Matt Young, Adil Dostmohamed, Ben Moran, Ken Caluwaerts, Marissa Giustina, Joss Moore, Kieran Connell, Francesco Nori, Nicolas Heess, Steven Bohez, Arunkumar Byravan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In robot learning, it is common to either ignore the environment semantics,
focusing on tasks like whole-body control which only require reasoning about
robot-environment contacts, or conversely to ignore contact dynamics, focusing
on grounding high-level movement in vision and language. In this work, we show
that advances in generative modeling, photorealistic rendering, and procedural
generation allow us to tackle tasks requiring both. By generating contact-rich
trajectories with accurate physics in semantically-diverse simulations, we can
distill behaviors into large multimodal models that directly transfer to the
real world: a system we call Proc4Gem. Specifically, we show that a foundation
model, Gemini, fine-tuned on only simulation data, can be instructed in
language to control a quadruped robot to push an object with its body to unseen
targets in unseen real-world environments. Our real-world results demonstrate
the promise of using simulation to imbue foundation models with physical
agency. Videos can be found at our website:
https://sites.google.com/view/proc4gem
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MoE-Loco: Mixture of Experts for Multitask <span class="highlight-title">Locomotion</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08564v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08564v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Runhan Huang, Shaoting Zhu, Yilun Du, Hang Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present MoE-Loco, a Mixture of Experts (MoE) framework for multitask
locomotion for legged robots. Our method enables a single policy to handle
diverse terrains, including bars, pits, stairs, slopes, and baffles, while
supporting quadrupedal and bipedal gaits. Using MoE, we mitigate the gradient
conflicts that typically arise in multitask reinforcement learning, improving
both training efficiency and performance. Our experiments demonstrate that
different experts naturally specialize in distinct locomotion behaviors, which
can be leveraged for task migration and skill composition. We further validate
our approach in both simulation and real-world deployment, showcasing its
robustness and adaptability.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 10 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Can We Detect Failures Without Failure Data? Uncertainty-Aware Runtime
  Failure Detection for Imitation Learning Policies 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08558v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08558v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chen Xu, Tony Khuong Nguyen, Emma Dixon, Christopher Rodriguez, Patrick Miller, Robert Lee, Paarth Shah, Rares Ambrus, Haruki Nishimura, Masha Itkina
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent years have witnessed impressive robotic manipulation systems driven by
advances in imitation learning and generative modeling, such as diffusion- and
flow-based approaches. As robot policy performance increases, so does the
complexity and time horizon of achievable tasks, inducing unexpected and
diverse failure modes that are difficult to predict a priori. To enable
trustworthy policy deployment in safety-critical human environments, reliable
runtime failure detection becomes important during policy inference. However,
most existing failure detection approaches rely on prior knowledge of failure
modes and require failure data during training, which imposes a significant
challenge in practicality and scalability. In response to these limitations, we
present FAIL-Detect, a modular two-stage approach for failure detection in
imitation learning-based robotic manipulation. To accurately identify failures
from successful training data alone, we frame the problem as sequential
out-of-distribution (OOD) detection. We first distill policy inputs and outputs
into scalar signals that correlate with policy failures and capture epistemic
uncertainty. FAIL-Detect then employs conformal prediction (CP) as a versatile
framework for uncertainty quantification with statistical guarantees.
Empirically, we thoroughly investigate both learned and post-hoc scalar signal
candidates on diverse robotic manipulation tasks. Our experiments show learned
signals to be mostly consistently effective, particularly when using our novel
flow-based density estimator. Furthermore, our method detects failures more
accurately and faster than state-of-the-art (SOTA) failure detection baselines.
These results highlight the potential of FAIL-Detect to enhance the safety and
reliability of imitation learning-based robotic systems as they progress toward
real-world deployment.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ TLA: Tactile-Language-Action Model for Contact-Rich <span class="highlight-title">Manipulation</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08548v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08548v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Peng Hao, Chaofan Zhang, Dingzhe Li, Xiaoge Cao, Xiaoshuai Hao, Shaowei Cui, Shuo Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Significant progress has been made in vision-language models. However,
language-conditioned robotic manipulation for contact-rich tasks remains
underexplored, particularly in terms of tactile sensing. To address this gap,
we introduce the Tactile-Language-Action (TLA) model, which effectively
processes sequential tactile feedback via cross-modal language grounding to
enable robust policy generation in contact-intensive scenarios. In addition, we
construct a comprehensive dataset that contains 24k pairs of tactile action
instruction data, customized for fingertip peg-in-hole assembly, providing
essential resources for TLA training and evaluation. Our results show that TLA
significantly outperforms traditional imitation learning methods (e.g.,
diffusion policy) in terms of effective action generation and action accuracy,
while demonstrating strong generalization capabilities by achieving over 85\%
success rate on previously unseen assembly clearances and peg shapes. We
publicly release all data and code in the hope of advancing research in
language-conditioned tactile manipulation skill learning. Project website:
https://sites.google.com/view/tactile-language-action/
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Deformable Linear Object Surface Placement Using Elastica <span class="highlight-title">Plan</span>ning and
  Local Shape Control 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08545v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08545v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        I. Grinberg, A. Levin, E. D. Rimon
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Manipulation of deformable linear objects (DLOs) in constrained environments
is a challenging task. This paper describes a two-layered approach for placing
DLOs on a flat surface using a single robot hand. The high-level layer is a
novel DLO surface placement method based on Euler's elastica solutions. During
this process one DLO endpoint is manipulated by the robot gripper while a
variable interior point of the DLO serves as the start point of the portion
aligned with the placement surface. The low-level layer forms a pipeline
controller. The controller estimates the DLO current shape using a Residual
Neural Network (ResNet) and uses low-level feedback to ensure task execution in
the presence of modeling and placement errors. The resulting DLO placement
approach can recover from states where the high-level manipulation planner has
failed as required by practical robot manipulation systems. The DLO placement
approach is demonstrated with simulations and experiments that use silicon
mock-up objects prepared for fresh food applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Light<span class="highlight-title">Plan</span>ner: Unleashing the Reasoning Capabilities of Lightweight Large
  Language Models in Task <span class="highlight-title">Plan</span>ning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08508v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08508v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Weijie Zhou, Yi Peng, Manli Tao, Chaoyang Zhao, Honghui Dong, Ming Tang, Jinqiao Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, lightweight large language models (LLMs) have garnered
significant attention in the robotics field due to their low computational
resource requirements and suitability for edge deployment. However, in task
planning -- particularly for complex tasks that involve dynamic semantic logic
reasoning -- lightweight LLMs have underperformed. To address this limitation,
we propose a novel task planner, LightPlanner, which enhances the performance
of lightweight LLMs in complex task planning by fully leveraging their
reasoning capabilities. Unlike conventional planners that use fixed skill
templates, LightPlanner controls robot actions via parameterized function
calls, dynamically generating parameter values. This approach allows for
fine-grained skill control and improves task planning success rates in complex
scenarios. Furthermore, we introduce hierarchical deep reasoning. Before
generating each action decision step, LightPlanner thoroughly considers three
levels: action execution (feedback verification), semantic parsing (goal
consistency verification), and parameter generation (parameter validity
verification). This ensures the correctness of subsequent action controls.
Additionally, we incorporate a memory module to store historical actions,
thereby reducing context length and enhancing planning efficiency for long-term
tasks. We train the LightPlanner-1.5B model on our LightPlan-40k dataset, which
comprises 40,000 action controls across tasks with 2 to 13 action steps.
Experiments demonstrate that our model achieves the highest task success rate
despite having the smallest number of parameters. In tasks involving spatial
semantic reasoning, the success rate exceeds that of ReAct by 14.9 percent.
Moreover, we demonstrate LightPlanner's potential to operate on edge devices.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Hybrid Deep Reinforcement Learning for Radio Tracer Localisation in
  Robotic-assisted Radioguided Surgery <span class="chip">ICRA</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08492v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08492v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hanyi Zhang, Kaizhong Deng, Zhaoyang Jacopo Hu, Baoru Huang, Daniel S. Elson
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Radioguided surgery, such as sentinel lymph node biopsy, relies on the
precise localization of radioactive targets by non-imaging gamma/beta
detectors. Manual radioactive target detection based on visual display or
audible indication of gamma level is highly dependent on the ability of the
surgeon to track and interpret the spatial information. This paper presents a
learning-based method to realize the autonomous radiotracer detection in
robot-assisted surgeries by navigating the probe to the radioactive target. We
proposed novel hybrid approach that combines deep reinforcement learning (DRL)
with adaptive robotic scanning. The adaptive grid-based scanning could provide
initial direction estimation while the DRL-based agent could efficiently
navigate to the target utilising historical data. Simulation experiments
demonstrate a 95% success rate, and improved efficiency and robustness compared
to conventional techniques. Real-world evaluation on the da Vinci Research Kit
(dVRK) further confirms the feasibility of the approach, achieving an 80%
success rate in radiotracer detection. This method has the potential to enhance
consistency, reduce operator dependency, and improve procedural accuracy in
radioguided surgeries.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to IEEE International Conference on Robotics and Automation
  (ICRA) 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Soft Actor-Critic-based Control Barrier Adaptation for Robust Autonomous
  <span class="highlight-title">Navigation</span> in Unknown Environments <span class="chip">ICRA</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08479v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08479v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nicholas Mohammad, Nicola Bezzo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Motion planning failures during autonomous navigation often occur when safety
constraints are either too conservative, leading to deadlocks, or too liberal,
resulting in collisions. To improve robustness, a robot must dynamically adapt
its safety constraints to ensure it reaches its goal while balancing safety and
performance measures. To this end, we propose a Soft Actor-Critic (SAC)-based
policy for adapting Control Barrier Function (CBF) constraint parameters at
runtime, ensuring safe yet non-conservative motion. The proposed approach is
designed for a general high-level motion planner, low-level controller, and
target system model, and is trained in simulation only. Through extensive
simulations and physical experiments, we demonstrate that our framework
effectively adapts CBF constraints, enabling the robot to reach its final goal
without compromising safety.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To Appear in 2025 IEEE/RSJ International Conference on Robotics and
  Automation (ICRA), 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Guide-LLM: An Embodied LLM Agent and Text-Based Topological Map for
  Robotic Guidance of People with Visual Impairments 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.20666v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.20666v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sangmim Song, Sarath Kodagoda, Amal Gunatilake, Marc G. Carmichael, Karthick Thiyagarajan, Jodi Martin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Navigation presents a significant challenge for persons with visual
impairments (PVI). While traditional aids such as white canes and guide dogs
are invaluable, they fall short in delivering detailed spatial information and
precise guidance to desired locations. Recent developments in large language
models (LLMs) and vision-language models (VLMs) offer new avenues for enhancing
assistive navigation. In this paper, we introduce Guide-LLM, an embodied
LLM-based agent designed to assist PVI in navigating large indoor environments.
Our approach features a novel text-based topological map that enables the LLM
to plan global paths using a simplified environmental representation, focusing
on straight paths and right-angle turns to facilitate navigation. Additionally,
we utilize the LLM's commonsense reasoning for hazard detection and
personalized path planning based on user preferences. Simulated experiments
demonstrate the system's efficacy in guiding PVI, underscoring its potential as
a significant advancement in assistive technology. The results highlight
Guide-LLM's ability to offer efficient, adaptive, and personalized navigation
assistance, pointing to promising advancements in this field.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Object-Pose Estimation With Neural Population Codes 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.13403v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.13403v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Heiko Hoffmann, Richard Hoffmann
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Robotic assembly tasks require object-pose estimation, particularly for tasks
that avoid costly mechanical constraints. Object symmetry complicates the
direct mapping of sensory input to object rotation, as the rotation becomes
ambiguous and lacks a unique training target. Some proposed solutions involve
evaluating multiple pose hypotheses against the input or predicting a
probability distribution, but these approaches suffer from significant
computational overhead. Here, we show that representing object rotation with a
neural population code overcomes these limitations, enabling a direct mapping
to rotation and end-to-end learning. As a result, population codes facilitate
fast and accurate pose estimation. On the T-LESS dataset, we achieve inference
in 3.2 milliseconds on an Apple M1 CPU and a Maximum Symmetry-Aware Surface
Distance accuracy of 84.7% using only gray-scale image input, compared to 69.7%
accuracy when directly mapping to pose.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Recursive Model-agnostic Inverse Dynamics of Serial Soft-Rigid Robots 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.07037v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.07037v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pietro Pustina, Cosimo Della Santina, Alessandro De Luca
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Robotics is shifting from rigid, articulated systems to more sophisticated
and heterogeneous mechanical structures. Soft robots, for example, have
continuously deformable elements capable of large deformations. The flourishing
of control techniques developed for this class of systems is fueling the need
of efficient procedures for evaluating their inverse dynamics (ID), which is
challenging due to the complex and mixed nature of these systems. As of today,
no single ID algorithm can describe the behavior of generic (combinations of)
models of soft robots. We address this challenge for generic series-like
interconnections of possibly soft structures that may require heterogeneous
modeling techniques. Our proposed algorithm requires as input a purely
geometric description (forward-kinematics-like) of the mapping from
configuration space to deformation space. With this information only, the
complete equations of motion can be given an exact recursive structure which is
essentially independent from (or `agnostic' to) the underlying reduced-order
kinematic modeling techniques. We achieve this goal by exploiting Kane's method
to manipulate the equations of motion, showing then their recursive structure.
The resulting ID algorithms have optimal computational complexity within the
proposed setting, i.e., linear in the number of distinct modules. Further, a
variation of the algorithm is introduced that can evaluate the generalized mass
matrix without increasing computation costs. We showcase the applicability of
this method to robot models involving a mixture of rigid and soft elements,
described via possibly heterogeneous reduced order models (ROMs), such as
Volumetric FEM, Cosserat strain-based, and volume-preserving deformation
primitives. None of these systems can be handled using existing ID techniques.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ An Unsupervised C-Uniform Trajectory Sampler with Applications to Model
  Predictive Path Integral Control <span class="chip">IROS2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.05819v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.05819v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        O. Goktug Poyrazoglu, Rahul Moorthy, Yukang Cao, William Chastek, Volkan Isler
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sampling-based model predictive controllers generate trajectories by sampling
control inputs from a fixed, simple distribution such as the normal or uniform
distributions. This sampling method yields trajectory samples that are tightly
clustered around a mean trajectory. This clustering behavior in turn, limits
the exploration capability of the controller and reduces the likelihood of
finding feasible solutions in complex environments. Recent work has attempted
to address this problem by either reshaping the resulting trajectory
distribution or increasing the sample entropy to enhance diversity and promote
exploration. In our recent work, we introduced the concept of C-Uniform
trajectory generation [1] which allows the computation of control input
probabilities to generate trajectories that sample the configuration space
uniformly. In this work, we first address the main limitation of this method:
lack of scalability due to computational complexity. We introduce Neural
C-Uniform, an unsupervised C-Uniform trajectory sampler that mitigates
scalability issues by computing control input probabilities without relying on
a discretized configuration space. Experiments show that Neural C-Uniform
achieves a similar uniformity ratio to the original C-Uniform approach and
generates trajectories over a longer time horizon while preserving uniformity.
Next, we present CU-MPPI, which integrates Neural C-Uniform sampling into
existing MPPI variants. We analyze the performance of CU-MPPI in simulation and
real-world experiments. Our results indicate that in settings where the optimal
solution has high curvature, CU-MPPI leads to drastic improvements in
performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to IROS2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Towards Motion Compensation in Autonomous Robotic Subretinal Injections 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.18521v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.18521v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Demir Arikan, Peiyao Zhang, Michael Sommersperger, Shervin Dehghani, Mojtaba Esfandiari, Russel H. Taylor, M. Ali Nasseri, Peter Gehlbach, Nassir Navab, Iulian Iordachita
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Exudative (wet) age-related macular degeneration (AMD) is a leading cause of
vision loss in older adults, typically treated with intravitreal injections.
Emerging therapies, such as subretinal injections of stem cells, gene therapy,
small molecules and RPE cells require precise delivery to avoid damaging
delicate retinal structures. Robotic systems can potentially offer the
necessary precision for these procedures. This paper presents a novel approach
for motion compensation in robotic subretinal injections, utilizing real time
Optical Coherence Tomography (OCT). The proposed method leverages B$^5$-scans,
a rapid acquisition of small-volume OCT data, for dynamic tracking of retinal
motion along the Z-axis, compensating for physiological movements such as
breathing and heartbeat. Validation experiments on ex vivo porcine eyes
revealed challenges in maintaining a consistent tool-to-retina distance, with
deviations of up to 200 $\mu m$ for 100 $\mu m$ amplitude motions and over 80
$\mu m$ for 25 $\mu m$ amplitude motions over one minute. Subretinal injections
faced additional difficulties, with phase shifts causing the needle to move
off-target and inject into the vitreous. These results highlight the need for
improved motion prediction and horizontal stability to enhance the accuracy and
safety of robotic subretinal procedures.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Real-time Deformation-aware Control for Autonomous Robotic Subretinal
  Injection under iOCT Guidance 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.06557v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.06557v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Demir Arikan, Peiyao Zhang, Michael Sommersperger, Shervin Dehghani, Mojtaba Esfandiari, Russel H. Taylor, M. Ali Nasseri, Peter Gehlbach, Nassir Navab, Iulian Iordachita
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Robotic platforms provide consistent and precise tool positioning that
significantly enhances retinal microsurgery. Integrating such systems with
intraoperative optical coherence tomography (iOCT) enables image-guided robotic
interventions, allowing autonomous performance of advanced treatments, such as
injecting therapeutic agents into the subretinal space. However, tissue
deformations due to tool-tissue interactions constitute a significant challenge
in autonomous iOCT-guided robotic subretinal injections. Such interactions
impact correct needle positioning and procedure outcomes. This paper presents a
novel method for autonomous subretinal injection under iOCT guidance that
considers tissue deformations during the insertion procedure. The technique is
achieved through real-time segmentation and 3D reconstruction of the surgical
scene from densely sampled iOCT B-scans, which we refer to as B${^5}$-scans.
Using B${^5}$-scans we monitor the position of the instrument relative to a
virtual target layer between the ILM and RPE. Our experiments on ex vivo
porcine eyes demonstrate dynamic adjustment of the insertion depth and overall
improved accuracy in needle positioning compared to prior autonomous insertion
approaches. Compared to a 35% success rate in subretinal bleb generation with
previous approaches, our method reliably created subretinal blebs in 90% our
experiments.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Data-driven tool wear prediction in milling, based on a
  process-integrated single-sensor approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.19950v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.19950v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Eric Hirsch, Christian Friedrich
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Accurate tool wear prediction is essential for maintaining productivity and
minimizing costs in machining. However, the complex nature of the tool wear
process poses significant challenges to achieving reliable predictions. This
study explores data-driven methods, in particular deep learning, for tool wear
prediction. Traditional data-driven approaches often focus on a single process,
relying on multi-sensor setups and extensive data generation, which limits
generalization to new settings. Moreover, multi-sensor integration is often
impractical in industrial environments. To address these limitations, this
research investigates the transferability of predictive models using minimal
training data, validated across two processes. Furthermore, it uses a simple
setup with a single acceleration sensor to establish a low-cost data generation
approach that facilitates the generalization of models to other processes via
transfer learning. The study evaluates several machine learning models,
including transformer-inspired convolutional neural networks (CNN), long
short-term memory networks (LSTM), support vector machines (SVM), and decision
trees, trained on different input formats such as feature vectors and
short-time Fourier transform (STFT). The performance of the models is evaluated
on two machines and on different amounts of training data, including scenarios
with significantly reduced datasets, providing insight into their effectiveness
under constrained data conditions. The results demonstrate the potential of
specific models and configurations for effective tool wear prediction,
contributing to the development of more adaptable and efficient predictive
maintenance strategies in machining. Notably, the ConvNeXt model has an
exceptional performance, achieving 99.1\% accuracy in identifying tool wear
using data from only four milling tools operated until they are worn.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This preprint has been submitted to Robotics and Computer-Integrated
  Manufacturing for possible publication ,14 pages, 12 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Force Aware Branch <span class="highlight-title">Manipulation</span> To Assist Agricultural Tasks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07497v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07497v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Madhav Rijal, Rashik Shrestha, Trevor Smith, Yu Gu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study presents a methodology to safely manipulate branches to aid
various agricultural tasks. Humans in a real agricultural environment often
manipulate branches to perform agricultural tasks effectively, but current
agricultural robots lack this capability. This proposed strategy to manipulate
branches can aid in different precision agriculture tasks, such as fruit
picking in dense foliage, pollinating flowers under occlusion, and moving
overhanging vines and branches for navigation. The proposed method modifies
RRT* to plan a path that satisfies the branch geometric constraints and obeys
branch deformable characteristics. Re-planning is done to obtain a path that
helps the robot exert force within a desired range so that branches are not
damaged during manipulation. Experimentally, this method achieved a success
rate of 78% across 50 trials, successfully moving a branch from different
starting points to a target region.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Online Control-Informed Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03924v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03924v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zihao Liang, Tianyu Zhou, Zehui Lu, Shaoshuai Mou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper proposes an Online Control-Informed Learning (OCIL) framework,
which employs the well-established optimal control and state estimation
techniques in the field of control to solve a broad class of learning tasks in
an online fashion. This novel integration effectively handles practical issues
in machine learning such as noisy measurement data, online learning, and data
efficiency. By considering any robot as a tunable optimal control system, we
propose an online parameter estimator based on extended Kalman filter (EKF) to
incrementally tune the system in an online fashion, enabling it to complete
designated learning or control tasks. The proposed method also improves the
robustness in learning by effectively managing noise in the data. Theoretical
analysis is provided to demonstrate the convergence of OCIL. Three learning
modes of OCIL, i.e. Online Imitation Learning, Online System Identification,
and Policy Tuning On-the-fly, are investigated via experiments, which validate
their effectiveness.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Automating High Quality RT <span class="highlight-title">Plan</span>ning at Scale 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.11803v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.11803v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Riqiang Gao, Mamadou Diallo, Han Liu, Anthony Magliari, Jonathan Sackett, Wilko Verbakel, Sandra Meyers, Masoud Zarepisheh, Rafe Mcbeth, Simon Arberet, Martin Kraus, Florin C. Ghesu, Ali Kamen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Radiotherapy (RT) planning is complex, subjective, and time-intensive.
Advances in artificial intelligence (AI) promise to improve its precision,
efficiency, and consistency, but progress is often limited by the scarcity of
large, standardized datasets. To address this, we introduce the Automated
Iterative RT Planning (AIRTP) system, a scalable solution for generating
high-quality treatment plans. This scalable solution is designed to generate
substantial volumes of consistently high-quality treatment plans, overcoming a
key obstacle in the advancement of AI-driven RT planning. Our AIRTP pipeline
adheres to clinical guidelines and automates essential steps, including
organ-at-risk (OAR) contouring, helper structure creation, beam setup,
optimization, and plan quality improvement, using AI integrated with RT
planning software like Eclipse of Varian. Furthermore, a novel approach for
determining optimization parameters to reproduce 3D dose distributions, i.e. a
method to convert dose predictions to deliverable treatment plans constrained
by machine limitations. A comparative analysis of plan quality reveals that our
automated pipeline produces treatment plans of quality comparable to those
generated manually, which traditionally require several hours of labor per
plan. Committed to public research, the first data release of our AIRTP
pipeline includes nine cohorts covering head-and-neck and lung cancer sites to
support an AAPM 2025 challenge. This data set features more than 10 times the
number of plans compared to the largest existing well-curated public data set
to our best knowledge. Repo:
https://github.com/RiqiangGao/GDP-HMM_AAPMChallenge.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>radiotherapy planning</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ GraphSCENE: On-Demand Critical Scenario Generation for Autonomous
  Vehicles in Simulation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13514v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13514v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Efimia Panagiotaki, Georgi Pramatarov, Lars Kunze, Daniele De Martini
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Testing and validating Autonomous Vehicle (AV) performance in safety-critical
and diverse scenarios is crucial before real-world deployment. However,
manually creating such scenarios in simulation remains a significant and
time-consuming challenge. This work introduces a novel method that generates
dynamic temporal scene graphs corresponding to diverse traffic scenarios,
on-demand, tailored to user-defined preferences, such as AV actions, sets of
dynamic agents, and criticality levels. A temporal Graph Neural Network (GNN)
model learns to predict relationships between ego-vehicle, agents, and static
structures, guided by real-world spatiotemporal interaction patterns and
constrained by an ontology that restricts predictions to semantically valid
links. Our model consistently outperforms the baselines in accurately
generating links corresponding to the requested scenarios. We render the
predicted scenarios in simulation to further demonstrate their effectiveness as
testing environments for AV agents.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 8 figures</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Systems and Control <span class="chip" style="font-size: 60%">47</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Over-the-Air Time-Frequency Synchronization in Distributed ISAC Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08920v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08920v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kawon Han, Kaitao Meng, Christos Masouros
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A distributed integrated sensing and communication (D-ISAC) system offers
significant cooperative gains for both sensing and communication performance.
These gains, however, can only be fully realized when the distributed nodes are
perfectly synchronized, which is a challenge that remains largely unaddressed
in current ISAC research. In this paper, we propose an over-the-air
time-frequency synchronization framework for the D-ISAC system, leveraging the
reciprocity of bistatic sensing channels. This approach overcomes the
impractical dependency of traditional methods on a direct line-of-sight (LoS)
link, enabling the estimation of time offset (TO) and carrier frequency offset
(CFO) between two ISAC nodes even in non-LoS (NLOS) scenarios. To achieve this,
we introduce a bistatic signal matching (BSM) technique with delay-Doppler
decoupling, which exploits offset reciprocity (OR) in bistatic observations.
This method compresses multiple sensing links into a single offset for
estimation. We further present off-grid super-resolution estimators for TO and
CFO, including the maximum likelihood estimator (MLE) and the matrix pencil
(MP) method, combined with BSM processing. These estimators provide accurate
offset estimation compared to spectral cross-correlation techniques. Also, we
extend the pairwise synchronization leveraging OR between two nodes to the
synchronization of $N$ multiple distributed nodes, referred to as centralized
pairwise synchronization. We analyze the Cramer-Rao bounds (CRBs) for TO and
CFO estimates and evaluate the impact of D-ISAC synchronization on the
bottom-line target localization performance. Simulation results validate the
effectiveness of the proposed algorithm, confirm the theoretical analysis, and
demonstrate that the proposed synchronization approach can recover up to 96% of
the bottom-line target localization performance of the fully-synchronous
D-ISAC.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages, 10 figures, submitted to IEEE for possible publication</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ High-Precision Overlay Registration via Spatial-Terminal Iterative
  Learning in Roll-to-Roll Manufacturing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08835v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08835v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zifeng Wang, Xiaoning Jin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Roll-to-roll (R2R) printing technologies are promising for high-volume
continuous production of substrate-based electronic products. One of the major
challenges in R2R flexible electronics printing is achieving tight alignment
tolerances, as specified by the device resolution (usually at the micro-meter
level), for multi-layer printed electronics. The alignment of the printed
patterns in different layers is known as registration. Conventional
registration control methods rely on real-time feedback controllers, such as
PID control, to regulate the web tension and the web speed. However, those
methods may lose effectiveness in compensating for recurring disturbances and
supporting effective mitigation of registration errors. In this paper, we
propose a Spatial-Terminal Iterative Learning Control (STILC) method integrated
with PID control to iteratively learn and reduce registration error
cycle-by-cycle, converging it to zero. This approach enables unprecedented
precision in the creation, integration, and manipulation of multi-layer
microstructures in R2R processes. We theoretically prove the convergence of the
proposed STILC-PID hybrid approach and validate its effectiveness through a
simulated registration error scenario caused by axis mismatch between roller
and motor, a common issue in R2R systems. The results demonstrate that the
STILC-PID hybrid control method can fully eliminate the registration error
after a feasible number of iterations. Additionally, we analyze the impact of
different learning gains on the convergence performance of STILC.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Stochastic <span class="highlight-title">Model Predictive</span> Control for Sub-Gaussian Noise 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08795v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08795v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yunke Ao, Johannes Köhler, Manish Prajapat, Yarden As, Melanie Zeilinger, Philipp Fürnstahl, Andreas Krause
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose a stochastic Model Predictive Control (MPC) framework that ensures
closed-loop chance constraint satisfaction for linear systems with general
sub-Gaussian process and measurement noise. By considering sub-Gaussian noise,
we can provide guarantees for a large class of distributions, including
time-varying distributions. Specifically, we first provide a new
characterization of sub-Gaussian random vectors using matrix variance proxies,
which can more accurately represent the predicted state distribution. We then
derive tail bounds under linear propagation for the new characterization,
enabling tractable computation of probabilistic reachable sets of linear
systems. Lastly, we utilize these probabilistic reachable sets to formulate a
stochastic MPC scheme that provides closed-loop guarantees for general
sub-Gaussian noise. We further demonstrate our approach in simulations,
including a challenging task of surgical planning from image observations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15 pages, 6 figures, submitted to Automatica</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ An Analysis of Safety Guarantees in Multi-Task Bayesian <span class="highlight-title">Optimization</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08555v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08555v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jannis O. Luebsen, Annika Eichler
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In many practical scenarios of black box optimization, the objective function
is subject to constraints that must be satisfied to avoid undesirable outcomes.
Such constraints are typically unknown and must be learned during optimization.
Safe Bayesian optimization aims to find the global optimum while ensuring that
the constraints are satisfied with high probability. However, it is often
sample-inefficient due to the small initial feasible set, which requires
expansion by evaluating the objective or constraint functions, limiting its
applicability to low-dimensional or inexpensive problems. To enhance sample
efficiency, additional information from cheap simulations can be leveraged,
albeit at the cost of safeness guarantees. This paper introduces a novel safe
multi-task Bayesian optimization algorithm that integrates multiple tasks while
maintaining high-probability safety. We derive robust uniform error bounds for
the multi-task case and demonstrate the effectiveness of the approach on
benchmark functions and a control problem. Our results show a significant
improvement in sample efficiency, making the proposed method well-suited for
expensive-to-evaluate functions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Input Delay Compensation for a Class of Switched Linear Systems via
  Averaging Exact Predictor Feedbacks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08446v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08446v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Andreas Katsanikakis, Nikolaos Bekiaris-Liberis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The key challenges in design of predictor-based control laws for switched
systems with arbitrary switching and long input delay are the potential
unavailability of the future values of the switching signal (at current time)
and the fact that dwell time may be arbitrary. In the present paper, we resolve
these challenges developing a new predictor-based control law that is,
essentially, an average of exact predictor feedbacks, each one corresponding to
an exact predictor-feedback law for a system that operates only in a single
mode. Because the predictor state in our control design does not correspond to
an exact predictor, stability can be guaranteed under a restriction on the
differences among the system's matrices and controller's gains. This is an
unavoidable limitation, for a switching signal whose future values may be
unavailable, when no constraint is imposed on the values of delay and dwell
time (as it is the case here). We establish (uniform) stability of the
closed-loop system employing a Lyapunov functional. The key step in the
stability proof is constructive derivation of an estimate of the mismatch
between an exact predictor feedback and the average of predictor feedbacks
constructed. We illustrate the performance of the proposed predictor-based
control law in simulation, including comparisons with alternative,
predictor-based control laws.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 6 figures, submitted to 2025 European Control Conference
  (ECC)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Spatiotemporal Tubes based Controller Synthesis against Omega-Regular
  Specifications for Unknown Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08337v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08337v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ratnangshu Das, Aiman Aatif Bayezeed, Pushpak Jagtap
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper provides a discretization-free solution to the synthesis of
approx-imation-free closed-form controllers for unknown nonlinear systems to
enforce complex properties expressed by $\omega$-regular languages, as
recognized by Non-deterministic B\"uchi Automata (NBA). In order to solve this
problem, we first decompose NBA into a sequence of reach-avoid problems, which
are solved using the Spatiotemporal Tubes (STT) approach. Controllers for each
reach-avoid task are then integrated into a hybrid policy that ensures the
fulfillment of the desired $\omega$-regular properties. We validate our method
through omnidirectional robot navigation and manipulator control case studies.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Geometric Nonlinear Filtering with Almost Global Convergence for
  Attitude and Bias Estimation on the Special Orthogonal Group 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08255v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08255v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Farooq Aslam, Muhammad Farooq Haydar, Suhail Akhtar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper proposes a novel geometric nonlinear filter for attitude and bias
estimation on the Special Orthogonal Group $SO(3)$ using matrix measurements.
The structure of the proposed filter is similar to that of the continuous-time
deterministic multiplicative extended Kalman filter (MEKF). The main difference
with the MEKF is the inclusion of curvature correction terms in both the filter
gain and gain update equations. These terms ensure that the proposed filter,
named the Generalized $SO(3)$-MEKF, renders the desired equilibrium of the
estimation error system to be almost globally uniformly asymptotically stable
(AGUAS). More precisely, the attitude and bias estimation errors converge
uniformly asymptotically to zero for almost all initial conditions except those
where the initial angular estimation error equals $\pi$ radians. Moreover, in
the case of small estimation errors, the proposed generalized $SO(3)$-MEKF
simplifies to the standard $SO(3)$-MEKF with matrix measurements. Simulation
results indicate that the proposed filter has similar performance compared to
the latter. Thus, the main advantage of the proposed filter over the MEKF is
the guarantee of (almost) global uniform asymptotic stability.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Generation and Balancing Capacity in Future Electric Power Systems --
  Scenario Analysis Using Bayesian Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08232v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08232v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Seppo Borenius, Pekka Kekolahti, Petri Mähönen, Matti Lehtonen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper examines the evolution of the Finnish electric energy system up to
2035, focusing on the likelihood of different development paths. The primary
contribution of this paper is the development of an extensive Bayesian Network,
designed to model and analyse the evolution of power generation capacity mix,
assess the likelihood of different grid management scenarios, and understand
the causal relationships underlying these scenarios. A target optimisation was
carried out using the constructed Bayesian Network to explore possibilities to
minimise grid management complexity. The results of the optimisation reveal
that the authorities and stakeholders should prioritise increasing demand
response, gas power, and battery storage capacities. These mature technologies
are well-suited to guarantee energy adequacy during peak consumption periods,
which in Finland typically occur during consecutive cold, dark and windless
winter weeks. Although this study focuses on the evolution of the Finnish power
grid, the constructed Bayesian Network approach is broadly applicable and can
be utilised to explore causal relationships in other countries by employing the
designed questionnaire and engaging a panel of experts specific to the
country's energy infrastructure.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages, 8 figures, 6 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ New Co-Simulation Variants for Emissions and Cost Reduction of
  Sustainable District Heating <span class="highlight-title">Plan</span>ning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08225v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08225v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haozhen Cheng, Verena Buccoliero, Alexander Kocher, Veit Hagenmeyer, Hüseyin K. Çakmak
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Classical heating of residential areas is very energy-intensive, so
alternatives are needed, including renewable energies and advanced heating
technologies. Thus, the present paper introduces a new methodology for
comprehensive variant analysis for future district heating planning, aiming at
optimizing emissions and costs. For this, an extensive Modelica-based modeling
study comprising models of heating center, heat grid pipelines and heating
interface units to buildings are coupled in co-simulations. These enable a
comparative analysis of the economic feasibility and sustainability for various
technologies and energy carriers to be carried out. The new modular and highly
parameterizable building model serves for validation of the introduced heat
grid model. The results show that bio-methane as an energy source reduces
carbon equivalent emissions by nearly 70% compared to conventional natural gas
heating, and the use of hydrogen as an energy source reduces carbon equivalent
emissions by 77% when equipped with a heat pump. In addition, the use of ground
source heat pumps has a high economic viability when economic benefits are
taken into account. The study findings highlight the importance of strategic
planning and flexible design in the early stages of district development in
order to achieve improved energy efficiency and a reduced carbon footprint.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Construction and Control of Validated Highly Configurable Multi-Physics
  Building Models for Multi-Energy System Analysis in a Co-Simulation Setup 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08215v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08215v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haozhen Cheng, Jan Stock, André Xhonneux, Hüseyin K. Çakmak, Veit Hagenmeyer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Improving energy efficiency by monitoring system behavior and predicting
future energy scenarios in light of increased penetration of renewable energy
sources are becoming increasingly important, especially for energy systems that
distribute and provide heat. On this background, digital twins of cities become
paramount in advancing urban energy system planning and infrastructure
management. The use of recorded energy data from sensors in district digital
twins in collaborative co-simulation platforms is a promising way to analyze
detailed system behavior and estimate future scenarios. However, the
development and coupling of multi-physics energy system models need to be
validated before they can be used for further in-depth analyses. In the present
paper, a new multi-physics/-modal and highly configurable building model is
presented. Its accuracy and reliability are validated by comparison with data
from the TABULA project, ensuring its relevance and applicability to real-world
scenarios. The modularity and flexibility with regard to the system
configurability of the developed building model is evaluated on various real
building types. In addition, the applicability of the building model in a
multi-energy system is highlighted by implementing the model in a collaborative
co-simulation setup and by coupling it to a district heating grid model in
yearly co-simulations. The simulation results for the proposed
multi-physical/-modal building modeling concept show a very high level of
agreement compared to published reference building data and can therefore be
used individually as flexible and modular building models including both
thermal and electrical systems for future sector-coupled energy system analyses
in view of sustainability.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Safety-Ensured Control Framework for Robotic Endoscopic Task Automation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08214v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08214v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yitaek Kim, Iñigo Iturrate, Christoffer Sloth, Hansoul Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  There is growing interest in automating surgical tasks using robotic systems,
such as endoscopy for treating gastrointestinal (GI) cancer. However, previous
studies have primarily focused on detecting and analyzing objects or robots,
with limited attention to ensuring safety, which is critical for clinical
applications, where accidents can be caused by unsafe robot motions. In this
study, we propose a new control framework that can formally ensure the safety
of automating certain processes involved in endoscopic submucosal dissection
(ESD), a representative endoscopic surgical method for the treatment of early
GI cancer, by using an endoscopic robot. The proposed framework utilizes
Control Barrier Functions (CBFs) to accurately identify the boundaries of
individual tumors, even in close proximity within the GI tract, ensuring
precise treatment and removal while preserving the surrounding normal tissue.
Additionally, by adopting a model-free control scheme, safety assurance is made
possible even in endoscopic robotic systems where dynamic modeling is
challenging. We demonstrate the proposed framework in cases where the tumors to
be removed are close to each other, showing that the safety constraints are
enforced. We show that the model-free CBF-based controlled robot eliminates one
tumor completely without damaging it, while not invading another nearby tumor.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This paper is submitted to IEEE Access</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Observer-Based Output-Feedback Backstepping Stabilization of Continua of
  Hyperbolic PDEs and Application to Large-Scale $n+m$ Coupled Hyperbolic PDEs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08209v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08209v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jukka-Pekka Humaloja, Nikolaos Bekiaris-Liberis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We develop a non-collocated, observer-based output-feedback law for a class
of continua of linear hyperbolic PDE systems, which are viewed as the continuum
version of $n+m$, general heterodirectional hyperbolic systems as $n\to\infty$.
The design relies on the introduction of a novel, continuum PDE backstepping
transformation, which enables the construction of a Lyapunov functional for the
estimation error system. Stability under the observer-based output-feedback law
is established by using the Lyapunov functional construction for the estimation
error system and proving well-posedness of the complete closed-loop system,
which allows utilization of the separation principle.
  Motivated by the fact that the continuum-based designs may provide
computationally tractable control laws for large-scale, $n+m$ systems, we then
utilize the control/observer kernels and the observer constructed for the
continuum system to introduce an output-feedback control design for the
original $n+m$ system. We establish exponential stability of the resulting
closed-loop system, which consists of a mixed $n+m$-continuum PDE system
(comprising the plant-observer dynamics), introducing a virtual continuum
system with resets, which enables utilization of the continuum approximation
property of the solutions of the $n+m$ system by its continuum counterpart (for
large $n$). We illustrate the potential computational complexity/flexibility
benefits of our approach via a numerical example of stabilization of a
large-scale $n+m$ system, for which we employ the continuum observer-based
controller, while the continuum-based stabilizing control/observer kernels can
be computed in closed form.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages, 4 figures, submitted to Automatica</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Cooperative Bearing-Only Target Pursuit via Multiagent Reinforcement
  Learning: Design and Experiment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08740v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08740v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jianan Li, Zhikun Wang, Susheng Ding, Shiliang Guo, Shiyu Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper addresses the multi-robot pursuit problem for an unknown target,
encompassing both target state estimation and pursuit control. First, in state
estimation, we focus on using only bearing information, as it is readily
available from vision sensors and effective for small, distant targets.
Challenges such as instability due to the nonlinearity of bearing measurements
and singularities in the two-angle representation are addressed through a
proposed uniform bearing-only information filter. This filter integrates
multiple 3D bearing measurements, provides a concise formulation, and enhances
stability and resilience to target loss caused by limited field of view (FoV).
Second, in target pursuit control within complex environments, where challenges
such as heterogeneity and limited FoV arise, conventional methods like
differential games or Voronoi partitioning often prove inadequate. To address
these limitations, we propose a novel multiagent reinforcement learning (MARL)
framework, enabling multiple heterogeneous vehicles to search, localize, and
follow a target while effectively handling those challenges. Third, to bridge
the sim-to-real gap, we propose two key techniques: incorporating adjustable
low-level control gains in training to replicate the dynamics of real-world
autonomous ground vehicles (AGVs), and proposing spectral-normalized RL
algorithms to enhance policy smoothness and robustness. Finally, we demonstrate
the successful zero-shot transfer of the MARL controllers to AGVs, validating
the effectiveness and practical feasibility of our approach. The accompanying
video is available at https://youtu.be/HO7FJyZiJ3E.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Ultra-low Power AMOLED Displays for Smart Wearable Applications: Theory
  and Practice 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08137v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08137v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bojia Lyu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the continuous advancement and maturity of AMOLED (Active-Matrix Organic
Light Emitting Diode) technology, smart wearable products such as watches and
bracelets are increasingly incorporating related technologies as display screen
implementation solutions. Using standby time is the most critical product
performance measurement indicator at the moment, according to the power supply
system design of smart wearable products and customer usage habits. AMOLED
displays, as one of the major power-consuming components in smart wearable
products, are also subject to extremely stringent power consumption
requirements. This paper divides an AMOLED display into five parts: the power
chip, the driver chip, the array substrate, the light-emitting structure, and
the light-transmitting structure. In this paper, we propose targeted
power-saving solutions for each component based on their respective operating
principles, subject areas, and the most recent advances in related fields, and
we provide the best overall solution by combining the interactions between each
component and even the entire system. The relevant solutions have been
validated in practice, and there is clear verification data to demonstrate
their feasibility.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Coordinated Path Following of UAVs using Event-Triggered Communication
  over Networks with Digraph Topologies 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08129v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08129v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hyungsoo Kang, Isaac Kaminer, Venanzio Cichella, Naira Hovakimyan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This article presents a novel time-coordination algorithm based on
event-triggered communication to ensure multiple UAVs progress along their
desired paths in coordination with one another. In the proposed algorithm, a
UAV transmits its progression information to its neighbor UAVs only when a
decentralized trigger condition is satisfied. Consequently, it significantly
reduces the volume of inter-vehicle communications required to achieve the goal
compared with the existing algorithms based on continuous communication. With
such intermittent communications, it is shown that a decentralized coordination
controller guarantees exponential convergence of the coordination error to a
neighborhood of zero. Furthermore, a lower bound on the difference between two
consecutive event-triggered times is provided showing that the Zeno behavior is
excluded with the proposed algorithm. Lastly, simulation results validate the
efficacy of the proposed algorithm.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>arXiv admin note: substantial text overlap with arXiv:2307.06961</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Forecast-Driven Scenario Generation for Building Energy Management Using
  Stochastic <span class="highlight-title">Optimization</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08113v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08113v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hossein Nourollahi Hokmabad, Tala Hemmati Shahsavar, Pedro P. Vergara, Oleksandr Husev, Juri Belikov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Buildings are essential components of power grids, and their energy
performance directly affects overall power system operation. This paper
presents a novel stochastic optimization framework for building energy
management systems, aiming to enhance buildings' energy performance and
facilitate their effective integration into emerging intelligent power grids.
In this method, solar power generation and building electricity demand
forecasts are combined with historical data, leveraging statistical
characteristics to generate probability matrices and corresponding scenarios
with associated probabilities. These scenarios are then used to solve the
stochastic optimization problem, optimizing building energy flow while
accounting for existing uncertainties. The results demonstrate that the
proposed methodology effectively manages inherent uncertainties while
maintaining performance and outperforming rule-based and custom build
reinforcement learning based solutions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>7 pages, 7 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Control Barrier Functions for Prescribed-time Reach-Avoid-Stay Tasks
  using Spatiotemporal Tubes 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08106v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08106v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ratnangshu Das, Pranav Bakshi, Pushpak Jagtap
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Prescribed-time reach-avoid-stay (PT-RAS) specifications are crucial in
applications requiring precise timing, state constraints, and safety
guarantees. While control carrier functions (CBFs) have emerged as a promising
approach, providing formal guarantees of safety, constructing CBFs that satisfy
PT-RAS specifications remains challenging. In this paper, we present a novel
approach using a spatiotemporal tubes (STTs) framework to construct CBFs for
PT-RAS tasks. The STT framework allows for the systematic design of CBFs that
dynamically manage both spatial and temporal constraints, ensuring the system
remains within a safe operational envelope while achieving the desired temporal
objectives. The proposed method is validated with two case studies: temporal
motion planning of an omnidirectional robot and temporal waypoint navigation of
a drone with obstacles, using higher-order CBFs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted in ECC 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhancing Vehicle Platooning Safety via Control Node Placement and
  Sizing under State and Input Bounds 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08089v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08089v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yifei She, Shen Wang, Ahmad Taha, Xiaofeng Tao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vehicle platooning with Cooperative Adaptive Cruise Control improves traffic
efficiency, reduces energy consumption, and enhances safety but remains
vulnerable to cyber-attacks that disrupt communication and cause unsafe
actions. To address these risks, this paper investigates control node placement
and input bound optimization to balance safety and defense efficiency under
various conditions. We propose a two-stage actuator placement and actuator
saturation approach, which focuses on identifying key actuators that maximize
the system's controllability while operating under state and input constraints.
By strategically placing and limiting the input bounds of critical actuators,
we ensure that vehicles maintain safe distances even under attack. Simulation
results show that our method effectively mitigates the impact of attacks while
preserving defense efficiency, offering a robust solution to vehicle platooning
safety challenges.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ TRUST: Stability and Safety Controller Synthesis for Unknown Dynamical
  Models Using a Single Trajectory 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08081v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08081v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jamie Gardner, Ben Wooding, Amy Nejati, Abolfazl Lavaei
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  TRUST is an open-source software tool developed for data-driven controller
synthesis of dynamical systems with unknown mathematical models, ensuring
either stability or safety properties. By collecting only a single input-state
trajectory from the unknown system and satisfying a rank condition that ensures
the system is persistently excited according to the Willems et al.'s
fundamental lemma, TRUST aims to design either control Lyapunov functions (CLF)
or control barrier certificates (CBC), along with their corresponding stability
or safety controllers. The tool implements sum-of-squares (SOS) optimization
programs solely based on data to enforce stability or safety properties across
four system classes: (i) continuous-time nonlinear polynomial systems, (ii)
continuous-time linear systems, (iii) discrete-time nonlinear polynomial
systems, and (iv) discrete-time linear systems. TRUST is a Python-based web
application featuring an intuitive, reactive graphic user interface (GUI) built
with web technologies. It can be accessed at https://trust.tgo.dev or installed
locally, and supports both manual data entry and data file uploads. Leveraging
the power of the Python backend and a JavaScript frontend, TRUST is designed to
be highly user-friendly and accessible across desktop, laptop, tablet, and
mobile devices. We apply TRUST to a set of physical benchmarks with unknown
dynamics, ensuring either stability or safety properties across the four
supported classes of models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Electrifying Heavy-Duty Trucks: Battery-Swapping vs Fast Charging 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08080v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08080v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ruiting Wang, Antoine Martinez, Zaid Allybokus, Wente Zeng, Nicolas Obrecht, Scott Moura
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The advantages and disadvantages of Battery Swapping Stations (BSS) for
heavy-duty trucks are poorly understood, relative to Fast Charging Stations
(FCS) systems. This study evaluates these two charging mechanisms for electric
heavy-duty trucks, aiming to compare the systems' efficiency and identify the
optimal design for each option. A model was developed to address the planning
and operation of BSS in a charging network, considering in-station batteries as
assets for various services. We assess performance metrics including
transportation efficiency and battery utilization efficiency. Our evaluation
reveals that BSS significantly increased transportation efficiency by reducing
vehicle downtime compared to fast charging, but may require more batteries. BSS
with medium-sized batteries offers improved transportation efficiency in terms
of time and labor. FCS-reliant trucks require larger batteries to compensate
for extended charging times. To understand the trade-off between these two
metrics, a cost-benefit analysis was performed under different scenarios
involving potential shifts in battery prices and labor costs. Additionally, BSS
shows potential for significant $\text{CO}_2$ emission reductions and increased
profitability through energy arbitrage and grid ancillary services. These
findings emphasize the importance of integrating BSS into future electric truck
charging networks and adopting carbon-aware operational frameworks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ From Data to Global Asymptotic Stability of Unknown Large-Scale Networks
  with Provable Guarantees 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08066v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08066v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mahdieh Zaker, Amy Nejati, Abolfazl Lavaei
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We offer a compositional data-driven scheme for synthesizing controllers that
ensure global asymptotic stability (GAS) across large-scale interconnected
networks, characterized by unknown mathematical models. In light of each
network's configuration composed of numerous subsystems with smaller
dimensions, our proposed framework gathers data from each subsystem's
trajectory, enabling the design of local controllers that ensure input-to-state
stability (ISS) properties over subsystems, signified by ISS Lyapunov
functions. To accomplish this, we require only a single input-state trajectory
from each unknown subsystem up to a specified time horizon, fulfilling certain
rank conditions. Subsequently, under small-gain compositional reasoning, we
leverage ISS Lyapunov functions derived from data to offer a control Lyapunov
function (CLF) for the interconnected network, ensuring GAS certificate over
the network. We demonstrate that while the computational complexity for
designing a CLF increases polynomially with the network dimension using
sum-of-squares (SOS) optimization, our compositional data-driven approach
significantly mitigates it to \emph{linear} with respect to the number of
subsystems. We showcase the efficacy of our data-driven approach over a set of
benchmarks, involving physical networks with diverse interconnection
topologies.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Data-Driven Dynamic Controller Synthesis for Discrete-Time General
  Nonlinear Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08060v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08060v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Behrad Samari, Abolfazl Lavaei
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Synthesizing safety controllers for general nonlinear systems is a highly
challenging task, particularly when the system models are unknown, and input
constraints are present. While some recent efforts have explored data-driven
safety controller design for nonlinear systems, these approaches are primarily
limited to specific classes of nonlinear dynamics (e.g., polynomials) and are
not applicable to general nonlinear systems. This paper develops a direct
data-driven approach for discrete-time general nonlinear systems, facilitating
the simultaneous learning of control barrier certificates (CBCs) and dynamic
controllers to ensure safety properties under input constraints. Specifically,
by leveraging the adding-one-integrator approach, we incorporate the
controller's dynamics into the system dynamics to synthesize a virtual
static-feedback controller for the augmented system, resulting in a dynamic
safety controller for the actual dynamics. We collect input-state data from the
augmented system during a finite-time experiment, referred to as a single
trajectory. Using this data, we learn augmented CBCs and the corresponding
virtual safety controllers, ensuring the safety of the actual system and
adherence to input constraints over a finite time horizon. We demonstrate that
our proposed conditions boil down to some data-dependent linear matrix
inequalities (LMIs), which are easy to satisfy. We showcase the effectiveness
of our data-driven approach through two case studies: one exhibiting
significant nonlinearity and the other featuring high dimensionality.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Optimizing AUV speed dynamics with a data-driven Koopman operator
  approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09628v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09628v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhiliang Liu, Xin Zhao, Peng Cai, Bing Cong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Autonomous Underwater Vehicles (AUVs) play an essential role in modern ocean
exploration, and their speed control systems are fundamental
  to their efficient operation. Like many other robotic systems, AUVs exhibit
multivariable nonlinear dynamics and face various constraints,
  including state limitations, input constraints, and constraints on the
increment input, making controller design challenging
  and requiring significant effort and time. This paper addresses these
challenges by employing a data-driven Koopman operator theory combined
  with Model Predictive Control (MPC), which takes into account the
aforementioned constraints. The proposed approach not only ensures
  the performance of the AUV under state and input limitations but also
considers the variation in incremental input to prevent
  rapid and potentially damaging changes to the vehicle's operation.
Additionally, we develop a platform based on ROS2 and Gazebo
  to validate the effectiveness of the proposed algorithms, providing new
control strategies for underwater vehicles against the complex and dynamic
nature of underwater environments.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>26 pages, 8 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Elastic Motion Policy: An Adaptive Dynamical System for Robust and
  Efficient One-Shot Imitation Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08029v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08029v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tianyu Li, Sunan Sun, Shubhodeep Shiv Aditya, Nadia Figueroa
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Behavior cloning (BC) has become a staple imitation learning paradigm in
robotics due to its ease of teaching robots complex skills directly from expert
demonstrations. However, BC suffers from an inherent generalization issue. To
solve this, the status quo solution is to gather more data. Yet, regardless of
how much training data is available, out-of-distribution performance is still
sub-par, lacks any formal guarantee of convergence and success, and is
incapable of allowing and recovering from physical interactions with humans.
These are critical flaws when robots are deployed in ever-changing
human-centric environments. Thus, we propose Elastic Motion Policy (EMP), a
one-shot imitation learning framework that allows robots to adjust their
behavior based on the scene change while respecting the task specification.
Trained from a single demonstration, EMP follows the dynamical systems paradigm
where motion planning and control are governed by first-order differential
equations with convergence guarantees. We leverage Laplacian editing in full
end-effector space, $\mathbb{R}^3\times SO(3)$, and online convex learning of
Lyapunov functions, to adapt EMP online to new contexts, avoiding the need to
collect new demonstrations. We extensively validate our framework in real robot
experiments, demonstrating its robust and efficient performance in dynamic
environments, with obstacle avoidance and multi-step task capabilities. Project
Website: https://elastic-motion-policy.github.io/EMP/
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Three-Dimensional Pursuit-Evasion Game Based on Fuzzy Actor-Critic
  Learning Algorithm 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08013v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08013v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Penglin Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Most of the existing research on pursuit-evasion game (PEG) is conducted in a
two-dimensional (2D) environment. In this paper, we investigate the PEG in a 3D
space. We extend the Apollonius circle (AC) to the 3D space and introduce its
detailed analytical form. To enhance the capture efficiency, we derive the
optimal motion space for both the pursuer and the evader. To address the issue
arising from a discrete state space, we design a fuzzy actor-critic learning
(FACL) algorithm to obtain the agents' strategies. To improve learning
performance, we devise a reward function for the agents, which enables obstacle
avoidance functionality. The effectiveness of the proposed algorithm is
validated through simulation experiments.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Integrated Energy Management for Operational Cost <span class="highlight-title">Optimization</span> in
  Community Microgrids 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08009v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08009v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Moslem Uddin, Huadong Mo, Daoyi Dong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study presents an integrated energy management strategy for cost
optimization in multi-energy community microgrids (MGs). The proposed approach
combines storage-based peak shaving, economic dispatch of diesel generators,
and efficient utilization of renewable energy sources to enhance energy
management in community MGs. The efficacy of the energy management system (EMS)
was validated through a simulation case study for a rural Australian community.
The results demonstrate that the proposed EMS effectively reduces the peak
energy demand by up to 43%, lowers operational costs by 84.63% (from
$189,939/year to $29,188/year), and achieves a renewable energy utilization of
92.3%, up from 47.8% in the base system. Furthermore, the levelized cost of
energy was reduced by 14.21% to $0.163/kWh. The strategy ensures an
uninterrupted power supply during grid outages by utilizing DGs and battery
energy storage systems. The environmental benefits included a 196.4% reduction
in CO2 emissions and 100% reductions in CO, unburned hydrocarbons, and
particulate matter. These findings validate the feasibility of the proposed EMS
in achieving cost-effective, reliable, and sustainable energy management in
community MGs. These findings contribute to the field by introducing a novel
approach and demonstrating the practical feasibility of multi-energy MGs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Joint Semantic Transmission and Resource Allocation for Intelligent
  Computation Task Offloading in MEC Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08001v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08001v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuanpeng Zheng, Tiankui Zhang, Xidong Mu, Yuanwei Liu, Rong Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Mobile edge computing (MEC) enables the provision of high-reliability and
low-latency applications by offering computation and storage resources in close
proximity to end-users. Different from traditional computation task offloading
in MEC systems, the large data volume and complex task computation of
artificial intelligence involved intelligent computation task offloading have
increased greatly. To address this challenge, we propose a MEC system for
multiple base stations and multiple terminals, which exploits semantic
transmission and early exit of inference. Based on this, we investigate a joint
semantic transmission and resource allocation problem for maximizing system
reward combined with analysis of semantic transmission and intelligent
computation process. To solve the formulated problem, we decompose it into
communication resource allocation subproblem, semantic transmission subproblem,
and computation capacity allocation subproblem. Then, we use 3D matching and
convex optimization method to solve subproblems based on the block coordinate
descent (BCD) framework. The optimized feasible solutions are derived from an
efficient BCD based joint semantic transmission and resource allocation
algorithm in MEC systems. Our simulation demonstrates that: 1) The proposed
algorithm significantly improves the delay performance for MEC systems compared
with benchmarks; 2) The design of transmission mode and early exit of inference
greatly increases system reward during offloading; and 3) Our proposed system
achieves efficient utilization of resources from the perspective of system
reward in the intelligent scenario.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A <span class="highlight-title">Survey</span> of Challenges and Sensing Technologies in Autonomous Retail
  Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07997v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07997v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shimmy Rukundo, David Wang, Front Wongnonthawitthaya, Youssouf Sidibé, Minsik Kim, Emily Su, Jiale Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Autonomous stores leverage advanced sensing technologies to enable
cashier-less shopping, real-time inventory tracking, and seamless customer
interactions. However, these systems face significant challenges, including
occlusion in vision-based tracking, scalability of sensor deployment, theft
prevention, and real-time data processing. To address these issues, researchers
have explored multi-modal sensing approaches, integrating computer vision,
RFID, weight sensing, vibration-based detection, and LiDAR to enhance accuracy
and efficiency. This survey provides a comprehensive review of sensing
technologies used in autonomous retail environments, highlighting their
strengths, limitations, and integration strategies. We categorize existing
solutions across inventory tracking, environmental monitoring, people-tracking,
and theft detection, discussing key challenges and emerging trends. Finally, we
outline future directions for scalable, cost-efficient, and privacy-conscious
autonomous store systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Decentralized Integration of Grid Edge Resources into Wholesale
  Electricity Markets via Mean-field Games 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07984v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07984v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chen Feng, Andrew L. Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Grid edge resources refer to distributed energy resources (DERs) located on
the consumer side of the electrical grid, controlled by consumers rather than
utility companies. Integrating DERs with real-time electricity pricing can
better align distributed supply with system demand, improving grid efficiency
and reliability. However, DER owners, known as prosumers, often lack the
expertise and resources to directly participate in wholesale energy markets,
limiting their ability to fully realize the economic potential of their assets.
Meanwhile, as DER adoption grows, the number of prosumers participating in the
energy system is expected to increase significantly, creating additional
challenges in coordination and market participation.
  To address these challenges, we propose a mean-field game framework that
enables prosumers to autonomously learn optimal decision policies based on
dynamic market prices and their variable solar generation. Our framework is
designed to accommodate heterogeneous agents and demonstrates the existence of
a mean-field equilibrium (MFE) in a wholesale energy market with many
prosumers. Additionally, we introduce an algorithm that automates prosumers'
resource control, facilitating real-time decision-making for energy storage
management. Numerical experiments suggest that our approach converges towards
an MFE and effectively reduces peak loads and price volatility, especially
during periods of external demand or supply shocks. This study highlights the
potential of a fully decentralized approach to integrating DERs into wholesale
markets while improving market efficiency.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Adaptive Control with Rate-Limited Integral Action for Systems with
  Matched, Time-Varying Uncertainties 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07971v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07971v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ying-Chun Chen, Craig Woolsey
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper considers the problem of controlling a piecewise continuously
differentiable system subject to time-varying uncertainties. The uncertainties
are decomposed into a time-invariant, linearly-parameterized portion and a
time-varying unstructured portion. The former is addressed using conventional
model reference adaptive control. The latter is handled using disturbance
observer-based control. The objective is to ensure good performance through
observer-based disturbance rejection when possible, while preserving the
robustness guarantees of adaptive control. A key feature of the observer-based
disturbance compensation is a magnitude and rate limit on the integral action
that prevents fast fluctuations in the control command due to the observer
dynamics.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 9 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Accelerating Development in UAV Network Digital Twins with a Flexible
  Simulation Framework 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07935v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07935v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Md Sharif Hossen, Anil Gurses, Mihail Sichitiu, Ismail Guvenc
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Unmanned aerial vehicles (UAVs) enhance coverage and provide flexible
deployment in 5G and next-generation wireless networks. The performance of such
wireless networks can be improved by developing new navigation and wireless
adaptation approaches in digital twins (DTs). However, challenges such as
complex propagation conditions and hardware complexities in real-world
scenarios introduce a realism gap with the DTs. Moreover, while using real-time
full-stack protocols in DTs enables subsequent deployment and testing in a
real-world environment, development in DTs requires high computational
complexity and involves a long development time. In this paper, to accelerate
the development cycle, we develop a measurement-calibrated Matlab-based
simulation framework to replicate performance in a full-stack UAV wireless
network DT. In particular, we use the DT from the NSF AERPAW platform and
compare its reports with those generated by our developed simulation framework
in wireless networks with similar settings. In both environments, we observe
comparable results in terms of RSRP measurement, hence motivating iterative use
of the developed simulation environment with the DT.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>WS24 ICC 2025 Workshop - DTNWN</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Counterfactual Ex<span class="highlight-title">plan</span>ations for Model Ensembles Using Entropic Risk
  Measures 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07934v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07934v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Erfaun Noorani, Pasan Dissanayake, Faisal Hamman, Sanghamitra Dutta
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Counterfactual explanations indicate the smallest change in input that can
translate to a different outcome for a machine learning model. Counterfactuals
have generated immense interest in high-stakes applications such as finance,
education, hiring, etc. In several use-cases, the decision-making process often
relies on an ensemble of models rather than just one. Despite significant
research on counterfactuals for one model, the problem of generating a single
counterfactual explanation for an ensemble of models has received limited
interest. Each individual model might lead to a different counterfactual,
whereas trying to find a counterfactual accepted by all models might
significantly increase cost (effort). We propose a novel strategy to find the
counterfactual for an ensemble of models using the perspective of entropic risk
measure. Entropic risk is a convex risk measure that satisfies several
desirable properties. We incorporate our proposed risk measure into a novel
constrained optimization to generate counterfactuals for ensembles that stay
valid for several models. The main significance of our measure is that it
provides a knob that allows for the generation of counterfactuals that stay
valid under an adjustable fraction of the models. We also show that a limiting
case of our entropic-risk-based strategy yields a counterfactual valid for all
models in the ensemble (worst-case min-max approach). We study the trade-off
between the cost (effort) for the counterfactual and its validity for an
ensemble by varying degrees of risk aversion, as determined by our risk
parameter knob. We validate our performance on real-world datasets.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Reduce, Reuse, Recycle: Categories for Compositional Reinforcement
  Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.13376v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.13376v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Georgios Bakirtzis, Michail Savvas, Ruihan Zhao, Sandeep Chinchali, Ufuk Topcu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In reinforcement learning, conducting task composition by forming cohesive,
executable sequences from multiple tasks remains challenging. However, the
ability to (de)compose tasks is a linchpin in developing robotic systems
capable of learning complex behaviors. Yet, compositional reinforcement
learning is beset with difficulties, including the high dimensionality of the
problem space, scarcity of rewards, and absence of system robustness after task
composition. To surmount these challenges, we view task composition through the
prism of category theory -- a mathematical discipline exploring structures and
their compositional relationships. The categorical properties of Markov
decision processes untangle complex tasks into manageable sub-tasks, allowing
for strategical reduction of dimensionality, facilitating more tractable reward
structures, and bolstering system robustness. Experimental results support the
categorical theory of reinforcement learning by enabling skill reduction,
reuse, and recycling when learning complex robotic arm tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ECAI 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ An Unsupervised C-Uniform Trajectory Sampler with Applications to Model
  Predictive Path Integral Control <span class="chip">IROS2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.05819v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.05819v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        O. Goktug Poyrazoglu, Rahul Moorthy, Yukang Cao, William Chastek, Volkan Isler
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sampling-based model predictive controllers generate trajectories by sampling
control inputs from a fixed, simple distribution such as the normal or uniform
distributions. This sampling method yields trajectory samples that are tightly
clustered around a mean trajectory. This clustering behavior in turn, limits
the exploration capability of the controller and reduces the likelihood of
finding feasible solutions in complex environments. Recent work has attempted
to address this problem by either reshaping the resulting trajectory
distribution or increasing the sample entropy to enhance diversity and promote
exploration. In our recent work, we introduced the concept of C-Uniform
trajectory generation [1] which allows the computation of control input
probabilities to generate trajectories that sample the configuration space
uniformly. In this work, we first address the main limitation of this method:
lack of scalability due to computational complexity. We introduce Neural
C-Uniform, an unsupervised C-Uniform trajectory sampler that mitigates
scalability issues by computing control input probabilities without relying on
a discretized configuration space. Experiments show that Neural C-Uniform
achieves a similar uniformity ratio to the original C-Uniform approach and
generates trajectories over a longer time horizon while preserving uniformity.
Next, we present CU-MPPI, which integrates Neural C-Uniform sampling into
existing MPPI variants. We analyze the performance of CU-MPPI in simulation and
real-world experiments. Our results indicate that in settings where the optimal
solution has high curvature, CU-MPPI leads to drastic improvements in
performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to IROS2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ On discount functions for economic <span class="highlight-title">model predictive</span> control without
  terminal conditions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.14361v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.14361v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lukas Schwenkel, Daniel Briem, Matthias A. Müller, Frank Allgöwer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we investigate discounted economic model predictive control
(E-MPC) schemes without terminal conditions in scenarios where the optimal
operating behavior is a periodic orbit. For such a setting, it is known that a
linearly discounted stage cost guarantees asymptotic stability of any
arbitrarily small neighborhood of the optimal orbit if the prediction horizon
is sufficiently long. However, in some examples very long prediction horizons
are needed to achieve the desired performance. In this work, we extend these
results by providing the same qualitative stability guarantees for a large
class of discount functions. Numerical examples illustrate the influence of the
discount function and show that with suitable discounting we can achieve
significantly better performance than the linearly discounted E-MPC, even for
short prediction horizons.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Optimal Output Feedback Learning Control for Discrete-Time Linear
  Quadratic Regulation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06226v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06226v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kedi Xie, Martin Guay, Shimin Wang, Fang Deng, Maobin Lu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper studies the linear quadratic regulation (LQR) problem of unknown
discrete-time systems via dynamic output feedback learning control. In contrast
to the state feedback, the optimality of the dynamic output feedback control
for solving the LQR problem requires an implicit condition on the convergence
of the state observer. Moreover, due to unknown system matrices and the
existence of observer error, it is difficult to analyze the convergence and
stability of most existing output feedback learning-based control methods. To
tackle these issues, we propose a generalized dynamic output feedback learning
control approach with guaranteed convergence, stability, and optimality
performance for solving the LQR problem of unknown discrete-time linear
systems. In particular, a dynamic output feedback controller is designed to be
equivalent to a state feedback controller. This equivalence relationship is an
inherent property without requiring convergence of the estimated state by the
state observer, which plays a key role in establishing the off-policy learning
control approaches. By value iteration and policy iteration schemes, the
adaptive dynamic programming based learning control approaches are developed to
estimate the optimal feedback control gain. In addition, a model-free stability
criterion is provided by finding a nonsingular parameterization matrix, which
contributes to establishing a switched iteration scheme. Furthermore, the
convergence, stability, and optimality analyses of the proposed output feedback
learning control approaches are given. Finally, the theoretical results are
validated by two numerical examples.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ From Classification to <span class="highlight-title">Optimization</span>: Slicing and Resource Management
  with TRACTOR 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.07896v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.07896v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Joshua Groen, Zixian Yang, Divyadharshini Muruganandham, Mauro Belgiovine, Lei Ying, Kaushik Chowdhury
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  5G and beyond networks promise advancements in bandwidth, latency, and
connectivity. The Open Radio Access Network (O-RAN) framework enhances
flexibility through network slicing and closed-loop RAN control. Central to
this evolution is integrating machine learning (ML) for dynamic network
control. This paper presents a framework to optimize O-RAN operation. First, we
build and share a robust O-RAN dataset from real-world traffic captured across
diverse locations and mobility scenarios, replicated within a full-stack
srsRAN-based O-RAN system using the Colosseum RF emulator. This dataset
supports ML training and deployment. We then introduce a traffic classification
approach leveraging various ML models, demonstrating rapid training, testing,
and refinement to improve accuracy. With up to 99% offline accuracy and 92%
online accuracy for specific slices, our framework adapts efficiently to
different models and network conditions. Finally, we present a physical
resource block (PRB) assignment optimization strategy using reinforcement
learning to refine resource allocation. Our learned policy achieves a mean
performance score (0.631), surpassing a manually configured expert policy
(0.609) and a random baseline (0.588), demonstrating improved PRB utilization.
More importantly, our approach exhibits lower variability, with the Coefficient
of Variation (CV) reduced by up to an order of magnitude in three out of four
cases, ensuring more consistent performance. Our contributions, including
open-source tools and datasets, accelerate O-RAN and ML-driven network control
research.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Journal version of TRACTOR: Traffic Analysis and Classification Tool
  for Open RAN</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Online Control-Informed Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03924v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03924v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zihao Liang, Tianyu Zhou, Zehui Lu, Shaoshuai Mou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper proposes an Online Control-Informed Learning (OCIL) framework,
which employs the well-established optimal control and state estimation
techniques in the field of control to solve a broad class of learning tasks in
an online fashion. This novel integration effectively handles practical issues
in machine learning such as noisy measurement data, online learning, and data
efficiency. By considering any robot as a tunable optimal control system, we
propose an online parameter estimator based on extended Kalman filter (EKF) to
incrementally tune the system in an online fashion, enabling it to complete
designated learning or control tasks. The proposed method also improves the
robustness in learning by effectively managing noise in the data. Theoretical
analysis is provided to demonstrate the convergence of OCIL. Three learning
modes of OCIL, i.e. Online Imitation Learning, Online System Identification,
and Policy Tuning On-the-fly, are investigated via experiments, which validate
their effectiveness.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Assessing Electricity Network Capacity Requirements for Industrial
  Decarbonisation in Great Britain 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.17384v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.17384v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ahmed Gailani, Peter Taylor
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Decarbonising the industrial sector is vital to reach net zero targets. The
deployment of industrial decarbonisation technologies is expected to increase
industrial electricity demand in many countries and this may require upgrades
to the existing electricity network or new network investment. While the
infrastructure requirements to support the introduction of new fuels and
technologies in industry, such as hydrogen and carbon capture, utilisation and
storage are often discussed, the need for investment to increase the capacity
of the electricity network to meet increasing industrial electricity demands is
often overlooked in the literature. This paper addresses this gap by
quantifying the requirements for additional electricity network capacity to
support the decarbonisation of industrial sectors across Great Britain (GB).
The Net Zero Industrial Pathways model is used to predict the future
electricity demand from industrial sites to 2050 which is then compared
spatially to the available headroom across the distribution network in GB. The
results show that network headroom is sufficient to meet extra capacity demands
from industrial sites over the period to 2030 in nearly all GB regions and
network scenarios. However, as electricity demand rises due to increased
electrification across all sectors and industrial decarbonisation accelerates
towards 2050, the network will need significant new capacity (71 GW + by 2050)
particularly in the central, south, and north-west regions of England, and
Wales. Without solving these network constraints, around 65% of industrial
sites that are large point sources of emissions would be constrained in terms
of electric capacity by 2040. These sites are responsible for 69% of industrial
point source emissions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Online Learning of Nonlinear Parametric Models under Non-smooth
  Regularization using EKF and ADMM 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.01282v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.01282v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lapo Frascati, Alberto Bemporad
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper proposes a novel combination of extended Kalman filtering (EKF)
with the alternating direction method of multipliers (ADMM) for learning
parametric nonlinear models online under non-smooth regularization terms,
including l1 and l0 penalties and bound constraints on model parameters. For
the case of linear time-varying models and non-smoothconvex regularization
terms, we provide a sublinear regret bound that ensures the proper behavior of
the online learning strategy. The approach is computationally efficient for a
wide range of regularization terms, which makes it appealing for its use in
embedded control applications for online model adaptation. We show the
performance of the proposed method in three simulation examples, highlighting
its effectiveness compared to other batch and online algorithms.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Parallel-in-Time Newton's Method for Nonlinear <span class="highlight-title">Model Predictive</span>
  Control 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.20027v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.20027v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Casian Iacob, Hany Abdulsamad, Simo Särkkä
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Model predictive control (MPC) is a powerful framework for optimal control of
dynamical systems. However, MPC solvers suffer from a high computational burden
that restricts their application to systems with low sampling frequency. This
issue is further amplified in nonlinear and constrained systems that require
nesting MPC solvers within iterative procedures. In this paper, we address
these issues by developing parallel-in-time algorithms for constrained
nonlinear optimization problems that take advantage of massively parallel
hardware to achieve logarithmic computational time scaling over the planning
horizon. We develop time-parallel second-order solvers based on interior point
methods and the alternating direction method of multipliers, leveraging fast
convergence and lower computational cost per iteration. The parallelization is
based on a reformulation of the subproblems in terms of associative operations
that can be parallelized using the associative scan algorithm. We validate our
approach on numerical examples of nonlinear and constrained dynamical systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Lipschitz Safe Bayesian <span class="highlight-title">Optimization</span> for Automotive Control 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.12969v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.12969v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Johanna Menn, Pietro Pelizzari, Michael Fleps-Dezasse, Sebastian Trimpe
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Controller tuning is a labor-intensive process that requires human
intervention and expert knowledge. Bayesian optimization has been applied
successfully in different fields to automate this process. However, when tuning
on hardware, such as in automotive applications, strict safety requirements
often arise. To obtain safety guarantees, many existing safe Bayesian
optimization methods rely on assumptions that are hard to verify in practice.
This leads to the use of unjustified heuristics in many applications, which
invalidates the theoretical safety guarantees. Furthermore, applications often
require multiple safety constraints to be satisfied simultaneously. Building on
recently proposed Lipschitz-only safe Bayesian optimization, we develop an
algorithm that relies on readily interpretable assumptions and satisfies
multiple safety constraints at the same time. We apply this algorithm to the
problem of automatically tuning a trajectory-tracking controller of a
self-driving car. Results both from simulations and an actual test vehicle
underline the algorithm's ability to learn tracking controllers without leaving
the track or violating any other safety constraints.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for publication at 63rd Conference on Decision and Control,
  December 16-19, 2024 in Milano, Italy</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Stochastic Tube-based <span class="highlight-title">Model Predictive</span> Control for Cyber-Physical
  Systems under False Data Injection Attacks with Bounded Probability 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07385v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07385v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuzhou Xiao, Senchun Chai, Li Dai, Yuanqing Xia, Runqi Chai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper addresses the challenge of amplitude-unbounded false data
injection (FDI) attacks targeting the sensor-to-controller (S-C) channel in
cyber-physical systems (CPSs). We introduce a resilient tube-based model
predictive control (MPC) scheme. This scheme incorporates a threshold-based
attack detector and a control sequence buffer to enhance system security. We
mathematically model the common FDI attacks and derive the maximum duration of
such attacks based on the hypothesis testing principle. Following this, the
minimum feasible sequence length of the control sequence buffer is obtained.
The system is proven to remain input-to-state stable (ISS) under bounded
external disturbances and amplitude-unbounded FDI attacks. Moreover, the
feasible region under this scenario is provided in this paper. Finally, the
proposed algorithm is validated by numerical simulations and shows superior
control performance compared to the existing methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This work has been submitted to the IEEE for possible publication</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Multilinear Extensions in Submodular <span class="highlight-title">Optimization</span> for Optimal Sensor
  Scheduling in Nonlinear Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.03833v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.03833v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohamad H. Kazma, Ahmad F. Taha
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Optimal sensing nodes selection (SNS) in dynamic systems is a combinatorial
optimization problem that has been thoroughly studied in the recent literature.
This problem can be formulated within the context of set optimization. For
high-dimensional nonlinear systems, the problem is extremely difficult to
solve. It scales poorly too. Current literature poses combinatorial submodular
set optimization problems via maximizing observability performance metrics
subject to matroid constraints. Such an approach is typically solved using
greedy algorithms that require lower computational effort yet often yield
sub-optimal solutions. In this paper, we address the SNS problem for nonlinear
dynamical networks using a variational form of the system dynamics, that
basically perturb the system physics. As a result, we show that the
observability performance metrics under such system representation are indeed
submodular. The optimal problem is then solved using the multilinear continuous
extension. This extension offers a computationally scalable and approximate
continuous relaxation with a performance guarantee. The effectiveness of the
extended submodular program is studied and compared to greedy algorithms. We
demonstrate the proposed set optimization formulation for SNS on nonlinear
natural gas combustion networks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To Appear in the 2025 American Control Conference (ACC'2025), Denver,
  Colorado, July 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ TinySense: A Lighter Weight and More Power-efficient Avionics System for
  Flying Insect-scale Robots <span class="chip">ICRA 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.03416v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.03416v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhitao Yu, Joshua Tran, Claire Li, Aaron Weber, Yash P. Talwekar, Sawyer Fuller
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we introduce advances in the sensor suite of an autonomous
flying insect robot (FIR) weighing less than a gram. FIRs, because of their
small weight and size, offer unparalleled advantages in terms of material cost
and scalability. However, their size introduces considerable control
challenges, notably high-speed dynamics, restricted power, and limited payload
capacity. While there have been advancements in developing lightweight sensors,
often drawing inspiration from biological systems, no sub-gram aircraft has
been able to attain sustained hover without relying on feedback from external
sensing such as a motion capture system. The lightest vehicle capable of
sustained hovering -- the first level of ``sensor autonomy'' -- is the much
larger 28 g Crazyflie. Previous work reported a reduction in size of that
vehicle's avionics suite to 187 mg and 21 mW. Here, we report a further
reduction in mass and power to only 78.4 mg and 15 mW. We replaced the laser
rangefinder with a lighter and more efficient pressure sensor, and built a
smaller optic flow sensor around a global-shutter imaging chip. A Kalman Filter
(KF) fuses these measurements to estimate the state variables that are needed
to control hover: pitch angle, translational velocity, and altitude. Our system
achieved performance comparable to that of the Crazyflie's estimator while in
flight, with root mean squared errors of 1.573 deg, 0.186 m/s, and 0.136 m,
respectively, relative to motion capture.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ICRA 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Categorical semantics of compositional reinforcement learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2208.13687v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2208.13687v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Georgios Bakirtzis, Michail Savvas, Ufuk Topcu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Compositional knowledge representations in reinforcement learning (RL)
facilitate modular, interpretable, and safe task specifications. However,
generating compositional models requires the characterization of minimal
assumptions for the robustness of the compositionality feature, especially in
the case of functional decompositions. Using a categorical point of view, we
develop a knowledge representation framework for a compositional theory of RL.
Our approach relies on the theoretical study of the category $\mathsf{MDP}$,
whose objects are Markov decision processes (MDPs) acting as models of tasks.
The categorical semantics models the compositionality of tasks through the
application of pushout operations akin to combining puzzle pieces. As a
practical application of these pushout operations, we introduce zig-zag
diagrams that rely on the compositional guarantees engendered by the category
$\mathsf{MDP}$. We further prove that properties of the category $\mathsf{MDP}$
unify concepts, such as enforcing safety requirements and exploiting
symmetries, generalizing previous abstraction theories for RL.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SysCaps: Language Interfaces for Simulation Surrogates of Complex
  Systems <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.19653v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.19653v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Patrick Emami, Zhaonan Li, Saumya Sinha, Truc Nguyen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Surrogate models are used to predict the behavior of complex energy systems
that are too expensive to simulate with traditional numerical methods. Our work
introduces the use of language descriptions, which we call ``system captions''
or SysCaps, to interface with such surrogates. We argue that interacting with
surrogates through text, particularly natural language, makes these models more
accessible for both experts and non-experts. We introduce a lightweight
multimodal text and timeseries regression model and a training pipeline that
uses large language models (LLMs) to synthesize high-quality captions from
simulation metadata. Our experiments on two real-world simulators of buildings
and wind farms show that our SysCaps-augmented surrogates have better accuracy
on held-out systems than traditional methods while enjoying new generalization
abilities, such as handling semantically related descriptions of the same test
system. Additional experiments also highlight the potential of SysCaps to
unlock language-driven design space exploration and to regularize training
through prompt augmentation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at ICLR 2025. 23 pages</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Optimization and Control <span class="chip" style="font-size: 60%">46</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Ensemble optimal control for managing drug resistance in cancer
  therapies 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08927v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08927v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alessandro Scagliotti, Federico Scagliotti, Laura Deborah Locati, Federico Sottotetti
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we explore the application of ensemble optimal control to
derive enhanced strategies for pharmacological cancer treatment. In particular,
we focus on moving beyond the classical clinical approach of giving the patient
the maximal tolerated drug dose (MTD), which does not properly exploit the
fight among sensitive and resistant cells for the available resources. Here, we
employ a Lotka-Volterra model to describe the two competing subpopulations, and
we enclose this system within the ensemble control framework. In the first
part, we establish general results suitable for application to various solid
cancers. Then, we carry out numerical simulations in the setting of prostate
cancer treated with androgen deprivation therapy, yielding a computed policy
that is reminiscent of the medical 'active surveillance' paradigm. Finally,
inspired by the numerical evidence, we propose a variant of the celebrated
adaptive therapy (AT), which we call 'Off-On' AT.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>26 pages, 6 figures, 4 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Revisiting Frank-Wolfe for Structured Nonconvex <span class="highlight-title">Optimization</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08921v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08921v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hoomaan Maskan, Yikun Hou, Suvrit Sra, Alp Yurtsever
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce a new projection-free (Frank-Wolfe) method for optimizing
structured nonconvex functions that are expressed as a difference of two convex
functions. This problem class subsumes smooth nonconvex minimization,
positioning our method as a promising alternative to the classical Frank-Wolfe
algorithm. DC decompositions are not unique; by carefully selecting a
decomposition, we can better exploit the problem structure, improve
computational efficiency, and adapt to the underlying problem geometry to find
better local solutions. We prove that the proposed method achieves a
first-order stationary point in $O(1/\epsilon^2)$ iterations, matching the
complexity of the standard Frank-Wolfe algorithm for smooth nonconvex
minimization in general. Specific decompositions can, for instance, yield a
gradient-efficient variant that requires only $O(1/\epsilon)$ calls to the
gradient oracle. Finally, we present numerical experiments demonstrating the
effectiveness of the proposed method compared to the standard Frank-Wolfe
algorithm.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Stochastic <span class="highlight-title">Model Predictive</span> Control for Sub-Gaussian Noise 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08795v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08795v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yunke Ao, Johannes Köhler, Manish Prajapat, Yarden As, Melanie Zeilinger, Philipp Fürnstahl, Andreas Krause
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose a stochastic Model Predictive Control (MPC) framework that ensures
closed-loop chance constraint satisfaction for linear systems with general
sub-Gaussian process and measurement noise. By considering sub-Gaussian noise,
we can provide guarantees for a large class of distributions, including
time-varying distributions. Specifically, we first provide a new
characterization of sub-Gaussian random vectors using matrix variance proxies,
which can more accurately represent the predicted state distribution. We then
derive tail bounds under linear propagation for the new characterization,
enabling tractable computation of probabilistic reachable sets of linear
systems. Lastly, we utilize these probabilistic reachable sets to formulate a
stochastic MPC scheme that provides closed-loop guarantees for general
sub-Gaussian noise. We further demonstrate our approach in simulations,
including a challenging task of surgical planning from image observations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15 pages, 6 figures, submitted to Automatica</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Some commutation principles for <span class="highlight-title">optimization</span> problems over
  transformation groups and semi-FTvN systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08654v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08654v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        M. Seetharama Gowda, David Sossa
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce the concepts of commutativity relative to a transformation group
and strong commutativity in the setting of a semi-FTvN system and show their
appearance as optimality conditions in certain optimization problems. In the
setting of a semi-FTvN system (in particular, in an FTvN system), we show that
strong commutativity implies commutativity and observe that in the special case
of Euclidean Jordan algebra, commutativity and strong commutativity concepts
reduce, respectively, to those of operator and strong operator commutativity.
We demonstrate that every complete hyperbolic polynomial induces a semi-FTvN
system. By way of an application, we describe several commutation principles.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Regularized Federated Methods with Universal Guarantees for Simple
  Bilevel <span class="highlight-title">Optimization</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08634v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08634v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohammadjavad Ebrahimi, Yuyang Qiu, Shisheng Cui, Farzad Yousefian
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study a bilevel federated learning (FL) problem, where clients
cooperatively seek to find among multiple optimal solutions of a primary
distributed learning problem, a solution that minimizes a secondary distributed
global loss function. This problem is motivated by model selection in
over-parameterized machine learning, in that the outer-level objective is a
suitably-defined regularizer and the inner-level objective is the training loss
function. Despite recent progress in centralized settings,
communication-efficient FL methods equipped with complexity guarantees for
resolving this problem class are primarily absent. Motivated by this lacuna, we
consider the setting where the inner-level objective is convex and the
outer-level objective is either convex or strongly convex. We propose a
universal regularized scheme and derive promising error bounds in terms of both
the inner-level and outer-level loss functions. Leveraging this unifying
theory, we then enable two existing FL methods to address the corresponding
simple bilevel problem and derive novel communication complexity guarantees for
each method. Additionally, we devise an FL method for addressing simple bilevel
optimization problems with a nonconvex outer-level loss function. Through a
two-loop scheme and by leveraging the universal theory, we derive new
complexity bounds for the nonconvex setting. This appears to be the first time
that federated simple bilevel optimization problems are provably addressed with
guarantees. We validate the theoretical findings on EMNIST and CIFAR-10
datasets.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Faithful global convergence for the rescaled Consensus--Based
  <span class="highlight-title">Optimization</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08578v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08578v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hui Huang, Hicham Kouhkouh, Lukang Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We analyze the Consensus-Based Optimization (CBO) algorithm with a consensus
point rescaled by a small fixed parameter $\kappa \in (0,1)$. Under minimal
assumptions on the objective function and the initial data, we establish its
unconditional convergence to the global minimizer. Our results hold in the
asymptotic regime where both the time--horizon $t \to \infty$ and the
inverse--temperature $\alpha \to \infty$, providing a rigorous theoretical
foundation for the algorithm's global convergence. Furthermore, our findings
extend to the case of multiple and non--discrete set of minimizers.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Convergence analysis of linearized $\ell_q$ penalty methods for
  nonconvex <span class="highlight-title">optimization</span> with nonlinear equality constraints 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08522v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08522v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lahcen El Bourkhissi, Ion Necoara
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we consider nonconvex optimization problems with nonlinear
equality constraints. We assume that the objective function and the functional
constraints are locally smooth. To solve this problem, we introduce a
linearized $\ell_q$ penalty based method, where $q \in (1,2]$ is the parameter
defining the norm used in the construction of the penalty function. Our method
involves linearizing the objective function and functional constraints in a
Gauss-Newton fashion at the current iteration in the penalty formulation and
introduces a quadratic regularization. This approach yields an easily solvable
subproblem, whose solution becomes the next iterate. By using a novel dynamic
rule for the choice of the regularization parameter, we establish that the
iterates of our method converge to an $\epsilon$-first-order solution in
$\mathcal{O}(1/{\epsilon^{2+ (q-1)/q}})$ outer iterations. Finally, we put
theory into practice and evaluate the performance of the proposed algorithm by
making numerical comparisons with existing methods from literature.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>27 pages, March 2025. arXiv admin note: text overlap with
  arXiv:2402.15639</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DISTINGUISH Workflow: A New Paradigm of Dynamic Well Placement Using
  Generative Machine Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08509v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08509v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sergey Alyaev, Kristian Fossum, Hibat Errahmen Djecta, Jan Tveranger, Ahmed H. Elsheikh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The real-time process of directional changes while drilling, known as
geosteering, is crucial for hydrocarbon extraction and emerging directional
drilling applications such as geothermal energy, civil infrastructure, and CO2
storage. The geo-energy industry seeks an automatic geosteering workflow that
continually updates the subsurface uncertainties and captures the latest
geological understanding given the most recent observations in real-time.
  We propose "DISTINGUISH": a real-time, AI-driven workflow designed to
transform geosteering by integrating Generative Adversarial Networks (GANs) for
geological parameterization, ensemble methods for model updating, and global
discrete dynamic programming (DDP) optimization for complex decision-making
during directional drilling operations. The DISTINGUISH framework relies on
offline training of a GAN model to reproduce relevant geology realizations and
a Forward Neural Network (FNN) to model Logging-While-Drilling (LWD) tools'
response for a given geomodel.
  This paper introduces a first-of-its-kind workflow that progressively reduces
GAN-geomodel uncertainty around and ahead of the drilling bit and adjusts the
well plan accordingly. The workflow automatically integrates real-time LWD data
with a DDP-based decision support system, enhancing predictive models of
geology ahead of drilling and leading to better steering decisions. We present
a simple yet representative benchmark case and document the performance target
achieved by the DISTINGUISH workflow prototype. This benchmark will be a
foundation for future methodological advancements and workflow refinements.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The conference version of this paper is published in EAGE ECMOR 2024
  proceedings: https://doi.org/10.3997/2214-4609.202437018</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Communication-Efficient and Differentially-Private Distributed
  Generalized Nash Equilibrium Seeking Algorithm for Aggregative Games 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08494v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08494v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenqing Zhao, Antai Xie, Yuchi Wu, Xinlei Yi, Xiaoqiang Ren
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper studies the distributed generalized Nash equilibrium seeking
problem for aggregative games with coupling constraints, where each player
optimizes its strategy depending on its local cost function and the estimated
strategy aggregation. The information transmission in distributed networks may
go beyond bandwidth capacity and eventuate communication bottlenecks.
Therefore, we propose a novel communication-efficient distributed generalized
Nash equilibrium seeking algorithm, in which the communication efficiency is
improved by event-triggered communication and information compression methods.
The proposed algorithm saves the transmitted rounds and bits of communication
simultaneously. Specifically, by developing precise step size conditions, the
proposed algorithm ensures provable convergence, and is proven to achieve
$(0,\delta)$-differential privacy with a stochastic quantization scheme. In the
end, simulation results verify the effectiveness of the proposed algorithm.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Progressive hedging for multi-stage stochastic lot sizing problems with
  setup carry-over under uncertain demand 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08477v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08477v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Manuel Schlenkrich, Jean-François Cordeau, Sophie N. Parragh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We investigate multi-stage demand uncertainty for the multi-item
multi-echelon capacitated lot sizing problem with setup carry-over. Considering
a multi-stage decision framework helps to quantify the benefits of being able
to adapt decisions to newly available information. The drawback is that
multi-stage stochastic optimization approaches lead to very challenging
formulations. This is because they usually rely on scenario tree
representations of the uncertainty, which grow exponentially in the number of
decision stages. Thus, even for a moderate number of decision stages it becomes
difficult to solve the problem by means of a compact optimization model. To
address this issue, we propose a progressive hedging algorithm and we
investigate and tune the crucial penalty parameter that influences the
conflicting goals of fast convergence and solution quality. While low penalty
parameters usually lead to high quality solutions, this comes at the cost of
slow convergence. To tackle this problem, we adapt metaheuristic adjustment
strategies to guide the algorithm towards a consensus more efficiently.
Furthermore, we consider several options to compute the consensus solution.
While averaging the subproblem decisions is a common choice, we also apply a
majority voting procedure. We test different algorithm configurations and
compare the results of progressive hedging to the solutions obtained by solving
a compact optimization model on well-known benchmark instances. For several
problem instances the progressive hedging algorithm converges to solutions
within 1% of the cost of the compact model's solution, while requiring shorter
runtimes.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A forward-reflected-anchored-backward splitting algorithm with double
  inertial effects for solving non-monotone inclusion problems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08432v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08432v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nam Van Tran
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we study inclusion problems where the involved operators may
not be monotone in the classical sense. Specifically, we assume the operators
to be generalized monotone, a weaker notion than classical monotonicity. This
allows us to extend the applicability of our results to a broader class of
operators. We apply the two-step inertial forward-reflected-anchored-backward
splitting algorithm proposed in \cite{CHIN} to these non-monotone inclusion
problems. We establish the strong convergence of the sequence generated by the
algorithm and demonstrate its applicability to other optimization problems,
including Constrained Optimization Problems, Mixed Variational Inequalities,
and Variational Inequalities.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Accelerated Distributed <span class="highlight-title">Optimization</span> with Compression and Error Feedback 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08427v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08427v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuan Gao, Anton Rodomanov, Jeremy Rack, Sebastian U. Stich
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Modern machine learning tasks often involve massive datasets and models,
necessitating distributed optimization algorithms with reduced communication
overhead. Communication compression, where clients transmit compressed updates
to a central server, has emerged as a key technique to mitigate communication
bottlenecks. However, the theoretical understanding of stochastic distributed
optimization with contractive compression remains limited, particularly in
conjunction with Nesterov acceleration -- a cornerstone for achieving faster
convergence in optimization.
  In this paper, we propose a novel algorithm, ADEF (Accelerated Distributed
Error Feedback), which integrates Nesterov acceleration, contractive
compression, error feedback, and gradient difference compression. We prove that
ADEF achieves the first accelerated convergence rate for stochastic distributed
optimization with contractive compression in the general convex regime.
Numerical experiments validate our theoretical findings and demonstrate the
practical efficacy of ADEF in reducing communication costs while maintaining
fast convergence.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Dual Koopman Approach to Observer Design for Nonlinear Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08345v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08345v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Judicaël Mohet, Alexandre Mauroy, Joseph J. Winkin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The Koopman operator approach to the state estimation problem for nonlinear
systems is a promising research area. The main goal of this paper is an attempt
to provide a rigorous theoretical framework for this approach. In particular,
the (linear) dual Koopman system is introduced and studied in an infinite
dimensional context. Moreover, new concepts of observability and detectability
are defined in the dual Koopman system, which are shown to be equivalent to the
observability and detectability of the nonlinear system, respectively. The
theoretical framework is applied to a class of holomorphic dynamics. For this
class, a Luenberger-type observer is designed for the dual Koopman system via a
spectral method, yielding an estimate of the state of the nonlinear system. A
particular attention is given to the existence of an appropriate solution to
the dual Koopman system and observer, which are defined in the Hardy space on
the polydisc. Spectral observability and detectability conditions are derived
in this setting, and the exponential convergence of the Koopman observer is
shown. Finally, numerical experiments support the theoretical findings.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Upper and Lower Bounds for a Class of Constrained Linear Time-Varying
  Games 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08310v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08310v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vincent Liu, Chris Manzie, Peter M. Dower
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper develops an algorithm for upper- and lower-bounding the value
function for a class of linear time-varying games subject to convex control
sets. In particular, a two-player zero-sum differential game is considered
where the respective players aim to minimise and maximise a convex terminal
state cost. A collection of solutions of a single-player dynamical system
subject to a trimmed control set is used to characterise a viscosity
supersolution of a Hamilton-Jacobi (HJ) equation, which in turn yields an upper
bound for the value function. Analogously, a collection of hyperplanes is used
to characterise a viscosity subsolution of the HJ equation, which yields a
lower bound. The computational complexity and memory requirement of the
proposed algorithm scales with the number of solutions and hyperplanes that
characterise the bounds, which is not explicitly tied to the number of system
states. Thus, the algorithm is tractable for systems of moderately high
dimension whilst preserving rigorous guarantees for optimal control and
differential game applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Nonlinear optimals and their role in sustaining turbulence in channel
  flow 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08283v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08283v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dario Klingenberg, Rich R. Kerswell
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We investigate the energy transfer from the mean profile to velocity
fluctuations in channel flow by calculating nonlinear optimal disturbances,i.e.
the initial condition of a given finite energy that achieves the highest
possible energy growth during a given fixed time horizon. It is found that for
a large range of time horizons and initial disturbance energies, the nonlinear
optimal exhibits streak spacing and amplitude consistent with DNS at least at
Re_tau = 180, which suggests that they isolate the relevant physical mechanisms
that sustain turbulence. Moreover, the time horizon necessary for a nonlinear
disturbance to outperform a linear optimal is consistent with previous
DNS-based estimates using eddy turnover time, which offers a new perspective on
how some turbulent time scales are determined.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Dynamically optimal portfolios for monotone mean--variance preferences 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08272v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08272v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aleš Černý, Johannes Ruf, Martin Schweizer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Monotone mean-variance (MMV) utility is the minimal modification of the
classical Markowitz utility that respects rational ordering of investment
opportunities. This paper provides, for the first time, a complete
characterization of optimal dynamic portfolio choice for the MMV utility in
asset price models with independent returns. The task is performed under
minimal assumptions, weaker than the existence of an equivalent martingale
measure and with no restrictions on the moments of asset returns. We interpret
the maximal MMV utility in terms of the monotone Sharpe ratio (MSR) and show
that the global squared MSR arises as the nominal yield from continuously
compounding at the rate equal to the maximal local squared MSR. The paper gives
simple necessary and sufficient conditions for mean-variance (MV) efficient
portfolios to be MMV efficient. Several illustrative examples contrasting the
MV and MMV criteria are provided.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Observer-Based Output-Feedback Backstepping Stabilization of Continua of
  Hyperbolic PDEs and Application to Large-Scale $n+m$ Coupled Hyperbolic PDEs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08209v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08209v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jukka-Pekka Humaloja, Nikolaos Bekiaris-Liberis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We develop a non-collocated, observer-based output-feedback law for a class
of continua of linear hyperbolic PDE systems, which are viewed as the continuum
version of $n+m$, general heterodirectional hyperbolic systems as $n\to\infty$.
The design relies on the introduction of a novel, continuum PDE backstepping
transformation, which enables the construction of a Lyapunov functional for the
estimation error system. Stability under the observer-based output-feedback law
is established by using the Lyapunov functional construction for the estimation
error system and proving well-posedness of the complete closed-loop system,
which allows utilization of the separation principle.
  Motivated by the fact that the continuum-based designs may provide
computationally tractable control laws for large-scale, $n+m$ systems, we then
utilize the control/observer kernels and the observer constructed for the
continuum system to introduce an output-feedback control design for the
original $n+m$ system. We establish exponential stability of the resulting
closed-loop system, which consists of a mixed $n+m$-continuum PDE system
(comprising the plant-observer dynamics), introducing a virtual continuum
system with resets, which enables utilization of the continuum approximation
property of the solutions of the $n+m$ system by its continuum counterpart (for
large $n$). We illustrate the potential computational complexity/flexibility
benefits of our approach via a numerical example of stabilization of a
large-scale $n+m$ system, for which we employ the continuum observer-based
controller, while the continuum-based stabilizing control/observer kernels can
be computed in closed form.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages, 4 figures, submitted to Automatica</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Extension of Controllability Score to Infinite-Dimensional Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08011v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08011v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuito Nakabe, Kazuhiro Sato
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Centrality analysis in dynamical network systems is essential for
understanding system behavior. In finite-dimensional settings, controllability
scores -- namely, the Volumetric Controllability Score (VCS) and the Average
Energy Controllability Score (AECS) -- are defined as the unique solutions of
specific optimization problems. In this work, we extend these concepts to
infinite-dimensional systems by formulating analogous optimization problems.
Moreover, we prove that these optimization problems have optimal solutions
under weak assumptions, and that both VCS and AECS remain unique in the
infinite-dimensional context under appropriate assumptions. The uniqueness of
the controllability scores is essential to use them as a centrality measure,
since it not only reflects the importance of each state in the dynamical
network but also provides a consistent basis for interpretation and comparison
across different researchers. Finally, we illustrate the behavior of VCS and
AECS with a numerical experiment based on the heat equation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On Minimizing Phase Space Energies 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07965v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07965v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Michael Updike, Nicholas Bohlsen, Hong Qin, Nathaniel Fisch
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A primary technical challenge for harnessing fusion energy is to control and
extract energy from a non-thermal distribution of charged particles. The fact
that phase space evolves by symplectomorphisms fundamentally limits how a
distribution may be manipulated. While the constraint of phase-space volume
preservation is well understood, other constraints remain to be fully
appreciated. To better understand these constraints, we study the problem of
extracting energy from a distribution of particles using area-preserving and
symplectic linear maps. When a quadratic potential is imposed, we find that the
maximal extractable energy can be computed as trace minimization problems. We
solve these problems and show that the extractable energy under linear
symplectomorphisms may be much smaller than the extractable energy under
special linear maps. The method introduced in the present study enables an
energy-based proof of the linear Gromov non-squeezing theorem.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages, 2 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Generalizations of Total Dual Integrality 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07925v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07925v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bertrand Guenin, Levent Tunçel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We design new tools to study variants of Total Dual Integrality. As an
application, we obtain a geometric characterization of Total Dual Integrality
for the case where the associated polyhedron is non-degenerate. We also give
sufficient conditions for a system to be Totally Dual Dyadic, and prove new
special cases of Seymour's Dyadic conjecture on ideal clutters.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>26 pages, 2 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Solving Functional <span class="highlight-title">Optimization</span> with Deep Networks and Variational
  Principles 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.06277v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.06277v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kawisorn Kamtue, Jose M. F. Moura, Orathai Sangpetch
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Can neural networks solve math problems using first a principle alone? This
paper shows how to leverage the fundamental theorem of the calculus of
variations to design deep neural networks to solve functional optimization
without requiring training data (e.g., ground-truth optimal solutions). Our
approach is particularly crucial when the solution is a function defined over
an unknown interval or support\textemdash such as in minimum-time control
problems. By incorporating the necessary conditions satisfied by the optimal
function solution, as derived from the calculus of variation, in the design of
the deep architecture, CalVNet leverages overparameterized neural networks to
learn these optimal functions directly. We validate CalVNet by showing that,
without relying on ground-truth data and simply incorporating first principles,
it successfully derives the Kalman filter for linear filtering, the bang-bang
optimal control for minimum-time problems, and finds geodesics on manifolds.
Our results demonstrate that CalVNet can be trained in an unsupervised manner,
without relying on ground-truth data, establishing a promising framework for
addressing general, potentially unsolved functional optimization problems that
still lack analytical solutions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ On discount functions for economic <span class="highlight-title">model predictive</span> control without
  terminal conditions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.14361v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.14361v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lukas Schwenkel, Daniel Briem, Matthias A. Müller, Frank Allgöwer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we investigate discounted economic model predictive control
(E-MPC) schemes without terminal conditions in scenarios where the optimal
operating behavior is a periodic orbit. For such a setting, it is known that a
linearly discounted stage cost guarantees asymptotic stability of any
arbitrarily small neighborhood of the optimal orbit if the prediction horizon
is sufficiently long. However, in some examples very long prediction horizons
are needed to achieve the desired performance. In this work, we extend these
results by providing the same qualitative stability guarantees for a large
class of discount functions. Numerical examples illustrate the influence of the
discount function and show that with suitable discounting we can achieve
significantly better performance than the linearly discounted E-MPC, even for
short prediction horizons.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Optimal Output Feedback Learning Control for Discrete-Time Linear
  Quadratic Regulation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06226v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06226v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kedi Xie, Martin Guay, Shimin Wang, Fang Deng, Maobin Lu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper studies the linear quadratic regulation (LQR) problem of unknown
discrete-time systems via dynamic output feedback learning control. In contrast
to the state feedback, the optimality of the dynamic output feedback control
for solving the LQR problem requires an implicit condition on the convergence
of the state observer. Moreover, due to unknown system matrices and the
existence of observer error, it is difficult to analyze the convergence and
stability of most existing output feedback learning-based control methods. To
tackle these issues, we propose a generalized dynamic output feedback learning
control approach with guaranteed convergence, stability, and optimality
performance for solving the LQR problem of unknown discrete-time linear
systems. In particular, a dynamic output feedback controller is designed to be
equivalent to a state feedback controller. This equivalence relationship is an
inherent property without requiring convergence of the estimated state by the
state observer, which plays a key role in establishing the off-policy learning
control approaches. By value iteration and policy iteration schemes, the
adaptive dynamic programming based learning control approaches are developed to
estimate the optimal feedback control gain. In addition, a model-free stability
criterion is provided by finding a nonsingular parameterization matrix, which
contributes to establishing a switched iteration scheme. Furthermore, the
convergence, stability, and optimality analyses of the proposed output feedback
learning control approaches are given. Finally, the theoretical results are
validated by two numerical examples.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Dynamic Pricing and Matching for Two-Sided Queues 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/1911.02213v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/1911.02213v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sushil Mahavir Varma, Pornpawee Bumpensanti, Siva Theja Maguluri, He Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Motivated by applications from gig economy and online marketplaces, we study
a two-sided queueing system under joint pricing and matching controls. The
queueing system is modeled by a bipartite graph, where the vertices represent
customer or server types and the edges represent compatible customer-server
pairs. Both customers and servers sequentially arrive to the system and join
separate queues according to their types. The arrival rates of different types
depend on the prices set by the system operator and the expected waiting time.
At any point in time, the system operator can choose certain customers to match
with compatible servers. The objective is to maximize the long-run average
profit for the system. We first propose a fluid approximation based pricing and
max-weight matching policy, which achieves an $O(\sqrt{\eta})$ optimality rate
when all the arrival rates are scaled by $\eta$. We further show that a
two-price and max-weight matching policy achieves an improved $O(\eta^{1/3})$
optimality rate. Under a broad class of pricing policies, we prove that any
matching policy has an optimality rate that is lower bounded by
$\Omega(\eta^{1/3})$. Thus, the latter policy achieves the optimal rate with
respect to $\eta$. We also demonstrate the advantage of max-weight matching
with respect to the number of server and customer types $n$. Under a complete
resource pooling condition, we show that max-weight matching achieves
$O(\sqrt{n})$ and $O(n^{1/3})$ optimality rates for static and two-price
policies, respectively, and the latter matches the lower bound
$\Omega(n^{1/3})$. In comparison, the randomized matching policy may have an
$\Omega(n)$ optimality rate.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Conference Version published in ACM Sigmetrics 2020 and Journal
  Version published in Operations Research</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Non-commutative <span class="highlight-title">optimization</span> problems with differential constraints 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.02572v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.02572v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mateus Araújo, Andrew J. P. Garner, Miguel Navascues
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Non-commutative polynomial optimization (NPO) problems seek to minimize the
state average of a polynomial of some operator variables, subject to polynomial
constraints, over all states and operators, as well as the Hilbert spaces where
those might be defined. Many of these problems are known to admit a complete
hierarchy of semidefinite programming (SDP) relaxations. In this work, we
consider a variant of NPO problems where a subset of the operator variables
satisfies a system of ordinary differential equations. We find that, under mild
conditions of operator boundedness, for every such problem one can construct a
standard NPO problem with the same solution. This allows us to define a
complete hierarchy of SDPs to tackle the original differential problem. We
apply this method to bound averages of local observables in quantum spin
systems subject to a Hamiltonian evolution (i.e., a quench). We find that, even
in the thermodynamic limit of infinitely many sites, low levels of the
hierarchy provide very good approximations for reasonably long evolution times.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>New version, more accessible for both physicists and mathematicians,
  with new results and applications in statistical physics (numerical tests
  included). If you wonder how far one can go with 2-RDMT or the bootstrap
  technique, this paper is for you!</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Building Interval Type-2 Fuzzy Membership Function: A Deck of Cards
  based Co-constructive Approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.01413v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.01413v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bapi Dutta, Diego García-Zamora, José Rui Figueira, Luis Martínez
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Since its inception, Fuzzy Set has been widely used to handle uncertainty and
imprecision in decision-making. However, conventional fuzzy sets, often
referred to as type-1 fuzzy sets (T1FSs) have limitations in capturing higher
levels of uncertainty, particularly when decision-makers (DMs) express
hesitation or ambiguity in membership degree. To address this, Interval Type-2
Fuzzy Sets (IT2FSs) have been introduced by incorporating uncertainty in
membership degree allocation, which enhanced flexibility in modelling
subjective judgments. Despite their advantages, existing IT2FS construction
methods often lack active involvement from DMs and that limits the
interpretability and effectiveness of decision models. This study proposes a
socio-technical co-constructive approach for developing IT2FS models of
linguistic terms by facilitating the active involvement of DMs in preference
elicitation and its application in multicriteria decision-making (MCDM)
problems. Our methodology is structured in two phases. The first phase involves
an interactive process between the DM and the decision analyst, in which a
modified version of Deck-of-Cards (DoC) method is proposed to construct T1FS
membership functions on a ratio scale. We then extend this method to
incorporate ambiguity in subjective judgment and that resulted in an IT2FS
model that better captures uncertainty in DM's linguistic assessments. The
second phase formalizes the constructed IT2FS model for application in MCDM by
defining an appropriate mathematical representation of such information,
aggregation rules, and an admissible ordering principle. The proposed framework
enhances the reliability and effectiveness of fuzzy decision-making not only by
accurately representing DM's personalized semantics of linguistic information.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Online Control-Informed Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03924v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03924v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zihao Liang, Tianyu Zhou, Zehui Lu, Shaoshuai Mou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper proposes an Online Control-Informed Learning (OCIL) framework,
which employs the well-established optimal control and state estimation
techniques in the field of control to solve a broad class of learning tasks in
an online fashion. This novel integration effectively handles practical issues
in machine learning such as noisy measurement data, online learning, and data
efficiency. By considering any robot as a tunable optimal control system, we
propose an online parameter estimator based on extended Kalman filter (EKF) to
incrementally tune the system in an online fashion, enabling it to complete
designated learning or control tasks. The proposed method also improves the
robustness in learning by effectively managing noise in the data. Theoretical
analysis is provided to demonstrate the convergence of OCIL. Three learning
modes of OCIL, i.e. Online Imitation Learning, Online System Identification,
and Policy Tuning On-the-fly, are investigated via experiments, which validate
their effectiveness.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Fast Inexact Bilevel <span class="highlight-title">Optimization</span> for Analytical Deep Image Priors 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09758v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09758v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohammad Sadegh Salehi, Tatiana A. Bubba, Yury Korolev
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The analytical deep image prior (ADP) introduced by Dittmer et al. (2020)
establishes a link between deep image priors and classical regularization
theory via bilevel optimization. While this is an elegant construction, it
involves expensive computations if the lower-level problem is to be solved
accurately. To overcome this issue, we propose to use adaptive inexact bilevel
optimization to solve ADP problems. We discuss an extension of a recent inexact
bilevel method called the method of adaptive inexact descent of Salehi et
al.(2024) to an infinite-dimensional setting required by the ADP framework. In
our numerical experiments we demonstrate that the computational speed-up
achieved by adaptive inexact bilevel optimization allows one to use ADP on
larger-scale problems than in the previous literature, e.g. in deblurring of 2D
color images.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 7 figures. Accepted to the 10th International Conference on
  Scale Space and Variational Methods in Computer Vision (SSVM 2025)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Statistical Inference for Linear Functionals of Online SGD in
  High-dimensional Linear Regression 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2302.09727v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2302.09727v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bhavya Agrawalla, Krishnakumar Balasubramanian, Promit Ghosal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Stochastic gradient descent (SGD) has emerged as the quintessential method in
a data scientist's toolbox. Using SGD for high-stakes applications requires,
however, careful quantification of the associated uncertainty. Towards that
end, in this work, we establish a high-dimensional Central Limit Theorem (CLT)
for linear functionals of online SGD iterates for overparametrized
least-squares regression with non-isotropic Gaussian inputs. We first show that
a bias-corrected CLT holds when the number of iterations of the online SGD,
$t$, grows sub-linearly in the dimensionality, $d$. In order to use the
developed result in practice, we further develop an online approach for
estimating the variance term appearing in the CLT, and establish
high-probability bounds for the developed online estimator. Together with the
CLT result, this provides a fully online and data-driven way to numerically
construct confidence intervals. This enables practical high-dimensional
algorithmic inference with SGD and to the best of our knowledge, is the first
such result.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Single-loop methods for bilevel parameter learning in inverse imaging 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.08123v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.08123v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ensio Suonperä, Tuomo Valkonen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Bilevel optimisation is used in inverse problems for hyperparameter learning
and experimental design. For instance, it can be used to find optimal
regularisation parameters and forward operators, based on a set of training
pairs. However, computationally, the process is costly. To reduce this cost,
recently in bilevel optimisation research, especially as applied to machine
learning, so-called single-loop approaches have been introduced. On each step
of an outer optimisation method, such methods only take a single gradient
descent step towards the solution of the inner problem. In this paper, we
flexibilise the inner algorithm, to allow for methods more applicable to
difficult inverse problems with nonsmooth regularisation, including primal-dual
proximal splitting (PDPS). Moreover, as we have recently shown, significant
performance improvements can be obtained in PDE-constrained optimisation by
interweaving the steps of conventional iterative solvers (Jacobi, Gauss-Seidel,
conjugate gradients) for both the PDE and its adjoint, with the steps of the
optimisation method. In this paper we demonstrate how the adjoint equation in
bilevel problems can also benefit from such interweaving with conventional
linear system solvers. We demonstrate the performance of our proposed methods
on learning the deconvolution kernel for image deblurring, and the subsampling
operator for magnetic resonance imaging (MRI).
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Quantum <span class="highlight-title">Optimization</span> Algorithm for Optimal Electric Vehicle Charging
  Station Placement for Intercity Trips 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.16231v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.16231v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tina Radvand, Alireza Talebpour, Homa Khosravian
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Electric vehicles (EVs) play a significant role in enhancing the
sustainability of transportation systems. However, their widespread adoption is
hindered by inadequate public charging infrastructure, particularly to support
long-distance travel. Identifying optimal charging station locations in large
transportation networks presents a well-known NP-hard combinatorial
optimization problem, as the search space grows exponentially with the number
of potential charging station locations. This paper introduces a quantum
search-based optimization algorithm designed to enhance the efficiency of
solving this NP-hard problem for transportation networks. By leveraging quantum
parallelism, amplitude amplification, and quantum phase estimation as a
subroutine, the optimal solution is identified with a quadratic improvement in
complexity compared to classical exact methods, such as branch and bound. The
detailed design and complexity of a resource-efficient quantum circuit are
discussed.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ On the required number of electrodes for uniqueness and convex
  reformulation in an inverse coefficient problem 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.00482v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.00482v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Andrej Brojatsch, Bastian Harrach
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce a computer-assisted proof for the required number of electrodes
for uniqueness and global reconstruction for the inverse Robin transmission
problem, where the corrosion function on the boundary of an interior object is
to be determined from electrode current-voltage measurements. We consider the
shunt electrode model where, in contrast to the standard Neumann boundary
condition, the applied electrical current is only partially known. The aim is
to determine the corrosion coefficient with a finite number of measurements.
  In this paper, we present a numerically verifiable criterion that ensures
unique solvability of the inverse problem, given a desired resolution. This
allows us to explicitly determine the required number and position of the
electrodes. Furthermore, we will present an error estimate for noisy data. By
rewriting the problem as a convex optimization problem, our aim is to develop a
globally convergent reconstruction algorithm.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages, 9 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Integral Quadratic Constraints on Linear Infinite-dimensional Systems
  for Robust Stability Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2003.06283v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2003.06283v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Barreau Matthieu, Scherer Carsten W., Gouaisbaut Frederic, Seuret Alexandre
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper proposes a framework to assess the stability of an ordinary
differential equation which is coupled to a 1D-partial differential equation
(PDE). The stability theorem is based on a new result on Integral Quadratic
Constraints (IQCs) and expressed in terms of two linear matrix inequalities
with a moderate computational burden. The IQCs are not generated using
dissipation inequalities involving the whole state of an infinite-dimensional
system, but by using projection coefficients of the infinite-dimensional state.
This permits to generalize our robustness result to many other PDEs. The
proposed methodology is applied to a time-delay system and numerical results
comparable to those in the literature are obtained.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Bilevel Learning with Inexact Stochastic Gradients 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.12049v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.12049v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohammad Sadegh Salehi, Subhadip Mukherjee, Lindon Roberts, Matthias J. Ehrhardt
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Bilevel learning has gained prominence in machine learning, inverse problems,
and imaging applications, including hyperparameter optimization, learning
data-adaptive regularizers, and optimizing forward operators. The large-scale
nature of these problems has led to the development of inexact and
computationally efficient methods. Existing adaptive methods predominantly rely
on deterministic formulations, while stochastic approaches often adopt a
doubly-stochastic framework with impractical variance assumptions, enforces a
fixed number of lower-level iterations, and requires extensive tuning. In this
work, we focus on bilevel learning with strongly convex lower-level problems
and a nonconvex sum-of-functions in the upper-level. Stochasticity arises from
data sampling in the upper-level which leads to inexact stochastic
hypergradients. We establish their connection to state-of-the-art stochastic
optimization theory for nonconvex objectives. Furthermore, we prove the
convergence of inexact stochastic bilevel optimization under mild assumptions.
Our empirical results highlight significant speed-ups and improved
generalization in imaging tasks such as image denoising and deblurring in
comparison with adaptive deterministic bilevel methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to the 10th International Conference on Scale Space and
  Variational Methods in Computer Vision (SSVM 2025)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Statistical and Geometrical properties of regularized Kernel
  Kullback-Leibler divergence <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.16543v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.16543v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Clémentine Chazal, Anna Korba, Francis Bach
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we study the statistical and geometrical properties of the
Kullback-Leibler divergence with kernel covariance operators (KKL) introduced
by Bach [2022]. Unlike the classical Kullback-Leibler (KL) divergence that
involves density ratios, the KKL compares probability distributions through
covariance operators (embeddings) in a reproducible kernel Hilbert space
(RKHS), and compute the Kullback-Leibler quantum divergence. This novel
divergence hence shares parallel but different aspects with both the standard
Kullback-Leibler between probability distributions and kernel embeddings
metrics such as the maximum mean discrepancy. A limitation faced with the
original KKL divergence is its inability to be defined for distributions with
disjoint supports. To solve this problem, we propose in this paper a
regularised variant that guarantees that the divergence is well defined for all
distributions. We derive bounds that quantify the deviation of the regularised
KKL to the original one, as well as finite-sample bounds. In addition, we
provide a closed-form expression for the regularised KKL, specifically
applicable when the distributions consist of finite sets of points, which makes
it implementable. Furthermore, we derive a Wasserstein gradient descent scheme
of the KKL divergence in the case of discrete distributions, and study
empirically its properties to transport a set of points to a target
distribution.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Paper accepted to NeurIPS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A finite element scheme for an optimal control problem on steady
  Navier-Stokes-Brinkman equations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09336v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09336v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jorge Aguayo Araneda, Julie Merten
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents a rigorous finite element framework for solving an
optimal control problem governed by the steady Navier-Stokes-Brinkman
equations, focusing on identifying a scalar permeability parameter $\gamma$
from local velocity observations. Three different finite element discretization
schemes are proposed, and a priori error estimates are proven under appropriate
regularity assumptions for each one. A key contribution of this paper is the
development of residual-based a posteriori error estimators for both fully
discrete and semi-discrete schemes, guiding adaptive mesh refinement to achieve
comparable accuracy with fewer degrees of freedom. The method of manufactured
solutions is used for numerical experiments to validate the theoretical
findings, to demonstrate optimal convergence rates and the effectivity index is
evaluated to measure their reliability. The framework offers insights into flow
control mechanisms and paving the way for extensions to time-dependent,
stochastic, or multiphysics problems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Energy matching in reduced passive and port-Hamiltonian systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2309.05778v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2309.05778v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tobias Holicki, Jonas Nicodemus, Paul Schwerdtner, Benjamin Unger
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  It is well known that any port-Hamiltonian (pH) system is passive, and
conversely, any minimal and stable passive system has a pH representation.
Nevertheless, this equivalence is only concerned with the input-output mapping
but not with the Hamiltonian itself. Thus, we propose to view a pH system
either as an enlarged dynamical system with the Hamiltonian as additional
output or as two dynamical systems with the input-output and the Hamiltonian
dynamic. Our first main result is a structure-preserving Kalman-like
decomposition of the enlarged pH system that separates the controllable and
zero-state observable parts. Moreover, for further approximations in the
context of structure-preserving model-order reduction (MOR), we propose to
search for a Hamiltonian in the reduced pH system that minimizes the
$\mathcal{H}_2$-distance to the full-order Hamiltonian without altering the
input-output dynamic, thus discussing a particular aspect of the corresponding
multi-objective minimization problem corresponding to $\mathcal{H}_2$-optimal
MOR for pH systems. We show that this optimization problem is uniquely
solvable, can be recast as a standard semidefinite program, and present two
numerical approaches for solving it. The results are illustrated with three
academic examples.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Exponential Convergence of Augmented Primal-dual Gradient Algorithms for
  Partially Strongly Convex Functions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02192v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02192v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mengmou Li, Masaaki Nagahara
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We show that the augmented primal-dual gradient algorithms can achieve global
exponential convergence with partially strongly convex functions. In
particular, the objective function only needs to be strongly convex in the
subspace satisfying the equality constraint and can be generally convex
elsewhere, provided the global Lipschitz condition for the gradient is
satisfied. This condition implies that states outside the equality subspace
will converge towards it exponentially fast. The analysis is then applied to
distributed optimization, where the partially strong convexity can be relaxed
to the restricted secant inequality condition, which is not necessarily convex.
This work unifies global exponential convergence results for some existing
centralized and distributed algorithms.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ACC2025. We have revised the proof of the main theorem</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Efficient Ptychography Reconstruction using the Hessian operator 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.10755v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.10755v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Marcus Carlsson, Herwig Wendt, Peter Cloetens, Viktor Nikitin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  X-ray ptychography is a powerful and robust coherent imaging method providing
access to the complex object and probe (illumination). Ptychography
reconstruction is typically performed using first-order methods due to their
computational efficiency. Higher-order methods, while potentially more
accurate, are often prohibitively expensive in terms of computation. In this
study, we present a mathematical framework for reconstruction using
second-order information, derived from an efficient computation of the bilinear
Hessian and Hessian operator. The formulation is provided for Gaussian based
models, enabling the simultaneous reconstruction of the object, probe, and
object positions. Synthetic data tests, along with experimental near-field
ptychography data processing, demonstrate a ten-fold reduction in computation
time compared to first-order methods. The derived formulas for computing the
Hessians, along with the strategies for incorporating them into optimization
schemes, are well-structured and easily adaptable to various ptychography
problem formulations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Parallel-in-Time Newton's Method for Nonlinear <span class="highlight-title">Model Predictive</span>
  Control 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.20027v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.20027v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Casian Iacob, Hany Abdulsamad, Simo Särkkä
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Model predictive control (MPC) is a powerful framework for optimal control of
dynamical systems. However, MPC solvers suffer from a high computational burden
that restricts their application to systems with low sampling frequency. This
issue is further amplified in nonlinear and constrained systems that require
nesting MPC solvers within iterative procedures. In this paper, we address
these issues by developing parallel-in-time algorithms for constrained
nonlinear optimization problems that take advantage of massively parallel
hardware to achieve logarithmic computational time scaling over the planning
horizon. We develop time-parallel second-order solvers based on interior point
methods and the alternating direction method of multipliers, leveraging fast
convergence and lower computational cost per iteration. The parallelization is
based on a reformulation of the subproblems in terms of associative operations
that can be parallelized using the associative scan algorithm. We validate our
approach on numerical examples of nonlinear and constrained dynamical systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ItsOPT: An inexact two-level smoothing framework for nonconvex
  <span class="highlight-title">optimization</span> via high-order Moreau envelope 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.19928v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.19928v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alireza Kabgani, Masoud Ahookhosh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces ItsOPT, an inexact two-level smoothing optimization
framework designed to find first-order critical points of nonsmooth and
nonconvex functions. The framework involves two levels of methodologies: at the
upper level, a zero-, first-, or second-order method will be tailored to
minimize a smooth approximation; at the lower level, the high-order proximal
auxiliary problems will be solved inexactly, generating an inexact oracle for
the smooth function. As a smoothing technique, we here introduce the high-order
Moreau envelope (HOME) and study its fundamental features under standard
assumptions. Next, introducing a boosted high-order proximal-point algorithm
(Boosted HiPPA) at the upper level using the inexact oracle from the lower
level leads to an instance of ItsOPT. Global convergence rates are established
under the Kurdyka-{\L}ojasiewicz (KL) property of the cost and envelope
functions, along with some reasonable conditions for the accuracy of the
proximal terms. surprisingly, for any KL exponent $\theta\in (0,1)$ of the
original cost, setting the regularization order $p=\frac{1}{1-\theta}$ ensures
that Boosted HiPPA converges linearly to a proximal fixed point, which is the
first algorithm with this property for KL functions. Preliminary numerical
experiments on a robust low-rank matrix recovery problem indicate a promising
performance of the proposed algorithm, validating our theoretical foundations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>24 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Multilinear Extensions in Submodular <span class="highlight-title">Optimization</span> for Optimal Sensor
  Scheduling in Nonlinear Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.03833v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.03833v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohamad H. Kazma, Ahmad F. Taha
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Optimal sensing nodes selection (SNS) in dynamic systems is a combinatorial
optimization problem that has been thoroughly studied in the recent literature.
This problem can be formulated within the context of set optimization. For
high-dimensional nonlinear systems, the problem is extremely difficult to
solve. It scales poorly too. Current literature poses combinatorial submodular
set optimization problems via maximizing observability performance metrics
subject to matroid constraints. Such an approach is typically solved using
greedy algorithms that require lower computational effort yet often yield
sub-optimal solutions. In this paper, we address the SNS problem for nonlinear
dynamical networks using a variational form of the system dynamics, that
basically perturb the system physics. As a result, we show that the
observability performance metrics under such system representation are indeed
submodular. The optimal problem is then solved using the multilinear continuous
extension. This extension offers a computationally scalable and approximate
continuous relaxation with a performance guarantee. The effectiveness of the
extended submodular program is studied and compared to greedy algorithms. We
demonstrate the proposed set optimization formulation for SNS on nonlinear
natural gas combustion networks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To Appear in the 2025 American Control Conference (ACC'2025), Denver,
  Colorado, July 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ INVALS: A Forward Looking Inventory Allocation System 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.04305v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.04305v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shiv Krishna Jaiswal, Karthik S. Gurumoorthy, Etika Agarwal, Shantala Manchenahally
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We design an Inventory Allocation System (INVALS) that, for each item-store
combination, plans the quantity to be allocated from a warehouse that
replenishes multiple stores using trailers, while respecting typical
operational constraints. We formulate a linear objective function which, when
maximized, determines the allocation plan by considering not only the immediate
store needs, but also its future (forward) expected demand. This
forward-looking allocation significantly improves the utilization of labor and
trailers in the warehouse. To reduce overstocking, we adapt from our objective
to prioritize allocating those items in excess which are sold faster at the
stores, keeping the days of supply (DOS) to a minimum. For the proposed
formulation, which is an instance of Mixed Integer Linear Programming (MILP),
we present a scalable algorithm using the concepts of submodularity and optimal
transport theory by: (i) sequentially adding trailers to stores based on
maximum incremental gain, (ii) transforming the resultant linear program (LP)
instance to an instance of capacity constrained optimal transport (COT),
solvable using double entropic regularization and incurring the same
computational complexity as the Sinkhorn algorithm. Compared against the
planning engine that only allocates for immediate store needs, INVALS increases
labor utilization by 34.70% and item occupancy in trailers by 37.08% on
average. The DOS distribution is also skewed to the left, indicating that
higher-demand items are allocated in excess, reducing the days they are
stocked. We empirically observed that for ~90% of the replenishment cycles, the
allocation results of INVALS are identical to the globally optimal MILP
solution.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Efficient Trajectory Inference in Wasserstein Space Using Consecutive
  Averaging 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.19679v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.19679v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Amartya Banerjee, Harlin Lee, Nir Sharon, Caroline Moosmüller
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Capturing data from dynamic processes through cross-sectional measurements is
seen in many fields, such as computational biology. Trajectory inference deals
with the challenge of reconstructing continuous processes from such
observations. In this work, we propose methods for B-spline approximation and
interpolation of point clouds through consecutive averaging that is intrinsic
to the Wasserstein space. Combining subdivision schemes with optimal
transport-based geodesic, our methods carry out trajectory inference at a
chosen level of precision and smoothness, and can automatically handle
scenarios where particles undergo division over time. We prove linear
convergence rates and rigorously evaluate our method on cell data characterized
by bifurcations, merges, and trajectory splitting scenarios like $supercells$,
comparing its performance against state-of-the-art trajectory inference and
interpolation methods. The results not only underscore the effectiveness of our
method in inferring trajectories but also highlight the benefit of performing
interpolation and approximation that respect the inherent geometric properties
of the data.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>International Conference on Artificial Intelligence and Statistics
  (AISTATS 2025)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Does SGD really happen in tiny subspaces? <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.16002v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.16002v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Minhak Song, Kwangjun Ahn, Chulhee Yun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Understanding the training dynamics of deep neural networks is challenging
due to their high-dimensional nature and intricate loss landscapes. Recent
studies have revealed that, along the training trajectory, the gradient
approximately aligns with a low-rank top eigenspace of the training loss
Hessian, referred to as the dominant subspace. Given this alignment, this paper
explores whether neural networks can be trained within the dominant subspace,
which, if feasible, could lead to more efficient training methods. Our primary
observation is that when the SGD update is projected onto the dominant
subspace, the training loss does not decrease further. This suggests that the
observed alignment between the gradient and the dominant subspace is spurious.
Surprisingly, projecting out the dominant subspace proves to be just as
effective as the original update, despite removing the majority of the original
update component. We observe similar behavior across practical setups,
including the large learning rate regime (also known as Edge of Stability),
Sharpness-Aware Minimization, momentum, and adaptive optimizers. We discuss the
main causes and implications of this spurious alignment, shedding light on the
dynamics of neural network training.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published at ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Time-reversal solution of BSDEs in stochastic optimal control: a linear
  quadratic study 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04615v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04615v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuhang Mei, Amirhossein Taghvaei
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper addresses the numerical solution of backward stochastic
differential equations (BSDEs) arising in stochastic optimal control.
Specifically, we investigate two BSDEs: one derived from the
Hamilton-Jacobi-Bellman equation and the other from the stochastic maximum
principle. For both formulations, we analyze and compare two numerical methods.
The first utilizes the least-squares Monte-Carlo (LSMC) approach for
approximating conditional expectations, while the second leverages a
time-reversal (TR) of diffusion processes. Although both methods extend to
nonlinear settings, our focus is on the linear-quadratic case, where analytical
solutions provide a benchmark. Numerical results demonstrate the superior
accuracy and efficiency of the TR approach across both BSDE representations,
highlighting its potential for broader applications in stochastic control.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>7 pages, 4 figures, 1 table</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2025-03-10T00:00:00Z">2025-03-10</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Systems and Control <span class="chip" style="font-size: 60%">37</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Co-Optimizing Distributed Energy Resources under Demand Charges and
  Bi-Directional Power Flow 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07907v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07907v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ruixiao Yang, Gulai Shen, Ahmed S. Alahmed, Chuchu Fan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We address the co-optimization of behind-the-meter (BTM) distributed energy
resources (DER), including flexible demands, renewable distributed generation
(DG), and battery energy storage systems (BESS) under net energy metering (NEM)
frameworks with demand charges. We formulate the problem as a stochastic
dynamic program that accounts for renewable generation uncertainty and
operational surplus maximization. Our theoretical analysis reveals that the
optimal policy follows a threshold structure. Finally, we show that even a
simple algorithm leveraging this threshold structure performs well in
simulation, emphasizing its importance in developing near-optimal algorithms.
These findings provide crucial insights for implementing prosumer energy
management systems under complex tariff structures.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages, 3 figures, 2 tables. Accepted at the 2025 IEEE PES General
  Meeting, Austin, TX</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Landmark-Aided <span class="highlight-title">Navigation</span> Approach Using Side-Scan Sonar 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07900v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07900v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ellen Davenport, Khoa Nguyen, Junsu Jang, Clair Ma, Sean Fish, Luc Lenain, Florian Meyer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Cost-effective localization methods for Autonomous Underwater Vehicle (AUV)
navigation are key for ocean monitoring and data collection at high resolution
in time and space. Algorithmic solutions suitable for real-time processing that
handle nonlinear measurement models and different forms of measurement
uncertainty will accelerate the development of field-ready technology. This
paper details a Bayesian estimation method for landmark-aided navigation using
a Side-scan Sonar (SSS) sensor. The method bounds navigation filter error in
the GPS-denied undersea environment and captures the highly nonlinear nature of
slant range measurements while remaining computationally tractable. Combining a
novel measurement model with the chosen statistical framework facilitates the
efficient use of SSS data and, in the future, could be used in real time. The
proposed filter has two primary steps: a prediction step using an unscented
transform and an update step utilizing particles. The update step performs
probabilistic association of sonar detections with known landmarks. We evaluate
algorithm performance and tractability using synthetic data and real data
collected field experiments. Field experiments were performed using two
different marine robotic platforms with two different SSS and at two different
sites. Finally, we discuss the computational requirements of the proposed
method and how it extends to real-time applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>23 pages, 10 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Real-Time Line Parameter Estimation Method for Multi-Phase Unbalanced
  Distribution Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07858v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07858v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sakirat Wolly, Xiaozhe Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  An accurate distribution network model is crucial for monitoring, state
estimation and energy management. However, existing data-driven methods often
struggle with scalability or impose a heavy computational burden on large
distribution networks. In this paper, leveraging natural load dynamics, we
propose a two-stage line estimation method for multiphase unbalanced
distribution networks. Simulation results using real-life load and PV data show
that the proposed method reduces computational time by one to two orders of
magnitude compared to existing methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ APECS: Adaptive Personalized Control System Architecture 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09624v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09624v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Marius F. R. Juston, Alex Gisi, William R. Norris, Dustin Nottage, Ahmet Soylemezoglu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents the Adaptive Personalized Control System (APECS)
architecture, a novel framework for human-in-the-loop control. An architecture
is developed which defines appropriate constraints for the system objectives. A
method for enacting Lipschitz and sector bounds on the resulting controller is
derived to ensure desirable control properties. An analysis of worst-case loss
functions and the optimal loss function weighting is made to implement an
effective training scheme. Finally, simulations are carried out to demonstrate
the effectiveness of the proposed architecture. This architecture resulted in a
4.5% performance increase compared to the human operator and 9% to an
unconstrained feedforward neural network trained in the same way.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 11 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Real-Time Structural Deflection Estimation in Hydraulically Actuated
  Systems Using 3D Flexible Multibody Simulation and DNNs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07528v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07528v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qasim Khadim, Peter Manzl, Emil Kurvinen, Aki Mikkola, Grzegorz Orzechowski, Johannes Gerstmayr
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The precision, stability, and performance of lightweight high-strength steel
structures in heavy machinery is affected by their highly nonlinear dynamics.
This, in turn, makes control more difficult, simulation more computationally
intensive, and achieving real-time autonomy, using standard approaches,
impossible. Machine learning through data-driven, physics-informed and
physics-inspired networks, however, promises more computationally efficient and
accurate solutions to nonlinear dynamic problems. This study proposes a novel
framework that has been developed to estimate real-time structural deflection
in hydraulically actuated three-dimensional systems. It is based on SLIDE, a
machine-learning-based method to estimate dynamic responses of mechanical
systems subjected to forced excitations.~Further, an algorithm is introduced
for the data acquisition from a hydraulically actuated system using randomized
initial configurations and hydraulic pressures.~The new framework was tested on
a hydraulically actuated flexible boom with various sensor combinations and
lifting various payloads. The neural network was successfully trained in less
time using standard parameters from PyTorch, ADAM optimizer, the various sensor
inputs, and minimal output data. The SLIDE-trained neural network accelerated
deflection estimation solutions by a factor of $10^7$ in reference to flexible
multibody simulation batches and provided reasonable accuracy. These results
support the studies goal of providing robust, real-time solutions for control,
robotic manipulators, structural health monitoring, and automation problems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages and 30 figures, Preprint version of the article submitted to
  MSSP (Mechanical Systems and Signal Processing)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Real-Time Load Estimation for Load-lifting Exoskeletons Using Insole
  Pressure Sensors and Machine Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07527v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07527v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kaida Wu, Peihao Xiang, Chaohao Lin, Lixuan Chen, Ou Bai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents a novel method for real-time lifting-load estimation to
enhance the control strategies of upper-limb assistive exoskeletons. By
leveraging cost-effective insole pressure sensors, the proposed system extracts
differential pressure data that minimizes disturbances from variations in body
weight and sensor placement. Two modeling approaches are explored: a
channel-based method that employs traditional regression techniques-Elastic
Net, Support Vector Regression (SVR), and Multi-Layer Perceptron (MLP)-and a
map-based method that utilizes transfer learning with a pre-trained MobileNetV2
model. The experiment is in the preliminary test stage, covering load ranges
from 2 kg to 10 kg in increments of 0.5 kg, and collecting data from three
subjects to test the approach. In the Channel-based method, the average
Weighted Mean Absolute Percentage Error(WMAPE) for three subjects showed that
the SVR achieved 13.46%, with the MLP performing similarly. In the Map-based
method, using data from one subject, the Fully Fine-Tuned MobileNetV2 model
reached a WMAPE of 9.74%. The results indicate that the integration of insole
sensor technology with advanced machine learning models provides an effective
solution for dynamic load estimation, potentially reducing the risks of over-
and under-compensation in exoskeleton control.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Sum-of-Squares Data-driven Robustly Stabilizing and Contracting
  Controller Synthesis for Polynomial Nonlinear Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07438v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07438v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hamza El-Kebir, Melkior Ornik
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This work presents a computationally efficient approach to data-driven robust
contracting controller synthesis for polynomial control-affine systems based on
a sum-of-squares program. In particular, we consider the case in which a system
alternates between periods of high-quality sensor data and low-quality sensor
data. In the high-quality sensor data regime, we focus on robust system
identification based on the data informativity framework. In low-quality sensor
data regimes we employ a robustly contracting controller that is synthesized
online by solving a sum-of-squares program based on data acquired in the
high-quality regime, so as to limit state deviation until high-quality data is
available. This approach is motivated by real-life control applications in
which systems experience periodic data blackouts or occlusion, such as
autonomous vehicles undergoing loss of GPS signal or solar glare in machine
vision systems. We apply our approach to a planar unmanned aerial vehicle model
subject to an unknown wind field, demonstrating its uses for verifiably tight
control on trajectory deviation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for presentation at the 2025 American Control Conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Advances in Hybrid Modular Climbing Robots: Design Principles and
  Refinement Strategies 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07423v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07423v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ryan Poon, Ian Hunter
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper explores the design strategies for hybrid pole- or trunk-climbing
robots, focusing on methods to inform design decisions and assess metrics such
as adaptability and performance. A wheeled-grasping hybrid robot with modular,
tendon-driven grasping arms and a wheeled drive system mounted on a turret was
developed to climb columns of varying diameters. Here, the key innovation is
the underactuated arms that can be adjusted to different column sizes by adding
or removing modular linkages, though the robot also features capabilities like
self-locking (the ability of the robot to stay on the column by friction
without power), autonomous grasping, and rotation around the column axis.
Mathematical models describe conditions for self-locking and vertical climbing.
Experimental results demonstrate the robot's efficacy in climbing and
self-locking, validating the proposed models and highlighting the potential for
fully automated solutions in industrial applications. This work provides a
comprehensive framework for evaluating and designing hybrid climbing robots,
contributing to advancements in autonomous robotics for environments where
climbing tall structures is critical.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 9 figures; This work has been submitted to the IEEE for
  possible publication</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Cost-Effective Design of Grid-tied Community Microgrid 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07414v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07414v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Moslem Uddin, Huadong Mo, Daoyi Dong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study aims to develop a cost-effective microgrid design that optimally
balances the economic feasibility, reliability, efficiency, and environmental
impact in a grid-tied community microgrid. A multi-objective optimization
framework is employed, integrating HOMER Pro for system sizing with deep
reinforcement learning (DRL). Sensitivity analyses are conducted to evaluate
the system performance under varying load demand and renewable energy
fluctuations, while an economic sensitivity assessment examines the impact of
electricity prices and capital costs on the Levelized Cost of Energy (LCOE).
The proposed microgrid configuration achieves high reliability, satisfying 100%
of the load, even under adverse weather conditions. The proposed framework
attains an efficiency of 91.99% while maintaining a carbon footprint of 302,747
kg/year, which is approximately 95% lower than that of the grid system. The
economic analysis indicates a net present cost (NPC) of $4.83M with a
competitive LCOE of $0.208/kWh. In addition, the operation cost is $201,473 per
year with a capital investment of $1.42M, rendering it a financially viable
alternative to conventional grid-dependent systems.This work can be valuable in
identifying effective solutions for supplying reliable and cost-effective power
to regional and remote areas.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Diagnostic-free onboard battery health assessment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07383v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07383v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yunhong Che, Vivek N. Lam, Jinwook Rhyu, Joachim Schaeffer, Minsu Kim, Martin Z. Bazant, William C. Chueh, Richard D. Braatz
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diverse usage patterns induce complex and variable aging behaviors in
lithium-ion batteries, complicating accurate health diagnosis and prognosis.
Separate diagnostic cycles are often used to untangle the battery's current
state of health from prior complex aging patterns. However, these same
diagnostic cycles alter the battery's degradation trajectory, are
time-intensive, and cannot be practically performed in onboard applications. In
this work, we leverage portions of operational measurements in combination with
an interpretable machine learning model to enable rapid, onboard battery health
diagnostics and prognostics without offline diagnostic testing and the
requirement of historical data. We integrate mechanistic constraints within an
encoder-decoder architecture to extract electrode states in a physically
interpretable latent space and enable improved reconstruction of the
degradation path. The health diagnosis model framework can be flexibly applied
across diverse application interests with slight fine-tuning. We demonstrate
the versatility of this model framework by applying it to three battery-cycling
datasets consisting of 422 cells under different operating conditions,
highlighting the utility of an interpretable diagnostic-free, onboard battery
diagnosis and prognosis model.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>25 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ AttentionSwarm: Reinforcement Learning with Attention Control Barier
  Function for Crazyflie Drones in Dynamic Environments 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07376v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07376v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Grik Tadevosyan, Valerii Serpiva, Aleksey Fedoseev, Roohan Ahmed Khan, Demetros Aschu, Faryal Batool, Nickolay Efanov, Artem Mikhaylov, Dzmitry Tsetserukou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce AttentionSwarm, a novel benchmark designed to evaluate safe and
efficient swarm control across three challenging environments: a landing
environment with obstacles, a competitive drone game setting, and a dynamic
drone racing scenario. Central to our approach is the Attention Model Based
Control Barrier Function (CBF) framework, which integrates attention mechanisms
with safety-critical control theory to enable real-time collision avoidance and
trajectory optimization. This framework dynamically prioritizes critical
obstacles and agents in the swarms vicinity using attention weights, while CBFs
formally guarantee safety by enforcing collision-free constraints. The safe
attention net algorithm was developed and evaluated using a swarm of Crazyflie
2.1 micro quadrotors, which were tested indoors with the Vicon motion capture
system to ensure precise localization and control. Experimental results show
that our system achieves landing accuracy of 3.02 cm with a mean time of 23 s
and collision-free landings in a dynamic landing environment, 100% and
collision-free navigation in a drone game environment, and 95% and
collision-free navigation for a dynamic multiagent drone racing environment,
underscoring its effectiveness and robustness in real-world scenarios. This
work offers a promising foundation for applications in dynamic environments
where safety and fastness are paramount.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ $\mathcal{H}_\infty$ Loop-shaping for Power Tracking Control of Wind
  Turbines 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07359v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07359v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aaron Grapentin, Christian A. Hans, Jörg Raisch
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we present an advanced wind turbine control scheme for power
maximization as well as for active power control, which is designed using
$\mathcal{H}_\infty$ loop-shaping. Our approach involves the synthesis of two
separate controllers for two different operating modes. To ensure smooth
transitions between these modes, we implement a bumpless transfer strategy that
reduces transient effects. A comprehensive case study demonstrates the efficacy
of our control scheme, showing significant improvements in power tracking
accuracy and a reduction in mechanical wear. Moreover, our control strategy
comes with robust stability guarantees.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 8 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Optimal Control Selection over the Edge-Cloud Continuum 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07349v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07349v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiyu Gu, Matthias Pezzutto, Luca Schenato, Subhrakanti Dey
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The emerging computing continuum paves the way for exploiting multiple
computing devices, ranging from the edge to the cloud, to implement the control
algorithm. Different computing units over the continuum are characterized by
different computational capabilities and communication latencies, thus
resulting in different control performances and advocating for an effective
trade-off. To this end, in this work, we first introduce a multi-tiered
controller and we propose a simple network delay compensator. Then we propose a
control selection policy to optimize the control cost taking into account the
delay and the disturbances. We theoretically investigate the stability of the
switching system resulting from the proposed control selection policy. Accurate
simulations show the improvements of the considered setup.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Decision-Dependent Stochastic <span class="highlight-title">Optimization</span>: The Role of Distribution
  Dynamics 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07324v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07324v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhiyu He, Saverio Bolognani, Florian Dörfler, Michael Muehlebach
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Distribution shifts have long been regarded as troublesome external forces
that a decision-maker should either counteract or conform to. An intriguing
feedback phenomenon termed decision dependence arises when the deployed
decision affects the environment and alters the data-generating distribution.
In the realm of performative prediction, this is encoded by distribution maps
parameterized by decisions due to strategic behaviors. In contrast, we
formalize an endogenous distribution shift as a feedback process featuring
nonlinear dynamics that couple the evolving distribution with the decision.
Stochastic optimization in this dynamic regime provides a fertile ground to
examine the various roles played by dynamics in the composite problem
structure. To this end, we develop an online algorithm that achieves optimal
decision-making by both adapting to and shaping the dynamic distribution.
Throughout the paper, we adopt a distributional perspective and demonstrate how
this view facilitates characterizations of distribution dynamics and the
optimality and generalization performance of the proposed algorithm. We
showcase the theoretical results in an opinion dynamics context, where an
opportunistic party maximizes the affinity of a dynamic polarized population,
and in a recommender system scenario, featuring performance optimization with
discrete distributions in the probability simplex.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Communication-aware Multi-agent Systems Control Based on $k$-hop
  Distributed Observers 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07246v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07246v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tommaso Zaccherini, Siyuan Liu, Dimos V. Dimarogonas
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose a distributed control strategy to allow the control of a
multi-agent system requiring k-hop interactions based on the design of
distributed state and input observers. In particular, we design for each agent
a finite time convergent state and input observer that exploits only the
communication with the 1-hop neighbors to reconstruct the information regarding
those agents at a 2-hop distance or more. We then demonstrate that if the k-hop
based control strategy is set-Input to State Stable with respect to the set
describing the goal, then the observer information can be adopted to achieve
the team objective with stability guarantees.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Short version of this paper was accepted for the 23rd European
  Control Conference (ECC)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Optimal Operation of Renewable Energy Communities under Demand Response
  Programs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07149v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07149v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gianni Bianchini, Marco Casini, Milad Gholami
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Within the context of renewable energy communities, this paper focuses on
optimal operation of producers equipped with energy storage systems in the
presence of demand response. A novel strategy for optimal scheduling of the
storage systems of the community members under price-volume demand response
programs, is devised. The underlying optimization problem is designed as a
low-complexity mixed-integer linear program that scales well with the community
size. Once the optimal solution is found, an algorithm for distributing the
demand response rewards is introduced in order to guarantee fairness among
participants. The proposed approach ensures increased benefits for producers
joining a community compared to standalone operation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Efficient Integration of Distributed Learning Services in
  Next-Generation Wireless Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07116v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07116v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Paul Zheng, Navid Keshtiarast, Pradyumna Kumar Bishoyi, Yao Zhu, Yulin Hu, Marina Petrova, Anke Schmeink
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Distributed learning (DL) is considered a cornerstone of intelligence
enabler, since it allows for collaborative training without the necessity for
local clients to share raw data with other parties, thereby preserving privacy
and security. Integrating DL into the 6G networks requires coexistence design
with existing services such as high-bandwidth (HB) traffic like eMBB. Current
designs in the literature mainly focus on communication round (CR)-wise designs
that assume a fixed resource allocation during each CR. However, fixed resource
allocation within a CR is a highly inefficient and inaccurate representation of
the system's realistic behavior. This is due to the heterogeneous nature of the
system, where clients inherently need to access the network at different times.
This work zooms into one arbitrary communication round and demonstrates the
importance of considering a time-dependent resource-sharing design with HB
traffic. We propose a time-dependent optimization problem for minimizing the
consumed time and energy by DL within the CR. Due to its intractability, a
session-based optimization problem has been proposed assuming a large-scale
coherence time. An iterative algorithm has been designed to solve such problems
and simulation results confirm the importance of such efficient and accurate
integration design.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Coordinated Energy-Trajectory Economic <span class="highlight-title">Model Predictive</span> Control for
  Autonomous Surface Vehicles under Disturbances 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07102v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07102v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhongqi Deng, Yuan Wang, Jian Huang, Hui Zhang, Yaonan Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The paper proposes a novel Economic Model Predictive Control (EMPC) scheme
for Autonomous Surface Vehicles (ASVs) to simultaneously address path following
accuracy and energy constraints under environmental disturbances. By
formulating lateral deviations as energy-equivalent penalties in the cost
function, our method enables explicit trade-offs between tracking precision and
energy consumption. Furthermore, a motion-dependent decomposition technique is
proposed to estimate terminal energy costs based on vehicle dynamics. Compared
with the existing EMPC method, simulations with real-world ocean disturbance
data demonstrate the controller's energy consumption with a 0.06 energy
increase while reducing cross-track errors by up to 18.61. Field experiments
conducted on an ASV equipped with an Intel N100 CPU in natural lake
environments validate practical feasibility, achieving 0.22 m average
cross-track error at nearly 1 m/s and 10 Hz control frequency. The proposed
scheme provides a computationally tractable solution for ASVs operating under
resource constraints.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Sensitivity of Online Feedback <span class="highlight-title">Optimization</span> to time-varying parameters 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07030v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07030v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Marta Zagorowska, Lars Imsland
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Online Feedback Optimization uses optimization algorithms as dynamic systems
to design optimal control inputs. The results obtained from Online Feedback
Optimization depend on the setup of the chosen optimization algorithm. In this
work we analyse the sensitivity of Online Feedback Optimization to the
parameters of projected gradient descent as the algorithm of choice. We derive
closed-form expressions for sensitivities of the objective function with
respect to the parameters of the projected gradient and to time-varying model
mismatch. The formulas are then used for analysis of model mismatch in a gas
lift optimization problem. The results of the case study indicate that the
sensitivity of Online Feedback Optimization to the model mismatch depends on
how long the controller has been running, with decreasing sensitivity to
mismatch in individual timesteps for long operation times.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to European Control Conference (ECC) 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Explicit Solution of Tunable Input-to-State Safe-Based Controller Under
  High-Relative-Degree Constraints 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07007v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07007v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yan Wei, Yu Feng, Linlin Ou, Yueying Wang, Xinyi Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper investigates the safety analysis and verification of nonlinear
systems subject to high-relative-degree constraints and unknown disturbance.
The closed-form solution of the high-order control barrier functions (HOCBF)
optimization problem with and without a nominal controller is first provided,
making it unnecessary to solve the quadratic program problem online and
facilitating the analysis. Further, we introduce the concept of tunable
input-to-state safety(ISSf), and a new tunable function in conjunction with
HOCBF is provided. When combined with the existing ISSf theorem, produces
controllers for constrained nonlinear systems with external disturbances. The
theoretical results are proven and supported by numerical simulations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to IEEE Transactions on Automatic Control. Under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ EnCortex: A General, Extensible and Scalable Framework for Decision
  Management in New-age Energy Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06959v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06959v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Millend Roy, Vaibhav Balloli, Anupam Sobti, Srinivasan Iyengar, Shivkumar Kalyanaraman, Tanuja Ganu, Akshay Nambi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With increased global warming, there has been a significant emphasis to
replace fossil fuel-dependent energy sources with clean, renewable sources.
These new-age energy systems are becoming more complex with an increasing
proportion of renewable energy sources (like solar and wind), energy storage
systems (like batteries), and demand side control in the mix. Most new-age
sources being highly dependent on weather and climate conditions bring about
high variability and uncertainty. Energy operators rely on such uncertain data
to make different planning and operations decisions periodically, and sometimes
in real-time, to maintain the grid stability and optimize their objectives
(cost savings, carbon footprint, etc.). Hitherto, operators mostly rely on
domain knowledge, heuristics, or solve point problems to take decisions. These
approaches fall short because of their specific assumptions and limitations.
Further, there is a lack of a unified framework for both research and
production environments at scale. In this paper, we propose EnCortex to address
these challenges. EnCortex provides a general, easy-to-use, extensible, and
scalable energy decision framework that enables operators to plan, build and
execute their real-world scenarios efficiently. We show that using EnCortex, we
can define and compose complex new-age scenarios, owing to industry-standard
abstractions of energy entities and the modularity of the framework. EnCortex
provides a foundational structure to support several state-of-the-art
optimizers with minimal effort. EnCortex supports both quick developments for
research prototypes and scaling the solutions to production environments. We
demonstrate the utility of EnCortex with three complex new-age real-world
scenarios and show that significant cost and carbon footprint savings can be
achieved.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Existence and Design of Target Output Controllers 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06927v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06927v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tyrone Fernando, Mohamed Darouach
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces new conditions for target output controllability and
provides existence conditions for placing a specific number of poles with a
target output controller. Additionally, an algorithm is presented for the
design of a target output controller. Controllability of the system under
consideration is not required for designing target output controllers in this
context. The findings in this paper extend the principles of full state
feedback control. Moreover, we present conditions for static output feedback
control under specific constraints. Several numerical examples are provided to
illustrate the results.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To appear in IEEE Transactions on Automatic Control. The first
  version of the paper was submitted to IEEE TAC for peer review on 29-02-2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Distributed Pose Graph <span class="highlight-title">Optimization</span> using the Splitting Method based on
  the Alternating Direction Method of Multipliers 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06912v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06912v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zeinab Ebrahimi, Mohammad Deghat
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Distributed optimization aims to leverage the local computation and
communication capabilities of each agent to achieve a desired global objective.
This paper addresses the distributed pose graph optimization (PGO) problem
under non-convex constraints, with the goal of approximating the rotation and
translation of each pose given relevant noisy measurements. To achieve this
goal, the splitting method based on the concepts of the alternating direction
method of multipliers (ADMM) and Bregman iteration are applied to solve the
rotation subproblems. The proposed approach enables the iterative resolution of
constrained problems, achieved through solving unconstrained problems and
orthogonality-constrained quadratic problems that have analytical solutions.
The performance of the proposed algorithm is compared against two practical
methods in pose graph optimization: the Distributed Gauss-Seidel (DGS)
algorithm and the centralized pose graph optimizer with an optimality
certificate (SE-Sync). The efficiency of the proposed method is verified
through its application to several simulated and real-world pose graph
datasets. Unlike the DGS method, our approach attempts to solve distributed PGO
problems without relaxing the non-convex constraints.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Reinforcement Learning Based Symbolic Regression for Load Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06879v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06879v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ding Lin, Han Guo, Jianhui Wang, Meng Yue, Tianqiao Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the increasing penetration of renewable energy sources, growing demand
variability, and evolving grid control strategies, accurate and efficient load
modeling has become a critical yet challenging task. Traditional methods, such
as fixed-form parametric models and data-driven approaches, often struggle to
balance accuracy, computational efficiency, and interpretability. This paper
introduces a novel symbolic regression algorithm based on the Actor-Critic
reinforcement learning framework, specifically tailored for dynamic load
modeling. The algorithm employs a trainable expression tree with controlled
depth and a predefined set of operators to generate compact and interpretable
mathematical expressions. The Actor network probabilistically selects operators
for the symbolic expression, while the Critic evaluates the resulting
expression tree through a loss function. To further enhance performance, a
candidate pool mechanism is implemented to store high-performing expressions,
which are subsequently fine-tuned using gradient descent. By focusing on
simplicity and precision, the proposed method significantly reduces
computational complexity while preserving interpretability. Experimental
results validate its superior performance compared to existing benchmarks,
which offers a robust and scalable solution for dynamic load modeling and
system analysis in modern power systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Recursive Estimation for Dynamical Systems with Measurement Bias,
  Outliers and Constraints 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06825v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06825v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Krishan Mohan Nagpal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper describes recursive algorithms for state estimation of linear
dynamical systems when measurements are noisy with unknown bias and/or
outliers. For situations with noisy and biased measurements, algorithms are
proposed that minimize $\epsilon$ insensitive loss function. In this approach
which is often used in Support Vector Machines, small errors are ignored making
the algorithm less sensitive to measurement bias. Apart from $\epsilon$
insensitive quadratic loss function, estimation algorithms are also presented
for $\epsilon$ insensitive Huber M loss function which provides good
performance in presence of both small noises as well as outliers. The advantage
of Huber cost function based estimator in presence of outliers is due to the
fact the error penalty function switches from quadratic to linear for errors
beyond a certain threshold. For both objective functions, estimation algorithms
are extended to cases when there are additional constraints on states and
exogenous signals such as known range of some states or exogenous signals or
measurement noises. Interestingly, the filtering algorithms are recursive and
structurally similar to Kalman filter with the main difference being that the
updates based on the new measurement ("innovation term") are based on solution
of a quadratic optimization problem with linear constraints.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Design Optimal Backstepping Controller for Quadrotor Based on Lyapunov
  Theory for Disturbances Environments 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06824v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06824v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dong LT Tran, Thanh C Vo, Hoang T Tran, Minh T Nguyen, Hai T. Do
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Various control methods have been studied to control the position and
attitude of quadrotors. There are some differences in the mathematical
equations between the two types of quadrotor configurations that lead to
different control efficiency in disturbance environments. This paper described
the nonlinear back stepping approach based on the Lyapunov function theory and
LaSalle Principle for the quadrotor control system, which can provide the
stability of all system states during the tracking of the desired trajectory.
Accordingly, a mathematical model of the cross quadrotor configuration together
with the controller has been built to stabilize the altitude and position of
the quadrotor. To clarify the effectiveness of this method with the selected
quadrotor configuration, we compare it with a traditional PID controller in an
environment affected by disturbances. The simulation results in MATLAB show
satisfactory stability of the quadrotor flight and following certain
trajectories, confirming the accuracy and validity of the control method.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Intra-day Solar and Power Forecast for <span class="highlight-title">Optimization</span> of Intraday Market
  Participation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.09551v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.09551v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nelson Salazar-Pena, Adolfo Palma-Vergara, Mateo Montes-Vera, Maria Alejandra Vargas-Torres, Rodrigo Hernandez-Vanegas, Maria Amador, Boris Rojas, Adriana Salinas, Andres Velasco, Alejandra Tabares, Andres Gonzalez-Mancera
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The prediction of solar irradiance enhances reliability in photovoltaic (PV)
solar plant generation and grid integration. In Colombia, PV plants face
penalties if energy production deviates beyond governmental thresholds from
intraday market offers. This research employs Long Short-Term Memory (LSTM) and
Bidirectional-LSTM (Bi-LSTM) models, utilizing meteorological data from a PV
plant in El Paso, Cesar, Colombia, to predict solar irradiance with a 6-hour
horizon and 10-minute resolution. While Bi-LSTM showed superior performance,
the LSTM model achieved comparable results with significantly reduced training
time (6 hours versus 18 hours), making it computationally advantageous. The
LSTM predictions were averaged to create an hourly resolution model, evaluated
using Mean Absolute Error, Root-Mean-Square Error, Normalized Root-Mean-Square
Error, and Mean Absolute Percentage Error metrics. Comparison with the Global
Forecast System (GFS) revealed similar performance, with both models
effectively capturing daily solar irradiance patterns. The forecast model
integrates with an Object-Oriented power production model, enabling accurate
energy offers in the intraday market while minimizing penalty costs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages, 37 figures, 9 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ASMA: An Adaptive Safety Margin Algorithm for Vision-Language Drone
  <span class="highlight-title">Navigation</span> via Scene-Aware Control Barrier Functions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.10283v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.10283v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sourav Sanyal, Kaushik Roy
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the rapidly evolving field of vision-language navigation (VLN), ensuring
safety for physical agents remains an open challenge. For a human-in-the-loop
language-operated drone to navigate safely, it must understand natural language
commands, perceive the environment, and simultaneously avoid hazards in real
time. Control Barrier Functions (CBFs) are formal methods that enforce safe
operating conditions. Model Predictive Control (MPC) is an optimization
framework that plans a sequence of future actions over a prediction horizon,
ensuring smooth trajectory tracking while obeying constraints. In this work, we
consider a VLN-operated drone platform and enhance its safety by formulating a
novel scene-aware CBF that leverages ego-centric observations from a camera
which has both Red-Green-Blue as well as Depth (RGB-D) channels. A CBF-less
baseline system uses a Vision-Language Encoder with cross-modal attention to
convert commands into an ordered sequence of landmarks. An object detection
model identifies and verifies these landmarks in the captured images to
generate a planned path. To further enhance safety, an Adaptive Safety Margin
Algorithm (ASMA) is proposed. ASMA tracks moving objects and performs
scene-aware CBF evaluation on-the-fly, which serves as an additional constraint
within the MPC framework. By continuously identifying potentially risky
observations, the system performs prediction in real time about unsafe
conditions and proactively adjusts its control actions to maintain safe
navigation throughout the trajectory. Deployed on a Parrot Bebop2 quadrotor in
the Gazebo environment using the Robot Operating System (ROS), ASMA achieves
64%-67% increase in success rates with only a slight increase (1.4%-5.8%) in
trajectory lengths compared to the baseline CBF-less VLN.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Sensor-fusion based Prognostics Framework for Complex Engineering
  Systems Exhibiting Multiple Failure Modes 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.12159v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.12159v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Benjamin Peters, Ayush Mohanty, Xiaolei Fang, Stephen K. Robinson, Nagi Gebraeel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Complex engineering systems are often subject to multiple failure modes.
Developing a remaining useful life (RUL) prediction model that does not
consider the failure mode causing degradation is likely to result in inaccurate
predictions. However, distinguishing between causes of failure without manually
inspecting the system is nontrivial. This challenge is increased when the
causes of historically observed failures are unknown. Sensors, which are useful
for monitoring the state-of-health of systems, can also be used for
distinguishing between multiple failure modes as the presence of multiple
failure modes results in discriminatory behavior of the sensor signals. When
systems are equipped with multiple sensors, some sensors may exhibit behavior
correlated with degradation, while other sensors do not. Furthermore, which
sensors exhibit this behavior may differ for each failure mode. In this paper,
we present a simultaneous clustering and sensor selection approach for
unlabeled training datasets of systems exhibiting multiple failure modes. The
cluster assignments and the selected sensors are then utilized in real-time to
first diagnose the active failure mode and then to predict the system RUL. We
validate the methodology using a simulated dataset of systems exhibiting two
failure modes and on NASA turbofan degradation dataset.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MPPI-Generic: A CUDA Library for Stochastic Trajectory <span class="highlight-title">Optimization</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.07563v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.07563v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bogdan Vlahov, Jason Gibson, Manan Gandhi, Evangelos A. Theodorou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces a new C++/CUDA library for GPU-accelerated stochastic
optimization called MPPI-Generic. It provides implementations of Model
Predictive Path Integral control, Tube-Model Predictive Path Integral Control,
and Robust Model Predictive Path Integral Control, and allows for these
algorithms to be used across many pre-existing dynamics models and cost
functions. Furthermore, researchers can create their own dynamics models or
cost functions following our API definitions without needing to change the
actual Model Predictive Path Integral Control code. Finally, we compare
computational performance to other popular implementations of Model Predictive
Path Integral Control over a variety of GPUs to show the real-time capabilities
our library can allow for. Library code can be found at:
https://acdslab.github.io/mppi-generic-website/ .
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Experiences with Sub-Arctic Sensor Network Deployment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.02986v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.02986v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Priyesh Pappinisseri Puluckul, Maarten Weyn
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper discusses the experiences gained from designing, deploying, and
maintaining low-power Wireless Sensor Networks (WSN) in three geothermally
active remote locations in Iceland. The network was deployed for environmental
monitoring and real-time data collection to assist in investigating the impact
of global warming on the (sub)Arctic climate and the resulting carbon release
from the region. Functional networks with more than 50 sensor nodes from three
sites with extreme weather conditions and hard-to-access terrain have been
collecting data since 2021. The networks employ primary cell-powered wireless
sensor nodes equipped with DASH7 Alliance Protocol (D7A) for low-power data
transmission and solar-powered D7A-cellular gateways for the backend
connection. The WSNs have so far achieved over three years of uptime with
minimal maintenance required throughout this period. We present a detailed
discussion of different network components, their architecture, and the
networks' overall performance and reliability.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to IEEE WCNC</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Lessons learned from field demonstrations of <span class="highlight-title">model predictive</span> control
  and reinforcement learning for residential and commercial HVAC: A <span class="highlight-title">review</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.05022v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.05022v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Arash J. Khabbazi, Elias N. Pergantis, Levi D. Reyes Premer, Panagiotis Papageorgiou, Alex H. Lee, James E. Braun, Gregor P. Henze, Kevin J. Kircher
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A large body of simulation research suggests that model predictive control
(MPC) and reinforcement learning (RL) for heating, ventilation, and
air-conditioning (HVAC) in residential and commercial buildings could reduce
energy costs, pollutant emissions, and strain on power grids. Despite this
potential, neither MPC nor RL has seen widespread industry adoption. Field
demonstrations could accelerate MPC and RL adoption by providing real-world
data that support the business case for deployment. This paper reviews 24 field
demonstrations of MPC and RL in residential buildings and 80 in commercial
buildings. After presenting demographic information -- such as experiment
scopes, locations, and durations -- this paper analyzes experiment protocols
and their influence on performance estimates. We find that 71% of the reviewed
field demonstrations use experiment protocols that may lead to unreliable
performance estimates. Over the remaining 29% that we view as reliable, the
weighted-average cost savings, weighted by experiment duration, are 16% in
residential buildings and 13% in commercial buildings. While these savings are
potentially attractive, making the business case for MPC and RL also requires
characterizing the costs of deployment, operation, and maintenance. Only 13 of
the 104 reviewed papers report these costs or discuss related challenges. Based
on these observations, we recommend directions for future field research,
including: Improving experiment protocols; reporting deployment, operation, and
maintenance costs; designing algorithms and instrumentation to reduce these
costs; controlling HVAC equipment alongside other distributed energy resources;
and pursuing emerging objectives such as peak shaving, arbitraging wholesale
energy prices, and providing power grid reliability services.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Digital Twin-Enabled Blockage-Aware Dynamic mmWave Multi-Hop V2X
  Communication 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03590v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03590v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Supat Roongpraiwan, Zongdian Li, Tao Yu, Kei Sakaguchi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Millimeter wave (mmWave) technology in vehicle-to-everything (V2X)
communication offers unprecedented data rates and low latency, but faces
significant reliability challenges due to signal blockages and limited range.
This paper introduces a novel system for managing dynamic multi-hop mmWave V2X
communications in complex blocking environments. We present a system
architecture that integrates a mobility digital twin (DT) with the multi-hop
routing control plane, providing a comprehensive, real-time view of the network
and its surrounding traffic environment. This integration enables the control
plane to make informed routing decisions based on rich contextual data about
vehicles, infrastructure, and potential signal blockages. Leveraging this
DT-enhanced architecture, we propose an advanced routing algorithm that
combines high-precision environmental data with trajectory prediction to
achieve blockage-aware mmWave multi-hop V2X routing. Our algorithm anticipates
network topology changes and adapts topology dynamically to maintain reliable
connections. We evaluate our approach through proof-of-concept simulations
using a mobility DT of the Nishishinjuku area. Results demonstrate that our
DT-enabled routing strategy significantly outperforms conventional methods in
maintaining reliable mmWave V2X connections across various traffic scenarios,
including fully connected and mixed traffic environments.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Koopman-based control using sum-of-squares <span class="highlight-title">optimization</span>: Improved
  stability guarantees and data efficiency 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.03875v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.03875v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Robin Strässer, Julian Berberich, Frank Allgöwer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we propose a novel controller design approach for unknown
nonlinear systems using the Koopman operator. In particular, we use the
recently proposed stability- and certificate-oriented extended dynamic mode
decomposition (SafEDMD) architecture to generate a data-driven bilinear
surrogate model with certified error bounds. Then, by accounting for the
obtained error bounds in a controller design based on the bilinear system, one
can guarantee closed-loop stability for the true nonlinear system. While
existing approaches over-approximate the bilinearity of the surrogate model,
thus introducing conservatism and providing only local guarantees, we
explicitly account for the bilinearity by using sum-of-squares (SOS)
optimization in the controller design. More precisely, we parametrize a
rational controller stabilizing the error-affected bilinear surrogate model
and, consequently, the underlying nonlinear system. The resulting SOS
optimization problem provides explicit data-driven controller design conditions
for unknown nonlinear systems based on semidefinite programming. Our approach
significantly reduces conservatism by establishing a larger region of
attraction and improved data efficiency. The proposed method is evaluated using
numerical examples, demonstrating its advantages over existing approaches.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Final version, accepted for publication in Proc. European Control
  Conference (ECC), 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Non-Parametric Learning of Stochastic Differential Equations with
  Non-asymptotic Fast Rates of Convergence 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2305.15557v6">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2305.15557v6.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Riccardo Bonalli, Alessandro Rudi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose a novel non-parametric learning paradigm for the identification of
drift and diffusion coefficients of multi-dimensional non-linear stochastic
differential equations, which relies upon discrete-time observations of the
state. The key idea essentially consists of fitting a RKHS-based approximation
of the corresponding Fokker-Planck equation to such observations, yielding
theoretical estimates of non-asymptotic learning rates which, unlike previous
works, become increasingly tighter when the regularity of the unknown drift and
diffusion coefficients becomes higher. Our method being kernel-based, offline
pre-processing may be profitably leveraged to enable efficient numerical
implementation, offering excellent balance between precision and computational
complexity.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ <span class="highlight-title">★</span> Decentralized Online Learning for Random Inverse Problems Over Graphs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2303.11789v9">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2303.11789v9.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tao Li, Xi<span class="highlight-author">wei Zhang</span>, Yan Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose a decentralized online learning algorithm for distributed random
inverse problems over network graphs with online measurements, and unifies the
distributed parameter estimation in Hilbert spaces and the least mean square
problem in reproducing kernel Hilbert spaces (RKHS-LMS). We transform the
convergence of the algorithm into the asymptotic stability of a class of
inhomogeneous random difference equations in Hilbert spaces with
$L_{2}$-bounded martingale difference terms and develop the $L_2$-asymptotic
stability theory in Hilbert spaces. We show that if the network graph is
connected and the sequence of forward operators satisfies the
infinite-dimensional spatio-temporal persistence of excitation condition, then
the estimates of all nodes are mean square and almost surely strongly
consistent. Moreover, we propose a decentralized online learning algorithm in
RKHS based on non-stationary online data streams, and prove that the algorithm
is mean square and almost surely strongly consistent if the operators induced
by the random input data satisfy the infinite-dimensional spatio-temporal
persistence of excitation condition.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ On w-<span class="highlight-title">Optimization</span> of the Split Covariance Intersection Filter 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2101.10159v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2101.10159v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hao Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The split covariance intersection filter (split CIF) is a useful tool for
general data fusion and has the potential to be applied in a variety of
engineering tasks. An indispensable optimization step (referred to as
w-optimization) involved in the split CIF concerns the performance and
implementation efficiency of the Split CIF, but explanation on w-optimization
is neglected in the paper [1] that provides a theoretical foundation for the
Split CIF. This note complements [1] by providing a theoretical proof for the
convexity of the w-optimization problem involved in the split CIF (convexity is
always a desired property for optimization problems as it facilitates
optimization considerably).
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Optimization and Control <span class="chip" style="font-size: 60%">45</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Whiteness-based bilevel estimation of weighted TV parameter maps for
  image denoising 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07814v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07814v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Monica Pragliola, Luca Calatroni, Alessandro Lanza
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We consider a bilevel optimisation strategy based on normalised residual
whiteness loss for estimating the weighted total variation parameter maps for
denoising images corrupted by additive white Gaussian noise. Compared to
supervised and semi-supervised approaches relying on prior knowledge of
(approximate) reference data and/or information on the noise magnitude, the
proposal is fully unsupervised. To avoid noise overfitting an early stopping
strategy is used, relying on simple statistics of optimal performances on a set
of natural images. Numerical results comparing the supervised/unsupervised
procedures for scalar/pixel-dependent \mbox{parameter maps are shown.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Operational route <span class="highlight-title">plan</span>ning under uncertainty for Demand Adaptive Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07812v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07812v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Benedikt Lienkamp, Mike Hewitt, Axel Parmentier, Maximilian Schiffer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With an increasing need for more flexible mobility services, we consider an
operational problem arising in the planning of Demand Adaptive Systems (DAS).
Motivated by the decision of whether to accept or reject passenger requests in
real time in a DAS, we introduce the operational route planning problem of
DASs. To this end, we propose an algorithmic framework that allows an operator
to plan which passengers to serve in a DAS in real-time. To do so, we model the
operational route planning problem as a Markov decision process (MDP) and
utilize a rolling horizon approach to approximate the MDP via a two-stage
stochastic program in each timestep to decide on the next action. Furthermore,
we determine the deterministic equivalent of our approximation through
sample-based approximation. This allows us to decompose the deterministic
equivalent of our two-stage stochastic program into several full information
planning problems, which can be solved in parallel efficiently. Additionally,
we propose a consensus-based heuristic and a myopic approach. We perform
extensive numerical studies based on real-world data provided to us by the
public transportation provider of Munich, Germany. We show that our exact
decomposition yields the best results in under five seconds, and our heuristic
approach reduces the serial computation time by 17 - 57% compared to our exact
decomposition, with a solution quality decline of less than one percent. From a
managerial perspective, we show that by switching a fixed-line bus route to a
DAS, an operator can increase profit by up to 49% and the number of served
passengers by up to 35% while only increasing the travel distance of the bus by
14%. Furthermore, we show that an operator can reduce their cost per passenger
by 43 - 51% by increasing route flexibility and that incentivizing passengers
to walk slightly longer distances reduces the cost per passenger by 83-85%.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Scaffold with Stochastic Gradients: New Analysis with Linear Speed-Up 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07594v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07594v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Paul Mangold, Alain Durmus, Aymeric Dieuleveut, Eric Moulines
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper proposes a novel analysis for the Scaffold algorithm, a popular
method for dealing with data heterogeneity in federated learning. While its
convergence in deterministic settings--where local control variates mitigate
client drift--is well established, the impact of stochastic gradient updates on
its performance is less understood. To address this problem, we first show that
its global parameters and control variates define a Markov chain that converges
to a stationary distribution in the Wasserstein distance. Leveraging this
result, we prove that Scaffold achieves linear speed-up in the number of
clients up to higher-order terms in the step size. Nevertheless, our analysis
reveals that Scaffold retains a higher-order bias, similar to FedAvg, that does
not decrease as the number of clients increases. This highlights opportunities
for developing improved stochastic federated learning algorithms
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Universally Optimal Primal-Dual Method for Minimizing Heterogeneous
  Compositions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07566v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07566v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aaron Zoll, Benjamin Grimmer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper proposes a universal, optimal algorithm for convex minimization
problems of the composite form $g_0(x)+h(g_1(x),\dots, g_m(x)) + u(x)$. We
allow each $g_j$ to independently range from being nonsmooth Lipschitz to
smooth, from convex to strongly convex, described by notions of H\"older
continuous gradients and uniform convexity. Note that, although the objective
is built from a heterogeneous combination of such structured components, it
does not necessarily possess smoothness, Lipschitzness, or any favorable
structure overall other than convexity. Regardless, we provide a universal
optimal method in terms of oracle access to (sub)gradients of each $g_j$. The
key insight enabling our optimal universal analysis is the construction of two
new constants, the Approximate Dualized Aggregate smoothness and strong
convexity, which combine the benefits of each heterogeneous structure into
single quantities amenable to analysis. As a key application, fixing $h$ as the
nonpositive indicator function, this model readily captures functionally
constrained minimization $g_0(x)+u(x)$ subject to $g_j(x)\leq 0$. In
particular, our algorithm and analysis are directly inspired by the smooth
constrained minimization method of Zhang and Lan and consequently recover and
generalize their accelerated guarantees.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Global maximum principle for optimal control of stochastic Volterra
  equations with singular kernels: An infinite dimensional approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07514v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07514v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yushi Hamaguchi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we consider optimal control problems of stochastic Volterra
equations (SVEs) with singular kernels, where the control domain is not
necessarily convex. We establish a global maximum principle by means of the
spike variation technique. To do so, we first show a Taylor type expansion of
the controlled SVE with respect to the spike variation, where the convergence
rates of the remainder terms are characterized by the singularity of the
kernels. Next, assuming additional structure conditions for the kernels, we
convert the variational SVEs appearing in the expansion to their infinite
dimensional lifts. Then, we derive first and second order adjoint equations in
form of infinite dimensional backward stochastic evolution equations (BSEEs) on
weighted $L^2$ spaces. Moreover, we show the well-posedness of the new class of
BSEEs on weighted $L^2$ spaces in a general setting.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>58 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Efficient data-driven flow modeling for accurate passive scalar
  advection in submesoscale domains 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07452v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07452v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Karlo Jakac, Luka Lanča, Ante Sikirica, Stefan Ivić
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Knowing the sea surface velocity field is essential for various applications,
such as search and rescue operations and oil spill monitoring, where
understanding the movement of objects or substances is critical. However,
obtaining an accurate approximation of these advection processes is
challenging, even with modern measuring equipment, such as high-frequency radar
or advanced simulations based on oceanic flow models. Therefore this paper
presents a data-driven framework to approximate sea surface velocity from
spatially distributed observations, thus enabling efficient probability
advection modeling across submesoscale domains. The system approximates
transient flows by leveraging quasi-steady flow assumptions. To overcome the
limitations of point measurements in capturing domain-wide circulation, the
method employs a fusion of two simplified 2D flow models to approximate
submesoscale dynamics, enabling complete velocity field reconstruction from
scattered data. To ensure reliable flow dynamics, the approach iteratively
adjusts boundary conditions in numerical simulations to align the simulated
flow with observations. Experimental validation in Kvarner Bay using
GPS-tracked drifters confirmed the system's ability to replace computationally
intensive transient simulations by approximating flow fields based on model
simplifications. The results demonstrate its efficiency across domains, making
it a practical tool for real-world submesoscale applications requiring swift
passive scalar advection.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Initial version of the manuscript</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PER-DPP Sampling Framework and Its Application in Path <span class="highlight-title">Plan</span>ning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07411v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07411v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junzhe Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Autonomous navigation in intelligent mobile systems represents a core
research focus within artificial intelligence-driven robotics. Contemporary
path planning approaches face constraints in dynamic environmental
responsiveness and multi-objective task scalability, limiting their capacity to
address growing intelligent operation requirements. Decision-centric
reinforcement learning frameworks, capitalizing on their unique strengths in
adaptive environmental interaction and self-optimization, have gained
prominence in advanced control system research. This investigation introduces
methodological improvements to address sample homogeneity challenges in
reinforcement learning experience replay mechanisms. By incorporating
determinant point processes (DPP) for diversity assessment, we develop a
dual-criteria sampling framework with adaptive selection protocols. This
approach resolves representation bias in conventional prioritized experience
replay (PER) systems while preserving algorithmic interoperability, offering
improved decision optimization for dynamic operational scenarios. Key
contributions comprise: Develop a hybrid sampling paradigm (PER-DPP) combining
priority sequencing with diversity maximization.Based on this,create an
integrated optimization scheme (PER-DPP-Elastic DQN) merging diversity-aware
sampling with adaptive step-size regulation. Comparative simulations in 2D
navigation scenarios demonstrate that the elastic step-size component
temporarily delays initial convergence speed but synergistically enhances
final-stage optimization with PER-DPP integration. The synthesized method
generates navigation paths with optimized length efficiency and directional
stability.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Are System Optimal Dynamic Flows Implementable by Tolls? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07387v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07387v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lukas Graf, Tobias Harks, Julian Schwarz
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A seminal result of [Fleischer et al. and Karakostas and Kolliopulos, both
FOCS 2004] states that system optimal multi-commodity static network flows are
always implementable as tolled Wardrop equilibrium flows even if users have
heterogeneous value-of-time sensitivities. Their proof uses LP-duality to
characterize the general implementability of network flows by tolls. For the
much more complex setting of $\textit{dynamic flows}$, [Graf et al., SODA 2025]
identified necessary and sufficient conditions for a dynamic $s$-$d$ flow to be
implementable as a tolled dynamic equilibrium. They used the machinery of
(infinite-dimensional) strong duality to obtain their characterizations. Their
work, however, does not answer the question of whether system optimal dynamic
network flows are implementable by tolls.
  We consider this question for a general dynamic flow model involving multiple
commodities with individual source-destination pairs, fixed inflow rates and
heterogeneous valuations of travel time and money spent. We present both a
positive and a, perhaps surprising, negative result: For the negative result,
we provide a network with multiple source and destination pairs in which under
the Vickrey queuing model no system optimal flow is implementable -- even if
all users value travel times and spent money the same. Our counter-example even
shows that the ratio of the achievable equilibrium travel times by using tolls
and of the system optimal travel times can be unbounded. For the single-source,
single-destination case, we show that if the traversal time functions are
suitably well-behaved (as is the case, for example, in the Vickrey queuing
model), any system optimal flow is implementable.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Decision-Dependent Stochastic <span class="highlight-title">Optimization</span>: The Role of Distribution
  Dynamics 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07324v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07324v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhiyu He, Saverio Bolognani, Florian Dörfler, Michael Muehlebach
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Distribution shifts have long been regarded as troublesome external forces
that a decision-maker should either counteract or conform to. An intriguing
feedback phenomenon termed decision dependence arises when the deployed
decision affects the environment and alters the data-generating distribution.
In the realm of performative prediction, this is encoded by distribution maps
parameterized by decisions due to strategic behaviors. In contrast, we
formalize an endogenous distribution shift as a feedback process featuring
nonlinear dynamics that couple the evolving distribution with the decision.
Stochastic optimization in this dynamic regime provides a fertile ground to
examine the various roles played by dynamics in the composite problem
structure. To this end, we develop an online algorithm that achieves optimal
decision-making by both adapting to and shaping the dynamic distribution.
Throughout the paper, we adopt a distributional perspective and demonstrate how
this view facilitates characterizations of distribution dynamics and the
optimality and generalization performance of the proposed algorithm. We
showcase the theoretical results in an opinion dynamics context, where an
opportunistic party maximizes the affinity of a dynamic polarized population,
and in a recommender system scenario, featuring performance optimization with
discrete distributions in the probability simplex.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Global and Robust Optimisation for Non-Convex Quadratic Programs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07310v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07310v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Asimina Marousi, Vassilis M. Charitopoulos
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents a novel algorithm integrating global and robust
optimisation methods to solve continuous non-convex quadratic problems under
convex uncertainty sets. The proposed Robust spatial branch-and-bound (RsBB)
algorithm combines the principles of spatial branch-and-bound (sBB) with robust
cutting planes. We apply the RsBB algorithm to quadratically constrained
quadratic programming (QCQP) pooling problems, utilising McCormick envelopes to
obtain convex lower bounds. The performance of the RsBB algorithm is compared
with state-of-the-art methods that rely on global solvers. As computational
test bed for our proposed approach we focus on pooling problems under different
types and sizes of uncertainty sets. The findings of our work highlight the
efficiency of the RsBB algorithm in terms of computational time and optimality
convergence and provide insights to the advantages of combining robustness and
optimality search.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Optimal Operation of Renewable Energy Communities under Demand Response
  Programs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07149v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07149v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gianni Bianchini, Marco Casini, Milad Gholami
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Within the context of renewable energy communities, this paper focuses on
optimal operation of producers equipped with energy storage systems in the
presence of demand response. A novel strategy for optimal scheduling of the
storage systems of the community members under price-volume demand response
programs, is devised. The underlying optimization problem is designed as a
low-complexity mixed-integer linear program that scales well with the community
size. Once the optimal solution is found, an algorithm for distributing the
demand response rewards is introduced in order to guarantee fairness among
participants. The proposed approach ensures increased benefits for producers
joining a community compared to standalone operation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Strat{é}gies de contr{ô}le pour les {é}oliennes flottantes :
  {é}tat de l'art et perspectives 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07138v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07138v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Flavie Didier, Salah Laghrouche, Daniel Depernet
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The floating wind turbines sector has great energy potential. However,
minimizing the movement of the structure under the combined effect of wind and
waves while ensuring maximum power extraction over a wide operating range is
one of the main challenges for the control of these turbines. This paper
presents a review of control methods for floating wind turbines from the recent
literature. The limitations of these controllers are discussed, before
introducing a presentation of several promising data-based methods. In
particular, this paper focuses on artificial intelligence techniques associated
with data-based control methods. Finally, the CREATIF project dealing with
real-time simulation of floating wind turbines and their intelligent controls
is presented.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>in French language. Conf{\'e}rence des Jeunes Chercheurs en G{\'e}nie
  {\'E}lectrique, Jun 2022, Le Croisic, France</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Optimal control problems with free right end point 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07134v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07134v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nico Tauchnitz
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper is dedicated to the elementary proof of Pontryagin's maximum
principle for problems with free right end point. The proof for the standard
problem is taken from the monography of Ioffe and Tichomirov. We assume
piecewise continuous controls and the proof turns out to be very simple. We
generalize the concept to the problem of optimal multiprocesses, to control
problems with delays and to the control of Volterra integral equations.
Furthermore, we discuss the problem on infinite horizon. Moreover, we state
Arrow type sufficiency conditions. The optimality conditions are demonstrated
on illustrative examples.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>in german. arXiv admin note: substantial text overlap with
  arXiv:1610.02829</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Numerical solution of optimal control problems using quadratic transport
  regularization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07105v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07105v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nicolas Borchard, Gerd Wachsmuth
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We address optimal control problems on the space of measures for an objective
containing a smooth functional and an optimal transport regularization. That
is, the quadratic Monge-Kantorovich distance between a given prior measure and
the control is penalized in the objective. We consider optimality conditions
and reparametrize the problem using the celebrated structure theorem by
Brenier. The optimality conditions can be formulated as a piecewise
differentiable equation. This is utilized to formulate solution algorithms and
to analyze their local convergence properties. We present a numerical example
to illustrate the theoretical findings.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Data-driven stabilization of polynomial systems using density functions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07092v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07092v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Huayuan Huang, M. Kanat Camlibel, Raffaella Carloni, Henk J. van Waarde
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper studies data-driven stabilization of a class of unknown polynomial
systems using data corrupted by bounded noise. Existing work addressing this
problem has focused on designing a controller and a Lyapunov function so that a
certain state-dependent matrix is negative definite, which ensures asymptotic
stability of all closed-loop systems compatible with the data. However, as we
demonstrate in this paper, considering the negative definiteness of this matrix
introduces conservatism, which limits the applicability of current approaches.
To tackle this issue, we develop a new method for the data-driven stabilization
of polynomial systems using the concept of density functions. The control
design consists of two steps. Firstly, a dual Lyapunov theorem is used to
formulate a sum of squares program that allows us to compute a rational state
feedback controller for all systems compatible with the data. By the dual
Lyapunov theorem, this controller ensures that the trajectories of the
closed-loop system converge to zero for almost all initial states. Secondly, we
propose a method to verify whether the designed controller achieves asymptotic
stability of all closed-loop systems compatible with the data. Apart from
reducing conservatism of existing methods, the proposed approach can also
readily take into account prior knowledge on the system parameters. A key
technical result developed in this paper is a new type of S-lemma for a
specific class of matrices that, in contrast to the classical S-lemma, avoids
the use of multipliers.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The Optimal Control Problem of Fully Coupled FBSDEs Driven by
  Sub-diffusion with Applications 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07034v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07034v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chenhui Hao, Jingtao Shi, Shuaiqi Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper is devoted to an optimal control problem of fully coupled
forward-backward stochastic differential equations driven by sub-diffusion,
whose solutions are not Markov processes. The stochastic maximum principle is
obtained, where the control domain may not be convex and the diffusion term is
independent of the control variable. Additionally, problem with state
constraint is researched by using Ekeland's variational principle. The
theoretical results obtained are applied to a cash management optimization
problem in bear market, and the optimal strategy is derived.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>27 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Sensitivity of Online Feedback <span class="highlight-title">Optimization</span> to time-varying parameters 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07030v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07030v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Marta Zagorowska, Lars Imsland
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Online Feedback Optimization uses optimization algorithms as dynamic systems
to design optimal control inputs. The results obtained from Online Feedback
Optimization depend on the setup of the chosen optimization algorithm. In this
work we analyse the sensitivity of Online Feedback Optimization to the
parameters of projected gradient descent as the algorithm of choice. We derive
closed-form expressions for sensitivities of the objective function with
respect to the parameters of the projected gradient and to time-varying model
mismatch. The formulas are then used for analysis of model mismatch in a gas
lift optimization problem. The results of the case study indicate that the
sensitivity of Online Feedback Optimization to the model mismatch depends on
how long the controller has been running, with decreasing sensitivity to
mismatch in individual timesteps for long operation times.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to European Control Conference (ECC) 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Inverse single facility location problem in the <span class="highlight-title">plan</span>e with variable
  coordinates 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07016v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07016v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nazanin Tour-Savadkoohi, Jafar Fathali
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In traditional facility location problems, a set of points is provided, and
the objective is to determine the best location for a new facility based on
criteria such as minimizing cost, time, and distances between clients and
facilities. Conversely, inverse single facility location problems focus on
adjusting the problem's parameters at minimal cost to make a specific point
optimal. In this paper, we present an algorithm for the general case of the
inverse single facility location problem with variable coordinates in a
two-dimensional space. We outline the optimality conditions of this algorithm.
Additionally, we examine the specific case namely the inverse minisum single
facility location problem and test the algorithm on various instances. The
results demonstrate the algorithm's effectiveness in these scenarios.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>22 page, 3 figure</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Data-Driven Sequential Sampling for Tail Risk Mitigation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06913v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06913v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dohyun Ahn, Taeho Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Given a finite collection of stochastic alternatives, we study the problem of
sequentially allocating a fixed sampling budget to identify the optimal
alternative with a high probability, where the optimal alternative is defined
as the one with the smallest value of extreme tail risk. We particularly
consider a situation where these alternatives generate heavy-tailed losses
whose probability distributions are unknown and may not admit any specific
parametric representation. In this setup, we propose data-driven sequential
sampling policies that maximize the rate at which the likelihood of falsely
selecting suboptimal alternatives decays to zero. We rigorously demonstrate the
superiority of the proposed methods over existing approaches, which is further
validated via numerical studies.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>52 pages, 5 Figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Co-<span class="highlight-title">optimization</span> of Short- and Long-term Decisions for the Transmission
  Grid's Resilience to Flooding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06909v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06909v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ashutosh Shukla, Erhan Kutanoglu, John Hasenbein
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present and analyze a three-stage stochastic optimization model that
integrates output from a geoscience-based flood model with a power flow model
for transmission grid resilience planning against flooding. The proposed model
coordinates the decisions made across multiple stages of resilience planning
and recommends an optimal allocation of the overall resilience investment
budget across short- and long-term measures. While doing so, the model balances
the cost of investment in both short- and long-term measures against the cost
of load shed that results from unmitigated flooding forcing grid components go
out-of-service. We also present a case study for the Texas Gulf Coast region to
demonstrate how the proposed model can provide insights into various grid
resilience questions. Specifically, we demonstrate that for a comprehensive yet
reasonable range of economic values assigned to load loss, we should make
significant investments in the permanent hardening of substations such that we
achieve near-zero load shed. We also show that not accounting for short-term
measures while making decisions about long-term measures can lead to
significant overspending. Furthermore, we demonstrate that a technological
development enabling to protect substations on short notice before imminent
hurricanes could vastly influence and reduce the total investment budget that
would otherwise be allocated for more expensive substation hardening. Lastly,
we also show that for a wide range of values associated with the cost of
mitigative long-term measures, the proportion allocated to such measures
dominates the overall resilience spending.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         <span class="highlight-title">★</span> A Beam Search Based Parallel Algorithm for the Two-Dimensional Strip
  Packing Problem 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08711v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08711v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yajie Wen, De<span class="highlight-author">fu Zhang</span>
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces BSPA, a parallel algorithm that leverages beam search
to address the two-dimensional strip packing problem. The study begins with a
comprehensive review of existing approaches and methodologies, followed by a
detailed presentation of the BSPA algorithm. Experimental results demonstrate
the effectiveness of the proposed method. To facilitate further research, both
the code and datasets are publicly available.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages,4figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Generic linear convergence for algorithms of non-linear least squares
  over smooth varieties 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06877v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06877v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shenglong Hu, Ke Ye
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In applications, a substantial number of problems can be formulated as
non-linear least squares problems over smooth varieties. Unlike the usual least
squares problem over a Euclidean space, the non-linear least squares problem
over a variety can be challenging to solve and analyze, even if the variety
itself is simple. Geometrically, this problem is equivalent to projecting a
point in the ambient Euclidean space onto the image of the given variety under
a non-linear map. It is the singularities of the image that make both the
computation and the analysis difficult. In this paper, we prove that under some
mild assumptions, these troublesome singularities can always be avoided. This
enables us to establish a linear convergence rate for iterative sequences
generated by algorithms satisfying some standard assumptions. We apply our
general results to the low-rank partially orthogonal tensor approximation
problem. As a consequence, we obtain the linear convergence rate for a
classical APD-ALS method applied to a generic tensor, without any further
assumptions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On the Wasserstein alignment problem 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06838v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06838v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Soumik Pal, Bodhisattva Sen, Ting-Kam Leonard Wong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Suppose we are given two metric spaces and a family of continuous
transformations from one to the other. Given a probability distribution on each
of these two spaces - namely the source and the target measures - the
Wasserstein alignment problem seeks the transformation that minimizes the
optimal transport cost between its pushforward of the source distribution and
the target distribution, ensuring the closest possible alignment in a
probabilistic sense. Examples of interest include two distributions on two
Euclidean spaces $\mathbb{R}^n$ and $\mathbb{R}^d$, and we want a spatial
embedding of the $n$-dimensional source measure in $\mathbb{R}^d$ that is
closest in some Wasserstein metric to the target distribution on
$\mathbb{R}^d$. Similar data alignment problems also commonly arise in shape
analysis and computer vision. In this paper we show that this nonconvex optimal
transport projection problem admits a convex Kantorovich-type dual. This allows
us to characterize the set of projections and devise a linear programming
algorithm. For certain special examples, such as orthogonal transformations on
Euclidean spaces of unequal dimensions and the $2$-Wasserstein cost, we
characterize the covariance of the optimal projections. Our results also cover
the generalization when we penalize each transformation by a function. An
example is the inner product Gromov-Wasserstein distance minimization problem
which has recently gained popularity.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>30 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Recursive Estimation for Dynamical Systems with Measurement Bias,
  Outliers and Constraints 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06825v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06825v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Krishan Mohan Nagpal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper describes recursive algorithms for state estimation of linear
dynamical systems when measurements are noisy with unknown bias and/or
outliers. For situations with noisy and biased measurements, algorithms are
proposed that minimize $\epsilon$ insensitive loss function. In this approach
which is often used in Support Vector Machines, small errors are ignored making
the algorithm less sensitive to measurement bias. Apart from $\epsilon$
insensitive quadratic loss function, estimation algorithms are also presented
for $\epsilon$ insensitive Huber M loss function which provides good
performance in presence of both small noises as well as outliers. The advantage
of Huber cost function based estimator in presence of outliers is due to the
fact the error penalty function switches from quadratic to linear for errors
beyond a certain threshold. For both objective functions, estimation algorithms
are extended to cases when there are additional constraints on states and
exogenous signals such as known range of some states or exogenous signals or
measurement noises. Interestingly, the filtering algorithms are recursive and
structurally similar to Kalman filter with the main difference being that the
updates based on the new measurement ("innovation term") are based on solution
of a quadratic optimization problem with linear constraints.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ <span class="highlight-title">★</span> On finding optimal collective variables for complex systems by
  minimizing the deviation between effective and full dynamics 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.02001v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.02001v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        <span class="highlight-author">Wei Zhang</span>, Christof Schütte
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper is concerned with collective variables, or reaction coordinates,
that map a discrete-in-time Markov process $X_n$ in $\mathbb{R}^d$ to a (much)
smaller dimension $k \ll d$. We define the effective dynamics under a given
collective variable map $\xi$ as the best Markovian representation of $X_n$
under $\xi$. The novelty of the paper is that it gives strict criteria for
selecting optimal collective variables via the properties of the effective
dynamics. In particular, we show that the transition density of the effective
dynamics of the optimal collective variable solves a relative entropy
minimization problem from certain family of densities to the transition density
of $X_n$. We also show that many transfer operator-based data-driven numerical
approaches essentially learn quantities of the effective dynamics. Furthermore,
we obtain various error estimates for the effective dynamics in approximating
dominant timescales / eigenvalues and transition rates of the original process
$X_n$ and how optimal collective variables minimize these errors. Our results
contribute to the development of theoretical tools for the understanding of
complex dynamical systems, e.g. molecular kinetics, on large timescales. These
results shed light on the relations among existing data-driven numerical
approaches for identifying good collective variables, and they also motivate
the development of new methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Revised and accepted version</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Beyond Discretization: Learning the Optimal Solution Path 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14885v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14885v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qiran Dong, Paul Grigas, Vishal Gupta
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Many applications require minimizing a family of optimization problems
indexed by some hyperparameter $\lambda \in \Lambda$ to obtain an entire
solution path. Traditional approaches proceed by discretizing $\Lambda$ and
solving a series of optimization problems. We propose an alternative approach
that parameterizes the solution path with a set of basis functions and solves a
\emph{single} stochastic optimization problem to learn the entire solution
path. Our method offers substantial complexity improvements over
discretization. When using constant-step size SGD, the uniform error of our
learned solution path relative to the true path exhibits linear convergence to
a constant related to the expressiveness of the basis. When the true solution
path lies in the span of the basis, this constant is zero. We also prove
stronger results for special cases common in machine learning: When $\lambda
\in [-1, 1]$ and the solution path is $\nu$-times differentiable, constant
step-size SGD learns a path with $\epsilon$ uniform error after at most
$O(\epsilon^{\frac{1}{1-\nu}} \log(1/\epsilon))$ iterations, and when the
solution path is analytic, it only requires
$O\left(\log^2(1/\epsilon)\log\log(1/\epsilon)\right)$. By comparison, the
best-known discretization schemes in these settings require at least
$O(\epsilon^{-1/2})$ discretization points (and even more gradient calls).
Finally, we propose an adaptive variant of our method that sequentially adds
basis functions and demonstrates strong numerical performance through
experiments.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ On real and observable rational realizations of input-output equations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2303.16799v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2303.16799v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sebastian Falkensteiner, Dmitrii Pavlov, Rafael Sendra
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Given a single (differential-algebraic) input-output equation, we present a
method for finding different representations of the associated system in the
form of rational realizations; these are dynamical systems with rational
right-hand sides. It has been shown that in the case where the input-output
equation is of order one, rational realizations can be computed, if they exist.
In this work, we focus first on the existence and actual computation of the
so-called observable rational realizations, and secondly on rational
realizations with real coefficients. The study of observable realizations
allows to find every rational realization of a given first order input-output
equation, and the necessary field extensions in this process. We show that for
first order input-output equations the existence of a rational realization is
equivalent to the existence of an observable rational realization. Moreover, we
give a criterion to decide the existence of real rational realizations. The
computation of observable and real realizations of first order input-output
equations is fully algorithmic. We also present partial results for the case of
higher order input-output equations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A nonlocal approximation of the area in codimension two 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.13696v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.13696v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Michele Caselli, Mattia Freguglia, Nicola Picenni
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  For $s\in (0,1)$ we introduce a notion of fractional $s$-mass on
$(n-2)$-dimensional closed, orientable surfaces in $\R^n$. Moreover, we prove
its $\Gamma$-convergence, with respect to the flat topology, and pointwise
convergence to the $(n-2)$-dimensional area.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>46 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ AdaFisher: Adaptive Second Order <span class="highlight-title">Optimization</span> via Fisher Information <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.16397v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.16397v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Damien Martins Gomes, Yanlei Zhang, Eugene Belilovsky, Guy Wolf, Mahdi S. Hosseini
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  First-order optimization methods are currently the mainstream in training
deep neural networks (DNNs). Optimizers like Adam incorporate limited curvature
information by employing the diagonal matrix preconditioning of the stochastic
gradient during the training. Despite their widespread, second-order
optimization algorithms exhibit superior convergence properties compared to
their first-order counterparts e.g. Adam and SGD. However, their practicality
in training DNNs is still limited due to increased per-iteration computations
compared to the first-order methods. We present \emph{AdaFisher}--an adaptive
second-order optimizer that leverages a \emph{diagonal block-Kronecker}
approximation of the Fisher information matrix for adaptive gradient
preconditioning. AdaFisher aims to bridge the gap between enhanced
\emph{convergence/generalization} capabilities and computational efficiency in
second-order optimization framework for training DNNs. Despite the slow pace of
second-order optimizers, we showcase that AdaFisher can be reliably adopted for
image classification, language modeling and stands out for its stability and
robustness in hyper-parameter tuning. We demonstrate that AdaFisher
\textbf{outperforms the SOTA optimizers} in terms of both accuracy and
convergence speed. Code is available from
https://github.com/AtlasAnalyticsLab/AdaFisher.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted in ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Localized and degenerate controls for the incompressible Navier-Stokes
  system 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2212.01221v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2212.01221v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vahagn Nersesyan, Manuel Rissel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We consider the global approximate controllability of the two-dimensional
incompressible Navier-Stokes system driven by a physically localized and
degenerate force. In other words, the fluid is regulated via four scalar
controls that depend only on time and appear as coefficients in an effectively
constructed driving force supported in a given subdomain. Our idea consists of
squeezing low mode controls into a small region, essentially by tracking their
actions along the characteristic curves of a linearized vorticity equation. In
this way, through explicit constructions and by connecting Coron's return
method with recent concepts from geometric control, the original problem for
the nonlinear Navier-Stokes system is reduced to one for a linear transport
equation steered by a global force. This article can be viewed as an attempt to
tackle a well-known open problem due to Agrachev.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>38 pages, 7 figures, to be published in Communications on Pure and
  Applied Mathematics</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Multi-Iteration Stochastic Optimizers 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2011.01718v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2011.01718v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Andre Carlon, Luis Espath, Rafael Lopez, Raul Tempone
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We here introduce Multi-Iteration Stochastic Optimizers, a novel class of
first-order stochastic optimizers where the relative $L^2$ error is estimated
and controlled using successive control variates along the path of iterations.
By exploiting the correlation between iterates, control variates may reduce the
estimator's variance so that an accurate estimation of the mean gradient
becomes computationally affordable. We name the estimator of the mean gradient
Multi-Iteration stochastiC Estimator (MICE). In principle, MICE can be flexibly
coupled with any first-order stochastic optimizer, given its non-intrusive
nature. Our generic algorithm adaptively decides which iterates to keep in its
index set. We present an error analysis of MICE and a convergence analysis of
Multi-Iteration Stochastic Optimizers for different classes of problems,
including some non-convex cases. Within the smooth, strongly convex setting, we
show that to approximate a minimizer with accuracy $tol$, SGD-MICE requires, on
average, $O(tol^{-1})$ stochastic gradient evaluations, while SGD with adaptive
batch sizes requires $O(tol^{-1} \log(tol^{-1}))$, correspondingly. Moreover,
in a numerical evaluation, SGD-MICE achieved tol with less than 3% the number
of gradient evaluations than adaptive batch SGD. The MICE estimator provides a
straightforward stopping criterion based on the gradient norm that is validated
in consistency tests. To assess the efficiency of MICE, we present several
examples in which we use SGD-MICE and Adam-MICE. We include one example based
on a stochastic adaptation of the Rosenbrock function and logistic regression
training for various datasets. When compared to SGD, SAG, SAGA, SVRG, and
SARAH, the Multi-Iteration Stochastic Optimizers reduced, without the need to
tune parameters for each example, the gradient sampling cost in all cases
tested, also being competitive in runtime in some cases.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Optimal Control of General Nonlocal Epidemic Models with Age and Space
  Structure 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.01466v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.01466v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Behzad Azmi, Nicolas Schlosser
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We analyze a class of general nonlinear epidemic models with age and space
structure, including a nonlocal infection term depending on age and space.
After establishing the well-posedness of the state partial differential
equation, we introduce a control parameter interpreted as a vaccination rate.
Under certain conditions, we show that an optimal control exists and how it can
be characterized by first-order optimality conditions. Finally, we present
numerical examples of the optimal control problems governed by these models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Boundary Effects on the Controllability of Coupled KdV Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2302.13443v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2302.13443v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        F. A. Gallego, A. F. Pazoto, I. Rivas
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study the exact boundary controllability of a nonlinear coupled system of
two Korteweg-de Vries equations on a bounded interval. The model describes the
interactions of two weakly nonlinear gravity waves in a stratified fluid. Due
to the nature of the system, six boundary conditions are required. However, to
study the controllability property, we consider a different combination of the
control inputs, with a maximum of four. Firstly, the results are obtained for
the linearized system through a classical duality approach and some hidden
regularity properties of the boundary terms. This approach reduces the
controllability problem to the study of a spectral problem, which is solved by
using the Paley-Wiener method introduced by Rosier. Then, the issue is to
establish when a certain quotient of entire functions still turns out to be an
entire function. It can be viewed as a problem of factoring an entire function
that, depending on the control configuration, leads to the study of a
transcendental equation. Finally, by using the contraction mapping theorem, we
derive the local controllability for the full system.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Entropic Risk-Averse Generalized Momentum Methods 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2204.11292v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2204.11292v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bugra Can, Mert Gürbüzbalaban
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the context of first-order algorithms subject to random gradient noise, we
study the trade-offs between the convergence rate (which quantifies how fast
the initial conditions are forgotten) and the "risk" of suboptimality, i.e.
deviations from the expected suboptimality. We focus on a general class of
momentum methods (GMM) which recover popular methods such as gradient descent
(GD), accelerated gradient descent (AGD), and heavy-ball (HB) method as special
cases depending on the choice of GMM parameters. We use well-known risk
measures "entropic risk" and "entropic value at risk" to quantify the risk of
suboptimality. For strongly convex smooth minimization, we first obtain new
convergence rate results for GMM with a unified theory that is also applicable
to both AGD and HB, improving some of the existing results for HB. We then
provide explicit bounds on the entropic risk and entropic value at risk of
suboptimality at a given iterate which also provides direct bounds on the
probability that the suboptimality exceeds a given threshold based on
Chernoff's inequality. Our results unveil fundamental trade-offs between the
convergence rate and the risk of suboptimality. We then plug the entropic risk
and convergence rate estimates we obtained in a computationally tractable
optimization framework and propose entropic risk-averse GMM (RA-GMM) and
entropic risk-averse AGD (RA-AGD) methods which can select the GMM parameters
to systematically trade-off the entropic value at risk with the convergence
rate. We show that RA-AGD and RA-GMM lead to improved performance on quadratic
optimization and logistic regression problems compared to the standard choice
of parameters. To our knowledge, our work is the first to resort to coherent
measures to design the parameters of momentum methods in a systematic manner.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Deterministic and Linear Model of Dynamic <span class="highlight-title">Optimization</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.17012v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.17012v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Somdeb Lahiri
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce a model of infinite horizon linear dynamic optimization and
obtain results concerning existence of solution and satisfaction of the Euler
condition and transversality condition being unconditionally sufficient for
optimality of a trajectory. We show that the optimal value function is concave
and continuous and the optimal trajectory satisfies the functional equation of
dynamic programming. Linearity bites when it comes to the definition of optimal
decision rules which can no longer be guaranteed to be single-valued. We show
that the optimal decision rule is an upper semi-continuous correspondence. For
linear cake-eating problems, we obtain monotonicity results for the optimal
value function and a conditional monotonicity result for optimal decision
rules. We also introduce the concept of a two-phase linear cake eating problem
and obtain a necessary condition that must be satisfied by all solutions of
such problems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages; JEL Classification Codes: C44, C61; edited</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Global Independence of Irrelevant Alternatives, State-Salient Decision
  Rules and the Strict Condorcet Choice Function 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.10986v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.10986v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Somdeb Lahiri
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a simple proof of a well-known axiomatic characterization of
state-salient decision rules, using Weak Dominance Criterion and Global
Independence of Irrelevant Alternatives. Subsequently we provide a simple
axiomatic characterization of the Strict-Condorcet choice function on the
domain of all preference profiles that have a strict-Condorcet winner, assuming
that if the first two ranks are occupied by the same two alternatives in all
states of nature, then the chosen alternative will be the one from these two
that is preferred to the other with probability greater than half-provided such
an alternative exists. We also show that this result is not valid if we extend
the domain to the set of all preference profiles that have a unique
weak-Condorcet winner.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages; typos corrected</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Convergence of the Chambolle-Pock Algorithm in the Absence of
  Monotonicity 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.06540v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.06540v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Brecht Evens, Puya Latafat, Panagiotis Patrinos
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The Chambolle-Pock algorithm (CPA), also known as the primal-dual hybrid
gradient method, has gained popularity over the last decade due to its success
in solving large-scale convex structured problems. This work extends its
convergence analysis for problems with varying degrees of (non)monotonicity,
quantified through a so-called oblique weak Minty condition on the associated
primal-dual operator. Our results reveal novel stepsize and relaxation
parameter ranges which do not only depend on the norm of the linear mapping,
but also on its other singular values. In particular, in nonmonotone settings,
in addition to the classical stepsize conditions, extra bounds on the stepsizes
and relaxation parameters are required. On the other hand, in the strongly
monotone setting, the relaxation parameter is allowed to exceed the classical
upper bound of two. Moreover, we build upon the recently introduced class of
semimonotone operators, providing sufficient convergence conditions for CPA
when the individual operators are semimonotone. Since this class of operators
encompasses traditional operator classes including (hypo)- and
co(hypo)-monotone operators, this analysis recovers and extends existing
results for CPA. Tightness of the proposed stepsize ranges is demonstrated
through several examples.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>33 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SGD with memory: fundamental properties and stochastic acceleration <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04228v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04228v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dmitry Yarotsky, Maksim Velikanov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  An important open problem is the theoretically feasible acceleration of
mini-batch SGD-type algorithms on quadratic problems with power-law spectrum.
In the non-stochastic setting, the optimal exponent $\xi$ in the loss
convergence $L_t\sim C_Lt^{-\xi}$ is double that in plain GD and is achievable
using Heavy Ball (HB) with a suitable schedule; this no longer works in the
presence of mini-batch noise. We address this challenge by considering
first-order methods with an arbitrary fixed number $M$ of auxiliary velocity
vectors (*memory-$M$ algorithms*). We first prove an equivalence between two
forms of such algorithms and describe them in terms of suitable characteristic
polynomials. Then we develop a general expansion of the loss in terms of signal
and noise propagators. Using it, we show that losses of stationary stable
memory-$M$ algorithms always retain the exponent $\xi$ of plain GD, but can
have different constants $C_L$ depending on their effective learning rate that
generalizes that of HB. We prove that in memory-1 algorithms we can make $C_L$
arbitrarily small while maintaining stability. As a consequence, we propose a
memory-1 algorithm with a time-dependent schedule that we show heuristically
and experimentally to improve the exponent $\xi$ of plain SGD.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICLR 2025 camera ready</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Optimal strategies for Wolbachia mosquito replacement technique:
  influence of the carrying capacity on spatial releases 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2309.04192v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2309.04192v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Luis Almeida, Jesús Bellver Arnau, Gwenaël Peltier, Nicolas Vauchelet
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This work is devoted to the mathematical study of an optimization problem
regarding control strategies of mosquito population in a heterogeneous
environment. Mosquitoes are well-known vectors of diseases. For some diseases,
such as dengue, it has been found that mosquitoes have a reduced vector
capacity when carrying the endosymbiotic bacterium Wolbachia. We consider a
mathematical model of a replacement technique consisting in rearing and
releasing Wolbachia-infected mosquitoes to replace the wild population. Our
goal is to optimize the release protocol to maximize replacement effectiveness
in a spatially inhomogeneous environment. Using a scalar model with
space-dependent carrying capacity, we explore the existence and properties of
an optimal release profile maximizing the replacement across the domain. In
particular, neglecting mosquito mobility and under some assumptions on the
biological parameters, we characterize the optimal releasing strategy for a
short time horizon, and we reduce the case of a long time horizon to a
one-dimensional optimization problem. Our theoretical results are illustrated
with several numerical simulations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Online estimation of the inverse of the Hessian for stochastic
  <span class="highlight-title">optimization</span> with application to universal stochastic Newton algorithms 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.10923v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.10923v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Antoine Godichon-Baggioni, Wei Lu, Bruno Portier
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper addresses second-order stochastic optimization for estimating the
minimizer of a convex function written as an expectation. A direct recursive
estimation technique for the inverse Hessian matrix using a Robbins-Monro
procedure is introduced. This approach enables to drastically reduces
computational complexity. Above all, it allows to develop universal stochastic
Newton methods and investigate the asymptotic efficiency of the proposed
approach. This work so expands the application scope of secondorder algorithms
in stochastic optimization.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Get rid of your constraints and reparametrize: A study in NNLS and
  implicit bias 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2207.08437v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2207.08437v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hung-Hsu Chou, Johannes Maly, Claudio Mayrink Verdun, Bernardo Freitas Paulo da Costa, Heudson Mirandola
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Over the past years, there has been significant interest in understanding the
implicit bias of gradient descent optimization and its connection to the
generalization properties of overparametrized neural networks. Several works
observed that when training linear diagonal networks on the square loss for
regression tasks (which corresponds to overparametrized linear regression)
gradient descent converges to special solutions, e.g., non-negative ones. We
connect this observation to Riemannian optimization and view overparametrized
GD with identical initialization as a Riemannian GD. We use this fact for
solving non-negative least squares (NNLS), an important problem behind many
techniques, e.g., non-negative matrix factorization. We show that gradient flow
on the reparametrized objective converges globally to NNLS solutions, providing
convergence rates also for its discretized counterpart. Unlike previous
methods, we do not rely on the calculation of exponential maps or geodesics. We
further show accelerated convergence using a second-order ODE, lending itself
to accelerated descent methods. Finally, we establish the stability against
negative perturbations and discuss generalization to other constrained
optimization problems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Koopman-based control using sum-of-squares <span class="highlight-title">optimization</span>: Improved
  stability guarantees and data efficiency 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.03875v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.03875v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Robin Strässer, Julian Berberich, Frank Allgöwer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we propose a novel controller design approach for unknown
nonlinear systems using the Koopman operator. In particular, we use the
recently proposed stability- and certificate-oriented extended dynamic mode
decomposition (SafEDMD) architecture to generate a data-driven bilinear
surrogate model with certified error bounds. Then, by accounting for the
obtained error bounds in a controller design based on the bilinear system, one
can guarantee closed-loop stability for the true nonlinear system. While
existing approaches over-approximate the bilinearity of the surrogate model,
thus introducing conservatism and providing only local guarantees, we
explicitly account for the bilinearity by using sum-of-squares (SOS)
optimization in the controller design. More precisely, we parametrize a
rational controller stabilizing the error-affected bilinear surrogate model
and, consequently, the underlying nonlinear system. The resulting SOS
optimization problem provides explicit data-driven controller design conditions
for unknown nonlinear systems based on semidefinite programming. Our approach
significantly reduces conservatism by establishing a larger region of
attraction and improved data efficiency. The proposed method is evaluated using
numerical examples, demonstrating its advantages over existing approaches.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Final version, accepted for publication in Proc. European Control
  Conference (ECC), 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Fully First-Order Methods for Decentralized Bilevel <span class="highlight-title">Optimization</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.19319v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.19319v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaoyu Wang, Xuxing Chen, Shiqian Ma, Tong Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper focuses on decentralized stochastic bilevel optimization (DSBO)
where agents only communicate with their neighbors. We propose Decentralized
Stochastic Gradient Descent and Ascent with Gradient Tracking (DSGDA-GT), a
novel algorithm that only requires first-order oracles that are much cheaper
than second-order oracles widely adopted in existing works. We further provide
a finite-time convergence analysis showing that for $n$ agents collaboratively
solving the DSBO problem, the sample complexity of finding an
$\epsilon$-stationary point in our algorithm is
$\mathcal{O}(n^{-1}\epsilon^{-7})$, which matches the currently best-known
results of the single-agent counterpart with linear speedup. The numerical
experiments demonstrate both the communication and training efficiency of our
algorithm.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>47 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Identification of Feasible Regions Using R-Functions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.05510v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.05510v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Segei Kucherenko, Nilay Shah, Oleksiy Klymenko
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The primary objective of flexibility analysis is to identify and define the
feasibility region, which represents the range of operational conditions (e.g.,
variations in process parameters) that ensure safe, reliable, and feasible
process performance. This work introduces a novel flexibility analysis method
that requires only that model constraints (e.g., defining product Critical
Quality Attributes or process Key Performance Indicators) be explicitly
provided or approximated by a closed-form function, such as a multivariate
polynomial model. The method is based on V.L. Rvachev's R-functions, enabling
an explicit analytical representation of the feasibility region without relying
on complex optimization-based approaches. R-functions offer a framework for
describing intricate geometric shapes and performing operations on them using
implicit functions and inequality constraints. The theory of R-functions
facilitates the identification of feasibility regions through algebraic
manipulation, making it a more practical alternative to traditional
optimization-based methods. The effectiveness of the proposed approach is
demonstrated using a suite of well-known test cases from the literature.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>31 page, 20 Figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Non-Parametric Learning of Stochastic Differential Equations with
  Non-asymptotic Fast Rates of Convergence 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2305.15557v6">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2305.15557v6.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Riccardo Bonalli, Alessandro Rudi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose a novel non-parametric learning paradigm for the identification of
drift and diffusion coefficients of multi-dimensional non-linear stochastic
differential equations, which relies upon discrete-time observations of the
state. The key idea essentially consists of fitting a RKHS-based approximation
of the corresponding Fokker-Planck equation to such observations, yielding
theoretical estimates of non-asymptotic learning rates which, unlike previous
works, become increasingly tighter when the regularity of the unknown drift and
diffusion coefficients becomes higher. Our method being kernel-based, offline
pre-processing may be profitably leveraged to enable efficient numerical
implementation, offering excellent balance between precision and computational
complexity.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2025-03-09T00:00:00Z">2025-03-09</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Systems and Control <span class="chip" style="font-size: 60%">27</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Chance-Constrained Trajectory <span class="highlight-title">Plan</span>ning with Multimodal Environmental
  Uncertainty 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06779v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06779v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kai Ren, Heejin Ahn, Maryam Kamgarpour
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We tackle safe trajectory planning under Gaussian mixture model (GMM)
uncertainty. Specifically, we use a GMM to model the multimodal behaviors of
obstacles' uncertain states. Then, we develop a mixed-integer conic
approximation to the chance-constrained trajectory planning problem with
deterministic linear systems and polyhedral obstacles. When the GMM moments are
estimated via finite samples, we develop a tight concentration bound to ensure
the chance constraint with a desired confidence. Moreover, to limit the amount
of constraint violation, we develop a Conditional Value-at-Risk (CVaR) approach
corresponding to the chance constraints and derive a tractable approximation
for known and estimated GMM moments. We verify our methods with
state-of-the-art trajectory prediction algorithms and autonomous driving
datasets.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published in IEEE Control Systems Letters</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Agile Climate-Sensor Design and Calibration Algorithms Using Machine
  Learning: Experiments From Cape Point 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06777v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06777v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Travis Barrett, Amit Kumar Mishra
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we describe the design of an inexpensive and agile climate
sensor system which can be repurposed easily to measure various pollutants. We
also propose the use of machine learning regression methods to calibrate CO2
data from this cost-effective sensing platform to a reference sensor at the
South African Weather Service's Cape Point measurement facility. We show the
performance of these methods and found that Random Forest Regression was the
best in this scenario. This shows that these machine learning methods can be
used to improve the performance of cost-effective sensor platforms and possibly
extend the time between manual calibration of sensor networks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Chance-constrained Linear Quadratic Gaussian Games for Multi-robot
  Interaction under Uncertainty 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06776v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06776v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kai Ren, Giulio Salizzoni, Mustafa Emre Gürsoy, Maryam Kamgarpour
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We address safe multi-robot interaction under uncertainty. In particular, we
formulate a chance-constrained linear quadratic Gaussian game with coupling
constraints and system uncertainties. We find a tractable reformulation of the
game and propose a dual ascent algorithm. We prove that the algorithm converges
to a generalized Nash equilibrium of the reformulated game, ensuring the
satisfaction of the chance constraints. We test our method in driving
simulations and real-world robot experiments. Our method ensures safety under
uncertainty and generates less conservative trajectories than single-agent
model predictive control.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to IEEE Robotics and Automation Letters</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Coordinated Ramp Metering Control based on Scalable Nonlinear Traffic
  Dynamics Model Discovery in a Large Network 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06767v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06767v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zihang Wei, Yang Zhou, Yunlong Zhang, Mihir Kulkarni
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study proposes a coordinated ramp metering control framework in large
networks based on scalable nonlinear traffic dynamics model discovery. Existing
coordinated ramp metering control methods often require accurate traffic
dynamics models in real time, however, for large-scale highway networks, since
these models are always nonlinear, they are extremely challenging to obtain. To
overcome this limitation, this study utilizes the Sparse Identification of
Nonlinear Dynamics with Control (SINDYc) to derive the accurate nonlinear
traffic dynamics model from observed data. The discovered dynamics model is
then integrated into a Model Predictive Control (MPC) coordinated ramp metering
controller, enabling optimized control actions that enhance traffic flow and
efficiency. The proposed framework is tested on a large-scale highway network
that includes three intersecting highways and eight on-ramps, which outperforms
the existing approaches, demonstrating its effectiveness and potential for
real-time application. This framework can offer a scalable and robust solution
for improving real-time traffic management in complex urban environments.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Transfer Learning for LQR Control 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06755v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06755v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Taosha Guo, Fabio Pasqualetti
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we study a transfer learning framework for Linear
  Quadratic Regulator (LQR) control, where (i) the dynamics of the
  system of interest (target system) are unknown and only a short
  trajectory of impulse responses from the target system is provided,
  and (ii) impulse responses are available from $N$ source systems
  with different dynamics. We show that the LQR controller can be
  learned from a sufficiently long trajectory of impulse
  responses. Further, a transferable mode set can be identified using
  the available data from source systems and the target system,
  enabling the reconstruction of the target system's impulse responses
  for controller design. By leveraging data from the source systems we
  demonstrate that only n+1 (n being the system dimension) samples
  of data from the target system are needed to learn the LQR
  controller, this yields a significant reduction of the required
  data.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Novel Multi-Objective Reinforcement Learning Algorithm for
  Pursuit-Evasion Game 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06741v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06741v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Penglin Hu, Chunhui Zhao, Quan Pan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In practical application, the pursuit-evasion game (PEG) often involves
multiple complex and conflicting objectives. The single-objective reinforcement
learning (RL) usually focuses on a single optimization objective, and it is
difficult to find the optimal balance among multiple objectives. This paper
proposes a three-objective RL algorithm based on fuzzy Q-learning (FQL) to
solve the PEG with different optimization objectives. First, the
multi-objective FQL algorithm is introduced, which uses the reward function to
represent three optimization objectives: evading pursuit, reaching target, and
avoiding obstacle. Second, a multi-objective evaluation method and action
selection strategy based on three-dimensional hypervolume are designed, which
solved the dilemma of exploration-exploitation. By sampling the Pareto front,
the update rule of the global strategy is obtained. The proposed algorithm
reduces computational load while ensuring exploration ability. Finally, the
performance of the algorithm is verified by simulation results.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>23 pages, 10 figures, 1 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Precise Insulin Delivery for Artificial Pancreas: A Reinforcement
  Learning Optimized Adaptive Fuzzy Control Approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06701v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06701v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Omar Mameche, Abdelhadi Abedou, Taqwa Mezaache, Mohamed Tadjine
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper explores the application of reinforcement learning to optimize the
parameters of a Type-1 Takagi-Sugeno fuzzy controller, designed to operate as
an artificial pancreas for Type 1 diabetes. The primary challenge in diabetes
management is the dynamic nature of blood glucose levels, which are influenced
by several factors such as meal intake and timing. Traditional controllers
often struggle to adapt to these changes, leading to suboptimal insulin
administration. To address this issue, we employ a reinforcement learning agent
tasked with adjusting 27 parameters of the Takagi-Sugeno fuzzy controller at
each time step, ensuring real-time adaptability. The study's findings
demonstrate that this approach significantly enhances the robustness of the
controller against variations in meal size and timing, while also stabilizing
glucose levels with minimal exogenous insulin. This adaptive method holds
promise for improving the quality of life and health outcomes for individuals
with Type 1 diabetes by providing a more responsive and precise management
tool. Simulation results are given to highlight the effectiveness of the
proposed approach.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Diffusion Model Based Probabilistic Day-ahead Load Forecasting 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06697v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06697v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ding Lin, Han Guo, Jianhui Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Accurate probabilistic load forecasting is crucial for maintaining the safety
and stability of power systems. However, the mainstream approach, multi-step
prediction, must be improved by cumulative errors and latency issues, which
limits its effectiveness in probabilistic day-ahead load forecasting (PDALF).
To overcome these challenges, we introduce DALNet, a novel denoising diffusion
model designed to generate load curves rather than relying on direct
prediction. By shifting the focus to curve generation, DALNet captures the
complex distribution of actual load time-series data under specific conditions
with greater fidelity. To further enhance DALNet, we propose the temporal
multi-scale attention block (TMSAB), a mechanism designed to integrate both
positional and temporal information for improved forecasting precision.
Furthermore, we utilize kernel density estimation (KDE) to reconstruct the
distribution of generated load curves and employ KL divergence to compare them
with the actual data distribution. Experimental results demonstrate that DALNet
excels in load forecasting accuracy and offers a novel perspective for other
predictive tasks within power systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Synthetic Data Generation for Minimum-Exposure <span class="highlight-title">Navigation</span> in a
  Time-Varying Environment using Generative AI Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06619v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06619v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nachiket U. Bapat, Randy C. Paffenroth, Raghvendra V. Cowlagi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study the problem of synthetic generation of samples of environmental
features for autonomous vehicle navigation. These features are described by a
spatiotemporally varying scalar field that we refer to as a threat field. The
threat field is known to have some underlying dynamics subject to process
noise. Some "real-world" data of observations of various threat fields are also
available. The assumption is that the volume of ``real-world'' data is
relatively small. The objective is to synthesize samples that are statistically
similar to the data. The proposed solution is a generative artificial
intelligence model that we refer to as a split variational recurrent neural
network (S-VRNN). The S-VRNN merges the capabilities of a variational
autoencoder, which is a widely used generative model, and a recurrent neural
network, which is used to learn temporal dependencies in data. The main
innovation in this work is that we split the latent space of the S-VRNN into
two subspaces. The latent variables in one subspace are learned using the
``real-world'' data, whereas those in the other subspace are learned using the
data as well as the known underlying system dynamics. Through numerical
experiments we demonstrate that the proposed S-VRNN can synthesize data that
are statistically similar to the training data even in the case of very small
volume of ``real-world'' training data.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for 2025 ECC</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Inverse Reinforcement Learning for Minimum-Exposure Paths in
  Spatiotemporally Varying Scalar Fields 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06611v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06611v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alexandra E. Ballentine, Raghvendra V. Cowlagi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Performance and reliability analyses of autonomous vehicles (AVs) can benefit
from tools that ``amplify'' small datasets to synthesize larger volumes of
plausible samples of the AV's behavior. We consider a specific instance of this
data synthesis problem that addresses minimizing the AV's exposure to adverse
environmental conditions during travel to a fixed goal location. The
environment is characterized by a threat field, which is a strictly positive
scalar field with higher intensities corresponding to hazardous and unfavorable
conditions for the AV. We address the problem of synthesizing datasets of
minimum exposure paths that resemble a training dataset of such paths. The main
contribution of this paper is an inverse reinforcement learning (IRL) model to
solve this problem. We consider time-invariant (static) as well as time-varying
(dynamic) threat fields. We find that the proposed IRL model provides excellent
performance in synthesizing paths from initial conditions not seen in the
training dataset, when the threat field is the same as that used for training.
Furthermore, we evaluate model performance on unseen threat fields and find low
error in that case as well. Finally, we demonstrate the model's ability to
synthesize distinct datasets when trained on different datasets with distinct
characteristics.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Joint submission to MECC-JAVS 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Non-Equilibrium MAV-Capture-MAV via Time-Optimal <span class="highlight-title">Plan</span>ning and
  Reinforcement Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06578v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06578v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Canlun Zheng, Zhanyu Guo, Zikang Yin, Chunyu Wang, Zhikun Wang, Shiyu Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The capture of flying MAVs (micro aerial vehicles) has garnered increasing
research attention due to its intriguing challenges and promising applications.
Despite recent advancements, a key limitation of existing work is that capture
strategies are often relatively simple and constrained by platform performance.
This paper addresses control strategies capable of capturing
high-maneuverability targets. The unique challenge of achieving target capture
under unstable conditions distinguishes this task from traditional
pursuit-evasion and guidance problems. In this study, we transition from larger
MAV platforms to a specially designed, compact capture MAV equipped with a
custom launching device while maintaining high maneuverability. We explore both
time-optimal planning (TOP) and reinforcement learning (RL) methods.
Simulations demonstrate that TOP offers highly maneuverable and shorter
trajectories, while RL excels in real-time adaptability and stability.
Moreover, the RL method has been tested in real-world scenarios, successfully
achieving target capture even in unstable states.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Intelligent Control of Merging Car-following and Lane-Changing Behavior 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06572v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06572v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Farzam Tajdari, Amin Rezasoltani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent research has paid little attention to complex driving behaviors,
namely merging car-following and lane-changing behavior, and how lane-changing
affects algorithms designed to model and control a car-following vehicle.
During the merging behavior, the Follower Vehicle (FV) might significantly
diverge from typical car-following models. Thus, this paper aims to control the
FV witnessing lane-changing behavior based on anticipation, perception,
preparation, and relaxation states defined by a novel measurable human
perception index. Data from human drivers are utilized to create a
perception-based fuzzy controller for the behavior vehicle's route guidance,
taking into account the opacity of human driving judgments. We illustrate the
efficacy of the established technique using simulated trials and data from
actual drivers, focusing on the benefits of the increased comfort, safety, and
uniformity of traffic flow and the decreased of wait time and motion sickness
this brings about.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Teager Energy Operator as a Metric to Evaluate Local Synchronization of
  Power System Devices 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06548v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06548v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bruno Pinheiro, Ignacio Ponce, Daniel Dotta, Federico Milano
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces a novel formulation to evaluate the local
synchronization of power system devices, namely Synchronization Energy (SE).
The formulation is derived based on the complex frequency concept and the
Teager Energy Operator applied to the complex power. This formulation offers
valuable insights into the relationship between complex frequency of voltage
and current of the device and its stationary operating. Based on this
relationship we derive the conditions for a novel definition of local
synchronization of power system devices. Through various case studies, the
paper demonstrates how SE can effectively assess local synchronization under
diverse operating conditions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Abdominal Undulation with Compliant Mechanism Improves Flight
  Performance of Biomimetic Robotic Butterfly 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06516v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06516v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xuyi Lian, Mingyu Luo, Te Lin, Chen Qian, Tiefeng Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Abdominal Undulation with Compliant Mechanism Improves Flight Performance of
Biomimetic Robotic ButterflThis paper presents the design, modeling, and
experimental validation of a biomimetic robotic butterfly (BRB) that integrates
a compliant mechanism to achieve coupled wing-abdomen motion. Drawing
inspiration from the natural f light dynamics of butterflies, a theoretical
model is developed to investigate the impact of abdominal undulation on flight
performance. To validate the model, motion capture experi ments are conducted
on three configurations: a BRB without an abdomen, with a fixed abdomen, and
with an undulating abdomen. The results demonstrate that abdominal undulation
enhances lift generation, extends flight duration, and stabilizes pitch
oscillations, thereby improving overall flight performance. These findings
underscore the significance of wing-abdomen interaction in flapping-wing aerial
vehicles (FWAVs) and lay the groundwork for future advancements in
energy-efficient biomimetic flight designs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Dynamics-Invariant Quadrotor Control using Scale-Aware Deep
  Reinforcement Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09622v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09622v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Varad Vaidya, Jishnu Keshavan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Due to dynamic variations such as changing payload, aerodynamic disturbances,
and varying platforms, a robust solution for quadrotor trajectory tracking
remains challenging. To address these challenges, we present a deep
reinforcement learning (DRL) framework that achieves physical dynamics
invariance by directly optimizing force/torque inputs, eliminating the need for
traditional intermediate control layers. Our architecture integrates a temporal
trajectory encoder, which processes finite-horizon reference
positions/velocities, with a latent dynamics encoder trained on historical
state-action pairs to model platform-specific characteristics. Additionally, we
introduce scale-aware dynamics randomization parameterized by the quadrotor's
arm length, enabling our approach to maintain stability across drones spanning
from 30g to 2.1kg and outperform other DRL baselines by 85% in tracking
accuracy. Extensive real-world validation of our approach on the Crazyflie 2.1
quadrotor, encompassing over 200 flights, demonstrates robust adaptation to
wind, ground effects, and swinging payloads while achieving less than 0.05m
RMSE at speeds up to 2.0 m/s. This work introduces a universal quadrotor
control paradigm that compensates for dynamic discrepancies across varied
conditions and scales, paving the way for more resilient aerial systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This work has been submitted to the IEEE for possible publication</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Generalizable Machine Learning Models for Predicting Data Center Server
  Power, Efficiency, and Throughput 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06439v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06439v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nuoa Lei, Arman Shehabi, Jun Lu, Zhi Cao, Jonathan Koomey, Sarah Smith, Eric Masanet
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the rapidly evolving digital era, comprehending the intricate dynamics
influencing server power consumption, efficiency, and performance is crucial
for sustainable data center operations. However, existing models lack the
ability to provide a detailed and reliable understanding of these intricate
relationships. This study employs a machine learning-based approach, using the
SPECPower_ssj2008 database, to facilitate user-friendly and generalizable
server modeling. The resulting models demonstrate high accuracy, with errors
falling within approximately 10% on the testing dataset, showcasing their
practical utility and generalizability. Through meticulous analysis, predictive
features related to hardware availability date, server workload level, and
specifications are identified, providing insights into optimizing energy
conservation, efficiency, and performance in server deployment and operation.
By systematically measuring biases and uncertainties, the study underscores the
need for caution when employing historical data for prospective server
modeling, considering the dynamic nature of technology landscapes.
Collectively, this work offers valuable insights into the sustainable
deployment and operation of servers in data centers, paving the way for
enhanced resource use efficiency and more environmentally conscious practices.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Explaining Control Policies through Predicate Decision Diagrams 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06420v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06420v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Debraj Chakraborty, Clemens Dubslaff, Sudeep Kanav, Jan Kretinsky, Christoph Weinhuber
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Safety-critical controllers of complex systems are hard to construct
manually. Automated approaches such as controller synthesis or learning provide
a tempting alternative but usually lack explainability. To this end, learning
decision trees (DTs) have been prevalently used towards an interpretable model
of the generated controllers. However, DTs do not exploit shared
decision-making, a key concept exploited in binary decision diagrams (BDDs) to
reduce their size and thus improve explainability. In this work, we introduce
predicate decision diagrams (PDDs) that extend BDDs with predicates and thus
unite the advantages of DTs and BDDs for controller representation. We
establish a synthesis pipeline for efficient construction of PDDs from DTs
representing controllers, exploiting reduction techniques for BDDs also for
PDDs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Vision-Based Cooperative MAV-Capturing-MAV 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06412v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06412v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Canlun Zheng, Yize Mi, Hanqing Guo, Huaben Chen, Shiyu Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  MAV-capturing-MAV (MCM) is one of the few effective methods for physically
countering misused or malicious MAVs.This paper presents a vision-based
cooperative MCM system, where multiple pursuer MAVs equipped with onboard
vision systems detect, localize, and pursue a target MAV. To enhance
robustness, a distributed state estimation and control framework enables the
pursuer MAVs to autonomously coordinate their actions. Pursuer trajectories are
optimized using Model Predictive Control (MPC) and executed via a low-level
SO(3) controller, ensuring smooth and stable pursuit. Once the capture
conditions are satisfied, the pursuer MAVs automatically deploy a flying net to
intercept the target. These capture conditions are determined based on the
predicted motion of the net. To enable real-time decision-making, we propose a
lightweight computational method to approximate the net motion, avoiding the
prohibitive cost of solving the full net dynamics. The effectiveness of the
proposed system is validated through simulations and real-world experiments. In
real-world tests, our approach successfully captures a moving target traveling
at 4 meters per second with an acceleration of 1 meter per square second,
achieving a success rate of 64.7 percent.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Decoding the Black Box: Integrating Moral Imagination with Technical AI
  Governance 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06411v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06411v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Krti Tallam
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper examines the intricate interplay among AI safety, security, and
governance by integrating technical systems engineering with principles of
moral imagination and ethical philosophy. Drawing on foundational insights from
Weapons of Math Destruction and Thinking in Systems alongside contemporary
debates in AI ethics, we develop a comprehensive multi-dimensional framework
designed to regulate AI technologies deployed in high-stakes domains such as
defense, finance, healthcare, and education. Our approach combines rigorous
technical analysis, quantitative risk assessment, and normative evaluation to
expose systemic vulnerabilities inherent in opaque, black-box models. Detailed
case studies, including analyses of Microsoft Tay (2016) and the UK A-Level
Grading Algorithm (2020), demonstrate how security lapses, bias amplification,
and lack of accountability can precipitate cascading failures that undermine
public trust. We conclude by outlining targeted strategies for enhancing AI
resilience through adaptive regulatory mechanisms, robust security protocols,
and interdisciplinary oversight, thereby advancing the state of the art in
ethical and technical AI governance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Reduced-Order Model-Based Gait Generation for Snake Robot <span class="highlight-title">Locomotion</span>
  using NMPC 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06402v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06402v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Adarsh Salagame, Eric Sihite, Milad Ramezani, Alireza Ramezani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents an optimization-based motion planning methodology for
snake robots operating in constrained environments. By using a reduced-order
model, the proposed approach simplifies the planning process, enabling the
optimizer to autonomously generate gaits while constraining the robot's
footprint within tight spaces. The method is validated through high-fidelity
simulations that accurately model contact dynamics and the robot's motion. Key
locomotion strategies are identified and further demonstrated through hardware
experiments, including successful navigation through narrow corridors.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Adaptive Deadlock Avoidance for Decentralized Multi-agent Systems via
  CBF-inspired Risk Measurement <span class="chip">ICRA 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09621v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09621v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yanze Zhang, Yiwei Lyu, Siwon Jo, Yupeng Yang, Wenhao Luo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Decentralized safe control plays an important role in multi-agent systems
given the scalability and robustness without reliance on a central authority.
However, without an explicit global coordinator, the decentralized control
methods are often prone to deadlock -- a state where the system reaches
equilibrium, causing the robots to stall. In this paper, we propose a
generalized decentralized framework that unifies the Control Lyapunov Function
(CLF) and Control Barrier Function (CBF) to facilitate efficient task execution
and ensure deadlock-free trajectories for the multi-agent systems. As the
agents approach the deadlock-related undesirable equilibrium, the framework can
detect the equilibrium and drive agents away before that happens. This is
achieved by a secondary deadlock resolution design with an auxiliary CBF to
prevent the multi-agent systems from converging to the undesirable equilibrium.
To avoid dominating effects due to the deadlock resolution over the original
task-related controllers, a deadlock indicator function using CBF-inspired risk
measurement is proposed and encoded in the unified framework for the agents to
adaptively determine when to activate the deadlock resolution. This allows the
agents to follow their original control tasks and seamlessly unlock or
deactivate deadlock resolution as necessary, effectively improving task
efficiency. We demonstrate the effectiveness of the proposed method through
theoretical analysis, numerical simulations, and real-world experiments.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>7 pages, accepted to ICRA 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Dynamic Load Balancing for EV Charging Stations Using Reinforcement
  Learning and Demand Prediction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06370v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06370v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hesam Mosalli, Saba Sanami, Yu Yang, Hen-Geul Yeh, Amir G. Aghdam
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents a method for load balancing and dynamic pricing in
electric vehicle (EV) charging networks, utilizing reinforcement learning (RL)
to enhance network performance. The proposed framework integrates a pre-trained
graph neural network to predict demand elasticity and inform pricing decisions.
The spatio-temporal EV charging demand prediction (EVCDP) dataset from Shenzhen
is utilized to capture the geographic and temporal characteristics of the
charging stations. The RL model dynamically adjusts prices at individual
stations based on occupancy, maximum station capacity, and demand forecasts,
ensuring an equitable network load distribution while preventing station
overloads. By leveraging spatially-aware demand predictions and a carefully
designed reward function, the framework achieves efficient load balancing and
adaptive pricing strategies that respond to localized demand and global network
dynamics, ensuring improved network stability and user satisfaction. The
efficacy of the approach is validated through simulations on the dataset,
showing significant improvements in load balancing and reduced overload as the
RL agent iteratively interacts with the environment and learns to dynamically
adjust pricing strategies based on real-time demand patterns and station
constraints. The findings highlight the potential of adaptive pricing and
load-balancing strategies to address the complexities of EV infrastructure,
paving the way for scalable and user-centric solutions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19th Annual IEEE International Systems Conference (SysCon 2025)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Probabilistic Dynamic Line Rating Forecasting with Line Graph
  Convolutional LSTM 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.12963v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.12963v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Minsoo Kim, Vladimir Dvorkin, Jip Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Dynamic line rating (DLR) is a promising solution to increase the utilization
of transmission lines by adjusting ratings based on real-time weather
conditions. Accurate DLR forecast at the scheduling stage is thus necessary for
system operators to proactively optimize power flows, manage congestion, and
reduce the cost of grid operations. However, the DLR forecast remains
challenging due to weather uncertainty. To reliably predict DLRs, we propose a
new probabilistic forecasting model based on line graph convolutional LSTM.
Like standard LSTM networks, our model accounts for temporal correlations
between DLRs across the planning horizon. The line graph-structured network
additionally allows us to leverage the spatial correlations of DLR features
across the grid to improve the quality of predictions. Simulation results on
the synthetic Texas 123-bus system demonstrate that the proposed model
significantly outperforms the baseline probabilistic DLR forecasting models
regarding reliability and sharpness while using the fewest parameters.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Sufficient and Necessary Barrier-like Conditions for Safety and
  Reach-avoid Verification of Stochastic Discrete-time Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.15572v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.15572v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bai Xue
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we examine necessary and sufficient barrier-like conditions
for infinite-horizon safety verification and reach-avoid verification of
stochastic discrete-time systems, derived through a relaxation of Bellman
equations. Unlike previous methods focused on barrier-like conditions that
primarily address sufficiency, our work rigorously integrates both necessity
and sufficiency for properties pertaining to infinite time. Safety verification
aims to certify the satisfaction of the safety property, which stipulates that
the probability of the system, starting from a specified initial state,
remaining within a safe set always is greater than or equal to a specified
lower bound. A necessary and sufficient barrier-like condition is formulated
for safety verification. In contrast, reach-avoid verification extends beyond
safety to include reachability, seeking to certify the satisfaction of the
reach-avoid property. It requires that the probability of the system, starting
from a specified initial state, reaching a target set eventually while
remaining within a safe set until the first hit of the target, is greater than
or equal to a specified lower bound. Two necessary and sufficient barrier-like
conditions are formulated under certain assumptions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ An Efficient Intelligent Semi-Automated Warehouse Inventory Stocktaking
  System 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2309.12365v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2309.12365v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chunan Tong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the context of evolving supply chain management, the significance of
efficient inventory management has grown substantially for businesses. However,
conventional manual and experience-based approaches often struggle to meet the
complexities of modern market demands. This research introduces an intelligent
inventory management system to address challenges related to inaccurate data,
delayed monitoring, and overreliance on subjective experience in forecasting.
The proposed system integrates bar code and distributed flutter application
technologies for intelligent perception, alongside comprehensive big data
analytics to enable data-driven decision-making. Through meticulous analysis,
system design, critical technology exploration, and simulation validation, the
effectiveness of the proposed system is successfully demonstrated. The
intelligent system facilitates second-level monitoring, high-frequency checks,
and artificial intelligence-driven forecasting, consequently enhancing the
automation, precision, and intelligence of inventory management. This system
contributes to cost reduction and optimized inventory sizes through accurate
predictions and informed decisions, ultimately achieving a mutually beneficial
scenario. The outcomes of this research offer
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Learning-based Control for Tendon-Driven Continuum Robotic Arms 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.04829v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.04829v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nima Maghooli, Omid Mahdizadeh, Mohammad Bajelani, S. Ali A. Moosavian
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents a learning-based approach for centralized position
control of Tendon Driven Continuum Robots (TDCRs) using Deep Reinforcement
Learning (DRL), with a particular focus on the Sim-to-Real transfer of control
policies. The proposed control method employs the Modified Transpose Jacobian
(MTJ) control strategy, with its parameters optimally tuned using the Deep
Deterministic Policy Gradient (DDPG) algorithm. Classical model-based
controllers encounter significant challenges due to the inherent uncertainties
and nonlinear dynamics of continuum robots. In contrast, model-free control
strategies require efficient gain-tuning to handle diverse operational
scenarios. This research aims to develop a model-free controller with
performance comparable to model-based strategies by integrating an optimal
adaptive gain-tuning system. Both simulations and real-world implementations
demonstrate that the proposed method significantly enhances the
trajectory-tracking performance of continuum robots independent of initial
conditions and paths within the operational task-space, effectively
establishing a task-free controller.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Online 4D Ultrasound-Guided Robotic Tracking Enables 3D Ultrasound
  Localisation Microscopy with Large Tissue Displacements 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.11391v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.11391v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jipeng Yan, Qingyuan Tan, Shusei Kawara, Jingwen Zhu, Bingxue Wang, Matthieu Toulemonde, Honghai Liu, Ying Tan, Meng-Xing Tang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Super-Resolution Ultrasound (SRUS) imaging through localising and tracking
microbubbles, also known as Ultrasound Localisation Microscopy (ULM), has
demonstrated significant potential for reconstructing microvasculature and
flows with sub-diffraction resolution in clinical diagnostics. However, imaging
organs with large tissue movements, such as those caused by respiration,
presents substantial challenges. Existing methods often require breath holding
to maintain accumulation accuracy, which limits data acquisition time and ULM
image saturation. To improve image quality in the presence of large tissue
movements, this study introduces an approach integrating high-frame-rate
ultrasound with online precise robotic probe control. Tested on a
microvasculature phantom with translation motions up to 20 mm, twice the
aperture size of the matrix array used, our method achieved real-time tracking
of the moving phantom and imaging volume rate at 85 Hz, keeping majority of the
target volume in the imaging field of view. ULM images of the moving cross
channels in the phantom were successfully reconstructed in post-processing,
demonstrating the feasibility of super-resolution imaging under large tissue
motions. This represents a significant step towards ULM imaging of organs with
large motion.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Optimization and Control <span class="chip" style="font-size: 60%">26</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Stochastic Optimal Control of an Epidemic Under Partial Information 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06804v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06804v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ibrahim Mbouandi Njiasse, Florent Ouabo Kamkumo, Ralf Wunderlich
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we address a social planner's optimal control problem for a
partially observable stochastic epidemic model. The control measures include
social distancing, testing, and vaccination. Using a diffusion approximation
for the state dynamics of the epidemic, we apply filtering arguments to
transform the partially observable stochastic optimal control problem into an
optimal control problem with complete information. This transformed problem is
treated as a Markov decision process. The associated Bellman equation is solved
numerically using optimal quantization methods for approximating the
expectations involved to mitigate the curse of dimensionality. We implement two
approaches, the first involves state discretization coupled with linear
interpolation of the value function at non-grid points. The second utilizes a
parametrization of the value function with educated ansatz functions. Extensive
numerical experiments are presented to demonstrate the efficacy of both
methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>52 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Optimistic Noise-Aware Sequential Quadratic Programming for Equality
  Constrained <span class="highlight-title">Optimization</span> with Rank-Deficient Jacobians 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06702v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06702v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Albert S. Berahas, Jiahao Shi, Baoyu Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose and analyze a sequential quadratic programming algorithm for
minimizing a noisy nonlinear smooth function subject to noisy nonlinear smooth
equality constraints. The algorithm uses a step decomposition strategy and, as
a result, is robust to potential rank-deficiency in the constraints, allows for
two different step size strategies, and has an early stopping mechanism. Under
the linear independence constraint qualification, convergence is established to
a neighborhood of a first-order stationary point, where the radius of the
neighborhood is proportional to the noise levels in the objective function and
constraints. Moreover, in the rank-deficient setting, the merit parameter may
converge to zero, and convergence to a neighborhood of an infeasible stationary
point is established. Numerical experiments demonstrate the efficiency and
robustness of the proposed method.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Precise Insulin Delivery for Artificial Pancreas: A Reinforcement
  Learning Optimized Adaptive Fuzzy Control Approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06701v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06701v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Omar Mameche, Abdelhadi Abedou, Taqwa Mezaache, Mohamed Tadjine
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper explores the application of reinforcement learning to optimize the
parameters of a Type-1 Takagi-Sugeno fuzzy controller, designed to operate as
an artificial pancreas for Type 1 diabetes. The primary challenge in diabetes
management is the dynamic nature of blood glucose levels, which are influenced
by several factors such as meal intake and timing. Traditional controllers
often struggle to adapt to these changes, leading to suboptimal insulin
administration. To address this issue, we employ a reinforcement learning agent
tasked with adjusting 27 parameters of the Takagi-Sugeno fuzzy controller at
each time step, ensuring real-time adaptability. The study's findings
demonstrate that this approach significantly enhances the robustness of the
controller against variations in meal size and timing, while also stabilizing
glucose levels with minimal exogenous insulin. This adaptive method holds
promise for improving the quality of life and health outcomes for individuals
with Type 1 diabetes by providing a more responsive and precise management
tool. Simulation results are given to highlight the effectiveness of the
proposed approach.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Necessary conditions for approximate solutions of vector and set
  <span class="highlight-title">optimization</span> problems with variable domination structure 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06681v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06681v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Marius Durea, Christian Günther, Radu Strugariu, Christiane Tammer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We consider vector and set optimization problems with respect to variable
domination structures given by set-valued mappings acting between the preimage
space and the image space of the objective mapping, as well as by set-valued
mappings with the same input and output space, that coincides with the image
space of the objective mapping. The aim of this paper is to derive necessary
conditions for approximately nondominated points of problems with a
single-valued objective function, employing an extension of Ekeland's
Variational Principle for problems with respect to variable domination
structures in terms of generalized differentiation in the sense of
Mordukhovich. For set-valued objective mappings, we derive necessary conditions
for approximately nondominated points of problems with variable domination
structure taking into account the incompatibility between openness and
optimality and a directional openness result for the sum of set-valued maps. We
describe the necessary conditions for approximately nondominated points of set
optimization problems with variable domination structure in terms of the
limiting (Mordukhovich) generalized differentiation objects.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ An exponentially stable discrete-time primal-dual algorithm for
  distributed constrained <span class="highlight-title">optimization</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06662v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06662v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaoxing Ren, Michelangelo Bin, Ivano Notarnicola, Thomas Parisini
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper studies a distributed algorithm for constrained consensus
optimization that is obtained by fusing the Arrow-Hurwicz-Uzawa primal-dual
gradient method for centralized constrained optimization and the Wang-Elia
method for distributed unconstrained optimization. It is shown that the optimal
primal-dual point is a semiglobally exponentially stable equilibrium for the
algorithm, which implies linear convergence. The analysis is based on the
separation between a slow centralized optimization dynamics describing the
evolution of the average estimate toward the optimum, and a fast dynamics
describing the evolution of the consensus error over the network. These two
dynamics are mutually coupled, and the stability analysis builds on control
theoretic tools such as time-scale separation, Lyapunov theory, and the
small-gain principle. Our analysis approach highlights that the consensus
dynamics can be seen as a fast, parasite one, and that stability of the
distributed algorithm is obtained as a robustness consequence of the semiglobal
exponential stability properties of the centralized method. This perspective
can be used to enable other significant extensions, such as time-varying
networks or delayed communication, that can be seen as ``perturbations" of the
centralized algorithm.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         <span class="highlight-title">★</span> A Block-Based Heuristic Algorithm for the Three-Dimensional Nuclear
  Waste Packing Problem 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.08705v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.08705v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yajie Wen, De<span class="highlight-author">fu Zhang</span>
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this study, we present a block-based heuristic search algorithm to address
the nuclear waste container packing problem in the context of real-world
nuclear power plants. Additionally, we provide a dataset comprising 1600
problem instances for future researchers to use. Experimental results on this
dataset demonstrate that the proposed algorithm effectively enhances the
disposal pool's space utilization while minimizing the radiation dose within
the pool. The code and data employed in this study are publicly available to
facilitate reproducibility and further investigation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages,7 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On Solving Minimization and Min-Max Problems by First-Order Methods with
  Relative Error in Gradients 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06628v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06628v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Artem Vasin, Valery Krivchenko, Dmitry Kovalev, Fedyor Stonyakin, Nazari Tupitsa, Pavel Dvurechensky, Mohammad Alkousa, Nikita Kornilov, Alexander Gasnikov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  First-order methods for minimization and saddle point (min-max) problems are
one of the cornerstones of modern ML. The majority of works obtain favorable
complexity guarantees of such methods assuming that exact gradient information
is available. At the same time, even the use floating-point representation of
real numbers already leads to relative error in all the computations. Relative
errors arise also in such applications as bilevel optimization, inverse
problems, derivative-free optimization, inexact proximal methods. This paper
answers several theoretical open questions on first-order optimization methods
under relative errors. We propose an explicit single-loop accelerated gradient
method that preserves optimal convergence rate under maximal possible relative
error in the gradient and explore the tradeoff between the relative error and
deterioration in the linear convergence rate. We further explore similar
questions for saddle point problems showing that a variant of gradient
descent-ascent and the extragradient method are robust to such errors.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Automated Proof of Polynomial Inequalities via Reinforcement Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06592v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06592v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Banglong Liu, Niuniu Qi, Xia Zeng, Lydia Dehbi, Zhengfeng Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Polynomial inequality proving is fundamental to many mathematical disciplines
and finds wide applications in diverse fields. Current traditional algebraic
methods are based on searching for a polynomial positive definite
representation over a set of basis. However, these methods are limited by
truncation degree. To address this issue, this paper proposes an approach based
on reinforcement learning to find a {Krivine-basis} representation for proving
polynomial inequalities. Specifically, we formulate the inequality proving
problem as a linear programming (LP) problem and encode it as a basis selection
problem using reinforcement learning (RL), achieving a non-negative {Krivine
basis}. Moreover, a fast multivariate polynomial multiplication method based on
Fast Fourier Transform (FFT) is employed to enhance the efficiency of action
space search. Furthermore, we have implemented a tool called {APPIRL}
(Automated Proof of Polynomial Inequalities via Reinforcement Learning).
Experimental evaluation on benchmark problems demonstrates the feasibility and
effectiveness of our approach. In addition, {APPIRL} has been successfully
applied to solve the maximum stable set problem.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Higher Order Reduced Rank Regression 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06528v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06528v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Leia Greenberg, Haim Avron
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reduced Rank Regression (RRR) is a widely used method for multi-response
regression. However, RRR assumes a linear relationship between features and
responses. While linear models are useful and often provide a good
approximation, many real-world problems involve more complex relationships that
cannot be adequately captured by simple linear interactions. One way to model
such relationships is via multilinear transformations. This paper introduces
Higher Order Reduced Rank Regression (HORRR), an extension of RRR that
leverages multi-linear transformations, and as such is capable of capturing
nonlinear interactions in multi-response regression. HORRR employs tensor
representations for the coefficients and a Tucker decomposition to impose
multilinear rank constraints as regularization akin to the rank constraints in
RRR. Encoding these constraints as a manifold allows us to use Riemannian
optimization to solve this HORRR problems. We theoretically and empirically
analyze the use of Riemannian optimization for solving HORRR problems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Robust <span class="highlight-title">Optimization</span> Approach for Solving Uncertain Multiobjective
  <span class="highlight-title">Optimization</span> Problems Using the Projected Gradient Method 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06509v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06509v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shubham Kumar, Nihar Kumar Mahatoa, Debdas Ghosh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Numerous real-world applications of uncertain multiobjective optimization
problems (UMOPs) can be found in science, engineering, business, and
management. To handle the solution of uncertain optimization problems, robust
optimization is a relatively new field. An extended version of the projected
gradient method (PGM) for a deterministic smooth multiobjective optimization
problem (MOP) is presented in the current study as a PGM for UMOP. An
objective-wise worst-case cost (OWWC) type robust counterpart is considered,
and the PGM is used to solve a UMOP by using OWWC. A projected gradient descent
algorithm is created using theoretical findings. It is demonstrated that the
projected gradient descent algorithm's generated sequence converges to the
robust counterpart's weak Pareto optimal solution, which will be the robust
weak Pareto optimal solution for UMOP. Under a few reasonable presumptions, the
projected gradient descent algorithm's full convergent behavior is also
justified. Finally, numerical tests are presented to validate the proposed
method.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Global Convergence and Rate Analysis of the Steepest Descent Method for
  Uncertain Multiobjective <span class="highlight-title">Optimization</span> via a Robust <span class="highlight-title">Optimization</span> Approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06476v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06476v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shubham Kumar, Nihar Kumar Mahato, Debdas Ghosh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this article, we extend our previous work (Applicable Analysis, 2024, pp.
1-25) on the steepest descent method for uncertain multiobjective optimization
problems. While that study established local convergence, it did not address
global convergence and the rate of convergence of the steepest descent
algorithm. To bridge this gap, we provide rigorous proofs for both global
convergence and the linear convergence rate of the steepest descent algorithm.
Global convergence analysis strengthens the theoretical foundation of the
steepest descent method for uncertain multiobjective optimization problems,
offering deeper insights into its efficiency and robustness across a broader
class of optimization problems. These findings enhance the method's practical
applicability and contribute to the advancement of robust optimization
techniques.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Null controllability for semi-discrete stochastic semilinear parabolic
  equations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06440v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06440v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yu Wang, Qingmei Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The global null controllability of stochastic semilinear parabolic equations
with globally Lipschitz nonlinearities has been addressed in recent literature.
However, there are no results concerning their numerical approximation and the
behavior of discrete controls when the discretization parameter goes to zero.
This paper is intended to studying the null controllability for semi-discrete
stochastic semilinear parabolic equations, where the spatial variable is
discretized with finite difference scheme and the time is kept as a continuous
variable. The proof is based on a new refined semi-discrete Carleman estimate
and Banach fixed point method. The main novelty here is that the Carleman
parameters and discretization parameter are made explicit and are then used in
a Banach fixed point method.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Optimizing Posterior Samples for Bayesian <span class="highlight-title">Optimization</span> via Rootfinding <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.22322v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.22322v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Taiwo A. Adebiyi, Bach Do, Ruda Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Bayesian optimization devolves the global optimization of a costly objective
function to the global optimization of a sequence of acquisition functions.
This inner-loop optimization can be catastrophically difficult if it involves
posterior sample paths, especially in higher dimensions. We introduce an
efficient global optimization strategy for posterior samples based on global
rootfinding. It provides gradient-based optimizers with two sets of judiciously
selected starting points, designed to combine exploration and exploitation. The
number of starting points can be kept small without sacrificing optimization
quality. Remarkably, even with just one point from each set, the global optimum
is discovered most of the time. The algorithm scales practically linearly to
high dimensions, breaking the curse of dimensionality. For Gaussian process
Thompson sampling (GP-TS), we demonstrate remarkable improvement in both inner-
and outer-loop optimization, surprisingly outperforming alternatives like EI
and GP-UCB in most cases. Our approach also improves the performance of other
posterior sample-based acquisition functions, such as variants of entropy
search. Furthermore, we propose a sample-average formulation of GP-TS, which
has a parameter to explicitly control exploitation and can be computed at the
cost of one posterior sample. Our implementation is available at
https://github.com/UQUH/TSRoots .
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published at the Thirteenth International Conference on Learning
  Representations (ICLR 2025)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Quadratically Regularized Optimal Transport: Existence and Multiplicity
  of Potentials 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.06847v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.06847v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Marcel Nutz
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The optimal transport problem with quadratic regularization is useful when
sparse couplings are desired. The density of the optimal coupling is described
by two functions called potentials; equivalently, potentials can be defined as
a solution of the dual problem. We prove the existence of potentials for a
general square-integrable cost. Potentials are not necessarily unique, a
phenomenon directly related to sparsity of the optimal support. For discrete
problems, we describe the family of all potentials based on the connected
components of the support, for a graph-theoretic notion of connectedness. On
the other hand, we show that continuous problems have unique potentials under
standard regularity assumptions, regardless of sparsity. Using potentials, we
prove that the optimal support is indeed sparse for small regularization
parameter in a continuous setting with quadratic cost, which seems to be the
first theoretical guarantee for sparsity in this context.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To appear in 'SIAM Journal on Mathematical Analysis'</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Robust Clustering on High-Dimensional Data with Stochastic Quantization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.02066v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.02066v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anton Kozyriev, Vladimir Norkin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper addresses the limitations of conventional vector quantization
algorithms, particularly K-Means and its variant K-Means++, and investigates
the Stochastic Quantization (SQ) algorithm as a scalable alternative for
high-dimensional unsupervised and semi-supervised learning tasks. Traditional
clustering algorithms often suffer from inefficient memory utilization during
computation, necessitating the loading of all data samples into memory, which
becomes impractical for large-scale datasets. While variants such as Mini-Batch
K-Means partially mitigate this issue by reducing memory usage, they lack
robust theoretical convergence guarantees due to the non-convex nature of
clustering problems. In contrast, the Stochastic Quantization algorithm
provides strong theoretical convergence guarantees, making it a robust
alternative for clustering tasks. We demonstrate the computational efficiency
and rapid convergence of the algorithm on an image classification problem with
partially labeled data, comparing model accuracy across various ratios of
labeled to unlabeled data. To address the challenge of high dimensionality, we
employ a Triplet Network to encode images into low-dimensional representations
in a latent space, which serve as a basis for comparing the efficiency of both
the Stochastic Quantization algorithm and traditional quantization algorithms.
Furthermore, we enhance the algorithm's convergence speed by introducing
modifications with an adaptive learning rate.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>22 pages, 5 figures, published in the International Scientific
  Technical Journal "Problems of Control and Informatics"</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Variational Entropy Search for Adjusting Expected Improvement 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.11345v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.11345v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nuojin Cheng, Stephen Becker
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Bayesian optimization is a widely used technique for optimizing black-box
functions, with Expected Improvement (EI) being the most commonly utilized
acquisition function in this domain. While EI is often viewed as distinct from
other information-theoretic acquisition functions, such as entropy search (ES)
and max-value entropy search (MES), our work reveals that EI can be considered
a special case of MES when approached through variational inference (VI). In
this context, we have developed the Variational Entropy Search (VES)
methodology and the VES-Gamma algorithm, which adapts EI by incorporating
principles from information-theoretic concepts. The efficacy of VES-Gamma is
demonstrated across a variety of test functions and read datasets, highlighting
its theoretical and practical utilities in Bayesian optimization scenarios.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This is a preliminary technical report. For a more comprehensive
  study, please refer to arXiv:2501.18756</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Accelerated Extragradient-Type Methods -- Part 2: Generalization and
  Sublinear Convergence Rates under Co-Hypomonotonicity 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.04585v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.04585v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Quoc Tran-Dinh, Nghia Nguyen-Trung
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Following the first part of our project, this paper comprehensively studies
two types of extragradient-based methods: anchored extragradient and Nesterov's
accelerated extragradient for solving [non]linear inclusions (and, in
particular, equations), primarily under the Lipschitz continuity and the
co-hypomonotonicity assumptions. We unify and generalize a class of anchored
extragradient methods for monotone inclusions to a wider range of schemes
encompassing existing algorithms as special cases. We establish
$\mathcal{O}(1/k)$ last-iterate convergence rates on the residual norm of the
underlying mapping for this general framework and then specialize it to obtain
convergence guarantees for specific instances, where $k$ denotes the iteration
counter. We extend our approach to a class of anchored Tseng's
forward-backward-forward splitting methods to obtain a broader class of
algorithms for solving co-hypomonotone inclusions. Again, we analyze
$\mathcal{O}(1/k)$ last-iterate convergence rates for this general scheme and
specialize it to obtain convergence results for existing and new variants. We
generalize and unify Nesterov's accelerated extra-gradient method to a new
class of algorithms that covers existing schemes as special instances while
generating new variants. For these schemes, we can prove $\mathcal{O}(1/k)$
last-iterate convergence rates for the residual norm under co-hypomonotonicity,
covering a class of nonmonotone problems. We propose another novel class of
Nesterov's accelerated extragradient methods to solve inclusions.
Interestingly, these algorithms achieve both $\mathcal{O}(1/k)$ and $o(1/k)$
last-iterate convergence rates, and also the convergence of iterate sequences
under co-hypomonotonicity and Lipschitz continuity. Finally, we provide a set
of numerical experiments encompassing different scenarios to validate our
algorithms and theoretical guarantees.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>75 pages, 7 figures, and 1 table</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Entropic mean-field min-max problems via Best Response flow 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2306.03033v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2306.03033v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Razvan-Andrei Lascu, Mateusz B. Majka, Łukasz Szpruch
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We investigate the convergence properties of a continuous-time optimization
method, the \textit{Mean-Field Best Response} flow, for solving convex-concave
min-max games with entropy regularization. We introduce suitable Lyapunov
functions to establish exponential convergence to the unique mixed Nash
equilibrium. Additionally, we demonstrate the convergence of the fictitious
play flow as a by-product of our analysis.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>34 pages, revised version, accepted for publication in Applied
  Mathematics & Optimization. The final manuscript is available at Springer via
  https://link.springer.com/article/10.1007/s00245-025-10246-6#article-info</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Efficient and Near-Optimal Online Portfolio Selection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2209.13932v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2209.13932v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rémi Jézéquel, Dmitrii M. Ostrovskii, Pierre Gaillard
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the problem of online portfolio selection as formulated by Cover (1991),
the trader repeatedly distributes her capital over $ d $ assets in each of $ T
> 1 $ rounds, with the goal of maximizing the total return. Cover proposed an
algorithm, termed Universal Portfolios, that performs nearly as well as the
best (in hindsight) static assignment of a portfolio, with an $ O(d\log(T)) $
regret in terms of the logarithmic return. Without imposing any restrictions on
the market this guarantee is known to be worst-case optimal, and no other
algorithm attaining it has been discovered so far. Unfortunately, Cover's
algorithm crucially relies on computing certain $ d $-dimensional integral
which must be approximated in any implementation; this results in a prohibitive
$ \tilde O(d^4(T+d)^{14}) $ per-round runtime for the fastest known
implementation due to Kalai and Vempala (2002). We propose an algorithm for
online portfolio selection that admits essentially the same regret guarantee as
Universal Portfolios -- up to a constant factor and replacement of $ \log(T) $
with $ \log(T+d) $ -- yet has a drastically reduced runtime of $ \tilde
O(d^2(T+d)) $ per round. The selected portfolio minimizes the current
logarithmic loss regularized by the log-determinant of its Hessian --
equivalently, the hybrid logarithmic-volumetric barrier of the polytope
specified by the asset return vectors. As such, our work reveals surprising
connections of online portfolio selection with two classical topics in
optimization theory: cutting-plane and interior-point algorithms.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>48 pages; to appear at Mathematics of Operations Research</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The Implicit Bias of Heterogeneity towards Invariance: A Study of
  Multi-Environment Matrix Sensing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.01420v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.01420v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yang Xu, Yihong Gu, Cong Fang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Models are expected to engage in invariance learning, which involves
distinguishing the core relations that remain consistent across varying
environments to ensure the predictions are safe, robust and fair. While
existing works consider specific algorithms to realize invariance learning, we
show that model has the potential to learn invariance through standard training
procedures. In other words, this paper studies the implicit bias of Stochastic
Gradient Descent (SGD) over heterogeneous data and shows that the implicit bias
drives the model learning towards an invariant solution. We call the phenomenon
the implicit invariance learning. Specifically, we theoretically investigate
the multi-environment low-rank matrix sensing problem where in each
environment, the signal comprises (i) a lower-rank invariant part shared across
all environments; and (ii) a significantly varying environment-dependent
spurious component. The key insight is, through simply employing the large step
size large-batch SGD sequentially in each environment without any explicit
regularization, the oscillation caused by heterogeneity can provably prevent
model learning spurious signals. The model reaches the invariant solution after
certain iterations. In contrast, model learned using pooled SGD over all data
would simultaneously learn both the invariant and spurious signals. Overall, we
unveil another implicit bias that is a result of the symbiosis between the
heterogeneity of data and modern algorithms, which is, to the best of our
knowledge, first in the literature.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Learning time-scales in two-layers neural networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2303.00055v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2303.00055v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Raphaël Berthier, Andrea Montanari, Kangjie Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Gradient-based learning in multi-layer neural networks displays a number of
striking features. In particular, the decrease rate of empirical risk is
non-monotone even after averaging over large batches. Long plateaus in which
one observes barely any progress alternate with intervals of rapid decrease.
These successive phases of learning often take place on very different time
scales. Finally, models learnt in an early phase are typically `simpler' or
`easier to learn' although in a way that is difficult to formalize.
  Although theoretical explanations of these phenomena have been put forward,
each of them captures at best certain specific regimes. In this paper, we study
the gradient flow dynamics of a wide two-layer neural network in
high-dimension, when data are distributed according to a single-index model
(i.e., the target function depends on a one-dimensional projection of the
covariates). Based on a mixture of new rigorous results, non-rigorous
mathematical derivations, and numerical simulations, we propose a scenario for
the learning dynamics in this setting. In particular, the proposed evolution
exhibits separation of timescales and intermittency. These behaviors arise
naturally because the population gradient flow can be recast as a singularly
perturbed dynamical system.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>64 pages, 15 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Bregman-divergence-based Arimoto-Blahut algorithm 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.05454v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.05454v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Masahito Hayashi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We generalize the generalized Arimoto-Blahut algorithm to a general function
defined over Bregman-divergence system. In existing methods, when linear
constraints are imposed, each iteration needs to solve a convex minimization.
Exploiting our obtained algorithm, we propose a minimization-free-iteration
algorithm. This algorithm can be applied to classical and quantum
rate-distortion theory. We numerically apply our method to the derivation of
the optimal conditional distribution in the rate-distortion theory.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Quantum Langevin Dynamics for <span class="highlight-title">Optimization</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.15587v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.15587v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zherui Chen, Yuchen Lu, Hao Wang, Yizhou Liu, Tongyang Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We initiate the study of utilizing Quantum Langevin Dynamics (QLD) to solve
optimization problems, particularly those non-convex objective functions that
present substantial obstacles for traditional gradient descent algorithms.
Specifically, we examine the dynamics of a system coupled with an infinite heat
bath. This interaction induces both random quantum noise and a deterministic
damping effect to the system, which nudge the system towards a steady state
that hovers near the global minimum of objective functions. We theoretically
prove the convergence of QLD in convex landscapes, demonstrating that the
average energy of the system can approach zero in the low temperature limit
with an exponential decay rate correlated with the evolution time. Numerically,
we first show the energy dissipation capability of QLD by retracing its origins
to spontaneous emission. Furthermore, we conduct detailed discussion of the
impact of each parameter. Finally, based on the observations when comparing QLD
with classical Fokker-Plank-Smoluchowski equation, we propose a time-dependent
QLD by making temperature and $\hbar$ time-dependent parameters, which can be
theoretically proven to converge better than the time-independent case and also
outperforms a series of state-of-the-art quantum and classical optimization
algorithms in many non-convex landscapes.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>52 pages, 1 table, 25 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Robust Design <span class="highlight-title">Optimization</span> with Limited Data for Char Combustion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.01429v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.01429v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yulin Guo, Dongjin Lee, Boris Kramer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This work presents a robust design optimization approach for a char
combustion process in a limited-data setting, where simulations of the
fluid-solid coupled system are computationally expensive. We integrate a
polynomial dimensional decomposition (PDD) surrogate model into the design
optimization and induce computational efficiency in three key areas. First, we
transform the input random variables to have fixed probability measures, which
eliminates the need to recalculate the PDD's basis functions associated with
these probability quantities. Second, using the limited data available from a
physics-based high-fidelity solver, we estimate the PDD coefficients via
sparsity-promoting diffeomorphic modulation under observable response
preserving homotopy regression. Third, we propose a single-pass surrogate model
training that avoids the need to generate new training data and update the PDD
coefficients during the derivative-free optimization. The results provide
insights for optimizing process parameters to ensure consistently high energy
production from char combustion.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>23 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Equitable Routing -- Rethinking the Multiple Traveling Salesman Problem 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.08157v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.08157v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Abhay Singh Bhadoriya, Deepjyoti Deka, Kaarthik Sundar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The Multiple Traveling Salesman Problem (MTSP) generalizes the Traveling
Salesman Problem (TSP) by introducing multiple salesmen tasked with visiting a
set of targets from a single depot, ensuring each target is visited exactly
once while minimizing total tour length. A key variant, the min-max MTSP, seeks
to balance workloads by minimizing the longest tour among salesmen. However,
this problem is challenging to solve optimally due to weak lower bounds from
linear relaxations. This paper introduces two novel parametric variants of the
MTSP, termed "fair-MTSP". One variant is modeled as a Mixed-Integer Second
Order Cone Program (MISOCP), and the other as a Mixed Integer Linear Program
(MILP). Both variants aim to distribute tour lengths equitably among salesmen
while minimizing overall costs. We develop algorithms to achieve global
optimality for these fair-MTSP variants. We present computational results based
on benchmark and real-world scenarios, particularly in electric vehicle fleet
management and routing. Furthermore, we also show that the algorithmic
approaches presented for the fair-MTSP variants can be directly used to obtain
the Pareto-front of a bi-objective optimization problem where one objective
focuses on minimizing the total tour length and the other focuses on balancing
the tour lengths of the individual tours. The findings support fair-MTSP as a
promising alternative to the min-max MTSP, emphasizing fairness in workload
distribution.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>24 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Regularized neural network for general variational inequalities
  involving monotone couples of operators in Hilbert spaces 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.19054v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.19054v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pham Ky Anh, Trinh Ngoc Hai, Nguyen Van Manh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, based on the Tikhonov regularization technique, we study a
monotone general variational inequality (GVI) by considering an associated
strongly monotone GVI, depending on a regularization parameter $\alpha,$ such
that the latter admits a unique solution $x_\alpha$ which tends to some
solution of the initial GVI, as $\alpha \to 0.$ However, instead of solving the
regularized GVI for each $\alpha$, which may be very expensive, we consider a
neural network (also known as a dynamical system) associated with the
regularized GVI and establish the existence and the uniqueness of the strong
global solution to the corresponding Cauchy problem. An explicit discretization
of this neural network leads to strongly convergent iterative regularization
algorithms for monotone general variational inequality. Numerical tests are
performed to show the effectiveness of the proposed methods.
  This work extends our recent results in [Anh, Hai, Optim. Eng. 25 (2024)
2295-2313] to more general setting.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2025-03-08T00:00:00Z">2025-03-08</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Systems and Control <span class="chip" style="font-size: 60%">13</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Deep Reinforcement Learning-Based Semi-Autonomous Control for Magnetic
  Micro-robot <span class="highlight-title">Navigation</span> with Immersive <span class="highlight-title">Manipulation</span> <span class="chip">ICRA</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06359v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06359v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yudong Mao, Dandan Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Magnetic micro-robots have demonstrated immense potential in biomedical
applications, such as in vivo drug delivery, non-invasive diagnostics, and
cell-based therapies, owing to their precise maneuverability and small size.
However, current micromanipulation techniques often rely solely on a
two-dimensional (2D) microscopic view as sensory feedback, while traditional
control interfaces do not provide an intuitive manner for operators to
manipulate micro-robots. These limitations increase the cognitive load on
operators, who must interpret limited feedback and translate it into effective
control actions. To address these challenges, we propose a Deep Reinforcement
Learning-Based Semi-Autonomous Control (DRL-SC) framework for magnetic
micro-robot navigation in a simulated microvascular system. Our framework
integrates Mixed Reality (MR) to facilitate immersive manipulation of
micro-robots, thereby enhancing situational awareness and control precision.
Simulation and experimental results demonstrate that our approach significantly
improves navigation efficiency, reduces control errors, and enhances the
overall robustness of the system in simulated microvascular environments.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ICRA</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The Perfect Way to Manage Spectrum 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06318v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06318v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        William Webb, Arturas Medeisis, Leo Fulvio Minervini
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This article discusses the key principles of radio spectrum management with a
focus on spectrum allocation and access. We show the current regime's inherent
rigidity and constrained possibilities for introducing new radiocommunication
services and applications. The article proposes how governments and spectrum
users could cooperate in taking spectrum management to a qualitatively new
level, characterized by light touch regulation and flexible use. This could be
achieved through the broader introduction of emerging practices such as
Spectrum Usage Rights, liberalized spectrum trading, and full shared spectrum
access. We conclude by presenting a vision for a 'perfect' spectrum management
arrangement and future research directions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Dense or Sparse? Post-Packing Interconnection Analysis in FPGAs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06257v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06257v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        X. Wang, D. Stroobandt
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Packing is a crucial step of FPGA design, directly impacting interconnect
complexity, routing congestion, and overall performance. This paper presents a
post-packing interconnect-aware analysis, illustrating how dense (sparse)
packing changes the interconnection structure. We introduce a new metric,
RDensity, to define post-packing density and investigate its influence on
routability. Through a comparative study of two packing tools, we demonstrate
that density directly impacts routability. Our findings provide valuable
insights into how packing decisions affect FPGA efficiency and offer guidance
for improving FPGA packing tools and architecture design by integrating
interconnect-aware methods. The goal is to achieve efficient routing while
maintaining an optimal balance between cluster density, CLB pin counts, and
logical block sizes.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Asymmetric Modular Pulse Synthesizer: A High-Power High-Granularity
  Electronics Solution for Transcranial Magnetic Stimulation with Practically
  Any Pulse Shape for Neural Activation Selectivity 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06172v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06172v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jinshui Zhang, Angel Peterchev, Stefan Goetz
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Noninvasive brain stimulation can activate neurons in the brain but requires
power electronics with exceptionally high power in the mega-volt-ampere and
high frequencies in the kilohertz range. Whereas oscillator circuits offered
only one or very few pulse shapes, modular power electronics solved a
long-standing problem for the first time and enabled arbitrary software-based
design of the temporal shape of stimuli. However, synthesizing arbitrary
stimuli with a high output quality requires a large number of modules. Systems
with few modules and pulse-width modulation may generate apparently smooth
current shapes in the highly inductive coil, but the stimulation effect of the
neurons depends on the electric field and the electric field becomes a burst of
ultra-brief rectangular pulses. We propose an alternative solution that
achieves high-resolution pulse shaping with fewer modules by implementing
high-power wide-bandwidth voltage asymmetry. Rather than equal voltage steps,
our system strategically assigns different voltages to each module to achieve a
near-exponential improvement in resolution. Compared to prior designs, our
experimental prototype achieved better output quality, although it uses only
half the number of modules.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>4 pages, 1 figure</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Momentum-based Distributed Resource Scheduling <span class="highlight-title">Optimization</span> Subject to
  Sector-Bound Nonlinearity and Latency 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06167v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06167v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohammadreza Doostmohammadian, Zulfiya R. Gabidullina, Hamid R. Rabiee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper proposes an accelerated consensus-based distributed iterative
algorithm for resource allocation and scheduling. The proposed
gradient-tracking algorithm introduces an auxiliary variable to add momentum
towards the optimal state. We prove that this solution is all-time feasible,
implying that the coupling constraint always holds along the algorithm
iterative procedure; therefore, the algorithm can be terminated at any time.
This is in contrast to the ADMM-based solutions that meet constraint
feasibility asymptotically. Further, we show that the proposed algorithm can
handle possible link nonlinearity due to logarithmically-quantized data
transmission (or any sign-preserving odd sector-bound nonlinear mapping). We
prove convergence over uniformly-connected dynamic networks (i.e., a hybrid
setup) that may occur in mobile and time-varying multi-agent networks. Further,
the latency issue over the network is addressed by proposing delay-tolerant
solutions. To our best knowledge, accelerated momentum-based convergence,
nonlinear linking, all-time feasibility, uniform network connectivity, and
handling (possible) time delays are not altogether addressed in the literature.
These contributions make our solution practical in many real-world
applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Elsevier, Systems & Control Letters</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Natural Gradient Descent for Control 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06070v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06070v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ramin Esmzad, Farnaz Adib Yaghmaie, Hamidreza Modares
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper bridges optimization and control, and presents a novel closed-loop
control framework based on natural gradient descent, offering a
trajectory-oriented alternative to traditional cost-function tuning. By
leveraging the Fisher Information Matrix, we formulate a preconditioned
gradient descent update that explicitly shapes system trajectories. We show
that, in sharp contrast to traditional controllers, our approach provides
flexibility to shape the system's low-level behavior. To this end, the proposed
method parameterizes closed-loop dynamics in terms of stationary covariance and
an unknown cost function, providing a geometric interpretation of control
adjustments. We establish theoretical stability conditions. The simulation
results on a rotary inverted pendulum benchmark highlight the advantages of
natural gradient descent in trajectory shaping.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to ASME Letters in Dynamic Systems and Control (ALDSC)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A 2-6 GHz Ultra-Wideband CMOS Transceiver for Radar Applications 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06057v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06057v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alin Thomas Tharakan, Prince Phillip, Gokulan T, Sumit Kumar, Gaurab Banerjee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents a low power, low cost transceiver architecture to
implement radar-on-a-chip. The transceiver comprises of a full ultra-wideband
(UWB) transmitter and a full UWB band receiver. A design methodology to
maximize the tuning range of the voltage-controlled oscillator (VCO) is
presented. At the transmitter side, a sub-harmonic mixer is used for signal
up-conversion. The receiver low noise amplifier (LNA) has a 2 to 6 GHz input
matching bandwidth with a power gain of 9 dB and a noise figure of 2.5 dB. The
transceiver is implemented in Cadence EDA tools using 65nm CMOS technology. The
system achieves a total dc power consumption of 50 mW. Good noise figure
performance; good wide-band matching; gain; high level of integration; low
power; low cost of the proposed UWB radar transceiver front-end make it a
highly competitive SoC solution for low power UWB transceivers.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Energy-Efficient Motion <span class="highlight-title">Plan</span>ner for Legged Robots 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06050v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06050v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alexander Schperberg, Marcel Menner, Stefano Di Cairano
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose an online motion planner for legged robot locomotion with the
primary objective of achieving energy efficiency. The conceptual idea is to
leverage a placement set of footstep positions based on the robot's body
position to determine when and how to execute steps. In particular, the
proposed planner uses virtual placement sets beneath the hip joints of the legs
and executes a step when the foot is outside of such placement set.
Furthermore, we propose a parameter design framework that considers both
energy-efficiency and robustness measures to optimize the gait by changing the
shape of the placement set along with other parameters, such as step height and
swing time, as a function of walking speed. We show that the planner produces
trajectories that have a low Cost of Transport (CoT) and high robustness
measure, and evaluate our approach against model-free Reinforcement Learning
(RL) and motion imitation using biological dog motion priors as the reference.
Overall, within low to medium velocity range, we show a 50.4% improvement in
CoT and improved robustness over model-free RL, our best performing baseline.
Finally, we show ability to handle slippery surfaces, gait transitions, and
disturbances in simulation and hardware with the Unitree A1 robot.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 8 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ TeraSim: Uncovering Unknown Unsafe Events for Autonomous Vehicles
  through Generative Simulation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03629v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03629v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haowei Sun, Xintao Yan, Zhijie Qiao, Haojie Zhu, Yihao Sun, Jiawei Wang, Shengyin Shen, Darian Hogue, Rajanikant Ananta, Derek Johnson, Greg Stevens, Greg McGuire, Yifan Wei, Wei Zheng, Yong Sun, Yasuo Fukai, Henry X. Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Traffic simulation is essential for autonomous vehicle (AV) development,
enabling comprehensive safety evaluation across diverse driving conditions.
However, traditional rule-based simulators struggle to capture complex human
interactions, while data-driven approaches often fail to maintain long-term
behavioral realism or generate diverse safety-critical events. To address these
challenges, we propose TeraSim, an open-source, high-fidelity traffic
simulation platform designed to uncover unknown unsafe events and efficiently
estimate AV statistical performance metrics, such as crash rates. TeraSim is
designed for seamless integration with third-party physics simulators and
standalone AV stacks, to construct a complete AV simulation system.
Experimental results demonstrate its effectiveness in generating diverse
safety-critical events involving both static and dynamic agents, identifying
hidden deficiencies in AV systems, and enabling statistical performance
evaluation. These findings highlight TeraSim's potential as a practical tool
for AV safety assessment, benefiting researchers, developers, and policymakers.
The code is available at https://github.com/mcity/TeraSim.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Robust time series generation via Schrödinger Bridge: a comprehensive
  evaluation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.02943v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.02943v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alexandre Alouadi, Baptiste Barreau, Laurent Carlier, Huyên Pham
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We investigate the generative capabilities of the Schr\"odinger Bridge (SB)
approach for time series. The SB framework formulates time series synthesis as
an entropic optimal interpolation transport problem between a reference
probability measure on path space and a target joint distribution. This results
in a stochastic differential equation over a finite horizon that accurately
captures the temporal dynamics of the target time series. While the SB approach
has been largely explored in fields like image generation, there is a scarcity
of studies for its application to time series. In this work, we bridge this gap
by conducting a comprehensive evaluation of the SB method's robustness and
generative performance. We benchmark it against state-of-the-art (SOTA) time
series generation methods across diverse datasets, assessing its strengths,
limitations, and capacity to model complex temporal dependencies. Our results
offer valuable insights into the SB framework's potential as a versatile and
robust tool for time series generation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Recursively Feasible Chance-constrained <span class="highlight-title">Model Predictive</span> Control under
  Gaussian Mixture Model Uncertainty 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.03799v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.03799v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kai Ren, Colin Chen, Hyeontae Sung, Heejin Ahn, Ian Mitchell, Maryam Kamgarpour
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a chance-constrained model predictive control (MPC) framework
under Gaussian mixture model (GMM) uncertainty. Specifically, we consider the
uncertainty that arises from predicting future behaviors of moving obstacles,
which may exhibit multiple modes (for example, turning left or right). To
address the multi-modal uncertainty distribution, we propose three MPC
formulations: nominal chance-constrained planning, robust chance-constrained
planning, and contingency planning. We prove that closed-loop trajectories
generated by the three planners are safe. The approaches differ in
conservativeness and performance guarantee. In particular, the robust
chance-constrained planner is recursively feasible under certain assumptions on
the propagation of prediction uncertainty. On the other hand, the contingency
planner generates a less conservative closed-loop trajectory than the nominal
planner. We validate our planners using state-of-the-art trajectory prediction
algorithms in autonomous driving simulators.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published in IEEE Transactions on Control Systems Technology SI:
  Intelligent Decision Making, Planning and Control of Automated Vehicles</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Underwater Motions Analysis and Control of a Coupling-Tiltable Unmanned
  Aerial-Aquatic Vehicle <span class="chip">ICRA</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.07290v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.07290v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dongyue Huang, Minghao Dou, Xuchen Liu, Tao Sun, Jianguo Zhang, Ning Ding, Xinlei Chen, Ben M. Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Coupling-Tiltable Unmanned Aerial-Aquatic Vehicles (UAAVs) have gained
increasing importance, yet lack comprehensive analysis and suitable
controllers. This paper analyzes the underwater motion characteristics of a
self-designed UAAV, Mirs-Alioth, and designs a controller for it. The
effectiveness of the controller is validated through experiments. The
singularities of Mirs-Alioth are derived as Singular Thrust Tilt Angle (STTA),
which serve as an essential tool for an analysis of its underwater motion
characteristics. The analysis reveals several key factors for designing the
controller. These include the need for logic switching, using a Nussbaum
function to compensate control direction uncertainty in the auxiliary channel,
and employing an auxiliary controller to mitigate coupling effects. Based on
these key points, a control scheme is designed. It consists of a controller
that regulates the thrust tilt angle to the singular value, an auxiliary
controller incorporating a Saturated Nussbaum function, and a logic switch.
Eventually, two sets of experiments are conducted to validate the effectiveness
of the controller and demonstrate the necessity of the Nussbaum function.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This paper has been accepted for publication in the IEEE
  International Conference on Robotics and Automation(ICRA), 2025. Please cite
  the paper using appropriate formats</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Finite Sample Performance Analysis of MIMO Systems Identification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.11790v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.11790v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shuai Sun, Jiayun Li, Yilin Mo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper is concerned with the finite sample identification performance of
an n dimensional discrete-time Multiple-Input Multiple-Output (MIMO) Linear
Time-Invariant system, with p inputs and m outputs. We prove that the
widely-used Ho-Kalman algorithm and Multivariable Output Error State Space
(MOESP) algorithm are ill-conditioned for MIMO systems when n/m or n/p is
large. Moreover, by analyzing the Cra\'mer-Rao bound, we derive a fundamental
limit for identifying the real and stable (or marginally stable) poles of MIMO
system and prove that the sample complexity for any unbiased pole estimation
algorithm to reach a certain level of accuracy explodes superpolynomially with
respect to n/(pm). Numerical results are provided to illustrate the
ill-conditionedness of Ho-Kalman algorithm and MOESP algorithm as well as the
fundamental limit on identification.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Optimization and Control <span class="chip" style="font-size: 60%">12</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Exploiting Edited Large Language Models as General Scientific Optimizers 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.09620v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.09620v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qitan Lv, Tianyu Liu, Hong Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have been widely adopted in mathematical
optimization in scientific scenarios for their extensive knowledge and advanced
reasoning capabilities. Existing methods mainly focus on utilizing LLMs to
solve optimization problems in a prompt-based manner, which takes observational
feedback as additional textual descriptions. However, due to LLM's \textbf{high
sensitivity to the prompts} and \textbf{tendency to get lost in lengthy
prompts}, these methods struggle to effectively utilize the {observational}
feedback from each optimization step, which severely hinders the applications
for real-world scenarios. To address these challenges, we propose a
conceptually simple and general {bi-level} optimization method, namely
\textbf{G}eneral \textbf{S}cientific \textbf{O}ptimizers (GSO). Specifically,
GSO first utilizes inner-level simulators as experimental platforms to evaluate
the current solution and provide observational feedback. Then, LLMs serve as
knowledgeable and versatile scientists, generating new solutions by refining
potential errors from the feedback as the outer-level optimization. Finally,
simulations together with the expert knowledge in LLMs are jointly updated with
bi-level interactions via model editing. Extensive experiments show that GSO
consistently outperforms existing state-of-the-art methods using \textit{six}
different LLM backbones on \textit{seven} different tasks, demonstrating the
effectiveness and a wide range of applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Modified Bregman Golden Ratio Algorithm for Mixed Variational Inequality
  Problems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06285v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06285v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gourav Kumar, V. Vetrivel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this article, we provide a modification to the Bregman Golden Ratio
Algorithm (B-GRAAL). We analyze the B-GRAAL algorithm with a new step size
rule, where the step size increases after a certain number of iterations and
does not require prior knowledge of the global Lipschitz constant of the cost
operator. Under suitable assumptions, we establish the global iterate
convergence as well as the R-linear rate of convergence of the modified
algorithm. The numerical performance of the proposed approach is validated for
the matrix game problem and the sparse logistic regression problem in machine
learning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages, 12 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Broyden quasi-Newton secant-type method for solving constrained mixed
  generalized equations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06206v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06206v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        P. C. da Silva Junior, O. P. Ferreira, G. N. Silva
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents a novel variant of the Broyden quasi-Newton secant-type
method aimed at solving constrained mixed generalized equations, which can
include functions that are not necessarily differentiable. The proposed method
integrates the classical secant approach with techniques inspired by the
Conditional Gradient method to handle constraints effectively. We establish
local convergence results by applying the contraction mapping principle.
Specifically, under assumptions of Lipschitz continuity, a modified Broyden
update for derivative approximation, and the metric regularity property, we
show that the algorithm generates a well-defined sequence that converges
locally at a Q-linear rate.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ An adaptive ADMM with regularized spectral penalty for sparse portfolio
  selection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06185v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06185v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xin Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The mean-variance (MV) model is the core of modern portfolio theory.
Nevertheless, it suffers from the over-fitting problem due to the estimation
errors of model parameters. We consider the $\ell_{1}$ regularized MV model,
which adds an $\ell_{1}$ regularization term in the objective to prevent
over-fitting and promote sparsity of solutions. By investigating the
relationship between sample size and over-fitting, we propose an initial
regularization parameter scheme in the $\ell_{1}$ regularized MV model. Then we
propose an adaptive parameter tuning strategy to control the amount of short
sales. ADMM is a well established algorithm whose performance is affected by
the penalty parameter. In this paper, a penalty parameter scheme based on
regularized Barzilai-Borwein step size is proposed, and the modified ADMM is
used to solve the $\ell_{1}$ regularized MV problem. Numerical results verify
the effectiveness of the two types of parameters proposed in this paper.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Momentum-based Distributed Resource Scheduling <span class="highlight-title">Optimization</span> Subject to
  Sector-Bound Nonlinearity and Latency 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06167v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06167v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohammadreza Doostmohammadian, Zulfiya R. Gabidullina, Hamid R. Rabiee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper proposes an accelerated consensus-based distributed iterative
algorithm for resource allocation and scheduling. The proposed
gradient-tracking algorithm introduces an auxiliary variable to add momentum
towards the optimal state. We prove that this solution is all-time feasible,
implying that the coupling constraint always holds along the algorithm
iterative procedure; therefore, the algorithm can be terminated at any time.
This is in contrast to the ADMM-based solutions that meet constraint
feasibility asymptotically. Further, we show that the proposed algorithm can
handle possible link nonlinearity due to logarithmically-quantized data
transmission (or any sign-preserving odd sector-bound nonlinear mapping). We
prove convergence over uniformly-connected dynamic networks (i.e., a hybrid
setup) that may occur in mobile and time-varying multi-agent networks. Further,
the latency issue over the network is addressed by proposing delay-tolerant
solutions. To our best knowledge, accelerated momentum-based convergence,
nonlinear linking, all-time feasibility, uniform network connectivity, and
handling (possible) time delays are not altogether addressed in the literature.
These contributions make our solution practical in many real-world
applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Elsevier, Systems & Control Letters</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The uniqueness of Lyapunov rank among symmetric cones 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06143v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06143v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Michael Orlitzky, Giovanni Barbarino
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The Lyapunov rank of a cone is the dimension of the Lie algebra of its
automorphism group. It is invariant under linear isomorphism and in general not
unique - two or more non-isomorphic cones can share the same Lyapunov rank. It
is therefore not possible in general to identify cones using Lyapunov rank. But
suppose we look only among symmetric cones. Are there any that can be uniquely
identified (up to isomorphism) by their Lyapunov ranks? We provide a complete
answer for irreducible cones and make some progress in the general case.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Natural Gradient Descent for Control 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06070v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06070v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ramin Esmzad, Farnaz Adib Yaghmaie, Hamidreza Modares
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper bridges optimization and control, and presents a novel closed-loop
control framework based on natural gradient descent, offering a
trajectory-oriented alternative to traditional cost-function tuning. By
leveraging the Fisher Information Matrix, we formulate a preconditioned
gradient descent update that explicitly shapes system trajectories. We show
that, in sharp contrast to traditional controllers, our approach provides
flexibility to shape the system's low-level behavior. To this end, the proposed
method parameterizes closed-loop dynamics in terms of stationary covariance and
an unknown cost function, providing a geometric interpretation of control
adjustments. We establish theoretical stability conditions. The simulation
results on a rotary inverted pendulum benchmark highlight the advantages of
natural gradient descent in trajectory shaping.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to ASME Letters in Dynamic Systems and Control (ALDSC)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Dynamic Programming in Ordered Vector Space 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06055v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06055v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nisha Peng, John Stachurski
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent approaches to the theory of dynamic programming view dynamic programs
as families of policy operators acting on partially ordered sets. In this
paper, we extend these ideas by shifting from arbitrary partially ordered sets
to ordered vector space. The advantage of working in this setting is that
ordered vector spaces have well integrated algebric and order structure, which
leads to sharper fixed point results. These fixed point results can then be
exploited to obtain strong optimality properties. We illustrate our results
through a range of applications, including new findings for several useful
models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ <span class="highlight-title">Optimization</span> models for needle placement in 3D-printed masks for high
  dose rate brachytherapy 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.06000v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.06000v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nasim Mirzavand Boroujeni, Jean-Philippe P. Richard, David Sterling, Christopher Wilke
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  High dose rate brachytherapy (HDR-BT) is an appealing treatment option for
superficial cancers that permits the delivery of higher local doses than other
radiation modalities without a significant increase in toxicity. In order for
HDR-BT to be used in these situations, needles through which the radiation
source is passed must be strategically placed in close proximity to the
patient's body. Currently, this crucial step is performed manually by
physicians or medical physicists. The use of 3D-printed masks customized for
individual patients has been advocated as a way to more precisely and securely
position these needles, with the potential of producing better and safer
treatment plans. In this paper, we propose optimization approaches for
positioning needles within 3D-printed masks for HDR-BT, focusing on skin
cancers. We numerically show that the models we propose efficiently generate
more homogeneous plans than those derived manually and provide an alternative
to manual placement that can save planning time and enhance plan quality.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Column generation for multistage stochastic mixed-integer nonlinear
  programs with discrete state variables 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.05052v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.05052v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tushar Rathi, Benjamin P. Riley, Angela Flores-Quiroz, Qi Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Stochastic programming provides a natural framework for modeling sequential
optimization problems under uncertainty; however, the efficient solution of
large-scale multistage stochastic programs remains a challenge, especially in
the presence of discrete decisions and nonlinearities. In this work, we
consider multistage stochastic mixed-integer nonlinear programs (MINLPs) with
discrete state variables, which exhibit a decomposable structure that allows
its solution using a column generation approach. Following a Dantzig-Wolfe
reformulation, we apply column generation such that each pricing subproblem is
an MINLP of much smaller size, making it more amenable to global MINLP solvers.
We further propose a method for generating additional columns that satisfy the
nonanticipativity constraints, leading to significantly improved convergence
and optimal or near-optimal solutions for many large-scale instances in a
reasonable computation time. The effectiveness of the tailored column
generation algorithm is demonstrated via computational case studies on a
multistage blending problem and a problem involving the routing of mobile
generators in a power distribution network.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>31 pages, 10 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MGDA Converges under Generalized Smoothness, Provably 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.19440v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.19440v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qi Zhang, Peiyao Xiao, Shaofeng Zou, Kaiyi Ji
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multi-objective optimization (MOO) is receiving more attention in various
fields such as multi-task learning. Recent works provide some effective
algorithms with theoretical analysis but they are limited by the standard
$L$-smooth or bounded-gradient assumptions, which typically do not hold for
neural networks, such as Long short-term memory (LSTM) models and Transformers.
In this paper, we study a more general and realistic class of generalized
$\ell$-smooth loss functions, where $\ell$ is a general non-decreasing function
of gradient norm. We revisit and analyze the fundamental multiple gradient
descent algorithm (MGDA) and its stochastic version with double sampling for
solving the generalized $\ell$-smooth MOO problems, which approximate the
conflict-avoidant (CA) direction that maximizes the minimum improvement among
objectives. We provide a comprehensive convergence analysis of these algorithms
and show that they converge to an $\epsilon$-accurate Pareto stationary point
with a guaranteed $\epsilon$-level average CA distance (i.e., the gap between
the updating direction and the CA direction) over all iterations, where totally
$\mathcal{O}(\epsilon^{-2})$ and $\mathcal{O}(\epsilon^{-4})$ samples are
needed for deterministic and stochastic settings, respectively. We prove that
they can also guarantee a tighter $\epsilon$-level CA distance in each
iteration using more samples. Moreover, we analyze an efficient variant of MGDA
named MGDA-FA using only $\mathcal{O}(1)$ time and space, while achieving the
same performance guarantee as MGDA.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Convergence Guarantees for RMSProp and Adam in Generalized-smooth
  Non-convex <span class="highlight-title">Optimization</span> with Affine Noise Variance 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.01436v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.01436v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qi Zhang, Yi Zhou, Shaofeng Zou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper provides the first tight convergence analyses for RMSProp and Adam
in non-convex optimization under the most relaxed assumptions of
coordinate-wise generalized smoothness and affine noise variance. We first
analyze RMSProp, which is a special case of Adam with adaptive learning rates
but without first-order momentum. Specifically, to solve the challenges due to
dependence among adaptive update, unbounded gradient estimate and Lipschitz
constant, we demonstrate that the first-order term in the descent lemma
converges and its denominator is upper bounded by a function of gradient norm.
Based on this result, we show that RMSProp with proper hyperparameters
converges to an $\epsilon$-stationary point with an iteration complexity of
$\mathcal O(\epsilon^{-4})$. We then generalize our analysis to Adam, where the
additional challenge is due to a mismatch between the gradient and first-order
momentum. We develop a new upper bound on the first-order term in the descent
lemma, which is also a function of the gradient norm. We show that Adam with
proper hyperparameters converges to an $\epsilon$-stationary point with an
iteration complexity of $\mathcal O(\epsilon^{-4})$. Our complexity results for
both RMSProp and Adam match with the complexity lower bound established in
\cite{arjevani2023lower}.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2025-03-07T00:00:00Z">2025-03-07</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Systems and Control <span class="chip" style="font-size: 60%">27</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Learning about passivity from data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.05989v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.05989v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alexandre Sanfelici Bazanella
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents a data-driven methodology to estimate the storage
function of a passive system. The methodology consists in parametrizing the
storage function with a dictionary then running a linear program. Results on a
benchmark are presented to illustrate its properties, including its robustness
to noise. Various uses of the storage function that do not require knowledge of
a model are also discussed.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Kinodynamic <span class="highlight-title">Model Predictive</span> Control for Energy Efficient <span class="highlight-title">Locomotion</span> of
  Legged Robots with Parallel Elasticity <span class="chip">ICRA 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.05666v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.05666v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yulun Zhuang, Yichen Wang, Yanran Ding
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we introduce a kinodynamic model predictive control (MPC)
framework that exploits unidirectional parallel springs (UPS) to improve the
energy efficiency of dynamic legged robots. The proposed method employs a
hierarchical control structure, where the solution of MPC with simplified
dynamic models is used to warm-start the kinodynamic MPC, which accounts for
nonlinear centroidal dynamics and kinematic constraints. The proposed approach
enables energy efficient dynamic hopping on legged robots by using UPS to
reduce peak motor torques and energy consumption during stance phases.
Simulation results demonstrated a 38.8% reduction in the cost of transport
(CoT) for a monoped robot equipped with UPS during high-speed hopping.
Additionally, preliminary hardware experiments show a 14.8% reduction in energy
consumption. Video: https://youtu.be/AF11qMXJD48
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>7 pages, 6 figures. Accepted for publication at ICRA 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Design, Dynamic Modeling and Control of a 2-DOF Robotic Wrist Actuated
  by Twisted and Coiled Actuators 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.05508v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.05508v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yunsong Zhang, Xinyu Zhou, Feitian Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Robotic wrists play a pivotal role in the functionality of industrial
manipulators and humanoid robots, facilitating manipulation and grasping tasks.
In recent years, there has been a growing interest in integrating artificial
muscle-driven actuators for robotic wrists, driven by advancements in
technology offering high energy density, lightweight construction, and compact
designs. However, in the study of robotic wrists driven by artificial muscles,
dynamic model-based controllers are often overlooked, despite their critical
importance for motion analysis and dynamic control of robots. This paper
presents a novel design of a two-degree-of-freedom (2-DOF) robotic wrist driven
by twisted and coiled actuators (TCA) utilizing a parallel mechanism with a
3RRRR configuration. The proposed robotic wrist is expected to feature
lightweight structures and superior motion performance while mitigating
friction issues. The Lagrangian dynamic model of the wrist is established,
along with a nonlinear model predictive controller (NMPC) designed for
trajectory tracking tasks. A prototype of the robotic wrist is developed, and
extensive experiments are conducted to validate its superior motion performance
and the proposed dynamic model. Subsequently, extensive comparative experiments
between NMPC and PID controller were conducted under various operating
conditions. The experimental results demonstrate the effectiveness and
robustness of the dynamic model-based controller in the motion control of
TCA-driven robotic wrists.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Generating Building-Level Heat Demand Time Series by Combining Occupancy
  Simulations and Thermal Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.05427v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.05427v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Simon Malacek, José Portela, Yannick Marcus Werner, Sonja Wogrin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite various efforts, decarbonizing the heating sector remains a
significant challenge. To tackle it by smart planning, the availability of
highly resolved heating demand data is key. Several existing models provide
heating demand only for specific applications. Typically, they either offer
time series for a larger area or annual demand data on a building level, but
not both simultaneously. Additionally, the diversity in heating demand across
different buildings is often not considered. To address these limitations, this
paper presents a novel method for generating temporally resolved heat demand
time series at the building level using publicly available data. The approach
integrates a thermal building model with stochastic occupancy simulations that
account for variability in user behavior. As a result, the tool serves as a
cost-effective resource for cross-sectoral energy system planning and policy
development, particularly with a focus on the heating sector. The obtained data
can be used to assess the impact of renovation and retrofitting strategies, or
to analyze district heating expansion. To illustrate the potential applications
of this approach, we conducted a case study in Puertollano (Spain), where we
prepared a dataset of heating demand with hourly resolution for each of 9,298
residential buildings. This data was then used to compare two different
pathways for the thermal renovation of these buildings. By relying on publicly
available data, this method can be adapted and applied to various European
regions, offering broad usability in energy system optimization and analysis of
decarbonization strategies.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Data-Driven Decision Making for Enhancing Small-Signal Stability in
  Hybrid AC/DC Grids Through Converter Control Role Assignment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.05386v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.05386v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Francesca Rossi, Sergi Costa Dilme, Josep Arevalo-Soler, Eduardo Prieto-Araujo, Oriol Gomis-Bellmunt
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Hybrid AC/DC transmission grids incorporate Modular Multilevel Converters
functioning as Interconnecting Power Converters (IPCs). The control role
assigned to each converter significantly influences grid dynamics.
Traditionally, these converters operate with static control roles, but recent
studies have proposed scheduling their roles based on day-ahead forecasts to
enhance stability performance. However, in systems with high renewable energy
penetration, forecast deviations can render scheduled control assignments
suboptimal or even lead to instability. To address this challenge, this work
proposes an online scheduling recalculation algorithm that dynamically adapts
IPC control roles during system operation. The approach leverages a data-driven
multi-criteria decision-making framework, integrating surrogate models of
conventional small-signal stability analysis tools to enable a fast computation
of system stability and stability performance indicators.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Risk-aware Bi-level Bidding Strategy for Virtual Power <span class="highlight-title">Plan</span>t with
  Power-to-Hydrogen System 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.05366v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.05366v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jaehyun Yoo, Jip Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents a risk-aware bi-level bidding strategy for Virtual Power
Plant (VPP) that integrates Power-to-Hydrogen (P2H) system, addressing the
challenges posed by renewable energy variability and market volatility. By
incorporating Conditional Value at Risk (CVaR) within the bi-level optimization
framework, the proposed strategy enables VPPs to mitigate financial risks
associated with uncertain market conditions. The upper-level problem seeks to
maximize revenue through optimal bidding, while the lower-level problem ensures
market-clearing compliance. The integration of the P2H system allows surplus
renewable energy to be stored as hydrogen, which is utilized as an energy
carrier, thereby increasing market profitability and enhancing resilience
against financial risks. The effectiveness of the proposed strategy is
validated through a modified IEEE 14 bus system, demonstrating that the
inclusion of the P2H system and CVaR-based risk aversion enhances both revenue
and financial hedging capability under volatile market conditions.This paper
underscores the strategic role of hydrogen storage in VPP operations,
contributing to supporting improved profitability and the efficacy of a
risk-aware bidding strategy.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages, 5 figures, 2025 PES General Meeting</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Community Energy Management System for Fast Frequency Response: A
  Hierarchical Control Approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.05361v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.05361v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Joonsung Jung, Hyunjoong Kim, Hyunghwan Shin, Jip Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The increase in renewable energy sources (RES) has reduced power system
inertia, making frequency stabilization more challenging and highlighting the
need for fast frequency response (FFR) resources. While building energy
management systems (BEMS) equipped with distributed energy resources (DERs) can
provide FFR, individual BEMS alone cannot fully meet demand. To address this,
we propose a community energy management system (CEMS) operational model that
minimizes energy costs and generates additional revenue, which is provided FFR
through coordinated DERs and building loads under photovoltaic (PV) generation
uncertainty. The model incorporates a hierarchical control framework with three
levels: Level 1 allocates maximum FFR capacity, Level 2 employs scenario-based
stochastic model predictive control (SMPC) to adjust DER operations and ensure
FFR provision despite PV uncertainties, and Level 3 performs rapid load
adjustments in response to frequency fluctuations detected by a frequency
meter. Simulation results on a campus building cluster demonstrate the
effectiveness of the proposed model, achieving a 10\% reduction in energy costs
and a 24\% increase in FFR capacity, all while maintaining occupant comfort and
enhancing frequency stabilization.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages, 7 figures, submitted to PES General Meeting 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Environment-Aware Scheduling of URLLC and Sensing Services for Smart
  Industries 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.05313v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.05313v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Navid Keshtiarast, Pradyumna Kumar Bishoyi, Marina Petrova
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we address the problem of scheduling sensing and communication
functionality in an integrated sensing and communication (ISAC) enabled base
station (BS) operating in an indoor factory (InF) environment. The BS is
performing the task of detecting an AGV while managing downlink transmission of
ultra-reliable low-latency communication (URLLC) data in a time-sharing manner.
Scheduling fixed time slots for both sensing and communication is inefficient
for the InF environment, as the instantaneous environmental changes necessitate
a higher frequency of sensing operations to accurately detect the AGV. To
address this issue, we propose an environment-aware scheduling scheme, in which
we first formulate an optimization problem to maximize the probability of
detection of AGV while considering the survival time constraint of URLLC data.
Subsequently, utilizing the Nash bargaining theory, we propose an adaptive
time-sharing scheme that assigns sensing duration in accordance with the
environmental clutter density and distributes time to URLLC depending on the
incoming traffic rate. Using our own Python-based discrete-event link-level
simulator, we demonstrate the effectiveness of our proposed scheme over the
baseline scheme in terms of probability of detection and downlink latency.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This work has been accepted for publication in the IEEE ICC 2025
  Conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Identification of Minimally Restrictive Assembly Sequences using
  Supervisory Control Theory 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.05285v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.05285v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Martina Vinetti, Martin Fabian
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Modern assembly processes require flexibility and adaptability to handle
increasing product variety and customization. Traditional assembly planning
methods often prioritize finding an optimal assembly sequence, overlooking the
requirements of contemporary manufacturing. This work uses Supervisory Control
Theory to systematically generate all feasible assembly sequences while
ensuring compliance with precedence and process constraints. By synthesizing a
controllable, non-blocking, and minimally restrictive supervisor, the proposed
method guarantees that only valid sequences are allowed, balancing flexibility
and constraint enforcement. The obtained sequences can serve as a basis for
further optimization or exception management, improving responsiveness to
disruptions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Evaluation of 3D Terrestrial and Aerial Spectrum Sharing with Massive
  MIMO Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.05279v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.05279v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Achiel Colpaert, Zhuangzhuang Cui, Sofie Pollin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Connecting aerial and terrestrial users with a single base station (BS) is
increasingly challenging due to the rising number of aerial users like unmanned
aerial vehicles (UAVs). Traditional BSs, designed with down-tilted beams, focus
mainly on ground users, but massive MIMO (mMIMO) systems can significantly
enhance coverage in low-altitude airspace. This paper analyzes how a mMIMO BS
serves both aerial and terrestrial users in a 3D spectrum-sharing scheme. Using
Semi-orthogonal User Selection (SUS) and random scheduling, we assess the
spectral efficiency and performance limits of these systems. Results reveal
that mMIMO effectively supports more terrestrial users, influenced by channel
characteristics and user scheduling strategies, providing key insights for
future 3D aerial-terrestrial networks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages, 6 figures, EUCAP 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On reconstructing high derivatives of noisy time-series with confidence
  intervals 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.05222v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.05222v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mazen Alamir
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reconstructing high derivatives of noisy measurements is an important step in
many control, identification and diagnosis problems. In this paper, a heuristic
is proposed to address this challenging issue. The framework is based on a
dictionary of identified models indexed by the bandwidth, the noise level and
the required degrees of derivation. Each model in the dictionary is identified
via cross-validation using tailored learning data. It is also shown that the
proposed approach provides heuristically defined confidence intervals on the
resulting estimation. The performance of the framework is compared to the
state-of-the-art available algorithms showing noticeably higher accuracy.
Although the results are shown for up to the 4-th derivative, higher derivation
orders can be used with comparable results.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages; 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Merry-Go-Round: Safe Control of Decentralized Multi-Robot Systems with
  Deadlock Prevention 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.05848v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.05848v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wonjong Lee, Joonyeol Sim, Joonkyung Kim, Siwon Jo, Wenhao Luo, Changjoo Nam
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose a hybrid approach for decentralized multi-robot navigation that
ensures both safety and deadlock prevention. Building on a standard control
formulation, we add a lightweight deadlock prevention mechanism by forming
temporary "roundabouts" (circular reference paths). Each robot relies only on
local, peer-to-peer communication and a controller for base collision
avoidance; a roundabout is generated or joined on demand to avert deadlocks.
Robots in the roundabout travel in one direction until an escape condition is
met, allowing them to return to goal-oriented motion. Unlike classical
decentralized methods that lack explicit deadlock resolution, our roundabout
maneuver ensures system-wide forward progress while preserving safety
constraints. Extensive simulations and physical robot experiments show that our
method consistently outperforms or matches the success and arrival rates of
other decentralized control approaches, particularly in cluttered or
high-density scenarios, all with minimal centralized coordination.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>7 pages, 7 Figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Sparse identification of nonlinear dynamics with high accuracy and
  reliability under noisy conditions for applications to industrial systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.05154v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.05154v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shuichi Yahagi, Ansei Yonezawa, Hiroki Seto, Heisei Yonezawa, Itsuro Kajiwara
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper proposes a sparse identification of nonlinear dynamics (SINDy)
with control and exogenous inputs for highly accurate and reliable prediction
and applies the proposed method to the diesel engine airpath systems which are
known as a nonlinear complicated industrial system. Although SINDy is known as
a powerful approach for the identification of nonlinear systems, some problems
remain: there are few examples of application to industrial systems and
multi-step predictions are not guaranteed due to noisy data and an increase of
basis functions due to the extension of the coordinate such as time-delay
embedding. To address the problems, we propose an improved SINDy based on
ensemble learning, elite gathering, and classification techniques while keeping
convex calculation. In the proposed method, library bagging is performed, and
elites with an R-squared greater than 90% are gathered. Then, clustering is
performed on the surviving elites because physically motivated basis functions
are not always available and the elite models obtained do not always show the
same trends. After the classification, discrete model candidates are obtained
by taking the mean of each classified elite. Finally, the best model is
selected. The simulation results show that the proposed method realizes
multi-step prediction for the airpath system which is known as a complicated
industrial system under noisy conditions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhanced Koopman Operator Approximation for Nonlinear Systems Using
  Broading Learning System 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.05844v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.05844v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yangjun Sun, Zhiliang Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Traditional control methods often show limitations in dealing with complex
nonlinear systems, especially when it is difficult to accurately obtain the
exact system model, and the control accuracy and stability are difficult to
guarantee. To solve this problem, the Koopman operator theory provides an
effective method to linearise nonlinear systems, which simplifies the analysis
and control of the system by mapping the nonlinear dynamics into a
high-dimensional space. However, the existing extended dynamical mode
decomposition (EDMD) methods suffer from randomness in the selection of basis
functions, which leads to bias in the finite-dimensional approximation to the
Koopman operator, thus affecting the accuracy of model prediction. To solve
this problem, this paper proposes a BLS-EDMD method based on the Broad learning
system (BLS) network. The method achieves a high-precision approximation to the
Koopman operator by learning more accurate basis functions, which significantly
improves the prediction ability of the model. Building on this, we further
develop a model predictive controller (MPC) called BE-MPC. This controller
directly utilises the high-dimensional and high-precision predictors generated
by BLS-EDMD to predict the system state more accurately, thus achieving precise
control of the underwater unmanned vehicle (UUV), and its effectiveness is
verified by simulation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, 9 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Optimal and Robust Multivariable Reaching Time Sliding Mode Control
  Design 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.05083v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.05083v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        J. C. Geromel, L. Hsu, E. V. L. Nunes
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper addresses two minimum reaching time control problems within the
context of finite stable systems. The well-known Variable Structure Control
(VSC) and Unity Vector Control (UVC) strategies are analyzed, with the primary
objective of designing optimal and robust state feedback gains that ensure
minimum finite time convergence to the origin. This is achieved in the presence
of convex bounded parameter uncertainty and norm-bounded exogenous
disturbances. In both cases, the optimality conditions are expressed through
Linear Matrix Inequalities (LMIs), which are solved efficiently within the
framework of multivariable systems using existing numerical tools. The
theoretical results are demonstrated with two practically motivated examples.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Fitted Q-Iteration via Max-Plus-Linear Approximation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.08422v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.08422v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Y. Liu, M. A. S. Kolarijani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this study, we consider the application of max-plus-linear approximators
for Q-function in offline reinforcement learning of discounted Markov decision
processes. In particular, we incorporate these approximators to propose novel
fitted Q-iteration (FQI) algorithms with provable convergence. Exploiting the
compatibility of the Bellman operator with max-plus operations, we show that
the max-plus-linear regression within each iteration of the proposed FQI
algorithm reduces to simple max-plus matrix-vector multiplications. We also
consider the variational implementation of the proposed algorithm which leads
to a per-iteration complexity that is independent of the number of samples.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Coordinate-based neural representations for computational adaptive
  optics in widefield microscopy 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2307.03812v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2307.03812v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Iksung Kang, Qinrong Zhang, Stella X. Yu, Na Ji
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Widefield microscopy is widely used for non-invasive imaging of biological
structures at subcellular resolution. When applied to complex specimen, its
image quality is degraded by sample-induced optical aberration. Adaptive optics
can correct wavefront distortion and restore diffraction-limited resolution but
require wavefront sensing and corrective devices, increasing system complexity
and cost. Here, we describe a self-supervised machine learning algorithm,
CoCoA, that performs joint wavefront estimation and three-dimensional
structural information extraction from a single input 3D image stack without
the need for external training dataset. We implemented CoCoA for widefield
imaging of mouse brain tissues and validated its performance with
direct-wavefront-sensing-based adaptive optics. Importantly, we systematically
explored and quantitatively characterized the limiting factors of CoCoA's
performance. Using CoCoA, we demonstrated the first in vivo widefield mouse
brain imaging using machine-learning-based adaptive optics. Incorporating
coordinate-based neural representations and a forward physics model, the
self-supervised scheme of CoCoA should be applicable to microscopy modalities
in general.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>60 pages, 20 figures, 2 tables. Nat Mach Intell (2024)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Adaptive Kalman-Informed Transformer 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.09987v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.09987v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nadav Cohen, Itzik Klein
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The extended Kalman filter (EKF) is a widely adopted method for sensor fusion
in navigation applications. A crucial aspect of the EKF is the online
determination of the process noise covariance matrix reflecting the model
uncertainty. While common EKF implementation assumes a constant process noise,
in real-world scenarios, the process noise varies, leading to inaccuracies in
the estimated state and potentially causing the filter to diverge. Model-based
adaptive EKF methods were proposed and demonstrated performance improvements to
cope with such situations, highlighting the need for a robust adaptive
approach. In this paper, we derive an adaptive Kalman-informed transformer
(A-KIT) designed to learn the varying process noise covariance online. Built
upon the foundations of the EKF, A-KIT utilizes the well-known capabilities of
set transformers, including inherent noise reduction and the ability to capture
nonlinear behavior in the data. This approach is suitable for any application
involving the EKF. In a case study, we demonstrate the effectiveness of A-KIT
in nonlinear fusion between a Doppler velocity log and inertial sensors. This
is accomplished using real data recorded from sensors mounted on an autonomous
underwater vehicle operating in the Mediterranean Sea. We show that A-KIT
outperforms the conventional EKF by more than 49.5% and model-based adaptive
EKF by an average of 35.4% in terms of position accuracy.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Wasserstein Adaptive Value Estimation for Actor-Critic Reinforcement
  Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.10605v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.10605v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ali Baheri, Zahra Shahrooei, Chirayu Salgarkar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present Wasserstein Adaptive Value Estimation for Actor-Critic (WAVE), an
approach to enhance stability in deep reinforcement learning through adaptive
Wasserstein regularization. Our method addresses the inherent instability of
actor-critic algorithms by incorporating an adaptively weighted Wasserstein
regularization term into the critic's loss function. We prove that WAVE
achieves $\mathcal{O}\left(\frac{1}{k}\right)$ convergence rate for the
critic's mean squared error and provide theoretical guarantees for stability
through Wasserstein-based regularization. Using the Sinkhorn approximation for
computational efficiency, our approach automatically adjusts the regularization
based on the agent's performance. Theoretical analysis and experimental results
demonstrate that WAVE achieves superior performance compared to standard
actor-critic methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Safe Decentralized Multi-Agent Control using Black-Box Predictors,
  Conformal Decision Policies, and Control Barrier Functions <span class="chip">ICRA 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.18862v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.18862v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sacha Huriot, Hussein Sibai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We address the challenge of safe control in decentralized multi-agent robotic
settings, where agents use uncertain black-box models to predict other agents'
trajectories. We use the recently proposed conformal decision theory to adapt
the restrictiveness of control barrier functions-based safety constraints based
on observed prediction errors. We use these constraints to synthesize
controllers that balance between the objectives of safety and task
accomplishment, despite the prediction errors. We provide an upper bound on the
average over time of the value of a monotonic function of the difference
between the safety constraint based on the predicted trajectories and the
constraint based on the ground truth ones. We validate our theory through
experimental results showing the performance of our controllers when navigating
a robot in the multi-agent scenes in the Stanford Drone Dataset.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 1 figure, accepted for presentation at ICRA 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Transformer-Based Fault-Tolerant Control for Fixed-Wing UAVs Using
  Knowledge Distillation and In-Context Adaptation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.02975v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.02975v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Francisco Giral, Ignacio Gómez, Ricardo Vinuesa, Soledad Le Clainche
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study presents a transformer-based approach for fault-tolerant control
in fixed-wing Unmanned Aerial Vehicles (UAVs), designed to adapt in real time
to dynamic changes caused by structural damage or actuator failures. Unlike
traditional Flight Control Systems (FCSs) that rely on classical control theory
and struggle under severe alterations in dynamics, our method directly maps
outer-loop reference values -- altitude, heading, and airspeed -- into control
commands using the in-context learning and attention mechanisms of
transformers, thus bypassing inner-loop controllers and fault-detection layers.
Employing a teacher-student knowledge distillation framework, the proposed
approach trains a student agent with partial observations by transferring
knowledge from a privileged expert agent with full observability, enabling
robust performance across diverse failure scenarios. Experimental results
demonstrate that our transformer-based controller outperforms industry-standard
FCS and state-of-the-art reinforcement learning (RL) methods, maintaining high
tracking accuracy and stability in nominal conditions and extreme failure
cases, highlighting its potential for enhancing UAV operational safety and
reliability.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Memory-dependent abstractions of stochastic systems through the lens of
  transfer operators 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.04240v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.04240v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Adrien Banse, Giannis Delimpaltadakis, Luca Laurenti, Manuel Mazo Jr., Raphaël M. Jungers
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the increasing ubiquity of safety-critical autonomous systems operating
in uncertain environments, there is a need for mathematical methods for formal
verification of stochastic models. Towards formally verifying properties of
stochastic systems, methods based on discrete, finite Markov approximations --
abstractions -- thereof have surged in recent years. These are found in
contexts where: either a) one only has partial, discrete observations of the
underlying continuous stochastic process, or b) the original system is too
complex to analyze, so one partitions the continuous state-space of the
original system to construct a handleable, finite-state model thereof. In both
cases, the abstraction is an approximation of the discrete stochastic process
that arises precisely from the discretization of the underlying continuous
process. The fact that the abstraction is Markov and the discrete process is
not (even though the original one is) leads to approximation errors. Towards
accounting for non-Markovianity, we introduce memory-dependent abstractions for
stochastic systems, capturing dynamics with memory effects. Our contribution is
twofold. First, we provide a formalism for memory-dependent abstractions based
on transfer operators. Second, we quantify the approximation error by upper
bounding the total variation distance between the true continuous state
distribution and its discrete approximation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This paper was accepted for publication and presentation at the 2025
  Hybrid Systems: Computation and Control conference (HSCC 2025)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Uncertainty Propagation and Bayesian Fusion on Unimodular Lie Groups
  from a Parametric Perspective 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.03425v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.03425v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jikai Ye, Gregory S. Chirikjian
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We address the problem of uncertainty propagation and Bayesian fusion on
unimodular Lie groups. Starting from a stochastic differential equation (SDE)
defined on Lie groups via Mckean-Gangolli injection, we first convert it to a
parametric SDE in exponential coordinates. The coefficient transform method for
the conversion is stated for both Ito's and Stratonovich's interpretation of
the SDE. Then we derive a mean and covariance fitting formula for probability
distributions on Lie groups defined by a concentrated distribution on the
exponential coordinate. It is used to derive the mean and covariance
propagation equations for the SDE defined by injection, which coincides with
the result derived from a Fokker-Planck equation in previous work. We also
propose a simple modification to the update step of Kalman filters using the
fitting formula, which improves the fusion accuracy with moderate computation
time.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by CDC 2024; modified typos in theorem 2 and appendix A</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Scalable control synthesis for stochastic systems via structural IMDP
  abstractions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.11803v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.11803v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Frederik Baymler Mathiesen, Sofie Haesaert, Luca Laurenti
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces a novel abstraction-based framework for controller
synthesis of nonlinear discrete-time stochastic systems. The focus is on
probabilistic reach-avoid specifications. The framework is based on abstracting
a stochastic system into a new class of robust Markov models, called
orthogonally decoupled Interval Markov Decision Processes (odIMDPs).
Specifically, an odIMDPs is a class of robust Markov processes, where the
transition probabilities between each pair of states are uncertain and have the
product form. We show that such a specific form in the transition probabilities
allows one to build compositional abstractions of stochastic systems that, for
each state, are only required to store the marginal probability bounds of the
original system. This leads to improved memory complexity for our approach
compared to commonly employed abstraction-based approaches. Furthermore, we
show that an optimal control strategy for a odIMDPs can be computed by solving
a set of linear problems. When the resulting strategy is mapped back to the
original system, it is guaranteed to lead to reduced conservatism compared to
existing approaches. To test our theoretical framework, we perform an extensive
empirical comparison of our methods against Interval Markov Decision Process-
and Markov Decision Process-based approaches on various benchmarks including 7D
systems. Our empirical analysis shows that our approach substantially
outperforms state-of-the-art approaches in terms of both memory requirements
and the conservatism of the results.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at Hybrid Systems: Computation and Control, 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Compression and Distillation of Data Quadruplets in Non-intrusive
  Reduced-order Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.16683v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.16683v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Umair Zulfiqar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces a quadrature-free, data-driven approach to balanced
truncation for both continuous-time and discrete-time systems. The method
non-intrusively constructs reduced-order models using available transfer
function samples from the right half of the $s$-plane. It is highlighted that
the proposed data-driven balanced truncation and existing quadrature-based
balanced truncation algorithms share a common feature: both compress their
respective data quadruplets to derive reduced-order models. Additionally, it is
demonstrated that by using different compression strategies, these quadruplets
can be utilized to develop three data-driven formulations of the IRKA. These
formulations non-intrusively generate near-optimal reduced models using
transfer function samples from the $j\omega$-axis or the right half of the
$s$-plane, or impulse response samples. Notably, these IRKA formulations
eliminate the necessity of computing new transfer function samples as IRKA
iteratively updates the sampling points. The results are also extended to
discrete-time systems. The efficacy of the proposed algorithms is validated
through numerical examples, which show that the proposed data-driven approaches
perform comparably to their intrusive counterparts.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Personalized Hierarchical Split Federated Learning in Wireless Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.06042v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.06042v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Md-Ferdous Pervej, Andreas F. Molisch
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Extreme resource constraints make large-scale machine learning (ML) with
distributed clients challenging in wireless networks. On the one hand,
large-scale ML requires massive information exchange between clients and
server(s). On the other hand, these clients have limited battery and
computation powers that are often dedicated to operational computations. Split
federated learning (SFL) is emerging as a potential solution to mitigate these
challenges, by splitting the ML model into client-side and server-side model
blocks, where only the client-side block is trained on the client device.
However, practical applications require personalized models that are suitable
for the client's personal task. Motivated by this, we propose a personalized
hierarchical split federated learning (PHSFL) algorithm that is specially
designed to achieve better personalization performance. More specially, owing
to the fact that regardless of the severity of the statistical data
distributions across the clients, many of the features have similar attributes,
we only train the body part of the federated learning (FL) model while keeping
the (randomly initialized) classifier frozen during the training phase. We
first perform extensive theoretical analysis to understand the impact of model
splitting and hierarchical model aggregations on the global model. Once the
global model is trained, we fine-tune each client classifier to obtain the
personalized models. Our empirical findings suggest that while the globally
trained model with the untrained classifier performs quite similarly to other
existing solutions, the fine-tuned models show significantly improved
personalized performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for publication in IEEE ICC 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Exploring Robustness of Image Recognition Models on Hardware
  Accelerators 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2306.01697v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2306.01697v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nikolaos Louloudakis, Perry Gibson, José Cano, Ajitha Rajan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As the usage of Artificial Intelligence (AI) on resource-intensive and
safety-critical tasks increases, a variety of Machine Learning (ML) compilers
have been developed, enabling compatibility of Deep Neural Networks (DNNs) with
a variety of hardware acceleration devices. However, given that DNNs are widely
utilized for challenging and demanding tasks, the behavior of these compilers
must be verified. To this direction, we propose MutateNN, a tool that utilizes
elements of both differential and mutation testing in order to examine the
robustness of image recognition models when deployed on hardware accelerators
with different capabilities, in the presence of faults in their target device
code - introduced either by developers, or problems in their compilation
process. We focus on the image recognition domain by applying mutation testing
to 7 well-established DNN models, introducing 21 mutations of 6 different
categories. We deployed our mutants on 4 different hardware acceleration
devices of varying capabilities and observed that DNN models presented
discrepancies of up to 90.3% in mutants related to conditional operators across
devices. We also observed that mutations related to layer modification,
arithmetic types and input affected severely the overall model performance (up
to 99.8%) or led to model crashes, in a consistent manner across devices.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>7 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Optimization and Control <span class="chip" style="font-size: 60%">30</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Learning about passivity from data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.05989v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.05989v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alexandre Sanfelici Bazanella
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents a data-driven methodology to estimate the storage
function of a passive system. The methodology consists in parametrizing the
storage function with a dictionary then running a linear program. Results on a
benchmark are presented to illustrate its properties, including its robustness
to noise. Various uses of the storage function that do not require knowledge of
a model are also discussed.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Choosing Augmentation Parameters in OSQP- A New Approach based on
  Conjugate Directions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.05941v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.05941v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Avinash Kumar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This work proposes a new method to select the augmentation parameters in the
operator splitting quadratic program (OSQP) algorithm so as to reduce the
computation time of overall algorithm. The selection is based upon the
information of conjugate directions of the coefficient matrix of a linear
system of equations present in the algorithm. This selection makes it possible
to cache these conjugate directions, instead of computing them at each
iteration, resulting in faster computation of the solution of the linear system
thus reducing the overall computation time. This reduction is demonstrated by a
numerical example.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Nonlocal Stochastic Optimal Control for Diffusion Processes: Existence,
  Maximum Principle and Financial Applications 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.05912v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.05912v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Stefana-Lucia Anita, Luca Di Persio
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper investigates the optimal control problem for a class of parabolic
equations where the diffusion coefficient is influenced by a control function
acting nonlocally. Specifically, we consider the optimization of a cost
functional that incorporates a controlled probability density evolving under a
Fokker-Planck equation with state-dependent drift and diffusion terms. The
control variable is subject to spatial convolution through a kernel, inducing
nonlocal interactions in both drift and diffusion terms. We establish the
existence of optimal controls under appropriate convexity and regularity
conditions, leveraging compactness arguments in function spaces. A maximum
principle is derived to characterize the optimal control explicitly, revealing
its dependence on the adjoint state and the nonlocal structure of the system.
We further provide a rigorous financial application in the context of
mean-variance portfolio optimization, where both the asset drift and volatility
are controlled nonlocally, leading to an integral representation of the optimal
investment strategy. The results offer a mathematically rigorous framework for
optimizing diffusion-driven systems with spatially distributed control effects,
broadening the applicability of nonlocal control methods to stochastic
optimization and financial engineering.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ An implicit shock tracking method for simulation of shock-dominated
  flows over complex domains using mesh-based parametrizations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.05892v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.05892v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alexander M. Perez Reyes, Matthew J. Zahr
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A mesh-based parametrization is a parametrization of a geometric object that
is defined solely from a mesh of the object, e.g., without an analytical
expression or computer-aided design (CAD) representation of the object. In this
work, we propose a mesh-based parametrization of an arbitrary $d'$-dimensional
object embedded in a $d$-dimensional space using tools from high-order finite
elements. Using mesh-based parametrizations, we construct a boundary-preserving
parametrization of the nodal coordinates of a computational mesh that ensures
all nodes remain on all their original boundaries. These boundary-preseving
parametrizations allow the nodes of the mesh to move only in ways that will not
change the computational domain. They also ensure nodes will not move between
boundaries, which would cause issues assigning boundary conditions for partial
differential equation simulations and lead to inaccurate geometry
representations for non-smooth boundary transitions. Finally, we integrate
boundary-preserving, mesh-based parametrizations into high-order implicit shock
tracking, an optimization-based discontinuous Galerkin method that moves nodes
to align mesh faces with non-smooth flow features to represent them perfectly
with inter-element jumps, leaving the intra-element polynomial basis to
represent smooth regions of the flow with high-order accuracy. Mesh-based
parametrizations enable implicit shock tracking simulations of shock-dominated
flows over geometries without simple analytical parametrizations. Several
demonstrations of mesh-based parametrizations are provided.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>25 pages, 17 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The latent variable proximal point algorithm for variational problems
  with inequality constraints 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.05672v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.05672v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jørgen S. Dokken, Patrick E. Farrell, Brendan Keith, Ioannis P. A. Papadopoulos, Thomas M. Surowiec
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The latent variable proximal point (LVPP) algorithm is a framework for
solving infinite-dimensional variational problems with pointwise inequality
constraints. The algorithm is a saddle point reformulation of the Bregman
proximal point algorithm. At the continuous level, the two formulations are
equivalent, but the saddle point formulation is more amenable to discretization
because it introduces a structure-preserving transformation between a latent
function space and the feasible set. Working in this latent space is much more
convenient for enforcing inequality constraints than the feasible set, as
discretizations can employ general linear combinations of suitable basis
functions, and nonlinear solvers can involve general additive updates. LVPP
yields numerical methods with observed mesh-independence for obstacle problems,
contact, fracture, plasticity, and others besides; in many cases, for the first
time. The framework also extends to more complex constraints, providing means
to enforce convexity in the Monge--Amp\`ere equation and handling
quasi-variational inequalities, where the underlying constraint depends
implicitly on the unknown solution. In this paper, we describe the LVPP
algorithm in a general form and apply it to twelve problems from across
mathematics.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ BoGrape: Bayesian <span class="highlight-title">optimization</span> over graphs with shortest-path encoded 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.05642v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.05642v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yilin Xie, Shiqiang Zhang, Jixiang Qing, Ruth Misener, Calvin Tsay
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Graph-structured data play an important role across science and industry.
This paper asks: how can we optimize over graphs, for instance to find the best
graph structure and/or node features that minimize an expensive-to-evaluate
black-box objective? Such problem settings arise, e.g., in molecular design,
neural architecture search, and sensor placement. Bayesian optimization is a
powerful tool for optimizing black-box functions, and existing technologies can
be applied to optimize functions over nodes of a single fixed graph. We present
Bayesian optimization acquisition functions for a class of shortest-path
kernels and formulate them as mixed-integer optimization problems, enabling
global exploration of the graph domain while maintaining solution feasibility
when problem-specific constraints are present. We demonstrate our proposed
approach, BoGrape, on several molecular design case studies.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>21 pages, 5 figures, 4 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Control analysis and synthesis for general control-affine systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.05606v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.05606v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Cyprien Tamekue, ShiNung Ching
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper provides controllability analysis and control synthesis for
general control-affine systems, potentially subject to a bounded perturbation.
We establish sufficient controllability conditions based on a proper
generalization of the controllability Gramian for linear systems. Under these
sufficient conditions, control syntheses are developed. We provide two control
input constructions for a given system, either of which can steer the system
from a given initial state to any desired target state within a finite time
horizon. As in our analysis, in the case of linearity, these syntheses are
reduced to common control inputs based on the controllability of Gramian.
Additionally, we derive a sharp upper bound on the $L^2$-norm of these control
functions, allowing us to derive insights into the energy required to enact
control. The work advances the theory of nonlinear controllability and provides
an analytical framework that facilitates numerical verification and practical
implementation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Multi-asset optimal trade execution with stochastic cross-effects: An
  Obizhaeva-Wang-type framework 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.05594v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.05594v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Julia Ackermann, Thomas Kruse, Mikhail Urusov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We analyze a continuous-time optimal trade execution problem in multiple
assets where the price impact and the resilience can be matrix-valued
stochastic processes that incorporate cross-impact effects. In addition, we
allow for stochastic terminal and running targets. Initially, we formulate the
optimal trade execution task as a stochastic control problem with a
finite-variation control process that acts as an integrator both in the state
dynamics and in the cost functional. We then extend this problem continuously
to a stochastic control problem with progressively measurable controls. By
identifying this extended problem as equivalent to a certain linear-quadratic
stochastic control problem, we can use established results in linear-quadratic
stochastic control to solve the extended problem. This work generalizes
[Ackermann, Kruse, Urusov; FinancStoch'24] from the single-asset setting to the
multi-asset case. In particular, we reveal cross-hedging effects, showing that
it can be optimal to trade in an asset despite having no initial position.
Moreover, as a subsetting we discuss a multi-asset variant of the model in
[Obizhaeva, Wang; JFinancMark'13].
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>72 pages; 9 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ BARK: A Fully Bayesian Tree Kernel for Black-box <span class="highlight-title">Optimization</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.05574v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.05574v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Toby Boyne, Jose Pablo Folch, Robert M Lee, Behrang Shafei, Ruth Misener
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We perform Bayesian optimization using a Gaussian process perspective on
Bayesian Additive Regression Trees (BART). Our BART Kernel (BARK) uses tree
agreement to define a posterior over piecewise-constant functions, and we
explore the space of tree kernels using a Markov chain Monte Carlo approach.
Where BART only samples functions, the resulting BARK model obtains samples of
Gaussian processes defining distributions over functions, which allow us to
build acquisition functions for Bayesian optimization. Our tree-based approach
enables global optimization over the surrogate, even for mixed-feature spaces.
Moreover, where many previous tree-based kernels provide uncertainty
quantification over function values, our sampling scheme captures uncertainty
over the tree structure itself. Our experiments show the strong performance of
BARK on both synthetic and applied benchmarks, due to the combination of our
fully Bayesian surrogate and the optimization procedure.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 main pages, 22 total pages, 10 figures, 6 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Tractable Representations for Convergent Approximation of Distributional
  HJB Equations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.05563v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.05563v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Julie Alhosh, Harley Wiltzer, David Meger
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In reinforcement learning (RL), the long-term behavior of decision-making
policies is evaluated based on their average returns. Distributional RL has
emerged, presenting techniques for learning return distributions, which provide
additional statistics for evaluating policies, incorporating risk-sensitive
considerations. When the passage of time cannot naturally be divided into
discrete time increments, researchers have studied the continuous-time RL
(CTRL) problem, where agent states and decisions evolve continuously. In this
setting, the Hamilton-Jacobi-Bellman (HJB) equation is well established as the
characterization of the expected return, and many solution methods exist.
However, the study of distributional RL in the continuous-time setting is in
its infancy. Recent work has established a distributional HJB (DHJB) equation,
providing the first characterization of return distributions in CTRL. These
equations and their solutions are intractable to solve and represent exactly,
requiring novel approximation techniques. This work takes strides towards this
end, establishing conditions on the method of parameterizing return
distributions under which the DHJB equation can be approximately solved.
Particularly, we show that under a certain topological property of the mapping
between statistics learned by a distributional RL algorithm and corresponding
distributions, approximation of these statistics leads to close approximations
of the solution of the DHJB equation. Concretely, we demonstrate that the
quantile representation common in distributional RL satisfies this topological
property, certifying an efficient approximation algorithm for continuous-time
distributional RL.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to RLDM 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Constrained Reinforcement Learning for the Dynamic Inventory Routing
  Problem under Stochastic Supply and Demand 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.05276v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.05276v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Umur Hasturk, Albert H. Schrotenboer, Kees Jan Roodbergen, Evrim Ursavas
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Green hydrogen has multiple use cases and is produced from renewable energy,
such as solar or wind energy. It can be stored in large quantities, decoupling
renewable energy generation from its use, and is therefore considered essential
for achieving a climate-neutral economy. The intermittency of renewable energy
generation and the stochastic nature of demand are, however, challenging
factors for the dynamic planning of hydrogen storage and transportation. This
holds particularly in the early-adoption phase when hydrogen distribution
occurs through vehicle-based networks. We therefore address the Dynamic
Inventory Routing Problem (DIRP) under stochastic supply and demand with direct
deliveries for the vehicle-based distribution of hydrogen. To solve this
problem, we propose a Constrained Reinforcement Learning (CRL) framework that
integrates constraints into the learning process and incorporates parameterized
post-decision state value predictions. Additionally, we introduce
Lookahead-based CRL (LCRL), which improves decision-making over a multi-period
horizon to enhance short-term planning while maintaining the value predictions.
Our computational experiments demonstrate the efficacy of CRL and LCRL across
diverse instances. Our learning methods provide near-optimal solutions on small
scale instances that are solved via value iteration. Furthermore, both methods
outperform typical deep learning approaches such as Proximal Policy
Optimization, as well as classical inventory heuristics, such as
(s,S)-policy-based and Power-of-Two-based heuristics. Furthermore, LCRL
achieves a 10% improvement over CRL on average, albeit with higher
computational requirements. Analyses of optimal replenishment policies reveal
that accounting for stochastic supply and demand influences these policies,
showing the importance of our addition to the DIRP.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Spectral-Spatial Extraction through Layered Tensor Decomposition for
  Hyperspectral Anomaly Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.05183v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.05183v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Quan Yu, Yu-Hong Dai, Minru Bai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Low rank tensor representation (LRTR) methods are very useful for
hyperspectral anomaly detection (HAD). To overcome the limitations that they
often overlook spectral anomaly and rely on large-scale matrix singular value
decomposition, we first apply non-negative matrix factorization (NMF) to
alleviate spectral dimensionality redundancy and extract spectral anomaly and
then employ LRTR to extract spatial anomaly while mitigating spatial
redundancy, yielding a highly efffcient layered tensor decomposition (LTD)
framework for HAD. An iterative algorithm based on proximal alternating
minimization is developed to solve the proposed LTD model, with convergence
guarantees provided. Moreover, we introduce a rank reduction strategy with
validation mechanism that adaptively reduces data size while preventing
excessive reduction. Theoretically, we rigorously establish the equivalence
between the tensor tubal rank and tensor group sparsity regularization (TGSR)
and, under mild conditions, demonstrate that the relaxed formulation of TGSR
shares the same global minimizers and optimal values as its original
counterpart. Experimental results on the Airport-Beach-Urban and MVTec datasets
demonstrate that our approach outperforms state-of-the-art methods in the HAD
task.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Gap Penalty Reformulation for Mathematical Programming with
  Complementarity Constraints: Convergence Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.05181v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.05181v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kangyu Lin, Toshiyuki Ohtsuka
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Our recent study [1] proposed a new penalty method to solve the mathematical
programming with complementarity constraints (MPCC). This method reformulates
the MPCC as a parameterized nonlinear programming (NLP) called gap penalty
reformulation and solves a sequence of gap penalty reformulations with an
increasing penalty parameter. This letter studies the convergence behavior of
the new penalty method. We prove that it converges to a strongly stationary
point of MPCC, provided that: (1) The MPCC linear independence constraint
qualification holds; (2) The upper-level strict complementarity condition
holds; (3) The gap penalty reformulation satisfies the second-order necessary
conditions in terms of the second-order directional derivative. Since the
strong stationarity is used to identify the local minimum of MPCC, our
convergence analysis indicates that the new penalty method is capable of
finding an MPCC solution.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Self-Supervised Penalty-Based Learning for Robust Constrained
  <span class="highlight-title">Optimization</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.05175v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.05175v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wyame Benslimane, Paul Grigas
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose a new methodology for parameterized constrained robust
optimization, an important class of optimization problems under uncertainty,
based on learning with a self-supervised penalty-based loss function. Whereas
supervised learning requires pre-solved instances for training, our approach
leverages a custom loss function derived from the exact penalty method in
optimization to learn an approximation, typically defined by a neural network
model, of the parameterized optimal solution mapping. Additionally, we adapt
our approach to robust constrained combinatorial optimization problems by
incorporating a surrogate linear cost over mixed integer domains, and a smooth
approximations thereof, into the final layer of the network architecture. We
perform computational experiments to test our approach on three different
applications: multidimensional knapsack with continuous variables,
combinatorial multidimensional knapsack with discrete variables, and an
inventory management problem. Our results demonstrate that our self-supervised
approach is able to effectively learn neural network approximations whose
inference time is significantly smaller than the computation time of
traditional solvers for this class of robust optimization problems.
Furthermore, our results demonstrate that by varying the penalty parameter we
are able to effectively balance the trade-off between sub-optimality and robust
feasibility of the obtained solutions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To appear in the proceedings of CPAIOR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Stochastic Gradient Descent Revisited 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.06070v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.06070v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Azar Louzi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Stochastic gradient descent (SGD) has been a go-to algorithm for nonconvex
stochastic optimization problems arising in machine learning. Its theory
however often requires a strong framework to guarantee convergence properties.
We hereby present a full scope convergence study of biased nonconvex SGD,
including weak convergence, function-value convergence and global convergence,
and also provide subsequent convergence rates and complexities, all under
relatively mild conditions in comparison with literature.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>45 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A New Lyapunov-like Stability Inequality with an \textit{Asymmetric}
  Matrix and Application to Suboptimal LQ Control Design (to be corrected) 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.11556v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.11556v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Avinash Kumar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The Lyapunov inequality is an indispensable tool for stability analysis in
the linear control theory. This work proposes a new variant of this inequality
where-in the constituent matrix is allowed to be asymmetric. After developing
the stability conditions based on the proposed inequality for a class of linear
systems, we utilize these conditions to derive new results for the suboptimal
linear quadratic control problem where we characterize the cost of the
stabilizing controllers. We also demonstrate, by a numerical example, that the
proposed results can be easily molded for the structured suboptimal consensus
protocol design for multi-agent system where we also see that the asymmetry
condition of the design matrix turns up inherently.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Fitted Q-Iteration via Max-Plus-Linear Approximation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.08422v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.08422v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Y. Liu, M. A. S. Kolarijani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this study, we consider the application of max-plus-linear approximators
for Q-function in offline reinforcement learning of discounted Markov decision
processes. In particular, we incorporate these approximators to propose novel
fitted Q-iteration (FQI) algorithms with provable convergence. Exploiting the
compatibility of the Bellman operator with max-plus operations, we show that
the max-plus-linear regression within each iteration of the proposed FQI
algorithm reduces to simple max-plus matrix-vector multiplications. We also
consider the variational implementation of the proposed algorithm which leads
to a per-iteration complexity that is independent of the number of samples.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Optimizing $(L_0, L_1)$-Smooth Functions by Gradient Methods 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10800v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10800v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Daniil Vankov, Anton Rodomanov, Angelia Nedich, Lalitha Sankar, Sebastian U. Stich
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study gradient methods for optimizing $(L_0, L_1)$-smooth functions, a
class that generalizes Lipschitz-smooth functions and has gained attention for
its relevance in machine learning. We provide new insights into the structure
of this function class and develop a principled framework for analyzing
optimization methods in this setting. While our convergence rate estimates
recover existing results for minimizing the gradient norm in nonconvex
problems, our approach significantly improves the best-known complexity bounds
for convex objectives. Moreover, we show that the gradient method with Polyak
stepsizes and the normalized gradient method achieve nearly the same complexity
guarantees as methods that rely on explicit knowledge of~$(L_0, L_1)$. Finally,
we demonstrate that a carefully designed accelerated gradient method can be
applied to $(L_0, L_1)$-smooth functions, further improving all previous
results.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Optimal Transport for Probabilistic Circuits 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13061v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13061v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Adrian Ciotinga, YooJung Choi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce a novel optimal transport framework for probabilistic circuits
(PCs). While it has been shown recently that divergences between distributions
represented as certain classes of PCs can be computed tractably, to the best of
our knowledge, there is no existing approach to compute the Wasserstein
distance between probability distributions given by PCs. We propose a
Wasserstein-type distance that restricts the coupling measure of the associated
optimal transport problem to be a probabilistic circuit. We then develop an
algorithm for computing this distance by solving a series of small linear
programs and derive the circuit conditions under which this is tractable.
Furthermore, we show that we can easily retrieve the optimal transport plan
between the PCs from the solutions to these linear programs. Lastly, we study
the empirical Wasserstein distance between a PC and a dataset, and show that we
can estimate the PC parameters to minimize this distance through an efficient
iterative algorithm.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ BSAC-CoEx: Coexistence of URLLC and Distributed Learning Services via
  Device Selection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2212.11805v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2212.11805v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Milad Ganjalizadeh, Hossein Shokri Ghadikolaei, Deniz Gündüz, Marina Petrova
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in distributed intelligence have driven impressive progress
across a diverse range of applications, from industrial automation to
autonomous transportation. Nevertheless, deploying distributed learning
services over wireless networks poses numerous challenges. These arise from
inherent uncertainties in wireless environments (e.g., random channel
fluctuations), limited resources (e.g., bandwidth and transmit power), and the
presence of coexisting services on the network. In this paper, we investigate a
mixed service scenario wherein high-priority ultra-reliable low latency
communication (URLLC) and low-priority distributed learning services run
concurrently over a network. Utilizing device selection, we aim to minimize the
convergence time of distributed learning while simultaneously fulfilling the
requirements of the URLLC service. We formulate this problem as a Markov
decision process and address it via BSAC-CoEx, a framework based on the
branching soft actor-critic (BSAC) algorithm that determines each device's
participation decision through distinct branches in the actor's neural network.
We evaluate our solution with a realistic simulator that is compliant with 3GPP
standards for factory automation use cases. Our simulation results confirm that
our solution can significantly decrease the training delays of the distributed
learning service while keeping the URLLC availability above its required
threshold and close to the scenario where URLLC solely consumes all wireless
resources.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This work has been submitted to the IEEE for possible publication</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Fractional Sobolev paths on Wasserstein spaces and their
  energy-minimizing particle representations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.12068v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.12068v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ehsan Abedi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study a generalization of Kantorovich's optimal transportation problem.
Given a prescribed family of time-dependent probability measures $(\mu_t)$, we
aim to find, among all path-continuous stochastic processes whose
one-dimensional time marginals coincide with $(\mu_t)$ (if there is any), a
process that minimizes a given energy. After discussing a sufficient condition
for the energy to ensure the existence of a minimizer, we investigate
fractional Sobolev energies. Given a deterministic path $(\mu_t)$ on a
$p$-Wasserstein space with fractional Sobolev regularity $W^{\alpha,p}$, where
$1/p < \alpha < 1$, we provide conditions under which we prove the existence of
a process that minimizes the energy and construct a process that realizes the
regularity of $(\mu_t)$. While continuous paths of low regularity on
Wasserstein spaces naturally appear in stochastic analysis, they can also arise
deterministically as solutions to the continuity equation. This paper is
devoted to the deterministic setting to gain some understanding of the required
conditions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>45 pages, 6 figures, 1 table</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Stable Spare Parts Pooling for Military Weapon Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/1811.08145v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/1811.08145v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Loe Schlicher, Marco Slikker, Willem van Jaarsveld
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study under which circumstances Departments of Defenses should be willing
to deploy a joint parts part pooling program for their major weapon systems.
Using cooperative game theory and Markov Decision Processes, we demonstrate
that the type of pooling strategy plays a crucial role in the success of such a
joint spare parts pool. More precisely, we show that a joint spare parts pool
may not last long -- or even not arise -- if full pooling is applied, while it
is stable under threshold pooling.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Cauchy-Schwarz Regularizers <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.01639v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.01639v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sueda Taner, Ziyi Wang, Christoph Studer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce a novel class of regularization functions, called Cauchy-Schwarz
(CS) regularizers, which can be designed to induce a wide range of properties
in solution vectors of optimization problems. To demonstrate the versatility of
CS regularizers, we derive regularization functions that promote
discrete-valued vectors, eigenvectors of a given matrix, and orthogonal
matrices. The resulting CS regularizers are simple, differentiable, and can be
free of spurious stationary points, making them suitable for gradient-based
solvers and large-scale optimization problems. In addition, CS regularizers
automatically adapt to the appropriate scale, which is, for example, beneficial
when discretizing the weights of neural networks. To demonstrate the efficacy
of CS regularizers, we provide results for solving underdetermined systems of
linear equations and weight quantization in neural networks. Furthermore, we
discuss specializations, variations, and generalizations, which lead to an even
broader class of new and possibly more powerful regularizers.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Stochastic Modified Flows for Riemannian Stochastic Gradient Descent 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.03467v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.03467v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Benjamin Gess, Sebastian Kassing, Nimit Rana
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We give quantitative estimates for the rate of convergence of Riemannian
stochastic gradient descent (RSGD) to Riemannian gradient flow and to a
diffusion process, the so-called Riemannian stochastic modified flow (RSMF).
Using tools from stochastic differential geometry we show that, in the small
learning rate regime, RSGD can be approximated by the solution to the RSMF
driven by an infinite-dimensional Wiener process. The RSMF accounts for the
random fluctuations of RSGD and, thereby, increases the order of approximation
compared to the deterministic Riemannian gradient flow. The RSGD is build using
the concept of a retraction map, that is, a cost efficient approximation of the
exponential map, and we prove quantitative bounds for the weak error of the
diffusion approximation under assumptions on the retraction map, the geometry
of the manifold, and the random estimators of the gradient.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CrowdSurfer: Sampling <span class="highlight-title">Optimization</span> Augmented with Vector-Quantized
  Variational AutoEncoder for Dense Crowd <span class="highlight-title">Navigation</span> <span class="chip">ICRA 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.16011v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.16011v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Naman Kumar, Antareep Singha, Laksh Nanwani, Dhruv Potdar, Tarun R, Fatemeh Rastgar, Simon Idoko, Arun Kumar Singh, K. Madhava Krishna
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Navigation amongst densely packed crowds remains a challenge for mobile
robots. The complexity increases further if the environment layout changes,
making the prior computed global plan infeasible. In this paper, we show that
it is possible to dramatically enhance crowd navigation by just improving the
local planner. Our approach combines generative modelling with inference time
optimization to generate sophisticated long-horizon local plans at interactive
rates. More specifically, we train a Vector Quantized Variational AutoEncoder
to learn a prior over the expert trajectory distribution conditioned on the
perception input. At run-time, this is used as an initialization for a
sampling-based optimizer for further refinement. Our approach does not require
any sophisticated prediction of dynamic obstacles and yet provides
state-of-the-art performance. In particular, we compare against the recent
DRL-VO approach and show a 40% improvement in success rate and a 6% improvement
in travel time.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at IEEE ICRA 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Safe and Efficient Online Convex <span class="highlight-title">Optimization</span> with Linear Budget
  Constraints and Partial Feedback 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.03983v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.03983v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shanqi Liu, Xin Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper studies online convex optimization with unknown linear budget
constraints, where only the gradient information of the objective and the
bandit feedback of constraint functions are observed. We propose a safe and
efficient Lyapunov-optimization algorithm (SELO) that can achieve an
$O(\sqrt{T})$ regret and zero cumulative constraint violation. The result also
implies SELO achieves $O(\sqrt{T})$ regret when the budget is hard and not
allowed to be violated. The proposed algorithm is computationally efficient as
it resembles a primal-dual algorithm where the primal problem is an
unconstrained, strongly convex and smooth problem, and the dual problem has a
simple gradient-type update. The algorithm and theory are further justified in
a simulated application of energy-efficient task processing in distributed data
centers.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Fast Robust Kernel Regression through Sign Gradient Descent with Early
  Stopping 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2306.16838v7">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2306.16838v7.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Oskar Allerbo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Kernel ridge regression, KRR, is a generalization of linear ridge regression
that is non-linear in the data, but linear in the model parameters. Here, we
introduce an equivalent formulation of the objective function of KRR, which
opens up for replacing the ridge penalty with the $\ell_\infty$ and $\ell_1$
penalties. Using the $\ell_\infty$ and $\ell_1$ penalties, we obtain robust and
sparse kernel regression, respectively. We study the similarities between
explicitly regularized kernel regression and the solutions obtained by early
stopping of iterative gradient-based methods, where we connect $\ell_\infty$
regularization to sign gradient descent, $\ell_1$ regularization to forward
stagewise regression (also known as coordinate descent), and $\ell_2$
regularization to gradient descent, and, in the last case, theoretically bound
for the differences. We exploit the close relations between $\ell_\infty$
regularization and sign gradient descent, and between $\ell_1$ regularization
and coordinate descent to propose computationally efficient methods for robust
and sparse kernel regression. We finally compare robust kernel regression
through sign gradient descent to existing methods for robust kernel regression
on five real data sets, demonstrating that our method is one to two orders of
magnitude faster, without compromised accuracy.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Article arXiv:2306.16838v1 has been updated and split into two
  articles: this article and arXiv:2311.01762. Thus, some of the content in
  arXiv:2306.16838v1 is not a part of arXiv:2306.16838v2, but of
  arXiv:2311.01762</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ On the $O(\frac{\sqrt{d}}{T^{1/4}})$ Convergence Rate of RMSProp and Its
  Momentum Extension Measured by $\ell_1$ Norm 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.00389v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.00389v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Huan Li, Yiming Dong, Zhouchen Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Although adaptive gradient methods have been extensively used in deep
learning, their convergence rates proved in the literature are all slower than
that of SGD, particularly with respect to their dependence on the dimension.
This paper considers the classical RMSProp and its momentum extension and
establishes the convergence rate of $\frac{1}{T}\sum_{k=1}^T E\left[\|\nabla
f(x^k)\|_1\right]\leq O(\frac{\sqrt{d}C}{T^{1/4}})$ measured by $\ell_1$ norm
without the bounded gradient assumption, where $d$ is the dimension of the
optimization variable, $T$ is the iteration number, and $C$ is a constant
identical to that appeared in the optimal convergence rate of SGD. Our
convergence rate matches the lower bound with respect to all the coefficients
except the dimension $d$. Since $\|x\|_2\ll\|x\|_1\leq\sqrt{d}\|x\|_2$ for
problems with extremely large $d$, our convergence rate can be considered to be
analogous to the $\frac{1}{T}\sum_{k=1}^T E\left[\|\nabla f(x^k)\|_2\right]\leq
O(\frac{C}{T^{1/4}})$ rate of SGD in the ideal case of $\|\nabla
f(x)\|_1=\varTheta(\sqrt{d}\|\nabla f(x)\|_2)$.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>V4 vs V3: More experiments. V3 vs V2: A fairer comparison with (Li et
  al., 2023). V2 vs V1: (1) Correct one error in v1. (2) Improve the
  convergence rate matching the lower bound with respect to all the
  coefficients except the dimension</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Asymptotic behavior of penalty dynamics for constrained variational
  inequalities 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03902v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03902v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Siqi Qu, Mathias Staudigl, Juan Peypouquet
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose a comprehensive framework for solving constrained variational
inequalities via various classes of evolution equations displaying multi-scale
aspects. In a Hilbertian framework, the class of dynamical systems we propose
combine Tikhonov regularization and exterior penalization terms in order to
yield simultaneously strong convergence of trajectories to least norm solutions
in the constrained domain. Our construction thus unifies the literature on
regularization methods and penalty-term based dynamical systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This is a largely extended and revised version of the paper M.
  Staudigl and S. Qu, "Tikhonov Regularized Exterior Penalty Dynamics for
  Constrained Variational Inequalities," in IEEE Control Systems Letters, vol.
  8, pp. 622-627, 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Noise-driven Synchronization of Vicsek Model in Mean 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.13993v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.13993v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wei Su, Yongguang Yu, Ge Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The Vicsek model has long stood as a pivotal framework in exploring
collective behavior and self-organization, captivating the scientific community
with its compelling dynamics. However, understanding how noise influences
synchronization within this model and its associated phase transition
characteristics has presented significant challenges. While numerous studies
have focused on simulations due to the model's mathematical complexity,
comprehensive theoretical analyses remain sparse. In this paper, we deliver a
rigorous mathematical proof demonstrating that for any initial configuration of
the Vicsek model, there exists a bound on noise amplitude such that if the
noise amplitude is maintained within this bound, the system will achieve
synchronization in mean. This finding not only lays a solid mathematical
groundwork for the Vicsek model's phase transition theory but also underscores
the critical role of noise in collective dynamics, enhancing our understanding
of self-organizing systems in stochastic environments.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2025-03-06T00:00:00Z">2025-03-06</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Systems and Control <span class="chip" style="font-size: 60%">45</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhancing AUTOSAR-Based Firmware Over-the-Air Updates in the Automotive
  Industry with a Practical Implementation on a Steering System 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.05839v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.05839v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mostafa Ahmed Mostafa Ahmed, Mohamed Khaled Mohamed Elsayed, Radwa Waheed Ezzat Abdelmohsen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The automotive industry is increasingly reliant on software to manage complex
vehicle functionalities, making efficient and secure firmware updates
essential. Traditional firmware update methods, requiring physical connections
through On-Board Diagnostics (OBD) ports, are inconvenient, costly, and
time-consuming. Firmware Over-the-Air (FOTA) technology offers a revolutionary
solution by enabling wireless updates, reducing operational costs, and
enhancing the user experience. This project aims to design and implement an
advanced FOTA system tailored for modern vehicles, incorporating the AUTOSAR
architecture for scalability and standardization, and utilizing delta updating
to minimize firmware update sizes, thereby improving bandwidth efficiency and
reducing flashing times. To ensure security, the system integrates the UDS 0x27
protocol for authentication and data integrity during the update process.
Communication between Electronic Control Units (ECUs) is achieved using the CAN
protocol, while the ESP8266 module and the master ECU communicate via SPI for
data transfer. The system's architecture includes key components such as a
bootloader, boot manager, and bootloader updater to facilitate seamless
firmware updates. The functionality of the system is demonstrated through two
applications: a blinking LED and a Lane Keeping Assist (LKA) system, showcasing
its versatility in handling critical automotive features. This project
represents a significant step forward in automotive technology, offering a
user-centric, efficient, and secure solution for automotive firmware
management.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Bachelor's thesis</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ISC-POMDPs: Partially Observed Markov Decision Processes with
  Initial-State Dependent Costs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.05030v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.05030v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Timothy L. Molloy
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce a class of partially observed Markov decision processes (POMDPs)
with costs that can depend on both the value and (future) uncertainty
associated with the initial state. These Initial-State Cost POMDPs (ISC-POMDPs)
enable the specification of objectives relative to a priori unknown initial
states, which is useful in applications such as robot navigation, controlled
sensing, and active perception, that can involve controlling systems to
revisit, remain near, or actively infer their initial states. By developing a
recursive Bayesian fixed-point smoother to estimate the initial state that
resembles the standard recursive Bayesian filter, we show that ISC-POMDPs can
be treated as POMDPs with (potentially) belief-dependent costs. We demonstrate
the utility of ISC-POMDPs, including their ability to select controls that
resolve (future) uncertainty about (past) initial states, in simulation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 2 figures, accepted for publication in IEEE Control Systems
  Letters</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Security-Aware Sensor Fusion with MATE: the Multi-Agent Trust Estimator 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04954v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04954v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        R. Spencer Hallyburton, Miroslav Pajic
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Lacking security awareness, sensor fusion in systems with multi-agent
networks such as smart cities is vulnerable to attacks. To guard against recent
threats, we design security-aware sensor fusion that is based on the estimates
of distributions over trust. Trust estimation can be cast as a hidden Markov
model, and we solve it by mapping sensor data to trust pseudomeasurements
(PSMs) that recursively update trust posteriors in a Bayesian context. Trust
then feeds sensor fusion to facilitate trust-weighted updates to situational
awareness. Essential to security-awareness are a novel field of view estimator,
logic to map sensor data into PSMs, and the derivation of efficient Bayesian
updates. We evaluate security-aware fusion under attacks on agents using case
studies and Monte Carlo simulation in the physics-based Unreal Engine
simulator, CARLA. A mix of novel and classical security-relevant metrics show
that our security-aware fusion enables building trustworthy situational
awareness even in hostile conditions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Neural Configuration-Space Barriers for <span class="highlight-title">Manipulation</span> <span class="highlight-title">Plan</span>ning and
  Control 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04929v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04929v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kehan Long, Ki Myung Brian Lee, Nikola Raicevic, Niyas Attasseri, Melvin Leok, Nikolay Atanasov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Planning and control for high-dimensional robot manipulators in cluttered,
dynamic environments require both computational efficiency and robust safety
guarantees. Inspired by recent advances in learning configuration-space
distance functions (CDFs) as robot body representations, we propose a unified
framework for motion planning and control that formulates safety constraints as
CDF barriers. A CDF barrier approximates the local free configuration space,
substantially reducing the number of collision-checking operations during
motion planning. However, learning a CDF barrier with a neural network and
relying on online sensor observations introduce uncertainties that must be
considered during control synthesis. To address this, we develop a
distributionally robust CDF barrier formulation for control that explicitly
accounts for modeling errors and sensor noise without assuming a known
underlying distribution. Simulations and hardware experiments on a 6-DoF xArm
manipulator show that our neural CDF barrier formulation enables efficient
planning and robust real-time safe control in cluttered and dynamic
environments, relying only on onboard point-cloud observations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Extended Version: Non-Preemptive Scheduling of Flexible Loads in Smart
  Grids via Convex <span class="highlight-title">Optimization</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04909v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04909v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mehdi Davoudi, Mingyu Chen, Junjie Qin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper studies the scheduling of a large population of non-preemptive
flexible electric loads, each of which has a flexible starting time but once
started will follow a fixed load shape until completion. We first formulate the
scheduling problem as a mixed-integer convex program (MICP), then propose an
efficient polynomial time relaxation-adjustment-rounding algorithm for solving
the problem. The key novelty of the proposed method lies in its adjustment
step, which uses a graph-based algorithm to navigate within the set of optimal
points of the convex relaxation while reducing the number of fractional entries
in the solution. We establish mathematically that our algorithm yields
solutions that are near optimal for a finite number of loads and with its
sub-optimality independent of the number of loads. Consequently, the proposed
method is asymptotically optimal in a per-load cost sense when the number of
loads increases. Despite the gap between the MICP and its convex relaxation, we
establish that the solution of the proposed algorithm can be decentralized by
marginal prices of the convex relaxation. We also develop and analyze variants
of the proposed algorithm for settings with uncertainty and with time-varying
realistic load shapes. Finally, we numerically evaluate the proposed algorithm
in a case study for the non-preemptive scheduling of electric vehicles charging
loads.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Longer version of a paper submitted to IEEE Transactions on Control
  of Network Systems</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Dissipativity-Based Distributed Control and Communication Topology
  Co-Design for Voltage Regulation and Current Sharing in DC Microgrids 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04908v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04908v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohammad Javad Najafirad, Shirantha Welikala
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents a novel dissipativity-based distributed droop-free
control approach for voltage regulation and current sharing in DC microgrids
(MGs) comprised of an interconnected set of distributed generators (DGs),
loads, and power lines. First, we describe the closed-loop DC MG as a networked
system where the DGs and lines (i.e., subsystems) are interconnected via a
static interconnection matrix. This interconnection matrix demonstrates how the
inputs, outputs, and disturbances of DGs and lines are connected in a DC MG.
Each DG has a local controller and a distributed global controller. To design
the controller, we use the dissipativity properties of the subsystems and
formulate a linear matrix inequality (LMI) problem. To support the feasibility
of this problem, we identify a set of necessary local and global conditions
that we then enforce in a specifically developed LMI-based controller design
process. In contrast to existing DC MG control solutions, our approach proposes
a unified framework for co-designing the distributed controller and
communication topology. As the co-design process is LMI-based, it can be
efficiently implemented and evaluated. The effectiveness of the proposed
solution can be verified by simulating an islanded DC MG in a MATLAB/Simulink
environment under different scenarios, such as load changes and topological
constraint changes, and then comparing the performance with a recent droop
control algorithm.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ An Extended State Space Model of Aggregated Electric Vehicles for
  Flexibility Estimation and Power Control 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04714v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04714v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yiping Liu, Xiaozhe Wang, Geza Joos
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The increasing penetration of electric vehicles (EVs) can provide substantial
electricity to the grid, supporting the grids' stability. The state space model
(SSM) has been proposed as an effective modeling method for power prediction
and centralized control of aggregated EVs, offering low communication
requirements and computational complexity. However, the SSM may overlook
specific scenarios, leading to significant prediction and control inaccuracies.
This paper proposes an extended state space model (eSSM) for aggregated EVs and
develops associated control strategies. By accounting for the limited
flexibility of fully charged and discharged EVs, the eSSM more accurately
captures the state transition dynamics of EVs in various states of charge
(SOC). Comprehensive simulations show that the eSSM will provide more accurate
predictions of the flexibility and power trajectories of aggregated EVs, and
more effectively tracks real-time power references compared to the conventional
SSM method.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages, 9 figures, 2025 IEEE Power & Energy Society General Meeting
  (PESGM), Accepted</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Data-Driven Distributed <span class="highlight-title">Optimization</span> via Aggregative Tracking and
  Deep-Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04668v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04668v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Riccardo Brumali, Guido Carnevale, Giuseppe Notarstefano
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we propose a novel distributed data-driven optimization
scheme. In particular, we focus on the so-called aggregative framework, namely,
the scenario in which a set of agents aim to cooperatively minimize the sum of
local costs, each depending on both local decision variables and an aggregation
of all of them. We consider a data-driven setup in which each objective
function is unknown and can be only sampled at a single point per iteration
(thanks to, e.g., feedback from human users or physical sensors). We address
this scenario through a distributed algorithm that combines three key
components: (i) a learning part that leverages neural networks to learn the
local cost functions descent direction, (ii) an optimization routine that
steers the estimates according to the learned direction to minimize the global
cost, and (iii) a tracking mechanism that locally reconstructs the unavailable
global quantities. By using tools from system theory, i.e., timescale
separation and averaging theory, we formally prove that, in strongly convex
setups, the overall distributed strategy linearly converges in a neighborhood
of the optimal solution whose radius depends on the given accuracy capabilities
of the neural networks. Finally, we corroborate the theoretical results with
numerical simulations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ When Next-Gen Sensing Meets Legacy Wi-Fi: Performance Analyses of IEEE
  802.11bf and IEEE 802.11ax Coexistence 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04637v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04637v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Navid Keshtiarast, Pradyumna Kumar Bishoyi, Ido Manuel Lumbantobing, Marina Petrova
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sensing is emerging as a vital future service in next-generation wireless
networks, enabling applications such as object localization and activity
recognition. The IEEE 802.11bf standard extends Wi-Fi capabilities to
incorporate these sensing functionalities. However, coexistence with legacy
Wi-Fi in densely populated networks poses challenges, as contention for
channels can impair both sensing and communication quality. This paper develops
an analytical framework and a system-level simulation in ns-3 to evaluate the
coexistence of IEEE 802.11bf and legacy 802.11ax in terms of sensing delay and
communication throughput. Forthis purpose, we have developed a dedicated ns-3
module forIEEE 802.11bf, which is made publicly available as open-source. We
provide the first coexistence analysis between IEEE 802.11bfand IEEE 802.11ax,
supported by link-level simulation in ns-3to assess the impact on sensing delay
and network performance. Key parameters, including sensing intervals, access
categories, network densities, and antenna configurations, are systematically
analyzed to understand their influence on the sensing delay and aggregated
network throughput. The evaluation is further extended to a realistic indoor
office environment modeled after the 3GPP TR 38.901 standard. Our findings
reveal key trade-offs between sensing intervals and throughput and the need for
balanced sensing parameters to ensure effective coexistence in Wi-Fi networks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Multistage Economic MPC for Systems with a Cyclic Steady State: A Gas
  Network Case Study 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04622v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04622v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sakshi S. Naik, Lavinia M. Ghilardi, Robert B. Parker, Lorenz T. Biegler
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multistage model predictive control (MPC) provides a robust control strategy
for dynamic systems with uncertainties and a setpoint tracking objective.
Moreover, extending MPC to minimize an economic cost instead of tracking a
pre-calculated optimal setpoint improves controller performance. In this paper,
we develop a formulation for multistage economic MPC which directly minimizes
an economic objective function. The multistage economic MPC framework is
extended for systems with a cyclic steady state (CSS) and stability is
guaranteed by employing a Lyapunov-based stability constraint. The multistage
economic MPC framework is validated on two natural gas network case studies to
minimize the net energy consumption during gas transmission. In both instances,
the multistage economic MPC effectively manages uncertain demands by preventing
constraint violations and guides the network to its optimal cyclic operating
conditions. The Lyapunov function remains bounded in both instances, validating
the robust stability of the controller.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         <span class="highlight-title">★</span> Whole-Body Model-Predictive Control of Legged Robots with MuJoCo 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04613v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04613v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        <span class="highlight-author">John Z. Zhang</span>, Taylor A. Howell, Zeji Yi, <span class="highlight-author">Chaoyi Pan</span>, <span class="highlight-author">Guanya Shi</span>, Guannan Qu, Tom Erez, Yuval Tassa, <span class="highlight-author">Zachary Manchester</span>
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We demonstrate the surprising real-world effectiveness of a very simple
approach to whole-body model-predictive control (MPC) of quadruped and humanoid
robots: the iterative LQR (iLQR) algorithm with MuJoCo dynamics and
finite-difference approximated derivatives. Building upon the previous success
of model-based behavior synthesis and control of locomotion and manipulation
tasks with MuJoCo in simulation, we show that these policies can easily
generalize to the real world with few sim-to-real considerations. Our baseline
method achieves real-time whole-body MPC on a variety of hardware experiments,
including dynamic quadruped locomotion, quadruped walking on two legs, and
full-sized humanoid bipedal locomotion. We hope this easy-to-reproduce hardware
baseline lowers the barrier to entry for real-world whole-body MPC research and
contributes to accelerating research velocity in the community. Our code and
experiment videos will be available online
at:https://johnzhang3.github.io/mujoco_ilqr
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Grid-Aware Islanding and Resynchronisation of AC/DC Microgrids 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04597v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04597v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Willem Lambrichts, Jules Mace, Drazen Dujic, Mario Paolone
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper proposes an optimal, grid-aware control framework for the
islanding, island-operation and resynchronisation of hybrid AC/DC microgrids.
The optimal control framework is based on a formally derived linearized
load-flow model for multiterminal hybrid AC/DC networks. The load flow model
integrates the AC grid, DC grid, and interfacing converters (IC) into a unified
representation. This work extends an existing load flow model to include the
ICs' grid-forming operation.
  In traditional islanding control frameworks, the grid-forming converter is
typically interfaced with an energy storage system that can provide
bidirectional power to maintain the power balance. The proposed framework,
however, allows the ICs to operate as the grid-forming unit while being
connected to a DC grid rather than a single resource. This configuration allows
for a wider operating range and, thus, a more flexible control. Furthermore,
the optimal grid-aware control framework can steer the system to ensure a
feasible operation without any grid constraint violations before, during, and
after the islanding manoeuvre. The framework also guarantees smooth
transitions, i.e., without any significant transient behaviour, when
transitioning between grid-connected and islanding operations. The optimal
control framework is experimentally validated on a 27-bus hybrid AC/DC network
consisting of 3 ICs that interface the AC and DC networks. The hybrid grid
hosts various controllable and stochastic resources.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 12 figures, IEEE transaction</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Maestro: A 302 GFLOPS/W and 19.8GFLOPS RISC-V Vector-Tensor Architecture
  for Wearable Ultrasound Edge Computing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04581v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04581v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mattia Sinigaglia, Amirhossein Kiamarzi, Marco Bertuletti, Luigi Ghionda, Mattia Orlandi, Riccardo Tedeschi, Aurora Di Giampietro, Yvan Tortorella, Luca Bertaccini, Simone Benatti, Giuseppe Tagliavini, Luca Benini, Francesco Conti, Davide Rossi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Most Wearable Ultrasound (WUS) devices lack the computational power to
process signals at the edge, instead relying on remote offload, which
introduces latency, high power consumption, and privacy concerns. We present
Maestro, a RISC-V SoC with unified Vector-Tensor Unit (VTU) and memory-coupled
Fast Fourier Transform (FFT) accelerators targeting edge processing for
wearable ultrasound devices, fabricated using low-cost TSMC 65nm CMOS
technology. The VTU achieves peak 302GFLOPS/W and 19.8GFLOPS at FP16, while the
multi-precision 16/32-bit floating-point FFT accelerator delivers peak
60.6GFLOPS/W and 3.6GFLOPS at FP16, We evaluate Maestro on a US-based gesture
recognition task, achieving 1.62GFLOPS in signal processing at 26.68GFLOPS/W,
and 19.52GFLOPS in Convolutional Neural Network (CNN) workloads at
298.03GFLOPS/W. Compared to a state-of-the-art SoC with a similar mission
profile, Maestro achieves a 5x speedup while consuming only 12mW, with an
energy consumption of 2.5mJ in a wearable US channel preprocessing and ML-based
postprocessing pipeline.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Occlusion-Aware Consistent <span class="highlight-title">Model Predictive</span> Control for Robot <span class="highlight-title">Navigation</span>
  in Occluded Obstacle-Dense Environments 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04563v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04563v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Minzhe Zheng, Lei Zheng, Lei Zhu, Jun Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Ensuring safety and motion consistency for robot navigation in occluded,
obstacle-dense environments is a critical challenge. In this context, this
study presents an occlusion-aware Consistent Model Predictive Control (CMPC)
strategy. To account for the occluded obstacles, it incorporates adjustable
risk regions that represent their potential future locations. Subsequently,
dynamic risk boundary constraints are developed online to ensure safety. The
CMPC then constructs multiple locally optimal trajectory branches (each
tailored to different risk regions) to balance between exploitation and
exploration. A shared consensus trunk is generated to ensure smooth transitions
between branches without significant velocity fluctuations, further preserving
motion consistency. To facilitate high computational efficiency and ensure
coordination across local trajectories, we use the alternating direction method
of multipliers (ADMM) to decompose the CMPC into manageable sub-problems for
parallel solving. The proposed strategy is validated through simulation and
real-world experiments on an Ackermann-steering robot platform. The results
demonstrate the effectiveness of the proposed CMPC strategy through comparisons
with baseline approaches in occluded, obstacle-dense environments.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Safe Distributed Learning-Enhanced Predictive Control for Multiple
  Quadrupedal Robots 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.05836v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.05836v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Weishu Zhan, Zheng Liang, Hongyu Song, Wei Pan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Quadrupedal robots exhibit remarkable adaptability in unstructured
environments, making them well-suited for formation control in real-world
applications. However, keeping stable formations while ensuring collision-free
navigation presents significant challenges due to dynamic obstacles,
communication constraints, and the complexity of legged locomotion. This paper
proposes a distributed model predictive control framework for multi-quadruped
formation control, integrating Control Lyapunov Functions to ensure formation
stability and Control Barrier Functions for decentralized safety enforcement.
To address the challenge of dynamically changing team structures, we introduce
Scale-Adaptive Permutation-Invariant Encoding (SAPIE), which enables robust
feature encoding of neighboring robots while preserving permutation invariance.
Additionally, we develop a low-latency Data Distribution Service-based
communication protocol and an event-triggered deadlock resolution mechanism to
enhance real-time coordination and prevent motion stagnation in constrained
spaces. Our framework is validated through high-fidelity simulations in NVIDIA
Omniverse Isaac Sim and real-world experiments using our custom quadrupedal
robotic system, XG. Results demonstrate stable formation control, real-time
feasibility, and effective collision avoidance, validating its potential for
large-scale deployment.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Novel Control Strategy for Offset Points Tracking in the Context of
  Agricultural Robotics 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.05835v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.05835v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Stephane Ngnepiepaye Wembe, Vincent Rousseau, Johann Laconte, Roland Lenain
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we present a novel method to control a rigidly connected
location on the vehicle, such as a point on the implement in case of
agricultural tasks. Agricultural robots are transforming modern farming by
enabling precise and efficient operations, replacing humans in arduous tasks
while reducing the use of chemicals. Traditionnaly, path_following algorithms
are designed to guide the vehicle's center along a predefined trajetory.
However, since the actual agronomic task is performed by the implement, it is
essential to control a specific point on the implement itself rather than
vehicle's center. As such, we present in this paper two approaches for
achieving the control of an offset point on the robot. The first approach
adapts existing control laws, initially inteded for rear axle's midpoint, to
manage the desired lateral deviation. The second approach employs backstepping
control techniques to create a control law that directly targets the implement.
We conduct real-world experiments, highlighting the limitations of traditional
approaches for offset points control, and demonstrating the strengths and
weaknesses of the proposed methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Structural Damping Identification Sensitivity in Flutter Speed
  Estimation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04433v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04433v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gabriele Dessena, Alessandro Pontillo, Marco Civera, Dmitry I. Ignatyev, James F. Whidborne, Luca Zanotti Fragonara
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Predicting flutter remains a key challenge in aeroelastic research, with
certain models relying on modal parameters, such as natural frequencies and
damping ratios. These models are particularly useful in early design stages or
for the development of small UAVs (maximum take-off mass below 7 kg). This
study evaluates two frequency-domain system identification methods, Fast
Relaxed Vector Fitting (FRVF) and the Loewner Framework (LF), for predicting
the flutter onset speed of a flexible wing model. Both methods are applied to
extract modal parameters from Ground Vibration Testing data, which are
subsequently used to develop a reduced-order model with two degrees of freedom.
Results indicate that FRVF and LFinformed models provide reliable flutter
speed, with predictions deviating by no more than 3% (FRVF) and 5% (LF) from
the N4SID-informed benchmark. The findings highlight the sensitivity of flutter
speed predictions to damping ratio identification accuracy and demonstrate the
potential of these methods as computationally efficient alternatives for
preliminary aeroelastic assessments.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ AOLO: Analysis and <span class="highlight-title">Optimization</span> For Low-Carbon Oriented Wireless Large
  Language Model Services 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04418v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04418v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaoqi Wang, Hongyang Du, Yuehong Gao, Dong In Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in large language models (LLMs) have led to their
widespread adoption and large-scale deployment across various domains. However,
their environmental impact, particularly during inference, has become a growing
concern due to their substantial energy consumption and carbon footprint.
Existing research has focused on inference computation alone, overlooking the
analysis and optimization of carbon footprint in network-aided LLM service
systems. To address this gap, we propose AOLO, a framework for analysis and
optimization for low-carbon oriented wireless LLM services. AOLO introduces a
comprehensive carbon footprint model that quantifies greenhouse gas emissions
across the entire LLM service chain, including computational inference and
wireless communication. Furthermore, we formulate an optimization problem aimed
at minimizing the overall carbon footprint, which is solved through joint
optimization of inference outputs and transmit power under
quality-of-experience and system performance constraints. To achieve this joint
optimization, we leverage the energy efficiency of spiking neural networks
(SNNs) by adopting SNN as the actor network and propose a low-carbon-oriented
optimization algorithm, i.e., SNN-based deep reinforcement learning (SDRL).
Comprehensive simulations demonstrate that SDRL algorithm significantly reduces
overall carbon footprint, achieving an 18.77% reduction compared to the
benchmark soft actor-critic, highlighting its potential for enabling more
sustainable LLM inference services.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On the Analysis of Stability, Sensitivity and Transparency in Variable
  Admittance Control for pHRI Enhanced by Virtual Fixtures 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04414v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04414v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Davide Tebaldi, Dario Onfiani, Luigi Biagiotti
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The interest in Physical Human-Robot Interaction (pHRI) has significantly
increased over the last two decades thanks to the availability of collaborative
robots that guarantee user safety during force exchanges. For this reason,
stability concerns have been addressed extensively in the literature while
proposing new control schemes for pHRI applications. Because of the nonlinear
nature of robots, stability analyses generally leverage passivity concepts. On
the other hand, the proposed algorithms generally consider ideal models of
robot manipulators. For this reason, the primary objective of this paper is to
conduct a detailed analysis of the sources of instability for a class of pHRI
control schemes, namely proxy-based constrained admittance controllers, by
considering parasitic effects such as transmission elasticity, motor velocity
saturation, and actuation delay. Next, a sensitivity analysis supported by
experimental results is carried out, in order to identify how the control
parameters affect the stability of the overall system. Finally, an adaptation
technique for the proxy parameters is proposed with the goal of maximizing
transparency in pHRI. The proposed adaptation method is validated through both
simulations and experimental tests.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Proactive Robust Hardening of Resilient Power Distribution Network:
  Decision-Dependent Uncertainty Modeling and Fast Solution Strategy 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04375v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04375v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Donglai Ma, Xiaoyu Cao, Bo Zeng, Qing-Shan Jia, Chen Chen, Qiaozhu Zhai, Xiaohong Guan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  To address the power system hardening problem, traditional approaches often
adopt robust optimization (RO) that considers a fixed set of concerned
contingencies, regardless of the fact that hardening some components actually
renders relevant contingencies impractical. In this paper, we directly adopt a
dynamic uncertainty set that explicitly incorporates the impact of hardening
decisions on the worst-case contingencies, which leads to a decision-dependent
uncertainty (DDU) set. Then, a DDU-based robust-stochastic optimization
(DDU-RSO) model is proposed to support the hardening decisions on distribution
lines and distributed generators (DGs). Also, the randomness of load variations
and available storage levels is considered through stochastic programming (SP)
in the innermost level problem. Various corrective measures (e.g., the joint
scheduling of DGs and energy storage) are included, coupling with a finite
support of stochastic scenarios, for resilience enhancement. To relieve the
computation burden of this new hardening formulation, an enhanced customization
of parametric column-and-constraint generation (P-C&CG) algorithm is developed.
By leveraging the network structural information, the enhancement strategies
based on resilience importance indices are designed to improve the convergence
performance. Numerical results on 33-bus and 118-bus test distribution networks
have demonstrated the effectiveness of DDU-RSO aided hardening scheme.
Furthermore, in comparison to existing solution methods, the enhanced P-C&CG
has achieved a superior performance by reducing the solution time by a few
orders of magnitudes.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Energy Consumption of Robotic Arm with the Local Reduction Method 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04340v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04340v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Halima Ibrahim Kure, Jishna Retnakumari, Lucian Nita, Saeed Sharif, Hamed Balogun, Augustine O. Nwajana
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Energy consumption in robotic arms is a significant concern in industrial
automation due to rising operational costs and environmental impact. This study
investigates the use of a local reduction method to optimize energy efficiency
in robotic systems without compromising performance. The approach refines
movement parameters, minimizing energy use while maintaining precision and
operational reliability. A three-joint robotic arm model was tested using
simulation over a 30-second period for various tasks, including pick-and-place
and trajectory-following operations. The results revealed that the local
reduction method reduced energy consumption by up to 25% compared to
traditional techniques such as Model Predictive Control (MPC) and Genetic
Algorithms (GA). Unlike MPC, which requires significant computational
resources, and GA, which has slow convergence rates, the local reduction method
demonstrated superior adaptability and computational efficiency in real-time
applications. The study highlights the scalability and simplicity of the local
reduction approach, making it an attractive option for industries seeking
sustainable and cost-effective solutions. Additionally, this method can
integrate seamlessly with emerging technologies like Artificial Intelligence
(AI), further enhancing its application in dynamic and complex environments.
This research underscores the potential of the local reduction method as a
practical tool for optimizing robotic arm operations, reducing energy demands,
and contributing to sustainability in industrial automation. Future work will
focus on extending the approach to real-world scenarios and incorporating
AI-driven adjustments for more dynamic adaptability.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>4 pages, 3 figures, 1 table</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Stability analysis for nonlinear compressor system and active adaptive
  controller against surge with antisurge valve 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04337v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04337v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Seyed Mohammad Hosseindokht
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, a compressor system is analyzed in order to show its
characteristics and design a control scheme to improve its efficiency. A
mathematical technique has been created to forecast the onset of surge and
instability in a compressor chart, drawing from the nonlinear Greitzer and
Moore model. This approach employs the phase plane and Jacobian matrix to
identify both stable and unstable regions within the compressor, as well as to
capture the limit cycle within the unstable region. A predictive analytical
approach for anticipating compressor surge and instability is of great
importance in system instrumentation and control. State space model is built up
by nonlinear Greitzer equations. Validation from previous study about especial
compressor will be considered for evaluation of mathematic method. Upstream
flow acts as a disturbance to control loop and controller cannot satisfy
desired requirements with flow variances, ergo it is essential that controller
is adapted to new conditions. Since control signal is linearly related to
system output, a PD controller is used to control compressor system. An
adaptive PD controller is designed with MRAS method based on a reference model.
Adaptive controller can stabilize compressor and increase its efficiency in the
presence of any disturbances. Simulation results shows that an adaptive
controller can provide good performance and convergence in case of speed
changes by adapting gain parameters, and adaptive will be compared with normal
PID. Finally, controller stability is investigated.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ <span class="highlight-title">Manipulation</span> of Elasto-Flexible Cables with Single or Multiple UAVs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04304v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04304v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chiara Gabellieri, Lars Teeuwen, Yaolei Shen, Antonio Franchi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This work considers a large class of systems composed of multiple quadrotors
manipulating deformable and extensible cables. The cable is described via a
discretized representation, which decomposes it into linear springs
interconnected through lumped-mass passive spherical joints. Sets of flat
outputs are found for the systems. Numerical simulations support the findings
by showing cable manipulation relying on flatness-based trajectories.
Eventually, we present an experimental validation of the effectiveness of the
proposed discretized cable model for a two-robot example. Moreover, a
closed-loop controller based on the identified model and using cable-output
feedback is experimentally tested.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Performance Analysis of Multirate Systems: A Direct Frequency-Domain
  Identification Approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04248v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04248v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Max van Haren, Lennart Blanken, Tom Oomen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Frequency-domain performance analysis of intersample behavior in sampled-data
and multirate systems is challenging due to the lack of a frequency-separation
principle, and systematic identification techniques are lacking. The aim of
this \manuscript is to develop an efficient technique for identifying the full
intersample performance in the frequency-domain for closed-loop multirate
systems, in particular the Performance Frequency Gain (PFG). Through local
modeling techniques, aliased frequency components are effectively disentangled
when identifying the PFG, which is directly facilitated by frequency-lifting
the multirate system to a multivariable time-invariant representation. The
developed method accurately and directly identifies the PFG in a single
identification experiment. Finally, the developed method is experimentally
validated on a prototype motion system, showing accurate identification of
frequency-domain representations for the multirate system, including the PFG.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Digital twin with automatic disturbance detection for an
  expert-controlled SAG mill 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04225v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04225v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Paulina Quintanilla, Francisco Fernández, Cristóbal Mancilla, Matías Rojas, Daniel Navia
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study presents the development and validation of a digital twin for a
semi-autogenous grinding (SAG) mill controlled by an expert system. The digital
twin integrates three key components of the closed-loop operation: (1) fuzzy
logic for expert control, (2) a state-space model for regulatory control, and
(3) a recurrent neural network to simulate the SAG mill process. The digital
twin is combined with a statistical framework for automatically detecting
process disturbances (or critical operations), which triggers model retraining
only when deviations from expected behaviour are identified, ensuring
continuous updates with new data to enhance the SAG supervision. The model was
trained with 68 hours of operational industrial data and validated with an
additional 8 hours, allowing it to predict mill behaviour within a 2.5-minute
horizon at 30-second intervals with errors smaller than 5%.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Personalized Emotion Detection from Floor Vibrations Induced by
  Footsteps 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04190v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04190v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuyan Wu, Yiwen Dong, Sumer Vaid, Gabriella M. Harari, Hae Young Noh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Emotion recognition is critical for various applications such as early
detection of mental health disorders and emotion based smart home systems.
Previous studies used various sensing methods for emotion recognition, such as
wearable sensors, cameras, and microphones. However, these methods have
limitations in long term domestic, including intrusiveness and privacy
concerns. To overcome these limitations, this paper introduces a nonintrusive
and privacy friendly personalized emotion recognition system, EmotionVibe,
which leverages footstep induced floor vibrations for emotion recognition. The
main idea of EmotionVibe is that individuals' emotional states influence their
gait patterns, subsequently affecting the floor vibrations induced by their
footsteps. However, there are two main research challenges: 1) the complex and
indirect relationship between human emotions and footstep induced floor
vibrations and 2) the large between person variations within the relationship
between emotions and gait patterns. To address these challenges, we first
empirically characterize this complex relationship and develop an emotion
sensitive feature set including gait related and vibration related features
from footstep induced floor vibrations. Furthermore, we personalize the emotion
recognition system for each user by calculating gait similarities between the
target person (i.e., the person whose emotions we aim to recognize) and those
in the training dataset and assigning greater weights to training people with
similar gait patterns in the loss function. We evaluated our system in a
real-world walking experiment with 20 participants, summing up to 37,001
footstep samples. EmotionVibe achieved the mean absolute error (MAE) of 1.11
and 1.07 for valence and arousal score estimations, respectively, reflecting
19.0% and 25.7% error reduction compared to the baseline method.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Simulation-based Analysis Of Highway Trajectory <span class="highlight-title">Plan</span>ning Using
  High-Order Polynomial For Highly Automated Driving Function 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04159v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04159v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Milin Patel, Marzana Khatun, Rolf Jung, Michael Glaß
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  One of the fundamental tasks of autonomous driving is safe trajectory
planning, the task of deciding where the vehicle needs to drive, while avoiding
obstacles, obeying safety rules, and respecting the fundamental limits of road.
Real-world application of such a method involves consideration of surrounding
environment conditions and movements such as Lane Change, collision avoidance,
and lane merge. The focus of the paper is to develop and implement safe
collision free highway Lane Change trajectory using high order polynomial for
Highly Automated Driving Function (HADF). Planning is often considered as a
higher-level process than control. Behavior Planning Module (BPM) is designed
that plans the high-level driving actions like Lane Change maneuver to safely
achieve the functionality of transverse guidance ensuring safety of the vehicle
using motion planning in a scenario including environmental situation. Based on
the recommendation received from the (BPM), the function will generate a desire
corresponding trajectory. The proposed planning system is situation specific
with polynomial based algorithm for same direction two lane highway scenario.
To support the trajectory system polynomial curve can be used to reduces
overall complexity and thereby allows rapid computation. The proposed Lane
Change scenario is modeled, and results has been analyzed (verified and
validate) through the MATLAB simulation environment. The method proposed in
this paper has achieved a significant improvement in safety and stability of
Lane Changing maneuver.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Formally Verified Neural Network Controllers for Incremental
  Input-to-State Stability of Unknown Discrete-Time Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04129v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04129v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ahan Basu, Bhabani Shankar Dey, Pushpak Jagtap
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This work aims to synthesize a controller that ensures that an unknown
discrete-time system is incrementally input-to-state stable ($\delta$-ISS). In
this work, we introduce the notion of $\delta$-ISS control Lyapunov function
($\delta$-ISS-CLF), which, in conjunction with the controller, ensures that the
closed-loop system is incrementally ISS. To address the unknown dynamics of the
system, we parameterize the controller as well as the $\delta$-ISS-CLF as
neural networks and learn them by utilizing the sampled data from the state
space of the unknown system. To formally verify the obtained $\delta$-ISS-CLF,
we develop a validity condition and incorporate the condition into the training
framework to ensure a provable correctness guarantee at the end of the training
process. Finally, the usefulness of the proposed approach is proved using
multiple case studies - the first one is a scalar system with a non-affine
non-polynomial structure, the second example is a one-link manipulator system,
the third system is a nonlinear Moore-Grietzer model of the jet engine and the
final one is a rotating rigid spacecraft model.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Quantitative Flow Approximation Properties of Narrow Neural ODEs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04068v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04068v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Karthik Elamvazhuthi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this note, we revisit the problem of flow approximation properties of
neural ordinary differential equations (NODEs). The approximation properties
have been considered as a flow controllability problem in recent literature.
The neural ODE is considered {\it narrow} when the parameters have dimension
equal to the input of the neural network, and hence have limited width. We
derive the relation of narrow NODEs in approximating flows of shallow but wide
NODEs. Due to existing results on approximation properties of shallow neural
networks, this facilitates understanding which kind of flows of dynamical
systems can be approximated using narrow neural ODEs. While approximation
properties of narrow NODEs have been established in literature, the proofs
often involve extensive constructions or require invoking deep controllability
theorems from control theory. In this paper, we provide a simpler proof
technique that involves only ideas from ODEs and Gr{\"o}nwall's lemma.
Moreover, we provide an estimate on the number of switches needed for the time
dependent weights of the narrow NODE to mimic the behavior of a NODE with a
single layer wide neural network as the velocity field.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Object State Estimation Through Robotic Active Interaction for
  Biological Autonomous Drilling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04043v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04043v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaofeng Lin, Enduo Zhao, Saúl Alexis Heredia Pérez, Kanako Harada
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Estimating the state of biological specimens is challenging due to limited
observation through microscopic vision. For instance, during mouse skull
drilling, the appearance alters little when thinning bone tissue because of its
semi-transparent property and the high-magnification microscopic vision. To
obtain the object's state, we introduce an object state estimation method for
biological specimens through active interaction based on the deflection. The
method is integrated to enhance the autonomous drilling system developed in our
previous work. The method and integrated system were evaluated through 12
autonomous eggshell drilling experiment trials. The results show that the
system achieved a 91.7% successful ratio and 75% detachable ratio, showcasing
its potential applicability in more complex surgical procedures such as mouse
skull craniotomy. This research paves the way for further development of
autonomous robotic systems capable of estimating the object's state through
active interaction.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The first and second authors contribute equally to this research. 6
  pages, 5 figures, submitted to RA-L</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Autonomous Robotic Bone Micro-Milling System with Automatic Calibration
  and 3D Surface Fitting <span class="chip">IROS 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04038v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04038v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Enduo Zhao, Xiaofeng Lin, Yifan Wang, Kanako Harada
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Automating bone micro-milling using a robotic system presents challenges due
to the uncertainties in both the external and internal features of bone tissue.
For example, during a mouse cranial window creation, a circular path with a
radius of 2 to 4 mm needs to be milled on the mouse skull using a microdrill.
The uneven surface and non-uniform thickness of the mouse skull make it
difficult to fully automate this process, requiring the system to possess
advanced perceptual and adaptive capabilities. In this study, we propose an
automatic calibration and 3D surface fitting method and integrate it into an
autonomous robotic bone micro-milling system, enabling it to quickly, in
real-time, and accurately perceive and adapt to the uneven surface and
non-uniform thickness of the target without human assistance. Validation
experiments on euthanized mice demonstrate that the improved system achieves a
success rate of 85.7 % and an average milling time of 2.1 minutes, showing not
only significant performance improvements over the previous system but also
exceptional accuracy, speed, and stability compared to human operators.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 8 figures, submitted to IROS 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Vibration Analysis and Mitigation in Semiconductor Motion Stages Using
  DMAIC Methodology- A Case Study 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04019v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04019v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yin Li, Hua Chen, Fugee Tsung
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Motion stages are critical in semiconductor manufacturing equipment for
processes like die bonding, wafer loading, and chip packaging, as their
performance must meet the industry's stringent precision requirements.
Vibration, a significant yet often overlooked adversary to precision motion
stages, is challenging to identify and mitigate due to its subtle nature. This
study, conducted at a motion stage manufacturer facing frequent
vibration-related complaints, proposes a novel approach to resolving vibration
issues. By leveraging the DMAIC methodology, it introduces VIBGUARD, an active
vibration monitoring and mitigation solution, instead of solely focusing on
traditional hardware vibration control. This comprehensive strategy enhances
value and competitiveness, increasing UPH (units per hour) by 15.3% from 8,500
to 9,800 and reducing downtime by 68.2% from 2.2 to 0.7 occurrences per month.
This case study and the DMAIC methodology offer valuable resources for quality
control and problem analysis in the semiconductor industry.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Performance-Barrier Event-Triggered PDE Control of Traffic Flow 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.00722v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.00722v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Peihan Zhang, Bhathiya Rathnayake, Mamadou Diagne, Miroslav Krstic
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  For stabilizing stop-and-go oscillations in traffic flow by actuating a
variable speed limit (VSL) at a downstream boundary of a freeway segment, we
introduce event-triggered PDE backstepping designs employing the recent concept
of performance-barrier event-triggered control (P-ETC). Our design is for
linearized hyperbolic Aw-Rascle-Zhang (ARZ) PDEs governing traffic velocity and
density. Compared to continuous feedback, ETC provides a piecewise-constant VSL
commands-more likely to be obeyed by human drivers. Unlike the existing regular
ETC (R-ETC), which enforces conservatively a strict decrease of a Lyapunov
function, our performance-barrier (P-ETC) approach permits an increase, as long
as the Lyapunov function remains below a performance barrier, resulting in
fewer control updates than R-ETC. To relieve VSL from continuously monitoring
the triggering function, we also develop periodic event-triggered (PETC) and
self-triggered (STC) versions of both R-ETC and P-ETC. These are referred to as
R/P-PETC and R/P-STC, respectively, and we show that they both guarantee
Zeno-free behavior and exponential convergence in the spatial $L^2$ norm. With
comparative simulations, we illustrate the benefits of the performance-barrier
designs through traffic metrics (driver comfort, safety, travel time, fuel
consumption). The proposed algorithms reduce discomfort nearly in half relative
to driver behavior without VSL, while tripling the driver safety, measured by
the average dwell time, relative to the R-ETC frequent-switching VSL schedule.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A CAV-based perimeter-free regional traffic control strategy utilizing
  existing parking infrastructure 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.04620v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.04620v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hao Liu, Vikash V. Gayah
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper proposes a novel perimeter-free regional traffic management
strategy for traffic networks under a connected and autonomous vehicle (CAV)
environment. The proposed strategy requires CAVs, especially those with long
remaining travel distances, to temporarily wait at nearby parking facilities
when the network is congested. After a designated holding time, these CAVs are
allowed to re-enter the network. Doing so helps reduce congestion and improve
overall operational efficiency. Unlike traditional perimeter control approaches
that restrict inflows to congested regions, the proposed holding strategy
leverages existing parking infrastructure to temporarily hold vehicles in a way
that partially avoids local queue accumulation issues. The proposed method can
be easily integrated with existing signal control methods and retains the
maximum stability property of the original traffic signal control methods.
Simulation results show that the proposed strategy not only reduces travel time
for vehicles that are not held, but can also reduce travel times for some of
the held vehicles as well, which serves as another key merit of the proposed
approach. Compared to the two benchmark perimeter control algorithms, the
proposed strategy is more robust against demand patterns and generates stronger
improvements in the operational efficiency. Importantly, since the proposed
strategy requires existing parking infrastructure, its performance has been
demonstrated under various configurations of parking locations and capacities.
Particularly, it is demonstrated that the utilization of the parking facility
consistently improves overall traffic efficiency, regardless of the facility's
size. Lastly, the proposed strategy is shown to be beneficial in a partial CAV
environment where only a subset of vehicles are available for holding.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Cooperative Nonlinear Guidance Strategies for Guaranteed Pursuit-Evasion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.06176v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.06176v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Saurabh Kumar, Shashi Ranjan Kumar, Abhinav Sinha
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper addresses the pursuit-evasion problem involving three agents -- a
purser, an evader, and a defender. We develop cooperative guidance laws for the
evader-defender team that guarantee that the defender intercepts the pursuer
before it reaches the vicinity of the evader. Unlike heuristic methods, optimal
control, differential game formulation, and recently proposed time-constrained
guidance techniques, we propose a geometric solution to safeguard the evader
from the pursuer's incoming threat. The proposed strategy is computationally
efficient and expected to be scalable as the number of agents increases.
Another alluring feature of the proposed strategy is that the evader-defender
team does not require the knowledge of the pursuer's strategy and that the
pursuer's interception is guaranteed from arbitrary initial engagement
geometries. We further show that the necessary error variables for the
evader-defender team vanish within a time that can be exactly prescribed prior
to the three-body engagement. Finally, we demonstrate the efficacy of the
proposed cooperative defense strategy via simulation in diverse engagement
scenarios.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Risk-Aware Autonomous Driving with Linear Temporal Logic Specifications 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.09769v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.09769v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shuhao Qi, Zengjie Zhang, Zhiyong Sun, Sofie Haesaert
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Humans naturally balance the risks of different concerns while driving,
including traffic rule violations, minor accidents, and fatalities. However,
achieving the same behavior in autonomous systems remains an open problem. This
paper extends a risk metric that has been verified in human-like driving
studies to encompass more complex driving scenarios specified by linear
temporal logic (LTL) that go beyond just collision risks. This extension
incorporates the timing and severity of events into LTL specifications, thereby
reflecting a human-like risk awareness. Without sacrificing expressivity for
traffic rules, we adopt LTL specifications composed of safety and co-safety
formulas, allowing the control synthesis problem to be reformulated as a
reachability problem. By leveraging occupation measures, we formulate a linear
programming (LP) problem for this LTL-based risk metric. Consequently, the
synthesized policy balances different types of risks, including not only
collision risks but also traffic rule violations. The effectiveness of the
proposed approach is validated by three typical traffic scenarios in the Carla
simulator.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Data-Driven Aggressive Autonomous Racing Framework Utilizing Local
  Trajectory <span class="highlight-title">Plan</span>ning with Velocity Prediction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11570v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11570v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhouheng Li, Bei Zhou, Cheng Hu, Lei Xie, Hongye Su
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The development of autonomous driving has boosted the research on autonomous
racing. However, existing local trajectory planning methods have difficulty
planning trajectories with optimal velocity profiles at racetracks with sharp
corners, thus weakening the performance of autonomous racing. To address this
problem, we propose a local trajectory planning method that integrates Velocity
Prediction based on Model Predictive Contouring Control (VPMPCC). The optimal
parameters of VPMPCC are learned through Bayesian Optimization (BO) based on a
proposed novel Objective Function adapted to Racing (OFR). Specifically, VPMPCC
achieves velocity prediction by encoding the racetrack as a reference velocity
profile and incorporating it into the optimization problem. This method
optimizes the velocity profile of local trajectories, especially at corners
with significant curvature. The proposed OFR balances racing performance with
vehicle safety, ensuring safe and efficient BO training. In the simulation, the
number of training iterations for OFR-based BO is reduced by 42.86% compared to
the state-of-the-art method. The optimal simulation-trained parameters are then
applied to a real-world F1TENTH vehicle without retraining. During prolonged
racing on a custom-built racetrack featuring significant sharp corners, the
mean projected velocity of VPMPCC reaches 93.18% of the vehicle's handling
limits. The released code is available at https://github.com/zhouhengli/VPMPCC.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Learning Li-ion battery health and degradation modes from data with
  aging-aware circuit models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.06639v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.06639v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zihao Zhou, Antti Aitio, David Howey
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Non-invasive estimation of Li-ion battery state-of-health from operational
data is valuable for battery applications, but remains challenging. Pure
model-based methods may suffer from inaccuracy and long-term instability of
parameter estimates, whereas pure data-driven methods rely heavily on training
data quality and quantity, causing lack of generality when extrapolating to
unseen cases. We apply an aging-aware equivalent circuit model for health
estimation, combining the flexibility of data-driven techniques within a
model-based approach. A simplified electrical model with voltage source and
resistor incorporates Gaussian process regression to learn capacity fade over
time and also the dependence of resistance on operating conditions and time.
The approach was validated against two datasets and shown to give accurate
performance with less than 1% relative root mean square error (RMSE) in
capacity and less than 2% mean absolute percentage error (MAPE). Critically, we
show that the open circuit voltage versus state-of-charge function must be
accurately known, and any inaccuracies or changes in this over time strongly
influence the inferred resistance. However, this feature (or bug) may also be
used to estimate in operando differential voltage curves from operational data.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 10 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Tracking Control of Euler-Lagrangian Systems with Prescribed State,
  Input, and Temporal Constraints 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.01866v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.01866v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chidre Shravista Kashyap, Pushpak Jagtap, Jishnu Keshavan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The synthesis of a smooth tracking control policy for Euler-Lagrangian (EL)
systems with stringent regions of operation induced by state, input and
temporal (SIT) constraints is a very challenging task. In contrast with
existing methods that utilize prior knowledge of EL model parameters and
uncertainty bounds, this study proposes an approximation-free adaptive barrier
function-based control policy to ensure local prescribed time convergence of
tracking error under state and input constraints. The proposed control policy
accomplishes this by utilizing smooth time-based generator functions embedded
in the filtered tracking error, which is combined with a saturation function
that limits control action and confines states within the prescribed limits by
enforcing the time-varying bounds on the filtered tracking error. Importantly,
corresponding feasibility conditions pertaining to the minimum control
authority, maximum disturbance rejection capability of the control policy, and
the viable set of initial conditions are derived, illuminating the narrow
operating domain of the EL systems arising from the interplay of SIT
constraints. Numerical validation studies with three different robotic
manipulators are employed to demonstrate the efficacy of the proposed scheme. A
detailed performance comparison study with leading alternative designs is also
undertaken to illustrate the superior performance of the proposed scheme.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Pitch <span class="highlight-title">Plan</span>e Trajectory Tracking Control for Sounding Rockets via
  Adaptive Feedback Linearization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.05285v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.05285v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pedro dos Santos, Paulo Oliveira
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper proposes a pitch plane trajectory tacking control solution for
suborbital launch vehicles relying on adaptive feedback linearization.
Initially, the 2D dynamics and kinematics for a single-engine,
thrust-vector-controlled sounding rocket are obtained for control design
purposes. Then, an inner-outer control strategy, which simultaneously tackles
attitude and position control, is adopted, with the inner-loop comprising the
altitude and pitch control and the outer-loop addressing the horizontal
(downrange) position control. Feedback linearization is used to cancel out the
non-linearities in both the inner and outer dynamics. Making use of Lyapunov
stability theory, an adaptation law, which provides online estimates on the
inner-loop aerodynamic uncertainty, is jointly designed with the output
tracking controller via adaptive backstepping, ensuring global reference
tracking in the region where the feedback linearization is well-defined. The
zero dynamics of the inner-stabilized system are then exploited to obtain the
outerloop dynamics and derive a Linear Quadratic Regulator (LQR) with integral
action, which can stabilize them as well as reject external disturbances. In
the outermost loop, the estimate on the correspondent aerodynamic uncertainty
is indirectly obtained by using the inner loop estimates together with known
aerodynamics relations. The resulting inner-outer position control solution is
proven to be asymptotically stable in the region of interest. Using a
single-stage sounding rocket, propelled by a liquid engine, as reference
vehicle, different mission scenarios are tested in a simulation environment to
verify the adaptability of the proposed control strategy. The system is able to
track the requested trajectories while rejecting external wind disturbances.
Furthermore, the need to re-tune the control gains in between different mission
scenarios is minimal to none.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Paper presented at the IEEE Aerospace Conference 2025. Copyright:
  979-8-3503-5597-0/25/$31.00 @2025 IEEE</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Autonomous RISs and Oblivious Base Stations: The Observer Effect and its
  Mitigation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2304.10858v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2304.10858v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Victor Croisfelt, Francesco Devoti, Fabio Saggese, Vincenzo Sciancalepore, Xavier Costa-Pérez, Petar Popovski
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Autonomous reconfigurable intelligent surfaces (RISs) offer the potential to
simplify deployment by reducing the need for real-time remote control between a
base station (BS) and an RIS. However, we highlight two major challenges posed
by autonomy. The first is implementation complexity, as autonomy requires
hybrid RISs (HRISs) equipped with additional onboard hardware to monitor the
propagation environment and perform local channel estimation (CHEST), a process
known as probing. The second challenge, termed probe distortion, reflects a
form of the observer effect: during probing, an HRIS can inadvertently alter
the propagation environment, potentially disrupting the operations of other
communicating devices sharing the environment. Although implementation
complexity has been extensively studied, probe distortion remains largely
unexplored. To further assess the potential of autonomous RIS, this paper
comprehensively and pragmatically studies the fundamental trade-offs posed by
these challenges collectively. In particular, we examine the robustness of an
HRIS-assisted massive multiple-input multiple-output (mMIMO) system by
considering its critical components and stringent conditions. The latter
include: (a) two extremes of implementation complexity, represented by
minimalist operation designs of two distinct HRIS hardware architectures, and
(b) an oblivious BS that fully embraces probe distortion. To make our analysis
possible, we propose a physical-layer orchestration framework that aligns HRIS
and mMIMO operations. We present empirical evidence that autonomous RISs remain
promising under stringent conditions and outline research directions to deepen
probe distortion understanding.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, 9 figures, published in IEEE Transactions on Wireless
  Communications</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Eavesdropping on Goal-Oriented Communication: Timing Attacks and
  Countermeasures 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.07088v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.07088v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Federico Mason, Federico Chiariotti, Pietro Talli, Andrea Zanella
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Goal-oriented communication is a new paradigm that considers the meaning of
transmitted information to optimize communication. One possible application is
the remote monitoring of a process under communication costs: scheduling
updates based on goal-oriented considerations can significantly reduce
transmission frequency while maintaining high-quality tracking performance.
However, goal-oriented scheduling also opens a timing-based side-channel that
an eavesdropper may exploit to obtain information about the state of the remote
process, even if the content of updates is perfectly secure. In this work, we
study an eavesdropping attack against pull-based goal-oriented scheduling for
the tracking of remote Markov processes. We provide a theoretical framework for
defining the effectiveness of the attack and of possible countermeasures, as
well as a practical heuristic that can provide a balance between the
performance gains offered by goal-oriented communication and the information
leakage.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Auxiliary-Variable Adaptive Control Barrier Functions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.15026v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.15026v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shuo Liu, Wei Xiao, Calin A. Belta
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper addresses the challenge of ensuring safety and feasibility in
control systems using Control Barrier Functions (CBFs). Existing CBF-based
Quadratic Programs (CBF-QPs) often encounter feasibility issues due to mixed
relative degree constraints, input nullification problems, and the presence of
tight or time-varying control bounds, which can lead to infeasible solutions
and compromised safety. To address these challenges, we propose
Auxiliary-Variable Adaptive Control Barrier Functions (AVCBFs), a novel
framework that introduces auxiliary variables in auxiliary functions to
dynamically adjust CBF constraints without the need of excessive additional
constraints. The AVCBF method ensures that all components of the control input
explicitly appear in the desired-order safety constraint, thereby improving
feasibility while maintaining safety guarantees. Additionally, we introduce an
automatic tuning method that iteratively adjusts AVCBF hyperparameters to
ensure feasibility and safety with less conservatism. We demonstrate the
effectiveness of the proposed approach in adaptive cruise control and obstacle
avoidance scenarios, showing that AVCBFs outperform existing CBF methods by
reducing infeasibility and enhancing adaptive safety control under tight or
time-varying control bounds.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, 8 figures. arXiv admin note: substantial text overlap with
  arXiv:2304.00372</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ iWalker: Imperative Visual <span class="highlight-title">Plan</span>ning for Walking Humanoid Robot 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.18361v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.18361v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiao Lin, Yuhao Huang, Taimeng Fu, Xiaobin Xiong, Chen Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Humanoid robots, designed to operate in human-centric environments, serve as
a fundamental platform for a broad range of tasks. Although humanoid robots
have been extensively studied for decades, a majority of existing humanoid
robots still heavily rely on complex modular frameworks, leading to
inflexibility and potential compounded errors from independent sensing,
planning, and acting components. In response, we propose an end-to-end humanoid
sense-plan-act walking system, enabling vision-based obstacle avoidance and
footstep planning for whole body balancing simultaneously. We designed two
imperative learning (IL)-based bilevel optimizations for model-predictive step
planning and whole body balancing, respectively, to achieve self-supervised
learning for humanoid robot walking. This enables the robot to learn from
arbitrary unlabeled data, improving its adaptability and generalization
capabilities. We refer to our method as iWalker and demonstrate its
effectiveness in both simulated and real-world environments, representing a
significant advancement toward autonomous humanoid robots.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Joint-repositionable Inner-wireless <span class="highlight-title">Plan</span>ar Snake Robot 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.13916v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.13916v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ayato Kanada, Ryo Takahashi, Keito Hayashi, Ryusuke Hosaka, Wakako Yukita, Yasutaka Nakashima, Tomoyuki Yokota, Takao Someya, Mitsuhiro Kamezaki, Yoshihiro Kawahara, Motoji Yamamoto
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Bio-inspired multi-joint snake robots offer the advantages of terrain
adaptability due to their limbless structure and high flexibility. However, a
series of dozens of motor units in typical multiple-joint snake robots results
in a heavy body structure and hundreds of watts of high power consumption. This
paper presents a joint-repositionable, inner-wireless snake robot that enables
multi-joint-like locomotion using a low-powered underactuated mechanism. The
snake robot, consisting of a series of flexible passive links, can dynamically
change its joint coupling configuration by repositioning motor-driven joint
units along rack gears inside the robot. Additionally, a soft robot skin
wirelessly powers the internal joint units, avoiding the risk of wire tangling
and disconnection caused by the movable joint units. The combination of the
joint-repositionable mechanism and the wireless-charging-enabled soft skin
achieves a high degree of bending, along with a lightweight structure of 1.3 kg
and energy-efficient wireless power transmission of 7.6 watts.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Optimization and Control <span class="chip" style="font-size: 60%">41</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SPDE Games Driven by a Brownian Sheet with Applications to Pollution
  Minimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04993v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04993v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nacira Agram, Bernt Øksendal, Frank Proske, Olena Tymoshenko
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper studies a nonzero-sum stochastic differential game in the context
of shared spatial-domain pollution control. The pollution dynamics are governed
by a stochastic partial differential equation (SPDE) driven by a Brownian
sheet, capturing the stochastic nature of environmental fluctuations. Two
players, representing different regions, aim to minimize their respective cost
functionals, which balance pollution penalties with the cost of implementing
control strategies.
  The nonzero-sum framework reflects the interdependent yet conflicting
objectives of the players, where both cooperation and competition influence the
outcomes. We derive necessary and sufficient conditions for Nash equilibrium
strategies, using a maximum principle approach. This approach involves the
introduction of a new pair of adjoint variables, (L_1, L_2), which do not
appear in a corresponding formulation with the classical (1-parameter) Brownian
motion.
  Finally, we apply our results to two case studies in pollution control,
demonstrating how spatial and stochastic dynamics shape the equilibrium
strategies.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>28</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Extended Version: Non-Preemptive Scheduling of Flexible Loads in Smart
  Grids via Convex <span class="highlight-title">Optimization</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04909v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04909v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mehdi Davoudi, Mingyu Chen, Junjie Qin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper studies the scheduling of a large population of non-preemptive
flexible electric loads, each of which has a flexible starting time but once
started will follow a fixed load shape until completion. We first formulate the
scheduling problem as a mixed-integer convex program (MICP), then propose an
efficient polynomial time relaxation-adjustment-rounding algorithm for solving
the problem. The key novelty of the proposed method lies in its adjustment
step, which uses a graph-based algorithm to navigate within the set of optimal
points of the convex relaxation while reducing the number of fractional entries
in the solution. We establish mathematically that our algorithm yields
solutions that are near optimal for a finite number of loads and with its
sub-optimality independent of the number of loads. Consequently, the proposed
method is asymptotically optimal in a per-load cost sense when the number of
loads increases. Despite the gap between the MICP and its convex relaxation, we
establish that the solution of the proposed algorithm can be decentralized by
marginal prices of the convex relaxation. We also develop and analyze variants
of the proposed algorithm for settings with uncertainty and with time-varying
realistic load shapes. Finally, we numerically evaluate the proposed algorithm
in a case study for the non-preemptive scheduling of electric vehicles charging
loads.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Longer version of a paper submitted to IEEE Transactions on Control
  of Network Systems</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Efficiently Escaping Saddle Points under Generalized Smoothness via
  Self-Bounding Regularity 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04712v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04712v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Daniel Yiming Cao, August Y. Chen, Karthik Sridharan, Benjamin Tang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we study the problem of non-convex optimization on functions
that are not necessarily smooth using first order methods. Smoothness
(functions whose gradient and/or Hessian are Lipschitz) is not satisfied by
many machine learning problems in both theory and practice, motivating a recent
line of work studying the convergence of first order methods to first order
stationary points under appropriate generalizations of smoothness.
  We develop a novel framework to study convergence of first order methods to
first and \textit{second} order stationary points under generalized smoothness,
under more general smoothness assumptions than the literature. Using our
framework, we show appropriate variants of GD and SGD (e.g. with appropriate
perturbations) can converge not just to first order but also \textit{second
order stationary points} in runtime polylogarithmic in the dimension. To our
knowledge, our work contains the first such result, as well as the first
'non-textbook' rate for non-convex optimization under generalized smoothness.
We demonstrate that several canonical non-convex optimization problems fall
under our setting and framework.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>79 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Data-Driven Distributed <span class="highlight-title">Optimization</span> via Aggregative Tracking and
  Deep-Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04668v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04668v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Riccardo Brumali, Guido Carnevale, Giuseppe Notarstefano
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we propose a novel distributed data-driven optimization
scheme. In particular, we focus on the so-called aggregative framework, namely,
the scenario in which a set of agents aim to cooperatively minimize the sum of
local costs, each depending on both local decision variables and an aggregation
of all of them. We consider a data-driven setup in which each objective
function is unknown and can be only sampled at a single point per iteration
(thanks to, e.g., feedback from human users or physical sensors). We address
this scenario through a distributed algorithm that combines three key
components: (i) a learning part that leverages neural networks to learn the
local cost functions descent direction, (ii) an optimization routine that
steers the estimates according to the learned direction to minimize the global
cost, and (iii) a tracking mechanism that locally reconstructs the unavailable
global quantities. By using tools from system theory, i.e., timescale
separation and averaging theory, we formally prove that, in strongly convex
setups, the overall distributed strategy linearly converges in a neighborhood
of the optimal solution whose radius depends on the given accuracy capabilities
of the neural networks. Finally, we corroborate the theoretical results with
numerical simulations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Transferable Foundation Models for Geometric Tasks on Point Cloud
  Representations: Geometric Neural Operators 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04649v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04649v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Blaine Quackenbush, Paul J. Atzberger
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce methods for obtaining pretrained Geometric Neural Operators
(GNPs) that can serve as basal foundation models for use in obtaining geometric
features. These can be used within data processing pipelines for machine
learning tasks and numerical methods. We show how our GNPs can be trained to
learn robust latent representations for the differential geometry of
point-clouds to provide estimates of metric, curvature, and other shape-related
features. We demonstrate how our pre-trained GNPs can be used (i) to estimate
the geometric properties of surfaces of arbitrary shape and topologies with
robustness in the presence of noise, (ii) to approximate solutions of geometric
partial differential equations (PDEs) on manifolds, and (iii) to solve
equations for shape deformations such as curvature driven flows. We also
release a package of the codes and weights for using our pre-trained GNPs for
processing point cloud representations. This allows for incorporating our
pre-trained GNPs as components for reuse within existing and new data
processing pipelines. The GNPs also can be used as part of numerical solvers
involving geometry or as part of methods for performing inference and other
geometric tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Perturbation-Aware Distributionally Robust <span class="highlight-title">Optimization</span> for Inverse
  Problems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04646v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04646v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Floor van Maarschalkerwaart, Subhadip Mukherjee, Malena Sabaté Landman, Christoph Brune, Marcello Carioni
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper builds on classical distributionally robust optimization
techniques to construct a comprehensive framework that can be used for solving
inverse problems. Given an estimated distribution of inputs in $X$ and outputs
in $Y$, an ambiguity set is constructed by collecting all the perturbations
that belong to a prescribed set $K$ and are inside an entropy-regularized
Wasserstein ball. By finding the worst-case reconstruction within $K$ one can
produce reconstructions that are robust with respect to various types of
perturbations: $X$-robustness, $Y|X$-robustness and, more general, targeted
robustness depending on noise type, imperfect forward operators and noise
anisotropies. After defining the general robust optimization problem, we derive
its (weak) dual formulation and we use it to design an efficient algorithm.
Finally, we demonstrate the effectiveness of our general framework to solve
matrix inversion and deconvolution problems defining $K$ as the set of
multivariate Gaussian perturbations in $Y|X$.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Method for Establishing Asymptotically Accurate Bounds for Extremal
  Roots of Eulerian Polynomials Using Polynomial Stability Preservers 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04628v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04628v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alejandro González Nevado
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We develop the tools to bound extreme roots of multivariate real zero
polynomials globally. This is done through the use of a relaxation that
approximates their rigidly convex sets. This relaxation can easily be
constructed using the degree $3$ truncation of the polynomial and it produces
in this way a spectrahedron whose computation is relatively easy and whose size
is relatively small and depending solely on the number of variables of the
polynomial. As we know that, in order to be able to produce in general
spectrahedral representations of rigidly convex sets it is necessary to build
matrices of very big size, we try, analyze and experiment with several
constructions that could increase the size of these matrices. These
constructions are based principally in two main approaches: adding information
about higher degree monomials or non-trivially increasing the number of
variables of the original polynomial. We explore these two construction first
in a general setting and see that it is necessary to particularize to certain
families of polynomials in order to make them work. In particular, we are able
to prove that increasing the number of variables improves the behavior of the
relaxation along the diagonal in the case of Eulerian polynomials. We see that
applying the relaxation to multivariate Eulerian polynomials and then looking
at the univariate polynomials injected in their diagonals produces an
exponential asymptotic improvement in the bounds provided. We compare these
bounds with other bounds that have appeared previously in the literature and
refine these previous bounds in order to study how close do the bounds provided
by the relaxation are to the actual roots of the univariate Eulerian
polynomials.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>PhD thesis written by the author in the University of Konstanz.
  Supervised by Markus Schweighofer and financed with the support of the POEMA
  network. Still not defended. Comments are welcome!</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Optimal interpolation-based coordinate descent method for parameterized
  quantum circuits 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04620v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04620v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhijian Lai, Jiang Hu, Taehee Ko, Jiayuan Wu, Dong An
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Parameterized quantum circuits appear ubiquitously in the design of many
quantum algorithms, such as variational quantum algorithms, where the
optimization of parameters is crucial for algorithmic efficiency. In this work,
we propose an Optimal Interpolation-based Coordinate Descent (OICD) method to
solve the parameter optimization problem that arises in parameterized quantum
circuits. Our OICD method employs an interpolation technique to approximate the
cost function of a parameterized quantum circuit, effectively recovering its
trigonometric characteristics, then performs an argmin update on a single
parameter per iteration on a classical computer. We determine the optimal
interpolation nodes in our OICD method to mitigate the impact of statistical
errors from quantum measurements. Additionally, for the case of equidistant
frequencies -- commonly encountered when the Hermitian generators are Pauli
operators -- we show that the optimal interpolation nodes are equidistant
nodes, and our OICD method can simultaneously minimize the mean squared error,
the condition number of the interpolation matrix, and the average variance of
derivatives of the cost function. We perform numerical simulations of our OICD
method using Qiskit Aer and test its performance on the maxcut problem, the
transverse field Ising model, and the XXZ model. Numerical results imply that
our OICD method is more efficient than the commonly used stochastic gradient
descent method and the existing random coordinate descent method.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>22+14 pages, 9 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Globally Finite time and Globally Fixed-time stable Dynamical Systems
  for solving Inverse Quasi-variational inequality problems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04590v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04590v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nam Van Tran, Le Thi Thanh Hai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we propose two projection dynamical systems for solving
inverse quasi-variational inequality problems in finite-dimensional Hilbert
spaces-one ensuring finite-time stability and the other guaranteeing fixed-time
stability. We first establish the connection between these dynamical systems
and the solutions of inverse quasi-variational problems. Then, under mild
conditions on the operators and parameters, we analyze the global finite-time
and global fixed-time stability of the proposed systems. Both approaches offer
accelerated convergence, however, while the settling time of a finite-time
stable dynamical system depends on initial conditions, the fixed-time stable
system achieves convergence within a predefined time, independent of initial
conditions. To demonstrate their effectiveness, we provide numerical
experiments, including an application to the traffic assignment problem.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Moreau envelope and proximal-point methods under the lens of high-order
  regularization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04577v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04577v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alireza Kabgani, Masoud Ahookhosh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper is devoted to investigating the fundamental properties of
high-order proximal operator (HOPE) and high-order Moreau envelope (HOME) in
the nonconvex setting, meaning that the quadratic regularization ($p=2$) is
replaced with a regularization with $p>1$. After studying several basic
properties of HOPE and HOME, we investigate the differentiability and weak
smoothness of HOME under $q$-prox-regularity $q\geq 2$ and $p$-calmness for $p
\in (1,2]$ and $2 \leq p \leq q$. Further, we design of a high-order
proximal-point algorithm (HiPPA) for which the convergence of the generated
sequence to proximal fixed points is studied. Our results pave the way toward
the high-order smoothing theory with $p>1$ that can lead to algorithmic
developments in the nonconvex setting, where our numerical experiments of HiPPA
on Nesterov-Chebyshev-Rosenbrock functions show the potential of this
development for nonsmooth and nonconvex optimization.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>25 pages. arXiv admin note: substantial text overlap with
  arXiv:2410.19928</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ First-order methods on bounded-rank tensors converging to stationary
  points 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04523v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04523v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bin Gao, Renfeng Peng, Ya-xiang Yuan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Provably finding stationary points on bounded-rank tensors turns out to be an
open problem [E. Levin, J. Kileel, and N. Boumal, Math. Program., 199 (2023),
pp. 831--864] due to the inherent non-smoothness of the set of bounded-rank
tensors. We resolve this problem by proposing two first-order methods with
guaranteed convergence to stationary points. Specifically, we revisit the
variational geometry of bounded-rank tensors and explicitly characterize its
normal cones. Moreover, we propose gradient-related approximate projection
methods that are provable to find stationary points, where the decisive
ingredients are gradient-related vectors from tangent cones, line search along
approximate projections, and rank-decreasing mechanisms near rank-deficient
points. Numerical experiments on tensor completion validate that the proposed
methods converge to stationary points across various rank parameters.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>26 pages, 8 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Tight Analysis of Difference-of-Convex Algorithm (DCA) Improves
  Convergence Rates for Proximal Gradient Descent 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04486v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04486v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Teodor Rotaru, Panagiotis Patrinos, François Glineur
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We investigate a difference-of-convex (DC) formulation where the second term
is allowed to be weakly convex. We examine the precise behavior of a single
iteration of the difference-of-convex algorithm (DCA), providing a tight
characterization of the objective function decrease, distinguishing between six
distinct parameter regimes.
  Our proofs, inspired by the performance estimation framework, are notably
simplified compared to related prior research. We subsequently derive sublinear
convergence rates for the DCA towards critical points, assuming at least one of
the functions is smooth.
  Additionally, we explore the underexamined equivalence between proximal
gradient descent (PGD) and DCA iterations, demonstrating how DCA, a
parameter-free algorithm, without the need for a stepsize, serves as a tool for
studying the exact convergence rates of PGD.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A new Lagrangian approach to optimal control of second-order systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04466v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04466v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Michael Konopik, Sigrid Leyendecker, Sofya Maslovskaya, Sina Ober-Blöbaum, Rodrigo T. Sato Martín de Almagro
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work, we propose and study a new approach to formulate the optimal
control problem of second-order differential equations, with a particular
interest in those derived from force-controlled Lagrangian systems. The
formulation results in a new hyperregular control Langrangian and, thus, a new
control Hamiltonian whose equations of motion provide necessary optimality
conditions. We compare this approach to Pontryagin's maximum principle (PMP) in
this setting, providing geometric insight into their relation. This leads us to
define an extended Tulczyjew's triple with controls. Moreover, we study the
relationship between Noether symmetries of this new formulation and those of
the PMP.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Averaged Controllability of the Random Schrödinger Equation with
  Diffusivity Following Absolutely Continuous Distributions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04465v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04465v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jon Asier Bárcena-Petisco, Fouad Et-Tahri
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper is devoted to the averaged controllability of the random
Schr\"odinger equation, with diffusivity as a random variable drawn from a
general probability distribution. First, we show that the solutions to these
random Schr\"odinger equations are null averaged controllable with an open-loop
control independent of randomness from any arbitrary open set of the domain and
in any time. This is done for an interesting class of random variables,
including certain stable distributions, specifically recovering the known
result when the random diffusivity follows a normal or Cauchy distribution.
Second, by the Riemann-Lebesgue lemma, we prove for any time the lack of
averaged exact controllability in a $L^2$ setting for all absolutely continuous
random variables. Notably, this implies that this property is not inherited
from the exact controllability of the Schr\"odinger equation. Third, we show
that simultaneous null controllability is not possible except for a finite
number of scenarios. Finally, we perform numerical simulations that robustly
validate the theoretical results.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Graph-Partitioning Based Continuous <span class="highlight-title">Optimization</span> Approach to
  Semi-supervised Clustering Problems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04447v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04447v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wei Liu, Xin Liu, Michael K. Ng, Zaikun Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Semi-supervised clustering is a basic problem in various applications. Most
existing methods require knowledge of the ideal cluster number, which is often
difficult to obtain in practice. Besides, satisfying the must-link constraints
is another major challenge for these methods. In this work, we view the
semi-supervised clustering task as a partitioning problem on a graph associated
with the given dataset, where the similarity matrix includes a scaling
parameter to reflect the must-link constraints. Utilizing a relaxation
technique, we formulate the graph partitioning problem into a continuous
optimization model that does not require the exact cluster number, but only an
overestimate of it. We then propose a block coordinate descent algorithm to
efficiently solve this model, and establish its convergence result. Based on
the obtained solution, we can construct the clusters that theoretically meet
the must-link constraints under mild assumptions. Furthermore, we verify the
effectiveness and efficiency of our proposed method through comprehensive
numerical experiments.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Fredholm Approach to Nonlinear Propagator Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04323v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04323v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Eduardo Abi Jaber, Alessandro Bondi, Nathan De Carvalho, Eyal Neuman, Sturmius Tuschmann
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We formulate and solve an optimal trading problem with alpha signals, where
transactions induce a nonlinear transient price impact described by a general
propagator model, including power-law decay. Using a variational approach, we
demonstrate that the optimal trading strategy satisfies a nonlinear stochastic
Fredholm equation with both forward and backward coefficients. We prove the
existence and uniqueness of the solution under a monotonicity condition
reflecting the nonlinearity of the price impact. Moreover, we derive an
existence result for the optimal strategy beyond this condition when the
underlying probability space is countable. In addition, we introduce a novel
iterative scheme and establish its convergence to the optimal trading strategy.
Finally, we provide a numerical implementation of the scheme that illustrates
its convergence, stability, and the effects of concavity on optimal execution
strategies under exponential and power-law decay.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>38 pages, 9 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Mean field optimal stopping with uncontrolled state 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04269v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04269v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Andrea Cosso, Laura Perelli
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study a specific class of finite-horizon mean field optimal stopping
problems by means of the dynamic programming approach. In particular, we
consider problems where the state process is not affected by the stopping time.
Such problems arise, for instance, in the pricing of American options when the
underlying asset follows a McKean-Vlasov dynamics. Due to the time
inconsistency of these problems, we provide a suitable reformulation of the
original problem for which a dynamic programming principle can be established.
To accomplish this, we first enlarge the state space and then introduce the
so-called extended value function. We prove that the Snell envelope of the
original problem can be written in terms of the extended value function, from
which we can derive a characterization of the smallest optimal stopping time.
On the enlarged space, we restore time-consistency and in particular establish
a dynamic programming principle for the extended value function. Finally, by
employing the notion of Lions measure derivative, we derive the associated
Hamilton-Jacobi-Bellman equation, which turns out to be a second-order
variational inequality on the product space $[0, T ] \times \mathbb{R}^d \times
\mathcal{P}_2(\mathbb{R}^d)$; under suitable assumptions, we prove that the
extended value function is a viscosity solution to this equation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Primal and Dual Characterizations for Farkas type Lemmas in Terms of
  Closedness Criteria 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04226v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04226v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nguyen Dinh, Miguel A. Goberna, Michel Volle
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper deals with the characterization, in terms of closedness of certain
sets regarding other sets, of Farkas lemmas determining when the upperlevel set
of a given convex function contains the intersection, say F, of a convex set of
a locally convex space X with the inverse image by a continuous linear operator
from X to another locally convex space Y of certain convex subset of Y. More in
detail, each of the mentioned characterizations of Farkas type lemmas consists
in the closedness of certain subset of either one of the "primal" spaces XxYxR
and YxR, or of the "dual" space X'xR, regarding some singleton set of the
corresponding space. Moreover, the paper also provides an existence theorem for
the feasible set F in terms of the closedness of certain subset of the dual
space X'xR regarding the singleton set formed by the null element. These
results are illustrated with significant applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>24 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Admissibility of control operators for positive semigroups and
  robustness of input-to-state stability 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04097v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04097v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yassine El Gantouh, Yang Liu, Jianquan Lu, Jinde Cao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we establish the well-posedness and stability of distributed
parameter systems, focusing on linear positive control systems in a Banach
lattice setting. We characterize well-posedness and derive a sufficient
condition for admissibility based on a lower norm estimate of the resolvent
operator on the positive cone. Furthermore, we analyze input-to-state stability
(ISS) under boundary perturbations within the domain of the semigroup
generator. Notably, we provide necessary and sufficient conditions for the
robustness of ISS under Desch-Schappacher perturbations. Our theoretical
results are demonstrated through a boundary value-controlled transport equation
with non-local boundary conditions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Quantitative Flow Approximation Properties of Narrow Neural ODEs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04068v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04068v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Karthik Elamvazhuthi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this note, we revisit the problem of flow approximation properties of
neural ordinary differential equations (NODEs). The approximation properties
have been considered as a flow controllability problem in recent literature.
The neural ODE is considered {\it narrow} when the parameters have dimension
equal to the input of the neural network, and hence have limited width. We
derive the relation of narrow NODEs in approximating flows of shallow but wide
NODEs. Due to existing results on approximation properties of shallow neural
networks, this facilitates understanding which kind of flows of dynamical
systems can be approximated using narrow neural ODEs. While approximation
properties of narrow NODEs have been established in literature, the proofs
often involve extensive constructions or require invoking deep controllability
theorems from control theory. In this paper, we provide a simpler proof
technique that involves only ideas from ODEs and Gr{\"o}nwall's lemma.
Moreover, we provide an estimate on the number of switches needed for the time
dependent weights of the narrow NODE to mimic the behavior of a NODE with a
single layer wide neural network as the velocity field.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Efficient, Fast, and Fair Voting Through Dynamic Resource Allocation in
  a Secure Election Physical Intranet 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04053v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04053v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tiankuo Zhang, Benoit Montreuil, Ali V Barenji, Praveen Muthukrishnan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Resource allocations in an election system, often with hundreds of polling
locations over a territory such as a county, with the aim that voters receive
fair and efficient services, is a challenging problem, as election resources
are limited and the number of expected voters can be highly volatile through
the voting period. This paper develops two propositions to ensure efficiency,
fairness, resilience, and security. The first is to leverage Physical Internet
(PI) principles, notably setting up a "secure election physical intranet"
(SEPI) based on open resource sharing and flow consolidation between election
facilities in the territory. The second is to adopt a smart dynamic resource
allocation methodology within the SEPI based on queueing networks and
lexicographic optimization. A queueing model is developed to provide feasible
combinations of resources and individual performances for each polling location
by considering layout and utilization constraints. A two-stage lexicographic
optimizer receives the queueing model's outputs and finds an optimal solution
that is less expensive, fast, and fair. A scenario-based case study validates
the proposed methodology based on data from the 2020 US Presidential Election
in Fulton County, Georgia, USA.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Reheated Gradient-based Discrete Sampling for Combinatorial <span class="highlight-title">Optimization</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.04047v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.04047v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Muheng Li, Ruqi Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, gradient-based discrete sampling has emerged as a highly efficient,
general-purpose solver for various combinatorial optimization (CO) problems,
achieving performance comparable to or surpassing the popular data-driven
approaches. However, we identify a critical issue in these methods, which we
term ''wandering in contours''. This behavior refers to sampling new different
solutions that share very similar objective values for a long time, leading to
computational inefficiency and suboptimal exploration of potential solutions.
In this paper, we introduce a novel reheating mechanism inspired by the concept
of critical temperature and specific heat in physics, aimed at overcoming this
limitation. Empirically, our method demonstrates superiority over existing
sampling-based and data-driven algorithms across a diverse array of CO
problems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ On a Lemma by Brézis and Haraux 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.11662v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.11662v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Minh N. Bùi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose several applications of an often overlooked part of the 1976 paper
by Br\'ezis and Haraux, in which the Br\'ezis--Haraux theorem was established.
Our results unify and extend various existing ones on the range of a linearly
composite monotone operator and provide new insight into their seminal paper.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Approximability of the Containment Problem for Zonotopes and
  Ellipsotopes 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.11185v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.11185v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Adrian Kulmburg, Lukas Schäfer, Matthias Althoff
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The zonotope containment problem, i.e., whether one zonotope is contained in
another, is a central problem in control theory. Applications include detecting
faults and robustifying controllers by computing invariant sets, and obtain
fixed points in reachability analysis. Despite the inherent co-NP-hardness of
this problem, an approximation algorithm developed by S. Sadraddini and R.
Tedrake has gained widespread recognition for its swift execution and
consistent reliability in practice. In our study, we substantiate the precision
of the algorithm with a definitive proof, elucidating the empirical accuracy
observed in practice. Our proof hinges on establishing a connection between the
containment problem and the computation of matrix norms, thereby enabling the
extension of the approximation algorithm to encompass ellipsotopes -- a broader
class of sets derived from zonotopes. We also explore the computational
complexity of the ellipsotope containment problem with a focus on
approximability. Finally, we present new methods to compute safe sets for
linear dynamical systems, demonstrating the practical relevance of
approximating the ellipsotope containment problem.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A CAV-based perimeter-free regional traffic control strategy utilizing
  existing parking infrastructure 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.04620v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.04620v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hao Liu, Vikash V. Gayah
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper proposes a novel perimeter-free regional traffic management
strategy for traffic networks under a connected and autonomous vehicle (CAV)
environment. The proposed strategy requires CAVs, especially those with long
remaining travel distances, to temporarily wait at nearby parking facilities
when the network is congested. After a designated holding time, these CAVs are
allowed to re-enter the network. Doing so helps reduce congestion and improve
overall operational efficiency. Unlike traditional perimeter control approaches
that restrict inflows to congested regions, the proposed holding strategy
leverages existing parking infrastructure to temporarily hold vehicles in a way
that partially avoids local queue accumulation issues. The proposed method can
be easily integrated with existing signal control methods and retains the
maximum stability property of the original traffic signal control methods.
Simulation results show that the proposed strategy not only reduces travel time
for vehicles that are not held, but can also reduce travel times for some of
the held vehicles as well, which serves as another key merit of the proposed
approach. Compared to the two benchmark perimeter control algorithms, the
proposed strategy is more robust against demand patterns and generates stronger
improvements in the operational efficiency. Importantly, since the proposed
strategy requires existing parking infrastructure, its performance has been
demonstrated under various configurations of parking locations and capacities.
Particularly, it is demonstrated that the utilization of the parking facility
consistently improves overall traffic efficiency, regardless of the facility's
size. Lastly, the proposed strategy is shown to be beneficial in a partial CAV
environment where only a subset of vehicles are available for holding.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Cooperative Nonlinear Guidance Strategies for Guaranteed Pursuit-Evasion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.06176v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.06176v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Saurabh Kumar, Shashi Ranjan Kumar, Abhinav Sinha
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper addresses the pursuit-evasion problem involving three agents -- a
purser, an evader, and a defender. We develop cooperative guidance laws for the
evader-defender team that guarantee that the defender intercepts the pursuer
before it reaches the vicinity of the evader. Unlike heuristic methods, optimal
control, differential game formulation, and recently proposed time-constrained
guidance techniques, we propose a geometric solution to safeguard the evader
from the pursuer's incoming threat. The proposed strategy is computationally
efficient and expected to be scalable as the number of agents increases.
Another alluring feature of the proposed strategy is that the evader-defender
team does not require the knowledge of the pursuer's strategy and that the
pursuer's interception is guaranteed from arbitrary initial engagement
geometries. We further show that the necessary error variables for the
evader-defender team vanish within a time that can be exactly prescribed prior
to the three-body engagement. Finally, we demonstrate the efficacy of the
proposed cooperative defense strategy via simulation in diverse engagement
scenarios.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Theoretical and Empirical Advances in Forest Pruning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.05535v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.05535v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Albert Dorador
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Regression forests have long delivered state-of-the-art accuracy, often
outperforming regression trees and even neural networks, but they suffer from
limited interpretability as ensemble methods. In this work, we revisit forest
pruning, an approach that aims to have the best of both worlds: the accuracy of
regression forests and the interpretability of regression trees. This pursuit,
whose foundation lies at the core of random forest theory, has seen vast
success in empirical studies. In this paper, we contribute theoretical results
that support and qualify those empirical findings; namely, we prove the
asymptotic advantage of a Lasso-pruned forest over its unpruned counterpart
under weak assumptions, as well as high-probability finite-sample
generalization bounds for regression forests pruned according to the main
methods, which we then validate by way of simulation. Then, we test the
accuracy of pruned regression forests against their unpruned counterparts on 19
different datasets (16 synthetic, 3 real). We find that in the vast majority of
scenarios tested, there is at least one forest-pruning method that yields equal
or better accuracy than the original full forest (in expectation), while just
using a small fraction of the trees. We show that, in some cases, the reduction
in the size of the forest is so dramatic that the resulting sub-forest can be
meaningfully merged into a single tree, obtaining a level of interpretability
that is qualitatively superior to that of the original regression forest, which
remains a black box.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To be published in Proceedings of Machine Learning Research (PMLR)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Probable Event Constrained <span class="highlight-title">Optimization</span> and A Data-embedded Solution
  Paradigm 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2209.01119v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2209.01119v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qifeng Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper solves a new class of optimization problems under uncertainty,
called Probable Event Constrained Optimization (PECO), which optimizes an
objective function of decision variables and subjects to a set of Probable
Event Constraints (PEC). This new type of constraint guarantees that optimal
solutions are feasible for all uncertain events whose joint probabilities are
greater than a user-defined threshold. The PEC can be used as an alternative to
the conventional chance constraint, while the latter cannot guarantee the
solution's feasibility to high-probability uncertain events. Given that the
existing solution methods of optimization problems under uncertainty are not
suitable for solving PECO problems, we develop a novel data-embedded solution
paradigm that uses historical measurements/data of the uncertain parameters as
input samples. This solution paradigm is conceptually simple and allows us to
develop effective data-reduction schemes which reduce computational burden
while preserving high accuracy.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>26 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Tutorial on amortized <span class="highlight-title">optimization</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2202.00665v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2202.00665v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Brandon Amos
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Optimization is a ubiquitous modeling tool and is often deployed in settings
which repeatedly solve similar instances of the same problem. Amortized
optimization methods use learning to predict the solutions to problems in these
settings, exploiting the shared structure between similar problem instances.
These methods have been crucial in variational inference and reinforcement
learning and are capable of solving optimization problems many orders of
magnitudes times faster than traditional optimization methods that do not use
amortization. This tutorial presents an introduction to the amortized
optimization foundations behind these advancements and overviews their
applications in variational inference, sparse coding, gradient-based
meta-learning, control, reinforcement learning, convex optimization, optimal
transport, and deep equilibrium networks. The source code for this tutorial is
available at
https://github.com/facebookresearch/amortized-optimization-tutorial.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Foundations and Trends in Machine Learning</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A learning-based approach to stochastic optimal control under
  reach-avoid constraint 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.16561v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.16561v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tingting Ni, Maryam Kamgarpour
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We develop a model-free approach to optimally control stochastic, Markovian
systems subject to a reach-avoid constraint. Specifically, the state trajectory
must remain within a safe set while reaching a target set within a finite time
horizon. Due to the time-dependent nature of these constraints, we show that,
in general, the optimal policy for this constrained stochastic control problem
is non-Markovian, which increases the computational complexity. To address this
challenge, we apply the state-augmentation technique from arXiv:2402.19360,
reformulating the problem as a constrained Markov decision process (CMDP) on an
extended state space. This transformation allows us to search for a Markovian
policy, avoiding the complexity of non-Markovian policies. To learn the optimal
policy without a system model, and using only trajectory data, we develop a
log-barrier policy gradient approach. We prove that under suitable assumptions,
the policy parameters converge to the optimal parameters, while ensuring that
the system trajectories satisfy the stochastic reach-avoid constraint with high
probability.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Goh and Legendre-Clebsh conditions for nonsmooth control systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2308.06867v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2308.06867v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Francesca Angrisani, Franco Rampazzo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Higher order necessary conditions for a minimizer of an optimal control
problem are generally obtained for systems whose dynamics is at least
continuously differentiable in the state variable. Here, by making use of the
notion of set-valued Lie bracket introduced in "Set-valued differentials and a
nonsmooth version of Chow-Rashevski's theorem" by F. Rampazzo and H.J.Sussmann
and extended in "Iterated Lie brackets for nonsmooth vector fields" by E.
Feleqi and F.Rampazzo , we obtain Goh and Legendre-Clebsh type conditions for a
control affine system with Lipschitz continuous dynamics. In order to manage
the simultaneous lack of smoothness of the adjoint equation and of the Lie
bracket-like variations, we will exploit the notion of Quasi Differential
Quotient, introduced in "A geometrically based criterion to avoid infimum-gaps
in Optimal Control" by M. Palladino and F.Rampazzo. We finally exhibit an
example where the established higher order condition is capable to rule out the
optimality of a control verifying a first order Maximum Principle.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Tracking Control of Euler-Lagrangian Systems with Prescribed State,
  Input, and Temporal Constraints 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.01866v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.01866v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chidre Shravista Kashyap, Pushpak Jagtap, Jishnu Keshavan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The synthesis of a smooth tracking control policy for Euler-Lagrangian (EL)
systems with stringent regions of operation induced by state, input and
temporal (SIT) constraints is a very challenging task. In contrast with
existing methods that utilize prior knowledge of EL model parameters and
uncertainty bounds, this study proposes an approximation-free adaptive barrier
function-based control policy to ensure local prescribed time convergence of
tracking error under state and input constraints. The proposed control policy
accomplishes this by utilizing smooth time-based generator functions embedded
in the filtered tracking error, which is combined with a saturation function
that limits control action and confines states within the prescribed limits by
enforcing the time-varying bounds on the filtered tracking error. Importantly,
corresponding feasibility conditions pertaining to the minimum control
authority, maximum disturbance rejection capability of the control policy, and
the viable set of initial conditions are derived, illuminating the narrow
operating domain of the EL systems arising from the interplay of SIT
constraints. Numerical validation studies with three different robotic
manipulators are employed to demonstrate the efficacy of the proposed scheme. A
detailed performance comparison study with leading alternative designs is also
undertaken to illustrate the superior performance of the proposed scheme.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Laplace duality for integration 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.20842v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.20842v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jean B Lasserre
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We consider the integral v(y) = Ky f (x)dx on a domain Ky = {x $\in$ R d :
g(x) $\le$ y}, where g is nonnegative and Ky is compact for all y $\in$ [0,
+$\infty$). Under some assumptions, we show that for every y $\in$ (0,
$\infty$) there exists a distinguished scalar $\lambda$y $\in$ (0, +$\infty$)
such that which is the counterpart analogue for integration of Lagrangian
duality for optimization. A crucial ingredient is the Laplace transform, the
analogue for integration of Legendre-Fenchel transform in optimization. In
particular, if both f and g are positively homogeneous then $\lambda$y is a
simple explicitly rational function of y. In addition if g is quadratic form
then computing v(y) reduces to computing the integral of f with respect to a
specific Gaussian measure for which exact and approximate numerical methods
(e.g. cubatures) are available.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Deep unrolling for learning optimal spatially varying regularisation
  parameters for Total Generalised Variation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.16532v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.16532v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Thanh Trung Vu, Andreas Kofler, Kostas Papafitsoros
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We extend a recently introduced deep unrolling framework for learning
spatially varying regularisation parameters in inverse imaging problems to the
case of Total Generalised Variation (TGV). The framework combines a deep
convolutional neural network (CNN) inferring the two spatially varying TGV
parameters with an unrolled algorithmic scheme that solves the corresponding
variational problem. The two subnetworks are jointly trained end-to-end in a
supervised fashion and as such the CNN learns to compute those parameters that
drive the reconstructed images as close to the ground truth as possible.
Numerical results in image denoising and MRI reconstruction show a significant
qualitative and quantitative improvement compared to the best TGV scalar
parameter case as well as to other approaches employing spatially varying
parameters computed by unsupervised methods. We also observe that the inferred
spatially varying parameter maps have a consistent structure near the image
edges, asking for further theoretical investigations. In particular, the
parameter that weighs the first-order TGV term has a triple-edge structure with
alternating high-low-high values whereas the one that weighs the second-order
term attains small values in a large neighbourhood around the edges.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Flows of vector fields and the Kalman Theorem 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.07438v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.07438v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fabio Bagagiolo, Cristina Giannotti, Andrea Spiro, Marta Zoppello
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We give two proofs of the Kalman Theorem, alternative to the most common
ones, which infer such a classical result of Control Theory using just very
basic facts on flows of vector fields. These proofs are apt to be generalised
in diverse directions -- in fact one of them has been already generalised,
yielding new criteria for local controllability of non-linear real analytic
controlled systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Learning truly monotone operators with applications to nonlinear inverse
  problems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.00390v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.00390v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Younes Belkouchi, Jean-Christophe Pesquet, Audrey Repetti, Hugues Talbot
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This article introduces a novel approach to learning monotone neural networks
through a newly defined penalization loss. The proposed method is particularly
effective in solving classes of variational problems, specifically monotone
inclusion problems, commonly encountered in image processing tasks. The
Forward-Backward-Forward (FBF) algorithm is employed to address these problems,
offering a solution even when the Lipschitz constant of the neural network is
unknown. Notably, the FBF algorithm provides convergence guarantees under the
condition that the learned operator is monotone. Building on plug-and-play
methodologies, our objective is to apply these newly learned operators to
solving non-linear inverse problems. To achieve this, we initially formulate
the problem as a variational inclusion problem. Subsequently, we train a
monotone neural network to approximate an operator that may not inherently be
monotone. Leveraging the FBF algorithm, we then show simulation examples where
the non-linear inverse problem is successfully solved.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Posted Price versus Hybrid Mechanisms in Freight Transportation
  Marketplaces 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2106.00923v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2106.00923v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ruoran Chen, Sungwoo Kim, He Wang, Xuan Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We consider a freight platform that serves as an intermediary between
shippers and carriers in a truckload transportation network. The platform's
objective is to design a policy that determines prices for shippers and
payments to carriers, as well as how carriers are matched to loads to be
transported, to maximize its long-run average profit. We propose a two-stage
decision framework to model carriers' load choice behavior, where carriers
choose a lane according to the multinomial logit (MNL) model based on the
platform's posted price in the first stage and book a load in the second stage.
We analyze two types of carrier-side mechanisms commonly used by freight
platforms: a posted price mechanism and a hybrid mechanism where carriers can
either book loads at posted price or submit their bids in an auction. The
proposed mechanisms are constructed using a fluid approximation model to
incorporate carrier interactions in the freight network. We show that the
hybrid mechanism has higher profits than the posted price mechanism. We prove
tight bounds between these mechanisms for varying market sizes. The findings
are validated through a numerical simulation using industry data from the U.S.
freight market.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ On Discrete Subproblems in Integer Optimal Control with Total Variation
  Regularization in Two Dimensions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.09213v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.09213v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Paul Manns, Marvin Severitt
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We analyze integer linear programs which we obtain after discretizing
two-dimensional subproblems arising from a trust-region algorithm for mixed
integer optimal control problems with total variation regularization. We
discuss NP-hardness of the discretized problems and the connection to
graph-based problems. We show that the underlying polyhedron exhibits
structural restrictions in its vertices with regards to which variables can
attain fractional values at the same time. Based on this property, we derive
cutting planes by employing a relation to shortest-path and minimum bisection
problems. We propose a branching rule and a primal heuristic which improves
previously found feasible points. We validate the proposed tools with a
numerical benchmark in a standard integer programming solver. We observe a
significant speedup for medium-sized problems. Our results give hints for
scaling towards larger instances in the future.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Deep Reinforcement Learning for Infinite Horizon Mean Field Problems in
  Continuous Spaces 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2309.10953v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2309.10953v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Andrea Angiuli, Jean-Pierre Fouque, Ruimeng Hu, Alan Raydan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present the development and analysis of a reinforcement learning (RL)
algorithm designed to solve continuous-space mean field game (MFG) and mean
field control (MFC) problems in a unified manner. The proposed approach pairs
the actor-critic (AC) paradigm with a representation of the mean field
distribution via a parameterized score function, which can be efficiently
updated in an online fashion, and uses Langevin dynamics to obtain samples from
the resulting distribution. The AC agent and the score function are updated
iteratively to converge, either to the MFG equilibrium or the MFC optimum for a
given mean field problem, depending on the choice of learning rates. A
straightforward modification of the algorithm allows us to solve mixed mean
field control games (MFCGs). The performance of our algorithm is evaluated
using linear-quadratic benchmarks in the asymptotic infinite horizon framework.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Revisions made in accordance with reviewer's wishes. The revision
  primarily includes more results and plots from new simulations to show
  robustness of the method. 40 pages; 19 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Is Bellman Equation Enough for Learning Control? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.02171v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.02171v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haoxiang You, Lekan Molu, Ian Abraham
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The Bellman equation and its continuous-time counterpart, the
Hamilton-Jacobi-Bellman (HJB) equation, serve as necessary conditions for
optimality in reinforcement learning and optimal control. While the value
function is known to be the unique solution to the Bellman equation in tabular
settings, we demonstrate that this uniqueness fails to hold in continuous state
spaces. Specifically, for linear dynamical systems, we prove the Bellman
equation admits at least $\binom{2n}{n}$ solutions, where $n$ is the state
dimension. Crucially, only one of these solutions yields both an optimal policy
and a stable closed-loop system. We then demonstrate a common failure mode in
value-based methods: convergence to unstable solutions due to the exponential
imbalance between admissible and inadmissible solutions. Finally, we introduce
a positive-definite neural architecture that guarantees convergence to the
stable solution by construction to address this issue.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CONGO: Compressive Online Gradient <span class="highlight-title">Optimization</span> <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.06325v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.06325v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jeremy Carleton, Prathik Vijaykumar, Divyanshu Saxena, Dheeraj Narasimha, Srinivas Shakkottai, Aditya Akella
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We address the challenge of zeroth-order online convex optimization where the
objective function's gradient exhibits sparsity, indicating that only a small
number of dimensions possess non-zero gradients. Our aim is to leverage this
sparsity to obtain useful estimates of the objective function's gradient even
when the only information available is a limited number of function samples.
Our motivation stems from the optimization of large-scale queueing networks
that process time-sensitive jobs. Here, a job must be processed by potentially
many queues in sequence to produce an output, and the service time at any queue
is a function of the resources allocated to that queue. Since resources are
costly, the end-to-end latency for jobs must be balanced with the overall cost
of the resources used. While the number of queues is substantial, the latency
function primarily reacts to resource changes in only a few, rendering the
gradient sparse. We tackle this problem by introducing the Compressive Online
Gradient Optimization framework which allows compressive sensing methods
previously applied to stochastic optimization to achieve regret bounds with an
optimal dependence on the time horizon without the full problem dimension
appearing in the bound. For specific algorithms, we reduce the samples required
per gradient estimate to scale with the gradient's sparsity factor rather than
its full dimensionality. Numerical simulations and real-world microservices
benchmarks demonstrate CONGO's superiority over gradient descent approaches
that do not account for sparsity.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at ICLR 2025; 34 pages, 12 figures</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2025-03-05T00:00:00Z">2025-03-05</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Systems and Control <span class="chip" style="font-size: 60%">32</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Equivariant Filter Design for Range-only SLAM 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03973v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03973v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yixiao Ge, Arthur Pearce, Pieter van Goor, Robert Mahony
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Range-only Simultaneous Localisation and Mapping (RO-SLAM) is of interest due
to its practical applications in ultra-wideband (UWB) and Bluetooth Low Energy
(BLE) localisation in terrestrial and aerial applications and acoustic beacon
localisation in submarine applications. In this work, we consider a mobile
robot equipped with an inertial measurement unit (IMU) and a range sensor that
measures distances to a collection of fixed landmarks. We derive an equivariant
filter (EqF) for the RO-SLAM problem based on a symmetry Lie group that is
compatible with the range measurements. The proposed filter does not require
bootstrapping or initialisation of landmark positions, and demonstrates
robustness to the no-prior situation. The filter is demonstrated on a
real-world dataset, and it is shown to significantly outperform a
state-of-the-art EKF alternative in terms of both accuracy and robustness.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 5 figures, accepted for presentation at IEEE International
  Conference on Robotics and Automation 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Safe LLM-Controlled Robots with Formal Guarantees via Reachability
  Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03911v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03911v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ahmad Hafez, Alireza Naderi Akhormeh, Amr Hegazy, Amr Alanwar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The deployment of Large Language Models (LLMs) in robotic systems presents
unique safety challenges, particularly in unpredictable environments. Although
LLMs, leveraging zero-shot learning, enhance human-robot interaction and
decision-making capabilities, their inherent probabilistic nature and lack of
formal guarantees raise significant concerns for safety-critical applications.
Traditional model-based verification approaches often rely on precise system
models, which are difficult to obtain for real-world robotic systems and may
not be fully trusted due to modeling inaccuracies, unmodeled dynamics, or
environmental uncertainties. To address these challenges, this paper introduces
a safety assurance framework for LLM-controlled robots based on data-driven
reachability analysis, a formal verification technique that ensures all
possible system trajectories remain within safe operational limits. Our
framework specifically investigates the problem of instructing an LLM to
navigate the robot to a specified goal and assesses its ability to generate
low-level control actions that successfully guide the robot safely toward that
goal. By leveraging historical data to construct reachable sets of states for
the robot-LLM system, our approach provides rigorous safety guarantees against
unsafe behaviors without relying on explicit analytical models. We validate the
framework through experimental case studies in autonomous navigation and task
planning, demonstrating its effectiveness in mitigating risks associated with
LLM-generated commands. This work advances the integration of formal methods
into LLM-based robotics, offering a principled and practical approach to
ensuring safety in next-generation autonomous systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Pretrained LLMs as Real-Time Controllers for Robot Operated Serial
  Production Line 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03889v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03889v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Muhammad Waseem, Kshitij Bhatta, Chen Li, Qing Chang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The manufacturing industry is undergoing a transformative shift, driven by
cutting-edge technologies like 5G, AI, and cloud computing. Despite these
advancements, effective system control, which is crucial for optimizing
production efficiency, remains a complex challenge due to the intricate,
knowledge-dependent nature of manufacturing processes and the reliance on
domain-specific expertise. Conventional control methods often demand heavy
customization, considerable computational resources, and lack transparency in
decision-making. In this work, we investigate the feasibility of using Large
Language Models (LLMs), particularly GPT-4, as a straightforward, adaptable
solution for controlling manufacturing systems, specifically, mobile robot
scheduling. We introduce an LLM-based control framework to assign mobile robots
to different machines in robot assisted serial production lines, evaluating its
performance in terms of system throughput. Our proposed framework outperforms
traditional scheduling approaches such as First-Come-First-Served (FCFS),
Shortest Processing Time (SPT), and Longest Processing Time (LPT). While it
achieves performance that is on par with state-of-the-art methods like
Multi-Agent Reinforcement Learning (MARL), it offers a distinct advantage by
delivering comparable throughput without the need for extensive retraining.
These results suggest that the proposed LLM-based solution is well-suited for
scenarios where technical expertise, computational resources, and financial
investment are limited, while decision transparency and system scalability are
critical concerns.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages, 7 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Comparison of Experimental and Theoretical Mechanical Jitter in a THz
  Communication Link 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03740v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03740v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ethan Abele, Karl Strecker, John F. OHara
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The effect of mechanical vibration (jitter) is an increasingly important
parameter for next-generation, long-distance wireless communication links and
the channel models used for their engineering. Existing investigations of
jitter effects on the terahertz (THz) backhaul channel are theoretical and
derived primarily from free space optical models. These lack an empirical and
validated treatment of the true statistical nature of antenna motion. We
present novel experimental data which reveals that the statistical nature of
mechanical jitter in 6G links is more complex than previously assumed. An
unexpected multimodal distribution is discovered, which cannot be fit with the
commonly cited model. These results compel the refinement of THz channel models
under jitter and the resulting system performance metrics.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A modeling framework to support the electrification of private transport
  in African cities: a case study of Addis Ababa 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03671v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03671v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jérémy Dumoulin, Dawit Gebremeskel, Kanchwodia Gashaw, Ingeborg Graabak, Noémie Jeannin, Alejandro Pena-Bello, Christophe Ballif, Nicolas Wyrsch
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The electrification of road transport, as the predominant mode of
transportation in Africa, represents a great opportunity to reduce greenhouse
gas emissions and dependence on costly fuel imports. However, it introduces
major challenges for local energy infrastructures, including the deployment of
charging stations and the impact on often fragile electricity grids. Despite
its importance, research on electric mobility planning in Africa remains
limited, while existing planning tools rely on detailed local mobility data
that is often unavailable, especially for privately owned passenger vehicles.
In this study, we introduce a novel framework designed to support private
vehicle electrification in data-scarce regions and apply it to Addis Ababa,
simulating the mobility patterns and charging needs of 100,000 electric
vehicles. Our analysis indicate that these vehicles generate a daily charging
demand of approximately 350 MWh and emphasize the significant influence of the
charging location on the spatial and temporal distribution of this demand.
Notably, charging at public places can help smooth the charging demand
throughout the day, mitigating peak charging loads on the electricity grid. We
also estimate charging station requirements, finding that workplace charging
requires approximately one charging point per three electric vehicles, while
public charging requires only one per thirty. Finally, we demonstrate that
photovoltaic energy can cover a substantial share of the charging needs,
emphasizing the potential for renewable energy integration. This study lays the
groundwork for electric mobility planning in Addis Ababa while offering a
transferable framework for other African cities.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Optimal Policy Design for Repeated Decision-Making under Social
  Influence 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03657v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03657v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chiara Ravazzi, Valentina Breschi, Paolo Frasca, Fabrizio Dabbene, Mara Tanelli
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we present a novel model to characterize individual tendencies
in repeated decision-making scenarios, with the goal of designing model-based
control strategies that promote virtuous choices amidst social and external
influences. Our approach builds on the classical Friedkin and Johnsen model of
social influence, extending it to include random factors (e.g., inherent
variability in individual needs) and controllable external inputs. We
explicitly account for the temporal separation between two processes that shape
opinion dynamics: individual decision-making and social imitation. While
individual decisions occur at regular, frequent intervals, the influence of
social imitation unfolds over longer periods. The inclusion of random factors
naturally leads to dynamics that do not converge in the classical sense.
However, under specific conditions, we prove that opinions exhibit ergodic
behavior. Building on this result, we propose a constrained asymptotic optimal
control problem designed to foster, on average, social acceptance of a target
action within a network. To address the transient dynamics of opinions, we
reformulate this problem within a Model Predictive Control (MPC) framework.
Simulations highlight the significance of accounting for these transient
effects in steering individuals toward virtuous choices while managing policy
costs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Motion <span class="highlight-title">Plan</span>ning and Control with Unknown Nonlinear Dynamics through
  Predicted Reachability 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03633v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03633v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhiquan Zhang, Gokul Puthumanaillam, Manav Vora, Melkior Ornik
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Autonomous motion planning under unknown nonlinear dynamics presents
significant challenges. An agent needs to continuously explore the system
dynamics to acquire its properties, such as reachability, in order to guide
system navigation adaptively. In this paper, we propose a hybrid
planning-control framework designed to compute a feasible trajectory toward a
target. Our approach involves partitioning the state space and approximating
the system by a piecewise affine (PWA) system with constrained control inputs.
By abstracting the PWA system into a directed weighted graph, we incrementally
update the existence of its edges via affine system identification and reach
control theory, introducing a predictive reachability condition by exploiting
prior information of the unknown dynamics. Heuristic weights are assigned to
edges based on whether their existence is certain or remains indeterminate.
Consequently, we propose a framework that adaptively collects and analyzes data
during mission execution, continually updates the predictive graph, and
synthesizes a controller online based on the graph search outcomes. We
demonstrate the efficacy of our approach through simulation scenarios involving
a mobile robot operating in unknown terrains, with its unknown dynamics
abstracted as a single integrator model.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Design and Implementation of an IoT Cluster with Raspberry Pi Powered by
  Solar Energy: A Theoretical Approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03618v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03618v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Noel Portillo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This document presents the design and implementation of a low-power IoT
server cluster, based on Raspberry Pi 3 Model B and powered by solar energy.
The proposed architecture integrates Kubernetes (K3s) and Docker, providing an
efficient, scalable, and high-performance computing environment. The cluster is
designed to optimize energy consumption, leveraging a 200W solar panel system
and a 100Ah lithium-ion battery to support continuous operation under favorable
environmental conditions. Performance analysis was conducted based on
theoretical inferences and data obtained from external sources, evaluating
resource allocation, power consumption, and service availability. These
analyses provide theoretical estimates of the system's operational feasibility
under different scenarios. The results suggest that this system can serve as a
viable and sustainable alternative for edge computing applications and cloud
services, reducing dependence on traditional data centers. In addition to its
positive impact on environmental sustainability by significantly reducing the
carbon footprint, this solution also addresses economic concerns, as
conventional data centers consume enormous amounts of energy, leading to
increased demand on the power grid and higher operational costs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This manuscript has been previously published on Zenodo and is
  available at https://zenodo.org/records/14957338. The content remains
  unchanged, and this submission to arXiv is intended to increase accessibility
  and facilitate further discussion within the research community</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Domain Consistent Industrial Decarbonisation of Global Coal Power <span class="highlight-title">Plan</span>ts 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03571v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03571v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Waqar Muhammad Ashraf, Vivek Dua, Ramit Debnath
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Machine learning and optimisation techniques (MLOPT) hold significant
potential to accelerate the decarbonisation of industrial systems by enabling
data-driven operational improvements. However, the practical application of
MLOPT in industrial settings is often hindered by a lack of domain compliance
and system-specific consistency, resulting in suboptimal solutions with limited
real-world applicability. To address this challenge, we propose a novel
human-in-the-loop (HITL) constraint-based optimisation framework that
integrates domain expertise with data-driven methods, ensuring solutions are
both technically sound and operationally feasible. We demonstrate the efficacy
of this framework through a case study focused on enhancing the thermal
efficiency and reducing the turbine heat rate of a 660 MW supercritical
coal-fired power plant. By embedding domain knowledge as constraints within the
optimisation process, our approach yields solutions that align with the plant's
operational patterns and are seamlessly integrated into its control systems.
Empirical validation confirms a mean improvement in thermal efficiency of
0.64\% and a mean reduction in turbine heat rate of 93 kJ/kWh. Scaling our
analysis to 59 global coal power plants with comparable capacity and fuel type,
we estimate a cumulative lifetime reduction of 156.4 million tons of carbon
emissions. These results underscore the transformative potential of our
HITL-MLOPT framework in delivering domain-compliant, implementable solutions
for industrial decarbonisation, offering a scalable pathway to mitigate the
environmental impact of coal-based power generation worldwide.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 figures. 17 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards an Emotion-Aware Metaverse: A Human-Centric Shipboard Fire Drill
  Simulator 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03570v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03570v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Musaab H. Hamed-Ahmed, Diego Ramil-López, Paula Fraga-Lamas, Tiago M. Fernández-Caramés
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Traditional XR and Metaverse applications prioritize user experience (UX) for
adoption and success but often overlook a crucial aspect of user interaction:
emotions. This article addresses this gap by presenting an emotion-aware
Metaverse application: a Virtual Reality (VR) fire drill simulator designed to
prepare crews for shipboard emergencies. The simulator detects emotions in real
time, assessing trainees responses under stress to improve learning outcomes.
Its architecture incorporates eye-tracking and facial expression analysis via
Meta Quest Pro headsets. The system features four levels whose difficulty is
increased progressively to evaluate user decision-making and emotional
resilience. The system was evaluated in two experimental phases. The first
phase identified challenges, such as navigation issues and lack of visual
guidance. These insights led to an improved second version with a better user
interface, visual cues and a real-time task tracker. Performance metrics like
completion times, task efficiency and emotional responses were analyzed. The
obtained results show that trainees with prior VR or gaming experience
navigated the scenarios more efficiently. Moreover, the addition of
task-tracking visuals and navigation guidance significantly improved user
performance, reducing task completion times between 14.18\% and 32.72\%.
Emotional responses were captured, revealing that some participants were
engaged, while others acted indifferently, indicating the need for more
immersive elements. Overall, this article provides useful guidelines for
creating the next generation of emotion-aware Metaverse applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Transformer-Based Power <span class="highlight-title">Optimization</span> for Max-Min Fairness in Cell-Free
  Massive MIMO 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03561v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03561v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Irched Chafaa, Giacomo Bacci, Luca Sanguinetti
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Power allocation is an important task in wireless communication networks.
Classical optimization algorithms and deep learning methods, while effective in
small and static scenarios, become either computationally demanding or
unsuitable for large and dynamic networks with varying user loads. This letter
explores the potential of transformer-based deep learning models to address
these challenges. We propose a transformer neural network to jointly predict
optimal uplink and downlink power using only user and access point positions.
The max-min fairness problem in cell-free massive multiple input multiple
output systems is considered. Numerical results show that the trained model
provides near-optimal performance and adapts to varying numbers of users and
access points without retraining, additional processing, or updating its neural
network architecture. This demonstrates the effectiveness of the proposed model
in achieving robust and flexible power allocation for dynamic networks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages, IEEE WCL, 4 FIGURES</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Simulation-Based Performance Evaluation of 3D Object Detection Methods
  with Deep Learning for a LiDAR Point Cloud Dataset in a SOTIF-related Use
  Case 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03548v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03548v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Milin Patel, Rolf Jung
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Safety of the Intended Functionality (SOTIF) addresses sensor performance
limitations and deep learning-based object detection insufficiencies to ensure
the intended functionality of Automated Driving Systems (ADS). This paper
presents a methodology examining the adaptability and performance evaluation of
the 3D object detection methods on a LiDAR point cloud dataset generated by
simulating a SOTIF-related Use Case. The major contributions of this paper
include defining and modelling a SOTIF-related Use Case with 21 diverse weather
conditions and generating a LiDAR point cloud dataset suitable for application
of 3D object detection methods. The dataset consists of 547 frames,
encompassing clear, cloudy, rainy weather conditions, corresponding to
different times of the day, including noon, sunset, and night. Employing
MMDetection3D and OpenPCDET toolkits, the performance of State-of-the-Art
(SOTA) 3D object detection methods is evaluated and compared by testing the
pre-trained Deep Learning (DL) models on the generated dataset using Average
Precision (AP) and Recall metrics.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Simulation-Based Application of Safety of The Intended Functionality to
  Mitigate Foreseeable Misuse in Automated Driving Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03534v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03534v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Milin Patel, Rolf Jung
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The development of Automated Driving Systems (ADS) has the potential to
revolutionise the transportation industry, but it also presents significant
safety challenges. One of the key challenges is ensuring that the ADS is safe
in the event of Foreseeable Misuse (FM) by the human driver. To address this
challenge, a case study on simulation-based testing to mitigate FM by the
driver using the driving simulator is presented. FM by the human driver refers
to potential driving scenarios where the driver misinterprets the intended
functionality of ADS, leading to hazardous behaviour. Safety of the Intended
Functionality (SOTIF) focuses on ensuring the absence of unreasonable risk
resulting from hazardous behaviours related to functional insufficiencies
caused by FM and performance limitations of sensors and machine learning-based
algorithms for ADS. The simulation-based application of SOTIF to mitigate FM in
ADS entails determining potential misuse scenarios, conducting simulation-based
testing, and evaluating the effectiveness of measures dedicated to preventing
or mitigating FM. The major contribution includes defining (i) test
requirements for performing simulation-based testing of a potential misuse
scenario, (ii) evaluation criteria in accordance with SOTIF requirements for
implementing measures dedicated to preventing or mitigating FM, and (iii)
approach to evaluate the effectiveness of the measures dedicated to preventing
or mitigating FM. In conclusion, an exemplary case study incorporating
driver-vehicle interface and driver interactions with ADS forming the basis for
understanding the factors and causes contributing to FM is investigated.
Furthermore, the test procedure for evaluating the effectiveness of the
measures dedicated to preventing or mitigating FM by the driver is developed in
this work.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>SAE MobilityRxiv Preprint, 2023</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Potential gains of communication-compute-control co-design based
  performance <span class="highlight-title">optimization</span> methods in cyber-physical systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03521v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03521v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sándor Rácz, Norbert Reider
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper we propose and quantitatively evaluate three performance
optimization methods that exploit the concept of communication-compute-control
co-design by introducing awareness of communication and compute characteristics
into the application logic in different ways to improve overall system
performance. We have implemented a closed-loop control of a robotic arm over a
wireless network where the controller is deployed into an edge cloud
environment. When implementing an industrial system that leverages network and
cloud technologies, the level of determinism of the control application can be
decreased by nature. This means that some imperfections may be introduced into
the control system, and the closed-loop control in substance changes to
open-loop during disturbances. We aim to improve the performance of these
open-loop control periods by applying methods that can compensate for the
imperfections statistically or in a guaranteed way. We demonstrate that
co-design-based application improvements with minimal dependencies on the
underlying technologies can already yield an order of magnitude gain when it
comes to the accurate execution of the robot trajectories during the openloop
control periods. Furthermore, by combining the proposed methods, the
performance improvements add up and can produce up to 45% shorter trajectory
executions compared to individual evaluations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Coordinated Trajectories for Non-stop Flying Carriers Holding a
  Cable-Suspended Load 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03481v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03481v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chiara Gabellieri, Antonio Franchi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multirotor UAVs have been typically considered for aerial manipulation, but
their scarce endurance prevents long-lasting manipulation tasks. This work
demonstrates that the non-stop flights of three or more carriers are compatible
with holding a constant pose of a cable-suspended load, thus potentially
enabling aerial manipulation with energy-efficient non-stop carriers. It also
presents an algorithm for generating the coordinated non-stop trajectories. The
proposed method builds upon two pillars: (1)~the choice of $n$ special linearly
independent directions of internal forces within the $3n-6$-dimensional
nullspace of the grasp matrix of the load, chosen as the edges of a Hamiltonian
cycle on the graph that connects the cable attachment points on the load.
Adjacent pairs of directions are used to generate $n$ forces evolving on
distinct 2D affine subspaces, despite the attachment points being generically
in 3D; (2)~the construction of elliptical trajectories within these subspaces
by mapping, through appropriate graph coloring, each edge of the Hamiltonian
cycle to a periodic coordinate while ensuring that no adjacent coordinates
exhibit simultaneous zero derivatives. Combined with conditions for load
statics and attachment point positions, these choices ensure that each of the
$n$ force trajectories projects onto the corresponding cable constraint sphere
with non-zero tangential velocity, enabling perpetual motion of the carriers
while the load is still. The theoretical findings are validated through
simulations and laboratory experiments with non-stopping multirotor UAVs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Novel Multi-Criteria Local Latin Hypercube Refinement System for
  Commutation Angle Improvement in IPMSMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03372v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03372v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pedram Asef, Mouloud Denai, Johannes J. H. Paulides, Bruno Ricardo Marques, Andrew Lapthorn
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The commutation angle is defined as the angle between the fundamental of the
motor phase current and the fundamental of the back-EMF. It can be utilised to
provide a compensating effect in IPMSMs. This is due to the reluctance torque
component being dependent on the commutation angle of the phase current even
before entering the extended speed range. A real-time maximum torque per
current and voltage strategy is demonstrated to find the trajectory and optimum
commutation angles, gamma, where the level of accuracy depends on the
application and available computational speed. A magnet volume reduction using
a novel multi-criteria local Latin hypercube refinement (MLHR) sampling system
is also presented to improve the optimisation process. The proposed new
technique minimises the magnet mass to motor torque density whilst maintaining
a similar phase current level. A mapping of gamma allows the determination of
the optimum angles, as shown in this paper. The 3rd generation Toyota Prius
IPMSM is considered as the reference motor, where the rotor configuration is
altered to allow for an individual assessment.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Controlled Invariance in Fully Actuated Max-plus Linear Systems with
  Precedence Semimodules 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03357v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03357v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Davide Zorzenon, Jörg Raisch
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Given a max-plus linear system and a semimodule, the problem of computing the
maximal controlled invariant subsemimodule is still open to this day. In this
paper, we consider this problem for the specific class of fully actuated
systems and constraints in the form of precedence semimodules. The assumption
of full actuation corresponds to the existence of an input for each component
of the system state. A precedence semimodule is the set of solutions of
inequalities typically used to represent time-window constraints. We prove
that, in this setting, it is possible to (i) compute the maximal controlled
invariant subsemimodule and (ii) decide the convergence of a fixed-point
algorithm introduced by R.D. Katz in strongly polynomial time.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Human-In-The-Loop Simulation Framework for Evaluating Control
  Strategies in Gait Assistive Robots 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.05825v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.05825v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yifan Wang, Sherwin Stephen Chan, Mingyuan Lei, Lek Syn Lim, Henry Johan, Bingran Zuo, Wei Tech Ang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As the global population ages, effective rehabilitation and mobility aids
will become increasingly critical. Gait assistive robots are promising
solutions, but designing adaptable controllers for various impairments poses a
significant challenge. This paper presented a Human-In-The-Loop (HITL)
simulation framework tailored specifically for gait assistive robots,
addressing unique challenges posed by passive support systems. We incorporated
a realistic physical human-robot interaction (pHRI) model to enable a
quantitative evaluation of robot control strategies, highlighting the
performance of a speed-adaptive controller compared to a conventional PID
controller in maintaining compliance and reducing gait distortion. We assessed
the accuracy of the simulated interactions against that of the real-world data
and revealed discrepancies in the adaptation strategies taken by the human and
their effect on the human's gait. This work underscored the potential of HITL
simulation as a versatile tool for developing and fine-tuning personalized
control policies for various users.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Composite Nonlinear Trajectory Tracking Control of Co-Driving Vehicles
  Using Self-Triggered Adaptive Dynamic Programming 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03348v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03348v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chuan Hu, Sicheng Ge, Yingkui Shi, Weinan Gao, Wenfeng Guo, Xi Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This article presents a composite nonlinear feedback (CNF) control method
using self-triggered (ST) adaptive dynamic programming (ADP) algorithm in a
human-machine shared steering framework. For the overall system dynamics, a
two-degrees-of-freedom (2-DOF) vehicle model is established and a two-point
preview driver model is adopted. A dynamic authority allocation strategy based
on cooperation level is proposed to combine the steering input of the human
driver and the automatic controller. To make further improvements in the
controller design, three main contributions are put forward. Firstly, the CNF
controller is designed for trajectory tracking control with refined transient
performance. Besides, the self-triggered rule is applied such that the system
will update in discrete times to save computing resources and increase
efficiency. Moreover, by introducing the data-based ADP algorithm, the optimal
control problem can be solved through iteration using system input and output
information, reducing the need for accurate knowledge of system dynamics. The
effectiveness of the proposed control method is validated through
Carsim-Simulink co-simulations in diverse driving scenarios.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by IEEE Transactions on Consumer Electronics (12 pages)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SEAL: Safety Enhanced Trajectory <span class="highlight-title">Plan</span>ning and Control Framework for
  Quadrotor Flight in Complex Environments 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03346v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03346v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yiming Wang, Jianbin Ma, Junda Wu, Huizhe Li, Zhexuan Zhou, Youmin Gong, Jie Mei, Guangfu Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  For quadrotors, achieving safe and autonomous flight in complex environments
with wind disturbances and dynamic obstacles still faces significant
challenges. Most existing methods address wind disturbances in either
trajectory planning or control, which may lead to hazardous situations during
flight. The emergence of dynamic obstacles would further worsen the situation.
Therefore, we propose an efficient and reliable framework for quadrotors that
incorporates wind disturbance estimations during both the planning and control
phases via a generalized proportional integral observer. First, we develop a
real-time adaptive spatial-temporal trajectory planner that utilizes
Hamilton-Jacobi (HJ) reachability analysis for error dynamics resulting from
wind disturbances. By considering the forward reachability sets propagation on
an Euclidean Signed Distance Field (ESDF) map, safety is guaranteed.
Additionally, a Nonlinear Model Predictive Control (NMPC) controller
considering wind disturbance compensation is implemented for robust trajectory
tracking. Simulation and real-world experiments verify the effectiveness of our
framework. The video and supplementary material will be available at
https://github.com/Ma29-HIT/SEAL/.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Safety Verification of Nonlinear Stochastic Systems via Probabilistic
  Tube 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03328v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03328v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zishun Liu, Saber Jafarpour, Yongxin Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We address the problem of safety verification for nonlinear stochastic
systems, specifically the task of certifying that system trajectories remain
within a safe set with high probability. To tackle this challenge, we adopt a
set-erosion strategy, which decouples the effects of stochastic disturbances
from deterministic dynamics. This approach converts the stochastic safety
verification problem on a safe set into a deterministic safety verification
problem on an eroded subset of the safe set. The success of this strategy
hinges on the depth of erosion, which is determined by a probabilistic tube
that bounds the deviation of stochastic trajectories from their corresponding
deterministic trajectories. Our main contribution is the establishment of a
tight bound for the probabilistic tube of nonlinear stochastic systems. To
obtain a probabilistic bound for stochastic trajectories, we adopt a
martingale-based approach. The core innovation lies in the design of a novel
energy function associated with the averaged moment generating function, which
forms an affine martingale, a generalization of the traditional c-martingale.
Using this energy function, we derive a precise bound for the probabilistic
tube. Furthermore, we enhance this bound by incorporating the union-bound
inequality for strictly contractive dynamics. By integrating the derived
probabilistic tubes into the set-erosion strategy, we demonstrate that the
safety verification problem for nonlinear stochastic systems can be reduced to
a deterministic safety verification problem. Our theoretical results are
validated through applications in reachability-based safety verification and
safe controller synthesis, accompanied by several numerical examples that
illustrate their effectiveness.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Introduction to Online Control 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2211.09619v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2211.09619v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Elad Hazan, Karan Singh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This text presents an introduction to an emerging paradigm in control of
dynamical systems and differentiable reinforcement learning called online
nonstochastic control. The new approach applies techniques from online convex
optimization and convex relaxations to obtain new methods with provable
guarantees for classical settings in optimal and robust control.
  The primary distinction between online nonstochastic control and other
frameworks is the objective. In optimal control, robust control, and other
control methodologies that assume stochastic noise, the goal is to perform
comparably to an offline optimal strategy. In online nonstochastic control,
both the cost functions as well as the perturbations from the assumed dynamical
model are chosen by an adversary. Thus the optimal policy is not defined a
priori. Rather, the target is to attain low regret against the best policy in
hindsight from a benchmark class of policies.
  This objective suggests the use of the decision making framework of online
convex optimization as an algorithmic methodology. The resulting methods are
based on iterative mathematical optimization algorithms, and are accompanied by
finite-time regret and computational complexity guarantees.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Draft; comments/suggestions welcome at
  nonstochastic.control@gmail.com</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Dynamic Scheduling of a Multiclass Queue in the Halfin-Whitt Regime: A
  Computational Approach for High-Dimensional Problems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.18128v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.18128v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Baris Ata, Ebru Kasikaralar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We consider a multi-class queueing model of a telephone call center, in which
a system manager dynamically allocates available servers to customer calls.
Calls can terminate through either service completion or customer abandonment,
and the manager strives to minimize the expected total of holding costs plus
abandonment costs over a finite horizon. Focusing on the Halfin-Whitt heavy
traffic regime, we derive an approximating diffusion control problem, and
building on earlier work by Beck et al. (2021), develop a simulation-based
computational method for solution of such problems, one that relies heavily on
deep neural network technology. Using this computational method, we propose a
policy for the original (pre-limit) call center scheduling problem. Finally,
the performance of this policy is assessed using test problems based on
publicly available call center data. For the test problems considered so far,
our policy does as well as or better than the best benchmark we could find.
Moreover, our method is computationally feasible at least up to dimension 500,
that is, for call centers with 500 or more distinct customer classes.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ From Data to Predictive Control: A Framework for Stochastic Linear
  Systems with Output Measurements 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.17277v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.17277v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haldun Balim, Andrea Carron, Melanie N. Zeilinger, Johannes Köhler
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce data to predictive control, D2PC, a framework to facilitate the
design of robust and predictive controllers from data. The proposed framework
is designed for discrete-time stochastic linear systems with output
measurements and provides a principled design of a predictive controller based
on data. The framework starts with a parameter identification method based on
the Expectation-Maximization algorithm, which incorporates pre-defined
structural constraints. Additionally, we provide an asymptotically correct
method to quantify uncertainty in parameter estimates. Next, we develop a
strategy to synthesize robust dynamic output-feedback controllers tailored to
the derived uncertainty characterization. Finally, we introduce a predictive
control scheme that guarantees recursive feasibility and satisfaction of chance
constraints. This framework marks a significant advancement in integrating data
into robust and predictive control schemes. We demonstrate the efficacy of D2PC
through a numerical example involving a 10-dimensional spring-mass-damper
system.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Code link: https://github.com/haldunbalim/D2PC</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Adapting Gait Frequency for Posture-regulating Humanoid Push-recovery
  via Hierarchical <span class="highlight-title">Model Predictive</span> Control <span class="chip">ICRA 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.14342v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.14342v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junheng Li, Zhanhao Le, Junchao Ma, Quan Nguyen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Current humanoid push-recovery strategies often use whole-body motion, yet
they tend to overlook posture regulation. For instance, in manipulation tasks,
the upper body may need to stay upright and have minimal recovery displacement.
This paper introduces a novel approach to enhancing humanoid push-recovery
performance under unknown disturbances and regulating body posture by tailoring
the recovery stepping strategy. We propose a hierarchical-MPC-based scheme that
analyzes and detects instability in the prediction window and quickly recovers
through adapting gait frequency. Our approach integrates a high-level nonlinear
MPC, a posture-aware gait frequency adaptation planner, and a low-level convex
locomotion MPC. The planners predict the center of mass (CoM) state
trajectories that can be assessed for precursors of potential instability and
posture deviation. In simulation, we demonstrate improved maximum recoverable
impulse by 131% on average compared with baseline approaches. In hardware
experiments, a 125 ms advancement in recovery stepping timing/reflex has been
observed with the proposed approach. We also demonstrate improved push-recovery
performance and minimized body attitude change under 0.2 rad.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>7 pages, 6 figures, accepted to ICRA 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Controller Synthesis of Collaborative Signal Temporal Logic Tasks for
  Multi-Agent Systems via Assume-Guarantee Contracts 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2309.13499v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2309.13499v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Siyuan Liu, Adnane Saoud, Dimos V. Dimarogonas
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper considers the problem of controller synthesis of signal temporal
logic (STL) specifications for large-scale multi-agent systems, where the
agents are dynamically coupled and subject to collaborative tasks. A
compositional framework based on continuous-time assume-guarantee contracts is
developed to break the complex and large synthesis problem into subproblems of
manageable sizes. We first show how to formulate the collaborative STL tasks as
assume-guarantee contracts by leveraging the idea of funnel-based control. The
concept of contracts is used to establish our compositionality result, which
allows us to guarantee the satisfaction of a global contract by the multi-agent
system when all agents satisfy their local contracts. Then, a closed-form
continuous-time feedback controller is designed to enforce local contracts over
the agents in a distributed manner, which further guarantees the global task
satisfaction based on the compositionality result. Finally, the effectiveness
of our results is demonstrated by two numerical examples.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>arXiv admin note: substantial text overlap with arXiv:2203.10041</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Parameter-Dependent Control Lyapunov Functions for Stabilizing Nonlinear
  Parameter-Varying Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.06770v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.06770v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pan Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces the concept of parameter-dependent (PD) control
Lyapunov functions (CLFs) for gain-scheduled stabilization of nonlinear
parameter-varying (NPV) systems. It shows that given a PD-CLF, a min-norm
control law can be constructed by solving a robust quadratic program. For
polynomial control-affine NPV systems, it provides convex conditions, based on
the sum of squares programming, to jointly synthesize a PD-CLF and a PD
controller while maximizing the PD region of stabilization. Input constraints
can be straightforwardly incorporated into the synthesis procedure. Unlike
traditional linear parameter-varying (LPV) methods that rely on linearization
or over-approximation to get an LPV model, the proposed framework fully
captures the nonlinearities of the system dynamics. The theoretical results are
validated through numerical simulations, including a 2D rocket landing case
study under varying mass and inertia.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DMVC-Tracker: Distributed Multi-Agent Trajectory <span class="highlight-title">Plan</span>ning for Target
  Tracking Using Dynamic Buffered Voronoi and Inter-Visibility Cells 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.18086v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.18086v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yunwoo Lee, Jungwon Park, H. Jin Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This letter presents a distributed trajectory planning method for multi-agent
aerial tracking. The proposed method uses a Dynamic Buffered Voronoi Cell
(DBVC) and a Dynamic Inter-Visibility Cell (DIVC) to formulate the distributed
trajectory generation. Specifically, the DBVC and the DIVC are time-variant
spaces that prevent mutual collisions and occlusions among agents, while
enabling them to maintain suitable distances from the moving target. We combine
the DBVC and the DIVC with an efficient Bernstein polynomial motion
primitive-based tracking generation method, which has been refined into a less
conservative approach than in our previous work. The proposed algorithm can
compute each agent's trajectory within several milliseconds on an Intel i7
desktop. We validate the tracking performance in challenging scenarios,
including environments with dozens of obstacles.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Efficient pseudometrics for data-driven comparisons of nonlinear
  dynamical systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.18681v6">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.18681v6.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bryan Glaz
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Computationally efficient solutions for pseudometrics quantifying deviation
from topological conjugacy between dynamical systems are presented. Deviation
from conjugacy is quantified in a Pareto optimal sense that accounts for
spectral properties of Koopman operators as well as trajectory geometry.
Theoretical justification is provided for computing such pseudometrics in
Koopman eigenfunction space rather than observable space. Furthermore, it is
shown that theoretical consistency with topological conjugacy can be maintained
when restricting the search for optimal transformations between systems to the
unitary group. Therefore the pseudometrics are based on analytical solutions
for unitary transformations in Koopman eigenfunction space. Geometric
considerations for the deviation from conjugacy Pareto optimality problem are
used to develop scalar pseudometrics that account for all possible optimal
solutions given just two Pareto points. The approach is demonstrated on two
example problems; the first being a simple benchmarking problem and the second
an engineering example comparing the dynamics of morphological computation of
biological nonlinear muscle actuators to simplified mad-made (including
bioinspired) approaches. The benefits of considering operator and trajectory
geometry based dissimilarity measures in a unified and consistent formalism is
demonstrated. Overall, the deviation from conjugacy pseudometrics provide
practical advantages in terms of efficiency and scalability, while maintaining
theoretical consistency.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Appropriate preprint version, including correct equation for d_avg
  that matches the geometry of Fig 1</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Structured Input-Output Modeling and Robust Stability Analysis of
  Compressible Flows 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.14986v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.14986v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Diganta Bhattacharjee, Talha Mushtaq, Peter Seiler, Maziar S. Hemati
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The recently introduced structured input-output analysis is a powerful method
for capturing nonlinear phenomena associated with incompressible flows, and
this paper extends that method to the compressible regime. The proposed method
relies upon a reformulation of the compressible Navier-Stokes equations, which
allows for an exact quadratic formulation of the dynamics of perturbations
about a steady base flow. To facilitate the structured input-output analysis, a
pseudo-linear model for the quadratic nonlinearity is proposed and the
structural information of the nonlinearity is embedded into a structured
uncertainty comprising unknown `perturbations'. The structured singular value
framework is employed to compute the input-output gain, which provides an
estimate of the robust stability margin of the flow perturbations, as well as
the forcing and response modes that are consistent with the nonlinearity
structure. The analysis is then carried out on a plane, laminar compressible
Couette flow over a range of Mach numbers. The structured input-output gains
identify an instability mechanism, characterized by a spanwise elongated
structure in the streamwise-spanwise wavenumber space at a subsonic Mach
number, that takes the form of an oblique structure at sonic and supersonic
Mach numbers. In addition, the structured input-output forcing and response
modes provide insight into the thermodynamic and momentum characteristics
associated with a source of instability. Comparisons with a
resolvent/unstructured analysis reveal discrepancies in the distribution of
input-output gains over the wavenumber space as well as in the modal behavior
of an instability, thus highlighting the strong correlation between the
structural information of the nonlinearity and the underlying flow physics.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under Review in Journal of Fluid Mechanics</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ TAG: A Decentralized Framework for Multi-Agent Hierarchical
  Reinforcement Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.15425v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.15425v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Giuseppe Paolo, Abdelhakim Benechehab, Hamza Cherkaoui, Albert Thomas, Balázs Kégl
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Hierarchical organization is fundamental to biological systems and human
societies, yet artificial intelligence systems often rely on monolithic
architectures that limit adaptability and scalability. Current hierarchical
reinforcement learning (HRL) approaches typically restrict hierarchies to two
levels or require centralized training, which limits their practical
applicability. We introduce TAME Agent Framework (TAG), a framework for
constructing fully decentralized hierarchical multi-agent systems. TAG enables
hierarchies of arbitrary depth through a novel LevelEnv concept, which
abstracts each hierarchy level as the environment for the agents above it. This
approach standardizes information flow between levels while preserving loose
coupling, allowing for seamless integration of diverse agent types. We
demonstrate the effectiveness of TAG by implementing hierarchical architectures
that combine different RL agents across multiple levels, achieving improved
performance over classical multi-agent RL baselines on standard benchmarks. Our
results show that decentralized hierarchical organization enhances both
learning speed and final performance, positioning TAG as a promising direction
for scalable multi-agent systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Distributed <span class="highlight-title">Optimization</span> by Network Flows with Spatio-Temporal
  Compression 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.00002v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.00002v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zihao Ren, Lei Wang, Xinlei Yi, Xi Wang, Deming Yuan, Tao Yang, Zhengguang Wu, Guodong Shi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Several data compressors have been proposed in distributed optimization
frameworks of network systems to reduce communication overhead in large-scale
applications. In this paper, we demonstrate that effective information
compression may occur over time or space during sequences of node
communications in distributed algorithms, leading to the concept of
spatio-temporal compressors. This abstraction classifies existing compressors
as spatio-temporal compressors, with their effectiveness described by
constructive stability criteria from nonlinear system theory. Subsequently, we
apply these spatio-temporal compressors to standard continuous-time consensus
flows and distributed prime-dual flows, establishing conditions ensuring
convergence. Additionally, we introduce a novel observer-based distributed
primal-dual continuous flow integrated with spatio-temporal compressors, which
provides broader convergence conditions. These continuous flows achieve
exponential convergence to the global optimum when the objective function is
strongly convex and can be discretized using Euler approximations. Finally,
numerical simulations illustrate the versatility of the proposed
spatio-temporal compressors and verify the convergence of algorithms.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>arXiv admin note: text overlap with arXiv:2408.02332</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Optimization and Control <span class="chip" style="font-size: 60%">15</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Kantorovich duality for optimal transport on completely regular
  Hausdorff spaces 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03929v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03929v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohammed Bachir
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Given two completely regular Hausdorff spaces $X$ and $Y$, two tight Baire
measures $\mu$ and $\nu$ on $X$ and $Y$ respectively and a cost $c: X\times
Y\to \R$ bounded continuous such that the family $\{c(\cdot,y): y\in Y\}$
(resp. $\{c(x,\cdot): x\in X\}$) is equicontinuous, it is shown that the
Kantorovich primal and dual problems, both have solutions and realize the same
value. This extends results known on Polish spaces to the more general class of
completely regular Hausdorff spaces.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On the Convergence of Adam-Type Algorithm for Bilevel <span class="highlight-title">Optimization</span> under
  Unbounded Smoothness 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03908v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03908v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaochuan Gong, Jie Hao, Mingrui Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Adam has become one of the most popular optimizers for training modern deep
neural networks, such as transformers. However, its applicability is largely
restricted to single-level optimization problems. In this paper, we aim to
extend vanilla Adam to tackle bilevel optimization problems, which have
important applications in machine learning, such as meta-learning. In
particular, we study stochastic bilevel optimization problems where the
lower-level function is strongly convex and the upper-level objective is
nonconvex with potentially unbounded smoothness. This unbounded smooth
objective function covers a broad class of neural networks, including
transformers, which may exhibit non-Lipschitz gradients. In this work, we
introduce AdamBO, a single-loop Adam-type method that achieves
$\widetilde{O}(\epsilon^{-4})$ oracle complexity to find $\epsilon$-stationary
points, where the oracle calls involve stochastic gradient or
Hessian/Jacobian-vector product evaluations. The key to our analysis is a novel
randomness decoupling lemma that provides refined control over the lower-level
variable. We conduct extensive experiments on various machine learning tasks
involving bilevel formulations with recurrent neural networks (RNNs) and
transformers, demonstrating the effectiveness of our proposed Adam-type
algorithm.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>49 pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Endpoint-Explicit Differential Dynamic Programming via Exact Resolution <span class="chip">ICRA</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03897v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03897v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Maria Parilli, Sergi Martinez, Carlos Mastalli
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce a novel method for handling endpoint constraints in constrained
differential dynamic programming (DDP). Unlike existing approaches, our method
guarantees quadratic convergence and is exact, effectively managing rank
deficiencies in both endpoint and stagewise equality constraints. It is
applicable to both forward and inverse dynamics formulations, making it
particularly well-suited for model predictive control (MPC) applications and
for accelerating optimal control (OC) solvers. We demonstrate the efficacy of
our approach across a broad range of robotics problems and provide a
user-friendly open-source implementation within CROCODDYL.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>7 pages, IEEE ICRA paper</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On Optimal Control of Hybrid Dynamical Systems using Complementarity
  Constraints 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03879v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03879v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Saif R. Kazi, Kexin Wang, Lorenz T. Biegler
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Optimal control for switch-based dynamical systems is a challenging problem
in the process control literature. In this study, we model these systems as
hybrid dynamical systems with finite number of unknown switching points and
reformulate them using non-smooth and non-convex complementarity constraints as
a mathematical program with complementarity constraints (MPCC). We utilize a
moving finite element based strategy to discretize the differential equation
system to accurately locate the unknown switching points at the finite element
boundary and achieve high-order accuracy at intermediate non-collocation
points. We propose a globalization approach to solve the discretized MPCC
problem using a mixed NLP/MILP-based strategy to converge to a non-spurious
first-order optimal solution. The method is tested on three dynamic
optimization examples, including a gas-liquid tank model and an optimal control
problem with a sliding mode solution.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to Journal of Process Control</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Deterministic Global <span class="highlight-title">Optimization</span> of the Acquisition Function in
  Bayesian <span class="highlight-title">Optimization</span>: To Do or Not To Do? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03625v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03625v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anastasia Georgiou, Daniel Jungen, Luise Kaven, Verena Hunstig, Constantine Frangakis, Ioannis Kevrekidis, Alexander Mitsos
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Bayesian Optimization (BO) with Gaussian Processes relies on optimizing an
acquisition function to determine sampling. We investigate the advantages and
disadvantages of using a deterministic global solver (MAiNGO) compared to
conventional local and stochastic global solvers (L-BFGS-B and multi-start,
respectively) for the optimization of the acquisition function. For CPU
efficiency, we set a time limit for MAiNGO, taking the best point as optimal.
We perform repeated numerical experiments, initially using the Muller-Brown
potential as a benchmark function, utilizing the lower confidence bound
acquisition function; we further validate our findings with three alternative
benchmark functions. Statistical analysis reveals that when the acquisition
function is more exploitative (as opposed to exploratory), BO with MAiNGO
converges in fewer iterations than with the local solvers. However, when the
dataset lacks diversity, or when the acquisition function is overly
exploitative, BO with MAiNGO, compared to the local solvers, is more likely to
converge to a local rather than a global ly near-optimal solution of the
black-box function. L-BFGS-B and multi-start mitigate this risk in BO by
introducing stochasticity in the selection of the next sampling point, which
enhances the exploration of uncharted regions in the search space and reduces
dependence on acquisition function hyperparameters. Ultimately, suboptimal
optimization of poorly chosen acquisition functions may be preferable to their
optimal solution. When the acquisition function is more exploratory, BO with
MAiNGO, multi-start, and L-BFGS-B achieve comparable probabilities of
convergence to a globally near-optimal solution (although BO with MAiNGO may
require more iterations to converge under these conditions).
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>32 pages, 7 figures, 7 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Carleman estimate for semi-discrete stochastic parabolic operators in
  arbitrary dimension and applications to controllability 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.03596v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.03596v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rodrigo Lecaros, Ariel A. Pérez, Manuel F. Prado
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper considers a semi-discrete forward stochastic parabolic operator
with homogeneous Dirichlet conditions in arbitrary dimensions. We show the lack
of null controllability for a spatial semi-discretization of a
null-controllable stochastic parabolic system from any initial datum. However,
by proving a new Carleman estimate for its semi-discrete backward stochastic
adjoint system, we achieve a relaxed observability inequality, which is applied
to derivative $\phi$-null controllability by duality arguments.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Introduction to Online Control 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2211.09619v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2211.09619v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Elad Hazan, Karan Singh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This text presents an introduction to an emerging paradigm in control of
dynamical systems and differentiable reinforcement learning called online
nonstochastic control. The new approach applies techniques from online convex
optimization and convex relaxations to obtain new methods with provable
guarantees for classical settings in optimal and robust control.
  The primary distinction between online nonstochastic control and other
frameworks is the objective. In optimal control, robust control, and other
control methodologies that assume stochastic noise, the goal is to perform
comparably to an offline optimal strategy. In online nonstochastic control,
both the cost functions as well as the perturbations from the assumed dynamical
model are chosen by an adversary. Thus the optimal policy is not defined a
priori. Rather, the target is to attain low regret against the best policy in
hindsight from a benchmark class of policies.
  This objective suggests the use of the decision making framework of online
convex optimization as an algorithmic methodology. The resulting methods are
based on iterative mathematical optimization algorithms, and are accompanied by
finite-time regret and computational complexity guarantees.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Draft; comments/suggestions welcome at
  nonstochastic.control@gmail.com</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Dynamic Scheduling of a Multiclass Queue in the Halfin-Whitt Regime: A
  Computational Approach for High-Dimensional Problems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.18128v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.18128v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Baris Ata, Ebru Kasikaralar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We consider a multi-class queueing model of a telephone call center, in which
a system manager dynamically allocates available servers to customer calls.
Calls can terminate through either service completion or customer abandonment,
and the manager strives to minimize the expected total of holding costs plus
abandonment costs over a finite horizon. Focusing on the Halfin-Whitt heavy
traffic regime, we derive an approximating diffusion control problem, and
building on earlier work by Beck et al. (2021), develop a simulation-based
computational method for solution of such problems, one that relies heavily on
deep neural network technology. Using this computational method, we propose a
policy for the original (pre-limit) call center scheduling problem. Finally,
the performance of this policy is assessed using test problems based on
publicly available call center data. For the test problems considered so far,
our policy does as well as or better than the best benchmark we could find.
Moreover, our method is computationally feasible at least up to dimension 500,
that is, for call centers with 500 or more distinct customer classes.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ From Data to Predictive Control: A Framework for Stochastic Linear
  Systems with Output Measurements 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.17277v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.17277v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haldun Balim, Andrea Carron, Melanie N. Zeilinger, Johannes Köhler
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce data to predictive control, D2PC, a framework to facilitate the
design of robust and predictive controllers from data. The proposed framework
is designed for discrete-time stochastic linear systems with output
measurements and provides a principled design of a predictive controller based
on data. The framework starts with a parameter identification method based on
the Expectation-Maximization algorithm, which incorporates pre-defined
structural constraints. Additionally, we provide an asymptotically correct
method to quantify uncertainty in parameter estimates. Next, we develop a
strategy to synthesize robust dynamic output-feedback controllers tailored to
the derived uncertainty characterization. Finally, we introduce a predictive
control scheme that guarantees recursive feasibility and satisfaction of chance
constraints. This framework marks a significant advancement in integrating data
into robust and predictive control schemes. We demonstrate the efficacy of D2PC
through a numerical example involving a 10-dimensional spring-mass-damper
system.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Code link: https://github.com/haldunbalim/D2PC</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Local minimizers in $3$d of vector Allen-Cahn with a quadruple junction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.17687v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.17687v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Abhishek Adimurthi, Peter Sternberg
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  For $\Omega$ a perturbation of the unit ball in $\mathbb{R}^3$, we establish
the existence of a sequence of local minimizers for the vector Allen-Cahn
energy. The sequence converges in $L^1$ to a partition of $\Omega$ whose
skeleton is given by a tetrahedral cone and thus contains a quadruple point.
This is accomplished by proving that the partition is an isolated local
minimizer of a weighted perimeter problem arising as the associated
$\Gamma$-limit of the sequence of Allen-Cahn functionals.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>27 pages, 2 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Two-person Positive Shortest Path Games Have Nash Equilibria in Pure
  Stationary Strategies 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.09257v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.09257v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Endre Boros, Khaled Elbassioni, Vladimir Gurvich, Mikhail Vyalyi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We prove that every finite two-person shortest path game, where the local
cost of every move is positive for each player, has a Nash equilibrium (NE) in
pure stationary strategies, which can be computed in polynomial time. We also
extend the existence result to infinite graphs with finite out-degrees.
Moreover, our proof gives that a terminal NE (in which the play is a path from
the initial position to a terminal) exists provided at least one of the two
players can guarantee reaching a terminal. If none of the players can do it, in
other words, if each of the two players has a strategy that separates all
terminals from the initial position $s$, then, obviously, a cyclic NE exists,
although its cost is infinite for both players, since we restrict ourselves to
positive games. We conjecture that a terminal NE exists too, provided there
exists a directed path from $s$ to a terminal. However, this is open.
  We extend our result to short paths interdiction games, where at each vertex,
we allow one player to block some of the arcs and the other player to choose
one of the non-blocked arcs. Assuming that blocking sets are chosen from an
independence system given by an oracle, we give an algorithm for computing a NE
in time $O(|E|(\log|V|+\tau))$, where $V$ is the set of vertices, $E$ is the
set of arcs, and $\tau$ is the maximum time taken by the oracle on any input.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ HiGrad: Uncertainty Quantification for Online Learning and Stochastic
  Approximation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/1802.04876v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/1802.04876v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Weijie J. Su, Yuancheng Zhu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Stochastic gradient descent (SGD) is an immensely popular approach for online
learning in settings where data arrives in a stream or data sizes are very
large. However, despite an ever-increasing volume of work on SGD, much less is
known about the statistical inferential properties of SGD-based predictions.
Taking a fully inferential viewpoint, this paper introduces a novel procedure
termed HiGrad to conduct statistical inference for online learning, without
incurring additional computational cost compared with SGD. The HiGrad procedure
begins by performing SGD updates for a while and then splits the single thread
into several threads, and this procedure hierarchically operates in this
fashion along each thread. With predictions provided by multiple threads in
place, a $t$-based confidence interval is constructed by decorrelating
predictions using covariance structures given by a Donsker-style extension of
the Ruppert--Polyak averaging scheme, which is a technical contribution of
independent interest. Under certain regularity conditions, the HiGrad
confidence interval is shown to attain asymptotically exact coverage
probability. Finally, the performance of HiGrad is evaluated through extensive
simulation studies and a real data example. An R package \texttt{higrad} has
been developed to implement the method.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Appeared in JMLR</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Parameter-Dependent Control Lyapunov Functions for Stabilizing Nonlinear
  Parameter-Varying Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.06770v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.06770v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pan Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces the concept of parameter-dependent (PD) control
Lyapunov functions (CLFs) for gain-scheduled stabilization of nonlinear
parameter-varying (NPV) systems. It shows that given a PD-CLF, a min-norm
control law can be constructed by solving a robust quadratic program. For
polynomial control-affine NPV systems, it provides convex conditions, based on
the sum of squares programming, to jointly synthesize a PD-CLF and a PD
controller while maximizing the PD region of stabilization. Input constraints
can be straightforwardly incorporated into the synthesis procedure. Unlike
traditional linear parameter-varying (LPV) methods that rely on linearization
or over-approximation to get an LPV model, the proposed framework fully
captures the nonlinearities of the system dynamics. The theoretical results are
validated through numerical simulations, including a 2D rocket landing case
study under varying mass and inertia.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Reusing Historical Trajectories in Natural Policy Gradient via
  Importance Sampling: Convergence and Convergence Rate 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.00675v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.00675v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yifan Lin, Yuhao Wang, Enlu Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reinforcement learning provides a mathematical framework for learning-based
control, whose success largely depends on the amount of data it can utilize.
The efficient utilization of historical trajectories obtained from previous
policies is essential for expediting policy optimization. Empirical evidence
has shown that policy gradient methods based on importance sampling work well.
However, existing literature often neglect the interdependence between
trajectories from different iterations, and the good empirical performance
lacks a rigorous theoretical justification. In this paper, we study a variant
of the natural policy gradient method with reusing historical trajectories via
importance sampling. We show that the bias of the proposed estimator of the
gradient is asymptotically negligible, the resultant algorithm is convergent,
and reusing past trajectories helps improve the convergence rate. We further
apply the proposed estimator to popular policy optimization algorithms such as
trust region policy optimization. Our theoretical results are verified on
classical benchmarks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MDP Geometry, Normalization and Reward Balancing Solvers 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.06712v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.06712v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Arsenii Mustafin, Aleksei Pakharev, Alex Olshevsky, Ioannis Ch. Paschalidis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a new geometric interpretation of Markov Decision Processes (MDPs)
with a natural normalization procedure that allows us to adjust the value
function at each state without altering the advantage of any action with
respect to any policy. This advantage-preserving transformation of the MDP
motivates a class of algorithms which we call Reward Balancing, which solve
MDPs by iterating through these transformations, until an approximately optimal
policy can be trivially found. We provide a convergence analysis of several
algorithms in this class, in particular showing that for MDPs for unknown
transition probabilities we can improve upon state-of-the-art sample complexity
results.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>AISTATS 2025 camera-ready version</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>

</body>

<footer>
    <div>
        <time id="build-timestamp" datetime="2025-03-15T05:29:09.021505494Z">
            2025-03-15 05:29:09 UTC
        </time>
    </div>
</footer>
<script src="index.js"></script>
</html>
